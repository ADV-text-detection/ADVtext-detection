index_article,index_paragraph,content,label
1,1,"Neurogenesis is a regulated process that maintains the complex structure of the central nervous system. In adults, neurogenesis is a form of neural plasticity as it continuously generates new neurons from neural stem cells. This process involves several steps, including proliferation, restriction of precursors to neuronal lineages, cell cycle exit, migration and integration into target areas, differentiation, as well as morphological and functional maturation. At the end of this process, newly generated cells become functionally active neurons. These cells can be identified by their expression of doublecortin (DCX), which is mainly detected in the adult dentate gyrus of the hippocampus and in the subventricular zone/rostral migration stream/olfactory bulb axis. Transgenic mice have been generated to monitor neurogenesis in vitro and in vivo by driving reporter genes with the DCX promoter.",0
1,2,"The need to better understand adult neurogenesis at the molecular and cellular levels in order to develop therapeutic strategies for pathological neuronal losses has been emphasized. There is also accumulating evidence that abnormal neurogenesis could play a role in neuropsychiatric disorders. Various models have been created over the years, such as transgenic models utilizing cell-type specific promoters (nestin, GLAST, PLP, DCX) to research the biology of neural stem cells, radial glia, oligodendroglial precursors and neuronal precursors. However, these reporter mice have limitations for long-term studies such as fate tracing or assessing the long-term functional integration of newly generated neurons. For instance, the DCX reporter mice are not suitable for fate mapping studies in regions such as the SVZ/OB axis or the dentate gyrus since DCX expression is temporary (mostly less than 1 month in rodents).",0
1,3,"To solve the issue of lacking a proper tool for studying neuronal precursor fate, we created transgenic mice that have the CreERT2 recombinase gene controlled by the DCX promoter and can be induced by tamoxifen. We show that this new transgenic tool enables the labeling of newly-formed neurons and tracking of their fate over a long period. Additionally, it allows for the regulation of gene expression during an important period of neuronal development and the analysis of the functional impact of such regulation.",0
1,4,"The CreERT2 cDNA from the 2380-bp Sal I-Not I fragment of pCAG-CreERT2bpA-SS1 vector was subcloned into the BamH I and Not I site of the phuDCX-3509-DsRed2 cassette which has the promoter region of human DCX resulting in phuDCX-3509-CreERT2 (Additional file 1). In addition, a 7.7-kb DCX-3'UTR was amplified using RT-PCR with specific primers and cloned into a pCRII vector to obtain the pCRIITOPO-3'UTR plasmid. Next, a 7.7-kb Spe I-Not I fragment of pCRII-TOPO-3'UTR was further subcloned into the Spe I and Not I site of the phuDCX-3509-CreERT2 cassette to obtain the phuDCX-3509-CreERT2-3'UTR targeting plasmid.",0
1,5,"The plasmid used for targeting, phuDCX-3509-CreERT2-3’-UTR, underwent linearization via Sal I-Not I digestion. The DNA was then injected into the pronuclei of fertilized oocytes from FVB inbred mice. PCR analysis and Southern Blot of tail DNA were utilized to determine the genotypes of the offspring. Cre-positive mice were further analyzed with Southern Blot using a 1.27-kb Sal I-Hind III fragment of pCAG-CreERT2-bpA-SS1 vector as a probe. If there were positive insertions, a 7424 bp fragment would be detected after digestion of genomic DNA with Kpn I or two fragments would be detected after digestion with EcoR V. All restriction enzymes used were from Roche Applied Science.",0
1,6,"Animal experiments were conducted following the guidelines of the Council of European Communities Directive of 24 November 1986 (86/609/EEC) and approved by the HelmholtzZentrum Munich Institutional Animal Care and Use Committee. The research team expanded the DCXCreERT2 transgenic mouse line by breeding DCX-CreERT2 transgenic mice with wildtype C57Bl/6J mice. Additionally, DCX-CreERT2 transgenic mice were mated with two reporter lines - CAG-CAT-EGFP mice [22] or ROSA26lacZ mice [23] - to produce DCX-CreERT2: ROSA26lacZ or DCX-CreERT2:CAG-CAT-EGFP double transgenic mice. By inducing recombination activity in these lines, the expression of the corresponding reporter gene was activated, and this was used for the different analyses described later.",0
1,7,"Tamoxifen was mixed with corn oil to create a 10 mg/ml stock concentration. Pregnant mice were injected with 20 μg TAM/g bodyweight to analyze expression of certain genes in embryos. The same protocol was used in pregnant mice of 17.5 day gestational stage to study the fate of targeted cells during adulthood. To test the activation of CreERT2 recombination in adult brains, 200 μg TAM/g bodyweight was injected. Daily injections of 100 μg TAM/g bodyweight were used to study the expression patterns of genes and markers in adult brains, with mice analyzed at different time points after the last injection.",0
1,8,"The mice received an injection of BrdU (5-Bromo-2’deoxyuridine) in sterile PBS, pH7.4, 24 hours before perfusion. The dosage was 200 μg/g bodyweight. The BrdU was obtained from Sigma-Aldrich and prepared appropriately.",0
1,9,"For whole-mount X-gal staining, embryos were immersed in a solution containing 4% paraformaldehyde (PFA), 5 mM EGTA, 10 mM MgCl2 in PBS, and fixed for 30 minutes at room temperature (RT). After that, they were rinsed in 0.1 M sodium phosphate buffer pH 7.4 (PB), 2 mM MgCl2, 0.01% sodium deoxycholate, 0.02% NP-40, and incubated with X-gal staining buffer (0.1% X-gal, 2 mM MgCl 2 , 0.01% sodium deoxycholate, 0.02% NP-40, 5 mM K3Fe(CN)6, 5 mM K4Fe(CN)6 in PB) in the dark at 37°C for several hours, to visualize the beta-galactosidase (b-gal) activity as a blue reaction product. The stained embryos were then washed twice in PBS and post-fixed with 4% PFA in PBS, overnight at 4°C. For the X-gal staining of free-floating sections, the process was the same as before, except the sections were post-fixed with 4% PFA in PBS for only 1 hour at RT, and then lightly counterstained with Eosin Y (0.1%, E4382, Sigma-Aldrich).",0
1,10,"Embryonic specimens were fixed in 4% paraformaldehyde (PFA) in 0.1 M phosphate buffer with a pH of 7.5 for a duration of 2-8 hours. The whole embryo was embedded in paraffin and sectioned sagittally (8 μm) with the use of a Microm HM 355 s Microtome (Leica). Adult mouse brains were extracted post transcardial perfusion with 4% PFA in 0.1 M phosphate buffer pH 7.5. These brains were postfixed for 2 hours in the same fixative, submerged in 20% sucrose at 4°C overnight, and embedded in OCT compound. Leica cryostats were used to cut serial coronal or sagittal sections (40 μm) of the brain for systematic sampling of the entire structure.",0
1,11,"For immunofluorescence staining, the free-floating sections were initially washed with PBS and then blocked with PBS++ (PBS++ includes 5% fetal calf serum and 0.3% Triton X-100 in PBS) for one hour at room temperature. However, in cases where the detection of BrdU was necessary, the sections were treated with 2 N HCl for 30 minutes at 37°C, neutralized for 10 minutes in 0.1 M borate buffer, washed six times in PBS, and then blocked with PBS++. After blocking, the sections were exposed to primary antibody dilutions (given in Table 1) in PBS++ for 24 hours at 4°C, followed by three 10-minute washes in PBS. The sections were then treated with secondary antibody conjugated to cyanine 2 (cy2), cy3 or cy5 in PBS++ for two hours at room temperature in a 1:400 dilution (Jackson ImmunoResearch Lab). After three 10-minute washes in PBS, the sections were treated with 5 mg/ml 4’,6’-diamidino-2-phenylindole (DAPI) (SigmaAldrich, D9564) for 20 minutes, followed by three 5-minute washes in PBS. Finally, the sections were mounted using Aqua poly/Mount (Polysciences, 18606).",0
1,12,The number of recombination events was quantified by counting at least 100 positive cells per region of interest for each animal and time point. The presented data show the mean ± SD.,0
1,13,"The ability of a 3509-bp DCX genomic fragment to drive expression of reporter genes in neuronal precursors and immature neurons in vitro and in vivo was previously demonstrated (9,10). Hence, the CreERT2 encoding sequences were subcloned downstream of this DCX regulatory fragment (Additional file 1). After pronuclear injection, two male founders carrying the CreERT2 transgene were obtained. Both founders transmitted their transgene to the F1 generation, and Southern blot analysis indicated that only 1 copy of the transgene was integrated into the host genome (Additional file 1).",0
1,14,"Cre-recombinase activity was evaluated in the first generation of two founder-derived lines by mating them with Rosa26 lacZ reporter mice. This resulted in activation of a lacZ expression cassette following recombination [23]. Two-month-old DCX-CreERT2:Rosa26 lacZ mice were perfused two weeks after a tamoxifen (TAM) or vehicle injection and stained for b-gal activity. Both DCX-CreERT2 transgenic lines exhibited the expected TAM-induced b-gal expression in adult neurogenic regions, such as the SVZ and dentate gyrus (Additional file 1). However, no b-gal activity was detected following vehicle injections in the progeny derived from founder 2. In contrast, progeny from founder 1 showed numerous b-gal positive profiles after vehicle injection, indicating unspecific recombination events (data not shown). Therefore, only the transgenic DCXCreERT2 founder 2 line was expanded and used for subsequent experiments.",0
1,15,"To confirm that CreERT2 expression matches with the endogenous DCX expression in the DCX-CreERT2 transgenic mice, we examined their respective expression patterns. At the level of individual cells, CreERT2 was found in almost all DCX+ cells of the developing CNS (E15.5). Additionally, one day after TAM administration, the CreERT2 had translocated into the nucleus (Figure 1a). Similarly, in the adult brain, CreERT2 expression was exclusively present in the nucleus of DCX+ cells one day after TAM injection (Figure 1b). The nuclear distribution was motivated by TAM administration and is required for CreERT2 activity.",0
1,16,"To determine the timeframe during which CreERT2 operates in the nucleus following the TAM injection, DCX-CreERT2 adult mice were perfused at various points in time after the injection, and the sub-cellular localization of the CreERT2 protein was evaluated. The nuclear localization of CreERT2 was markedly reduced seven days following TAM injection as opposed to the initial day. At this stage, CreERT2 expression was still co-localized with DCX, but the distribution shifted back to being mostly cytoplasmic (Figure 1c). Moreover, two weeks post-TAM injection, CreERT2 was located exclusively in the cytoplasm (Figure 1d and 1e). Our findings suggest that CreERT2 nuclear localization quickly diminishes following the last TAM administration, indicating that CreERT2 activity is transient and practically ceases after seven days.",0
1,17,"After confirming that CreERT2 co-localizes correctly with DCX+ cells, we proceeded to examine the specificity and activity of recombination. We bred DCX-CreERT2 mice with Rosa26 lacZ or CAG-CATEGFP reporter mice to track activation of the relevant reporter gene expression upon successful excision of the loxP-flanked cassette. Analyzing reporter gene expression at different times after recombination allows us to monitor the outcome of DCX-expressing cells.",0
1,18,"After administering TAM injection on E14.5, CreERT2 activity was examined and it was observed that b-gal expression was limited to CNS and DRGs, similar to endogenous DCX expression. On E17.5, activation of CreERT2 by a single TAM-injection resulted in widespread EGFP reporter expression throughout the brain parenchyma, including the granular cell layer of dentate gyrus, striatum, cortex, thalamus, Ammon’s horn (CA1), etc., as per the DCX expression pattern.",0
1,19,"Virtually all cells that expressed EGFP also expressed NeuN which indicates that they had matured into neurons (Figure 2d to 2g). EGFP expression was not found in DCX-positive cells located in the SVZ (Figure 2f and 2g), the RMS (data not shown), or the SGZ of the dentate gyrus (Figure 2d and 2e). Some EGFP+ cells were observed in or near the ependymal layer of the lateral ventricles (Figure 2f, indicated by arrows). However, these EGFP+ cells did not co-express NeuN or DCX, and their identity is still unknown.",0
1,20,"In order to investigate the limited production of neurons in the adult CNS, adult mice were given TAM injections for five consecutive days before being perfused for analysis four weeks after the final injection. The results showed that EGFP+ cells generated in the SVZ reached the OB and were mainly distributed in the GrO layer, with fewer cells found in the pGl layer. These EGFP+ cells in the OB expressed NeuN, indicating maturity, but not DCX. Scattered EGFP+ cells expressing DCX were found in the rostral RMS, while few EGFP+ cells were present in the SVZ. Additionally, EGFP+ cells in the dentate gyrus expressed NeuN and not DCX. (Figure 2h–k).",0
1,21,"The recombination event in cells expressing DCX in the adult SVZ and SGZ was assessed for efficiency and specificity. The proportion of DCX+ cells that expressed EGFP represented efficiency while the percentage of EGFP+ cells that expressed DCX represented specificity. Since EGFP accumulation levels were low initially, an anti-EGFP antibody was used to amplify signals for subsequent experiments. In the SVZ, 94% of DCX+ cells co-expressed EGFP, while in the SGZ, EGFP was detected in 77% of DCX-expressing cells. Additionally, 96% of EGFP+ cells in the SVZ and 90% in the SGZ co-expressed DCX, indicating high efficiency and specificity of CreERT2 activity.",0
1,22,"To further understand how DCX+ cells move from their birthplace to their destination areas, the researchers studied the distribution of cells that expressed EGFP at different time intervals after treatment with TAM. Adult mice were sacrificed on the eighth, fifteenth, and twenty-ninth day after the last injection to investigate the co-localization of EGFP expression with DCX and NeuN in the SVZ-RMS-OB axis and the dentate gyrus.",0
1,23,"The percentage of DCX+ neurons expressing EGFP decreased from 100% at day 2 to 25% at day 15, while co-localization of EGFP and DCX in the SVZ decreased from 26.7% at day 8 to 12.5% at day 15. By day 29, few EGFP+ cells expressing DCX remained in the SVZ and no co-localization was detected in the SGZ. These results suggest that the main migration of EGFP-labeled neurons occurred within the first 15 days. (Figure 3)",0
1,24,"During the migration of EGFP+ cells along the RMS from D2 to D15, they were discovered to have an immature neuronal morphology and only a few instances of co-localization with NeuN were identified (as shown in Figure 4). As the cells arrived at either the GrO or pGl of the olfactory bulb over the next four weeks, there was a general increase in NeuN expression in EGFP+ cells (as demonstrated in Figure 2h and 2i, Figure 4 a, e and 4i). In the GrO, the expression of DCX in EGFP+ cells was weak, while DCX was still highly expressed in the cytoplasm of EGFP+ cells located at the front of the RMS (indicated by the arrow in Figure 2i), indicating that the expression of DCX decreased progressively as EGFP+ cells migrated towards their target regions (data not revealed). These findings show that the regulation of DCX expression in cells migrating towards the olfactory bulb is regional. Similarly, in the dentate gyrus, EGFP-expressing cells integrated into the inner granular layer over time and gradually induced the expression of NeuN. Quantitative study revealed that more than 80% of EGFP+ cells detected in the dentate gyrus (as shown in Figure 4m) and virtually all EGFP+ cells identified in the olfactory bulb (data not shown) expressed the mature neuronal marker NeuN, indicating their neurogenesis.",0
1,25,"The investigation of EGFP-labeled neurons' neuronal phenotypes was further conducted by immunohistology at D29 to detect the presence of neurotransmitter-specific markers and calcium-binding proteins (Figure 5). Previous studies' results were affirmed as GAD65 expression, a marker commonly found in GABAergic neurons, was found in EGFP-expressing cells situated in the OB. Additionally, a specific sub-population of periglomerular EGFP+ cells was observed to exhibit co-expression of TH, a marker that is unique to dopaminergic neurons (Figure 5).",0
1,26,"VGLUT2, a marker for glutamatergic terminations, was found in the granular layer of the dentate gyrus and surrounding EGFP+ cells at D29, indicating that the EGFP-expressing cells received glutamatergic inputs (Figure 5). The expression of calcium-binding proteins such as calbindin-D28K, calretinin and parvalbumin was also examined in the EGFP-labeled granule neurons at this time point. Calbindin-D28K was detected in most EGFP+ cells of the dentate gyrus, but no parvalbumin and only weak expression of calretinin were observed in EGFP+ cells at this time point. However, cells with high levels of parvalbumin or calretinin, particularly newly generated granule cells, were present in the vicinity (as shown by the arrow in Figure 5e).",0
1,27,"DCX expression occurs in a varied group of neuronal precursors and young neurons with different levels of maturation and proliferation. BrdU was used to label proliferative cells at different times after recombination. At the earliest time point (D2), 51.1% of EGFP+ cells in the SVZ and only 7.7% of EGFP+ cells in the SGZ incorporated BrdU, indicating that some cells were still proliferating. The higher number of actively dividing cells in the SVZ may be due to young post-mitotic neurons leaving the SVZ and the most immature cells remaining. Additionally, EGFP+ cells in the SVZ/RMS/OB axis could maintain proliferative capacity until at least D15, as evidenced by a few co-labeling BrdU+/EGFP+ cells found in the RMS. No further BrdU incorporation in EGFP+ cells was seen in SGZ at D15, demonstrating the restricted proliferative capacity of DCX+ cells.",0
1,28,"After TAM was given to adult DCXCreERT2:CAG-CAT-EGFP mice, EGFP+ cells were found beyond the neurogenic areas. Previous studies have reported scattered DCX-expressing cells in the cerebral cortex of adult rodents, cats, and primates. To confirm that the EGFP expression in cells located outside of the neurogenic regions correlated with DCX expression, the whole adult brain was examined by immunohistochemistry for DCX expression in relation to EGFP activation.",0
1,29,"Cells dispersed throughout the cerebral cortex exhibited low to moderate levels of DCX expression (see Figure 7), while weak DCX expression was noticeable in the corpus callosum, around the 3rd ventricle and hypothalamus, and the MCL and GCL of cerebellum (data not shown). Four weeks following TAM injection, EGFP+ cells were detected in these same regions (Figure 7), but the reporter expression levels were considerably greater than endogenous DCX expression levels due to the use of a strong promoter for recombination. Importantly, EGFP+ cells found outside of neurogenic regions were non-proliferative, as indicated by the absence of BrdU labeling. Therefore, further investigation is required to determine the identity and fate of these immature neurons.",0
1,30,"We have successfully demonstrated that the use of a DCX promoter-driven CreERT2 allows for efficient and specific recombination targeting in vivo within DCX-expressing cells, particularly in neuronal precursors and young neurons. This approach goes beyond previously generated DCX promoter-driven reporter lines, as our construct includes the 3’UTR region of the DCX mRNA which is known to have post-transcriptional regulation elements. While this did not result in any significant differences in CreERT2 expression pattern in our study, further investigation is needed to determine its potential impact on more faithful expression within the DCX-expressing cell population.",0
1,31,"After receiving TAM, the CreERT2 protein moved to the nuclear area of cells expressing DCX, allowing recombination to occur. This led to rapid activation of reporter expression, as b-gal or EGFP could be observed in both embryonic and adult CNS just one day after injection. With five daily TAM administrations, 94% of DCX+ cells in SVZ and 77% of DCX+ cells in the dentate gyrus showed EGFP expression, proving the high efficiency of recombination under our experimental conditions. Additionally, 96% of EGFP+ cells in SVZ and 90% in SGZ co-expressed DCX, indicating that recombination activity was highly specific. The study concluded that EGFP+ cells had a solely neuronal fate and that the absence of DCX expression in a small percentage of these cells was due to the downregulation of DCX expression during the 5-day TAM injection period. (Figure 2 and 3).",0
1,32,"The CreERT2 nuclear translocation was temporary, but the reporter expression became permanently induced after recombination, which enables long-term analysis of cell types derived from DCX+ cells. A month after the recombination in DCX-CreERT2, most of the EGFP+ cells in the neurogenic target regions expressed NeuN, indicating the presence of mature neurons. Some EGFP+ cells expressed low levels of DCX localized outside neurogenic regions and along neuroblasts' migratory route. Notably, there was no co-localization observed between the EGFP signal and astrocyte, oligodendrocyte, or microglia markers a month after the last TAM injection, indicating that DCX-expressing cells become neurons under physiological conditions. In contrast, the nestin promoter-driven CreERT resulted in labeling the neural stem cell population, which generates a continuous flow of new neurons and glia [17].",0
1,33,"Calbindin-D28K, calretinin, and parvalbumin are three types of low molecular weight calcium-binding proteins that are found in different subpopulations of neurons. Calbindin-D28K is a marker of mature granule cells, while calretinin is transiently expressed in newly generated neurons. In the dentate gyrus, EGFP+ granular cells expressed Calbindin-D28K, with a few expressing low levels of calretinin, and none expressing parvalbumin four weeks after recombination. There was no co-localization between EGFP and parvalbumin, suggesting that this GABAergic subpopulation is not replenished by new neurons in the adult dentate gyrus, although this is still a topic of debate.",0
1,34,"There were EGFP+ cells found in non-neurogenic areas after recombination in DCX-CreERT mice. DCX+ cells have been observed in various non-neurogenic regions of mammals, such as the temporal and prefrontal cortex layer II, piriform cortex layer III/endopiriform nucleus, corpus callosum, nucleus accumbens, ventromedial striatum, ventrolateral septum, bed nucleus of the stria terminalis, molecular cell layer, granular cell layer, and white matter of the cerebellum. The distribution and occurrence of these DCX+ cells tend to increase in more advanced species; however, it is unclear whether this is due to an upregulation of DCX expression levels or simply a better immunohistochemical detectability [7,8,35-37].",0
1,35,"The amount of cells positive for EGFP was significantly greater than those positive for DCX around the 3rd ventricle and hypothalamus, which is interesting. The difference in numbers may be due to the low level of DCX expression in these cells, making them difficult to detect using current antibodies. However, when DCX-associated recombination took place, a strong constitutive promoter controlled expression of reporter genes, making it easier to identify targeted cells.",0
1,36,"The function and origin of DCX-expressing cells that exist outside the neurogenic regions still need to be clarified. Research has shown that neural stem cells can be found in almost every region of adult CNS, and through specific treatment, neurogenic events have been induced in various areas, such as the cortex, striatum, CA1 region of the hippocampus, and even the white matter. Although some DCX-expressing cells found in these regions may have been generated through a very low rate continuous neurogenesis, the lack of BrdU labeling in these cells under physiological conditions suggests that this mechanism is most likely marginal.",0
1,37,"There is strong evidence to suggest that extra-neurogenic DCX-expressing cells are generated during developmental neurogenesis but don't fully mature, leaving them as ""quiescent"" local neuronal precursors in the parenchyma. The existence of these precursors has been suggested through grafting experiments with neural stem cells indicating that some immature neurons remain in the parenchyma, potentially serving as a reservoir of precursor cells for plasticity or local repair. (43, 44)",0
1,38,"Another mouse model expressing the DCXCreERT has been recently reported by Cheng and colleagues using a BAC construct encoding the murine DCX promoter. The differences observed between the two models may be due to the use of the human DCX promoter in our model and a possible positional effect of the transgene. While our mouse model is not exclusive to DCX-expressing cells within the hippocampus, the model presented by Cheng et al. is exclusively active in those cells. Additionally, the authors claim that recombination in their DCX-CreERT mice only occurs in post-mitotic neuronal precursors, suggesting a delayed induction of the DCXCreERT transgene expression in comparison to the endogenous DCX. The DCX-CreERT mouse model from Cheng and colleagues is suitable for studying the maturation and fate of newly generated granule cells of the dentate gyrus. However, there is still a lack of model(s) addressing the fate of DCX-expressing cells located outside of the dentate gyrus, such as in the subventricular zone (SVZ), which our model can address.",0
1,39,"We present a noteworthy transgenic mouse model utilizing an inducible Cre recombinase powered by the DCX promoter, named DCX-CreERT2. This model is highly specific and efficient for recombination in neuroblasts and newly generated neurons. Therefore, it is an effective tool for tracing neurogenesis and fate-analysis of newly generated neurons. Additionally, the model is useful for exploring the molecular mechanisms of neural plasticity and neurogenesis through the induction or silencing of specific genes in these cells. Finally, the long-term analysis of newly generated neurons provides an advantage for developing innovative therapies against neurologic diseases.",0
2,1,"Despite the numerous efforts made worldwide to control malaria, it remains a significant public health concern with almost one million deaths and approximately 250 million cases occurring annually. The majority of deaths are among children under five years old, with nearly all occurring in sub-Saharan African countries. In Benin, malaria accounted for a significant proportion of medical consultations and hospital admissions, and the National Malaria Control Programme has implemented the recommended preventive and curative strategies, including the use of Artemisinin combination therapy, intermittent preventive treatment during pregnancy, long-lasting insecticide-treated mosquito nets, and indoor residual spraying with carbamate insecticide in specific districts.",0
2,2,"Several studies have shown that the usage of insecticide treated nets significantly reduces the occurrence of uncomplicated malaria by half, but the problem of insecticide resistance in malaria vectors has increased dramatically in Africa, particularly in Benin. In experimental huts in South Benin, Anopheles gambiae was resistant to pyrethroids, which resulted in reduced efficacy of pyrethroids when used as either treated nets or IRS. To address insecticide resistance, the CREC collaborated with the IRD and the NMCP to successfully develop a new IRM strategy that combines a LLIN and a carbamate treated plastic sheeting in the same household. This strategy was evaluated in a health district in southern Benin as part of a future community-based evaluation (phase III trial), where a nation-wide distribution of LLINs to children <5 had already been implemented in 2007.",0
2,3,"A epidemiological investigation was conducted in the Ouidah-Kpomassè-Tori Bossito health district, located in southern Benin (Figure 1), between December 2007 and November 2008. The study region had a populace of 178,314 inhabitants according to the results of the 3rd General Census of the Population and the Environment (RGPH3) of February 2002, and the majority of the inhabitants lived in rural areas, where agriculture was the primary livelihood. The Aïzo ethnic group constituted most of the population. The weather was chiefly subequatorial, with two dry seasons - a long dry season from December to March and a short dry season in August and September - and two rainy seasons - a long rainy season from April to July and a short rainy season from October to November. With an average annual rainfall of around 1,200 mm, roughly 700-800 mm and 400-500 mm fell during the first and second rainy seasons, respectively. The warmest months were from February to April, with temperatures reaching 31°C, while the coldest months were between July to September, with temperatures partially dropping down to 27°C. Fewer than 30% of children in the study area went to the health centre when they were ill; instead, they usually received traditional treatment. In Benin, it was found in a recent survey that less than half of febrile children below the age of five were given anti-malarial drugs, of which just 7% were given ACT.",0
2,4,"Twenty-eight villages were selected based on certain criteria, including a population of 250-500 and the absence of a local health center. Among them, seven villages were chosen randomly, and the geographical, demographical, and environmental details are provided in Table 1. Around 60 children aged 0-71 months were selected from each village, excluding those born during the study period. Ethical clearance was obtained, and written consent was given by the mosquito collectors and the head of each selected family. During the monitoring period, medical care was provided free of charge to all children in the villages, whether or not they participated in the study.",0
2,5,"Active case detection for malaria was conducted over eight periods of six consecutive days at six-week intervals throughout the year. Each day, a nurse accompanied by a local helper trained for the study visited the households in the sample. The field work was supervised by a physician. The health of each child was recorded daily on a form, with the nurse examining and recording data on every case of sickness detected at home. A thick blood film was taken from every sick child and treated according to the clinical diagnosis made by the nurse. Cross-sectional surveys were carried out at each monitoring period on every asymptomatic child, with quality controls conducted every six weeks.",0
2,6,"Data was gathered two weeks prior to each clinical monitoring utilizing the Human Landing Catches (HLC) technique [21] to capture adult mosquitoes. The study area implemented 896 human-nights of capture of human landing mosquitoes, occurring every six weeks over a one-year period. This consisted of 128 nights per village, with eight locations per village and night, half of which were indoors and the other half outdoors. The mosquito collection sites hosted treated nets, and the mosquito species were identified by morphological characteristics, based on the identification keys of Gillies & De Meillon [22] and Gillies & Coetzee [23]. All mosquitoes belonging to the An. gambiae complex and Anopheles funestus group were stored individually in tubes with silicagel and kept at -20°C for P. falciparum circumsporozoite index estimation and molecular identification.",0
2,7,"During weekly surveys, nurses conducted unannounced visits in the late evening around 9.00 PM to check the ownership, use, and correct use of LLINs (Permanet® 2.0) that were distributed in October 2007. The visits determined whether the LLINs were seen, whether children were sleeping under them, and whether they were correctly hung and tucked without tears. The rates of ownership, use, and correct use were calculated based on the total number of observations.",0
2,8,"Laboratory processing was conducted at the CREC in Cotonou. Using Giemsa-stained thick smears, parasitological infection was detected and the asexual stages of each Plasmodium species were counted in the blood volume occupied by 200 leucocytes. The parasite density was then calculated based on the assumption of 8,000 leucocytes/μL of blood. The same experienced technician read the thick smears from each village under the supervision of a parasitologist. The readings of the two technicians were compared on the same set of blood samples, and there was no significant difference in their estimations of parasite detection and density. To ensure quality control, a randomly selected sample representing 10% of all thick smears underwent cross-checking.",0
2,9,Anopheles mosquitoes collected from the field were scored and their species were identified through PCR. The molecular M and S forms of An. gambiae s.s. were determined using Favia's method based on their presence and relative frequency. Infection of individual mosquitoes was determined through ELISA using monoclonal antibodies against P. falciparum CSP on their head and thorax. The L1014F kdr allele was molecularly detected using Martinez-Torrez's method.,0
2,10,"The Access 2003 database was used to double enter demographic, parasitological, clinical, and entomological data independently. The svy command in STATA 11.0 was utilized to analyze parasitological and clinical data. Only one blood sample per monitoring period was examined for analysis, except when a pathological condition was present, and the blood sample taken during the clinical episode was saved for examination. Parasitological data was examined separately for P. falciparum asexual blood forms prevalence, density in parasite positive blood thick films, and gametocytes prevalence. The statistical analysis of repeated measures was conducted using a generalized estimating equation approach that works with normal distributions and discrete data. An exchangeable correlation structure was used to take into consideration the interdependence of observations made on the same person, with a similar correlation between the observations made on an individual being assumed. Asymptomatic malaria infections prevalence was evaluated as a binomial response using a logistic regression model.",0
2,11,"The Poisson regression model was used to test the relationship between parasite density and clinical episodes, with clinical status as the dependent variable and parasite density as the independent variable. A random intercept variable was included to account for the interdependence of observations made on the same person. The probability of malaria causing a pathological period was estimated using the Attributable Fraction calculated from odds ratios associated with parasite density in the logistic model. Pathological episodes were defined using clinical symptoms or a history of fever, and the number of malaria attacks for individuals was estimated based on the sum of probabilities calculated using parasite density.",0
2,12,"The study examined three dependent variables - prevalence rate of P. falciparum infection, mean parasite density in positive children, and clinical incidence rate, with a focus on demographic factors such as age groups and sex, environmental variables such as season and villages, and sanitary variables such as LLIN's ownership, use, and good use. The researchers used the Chi 2 test to compare rates of ownership, use, and correct use of LLIN's, and calculated an optimum pyrogenic parasite density cut-off using a logistic model to estimate AFs. They also determined the sensitivity and specificity ratios, along with positive and negative Likelihood-ratio and Youden's J index.",0
2,13,"The rate at which humans were bitten by Anopheles mosquitoes was measured as HBR, which represents the number of bites per person per night. The proportion of mosquitoes that tested positive for CSP was calculated as the sporozoite index. The entomological inoculation rate (EIR) was determined by multiplying the HBR and the sporozoite index, and it reflects the number of infected bites per person annually.",0
2,14,"During a period of 18,262 persondays, 440 children across seven villages were clinically and parasitologically monitored. Of these, 402 children were missing due to either 366 children not being found or 36 refusals. Additionally, 10 children died during the study, with an average age of inclusion being 2.1 years old and a 1:1 female/male ratio. On average, each child was visited during 42 of the 48 days, and a total of 3,074 thick blood films were taken. These included 2,838 for asymptomatic children and 236 for sick children, with an average of seven per child.",0
2,15,"Plasmodium falciparum, Plasmodium malariae, and Plasmodium ovale were either present alone or in a mixed form. The annual prevalence rate of P. falciparum infection was found to be 21.8% (95%CI 19.1-24.4). According to the multivariate random-effects logistic regression model, the prevalence of infection was significantly associated with the age of children, season, village, and correct use of LLINs, but not with the ownership and use of LLINs. The correct use of LLINs was predicted to offer a 26% individual protective effect against infection prevalence (OR = 0.74 (95% CI 0.62-0.87), p = 0.005). The prevalence of infection was observed to increase with age, with children aged 1 to 2 years and 3 to 5 years being three to five times more often infected than children aged less than one year (22.0% (CI95% 17.0-27.0) and 33.0% (CI95% 28.4-37.6) versus 7.8% (CI95% 5.2-10.5)). Furthermore, the prevalence of infection was higher during the dry season (24.7% (CI95% 21.6-27.8)) than the rainy season (18.6% (CI95% 15.7-21.5)). The prevalence of infection was also higher in Satré, Wanho, Kindjitopka, and Hèkandji than in Dokanmè, Aidjèdo, and Guézohoué.",0
2,16,"The average amount of P. falciparum asexual forms in the blood of asymptomatic children who tested positive was 586 per μL (95%CI 504-680). Through the multivariate random-effects linear regression model, it was discovered that elevated parasite density was linked to specific villages (Dokanmè and Satré), not the age of the children, the seasons, or the use of LLINs (Table 4). Additionally, the annual prevalence of Plasmodium falciparum gametocytes was 3.0% (95%CI 2.2-5.6) and differed considerably between the dry (3.8% (95% CI 2.9-4.8)) and the wet season (2.2% (95%CI 1.4-3.0)), p = 0.008.",0
2,17,"During the research, 236 abnormal incidents were identified. Out of these, 110 were related to parasites, with 102 of them involving P. falciparum, three involving P. malariae, two involving P. ovale, and three involving mixed infections. The densities of P. malariae single infections were 480, 2,360, and 200 parasites/μL, and those of P. ovale single infections were 4,800 and 9,800 parasites/μL. The mixed infections of P. falciparum and P. ovale had combined densities of 3,760 Pf + 720 Po, 960 Pf + 400 Po, and 280 Pf + 120 Po. Healthy children had lower mean parasite densities than sick children in all age groups. Four cases of severe malaria with anaemia were diagnosed among the four parasite-positive cases with P. falciparum, which were referred to the health centre. The total count of pathological episodes attributable to P. falciparum malaria was 74. The optimal pyrogenic parasite cut-off was determined to be 2,000 P. falciparum asexual blood forms per μL, with corresponding levels of sensitivity and specificity of 94.0% and 94.5%, respectively. The mean annual clinical incidence rate was 1.5 per child per year (95%CI 1.2-1.9).",0
2,18,"A total of 13,602 mosquitoes were captured in seven villages, with 115 An. Gambiae sensu lato (s.l.) and 67 An. funestus. Of these, nine An. Gambiae s.l. and four An. funestus were CSP positive. The aggressiveness of mosquitoes and malaria vectors was determined to be 5,541 and 74 bites per human per year, respectively. The annual EIR was 5.3 infected bites per human per year. The 1014F kdr allele was present in both the molecular M and S forms, with a frequency of 0.47 and 0.61, respectively.",0
2,19,"The rate of ownership of LLINs was 91.8% (2,769/3017; 95%IC 90.8-92.8) and remained consistently high throughout the year. However, usage was found to be significantly higher during the rainy season at 73% (1,062/1,451; 95%CI 70-75) compared to the dry season at 67% (1,047/1,566; 95%CI 64-69) with a p-value of 0.0001. Use of LLINs also significantly declined to 31% (118/385; 95%CI 26-31) in the middle of the dry season. During the rainy season, there was correct use of LLINs at its highest rate of 68% (990/1,566; 95%CI 65-70) whereas it was at 42% (665/1,171; 95%CI 40-45) during the dry season, with a p-value of <0.0001 as shown in Figure 3C.",0
2,20,"A study was conducted to characterize the epidemiology of malaria in the health district of Ouidah-KpomassèTori Bossito after the distribution of LLINs to children in October 2007. Previous studies have mainly focused on malaria transmission and clinical and parasitological aspects in rural and urban areas of Benin. Other studies have looked at process indicators for malaria control and the impact of LLIN distribution in Africa. Pyrethroid resistance in malaria vectors is a concern in many African countries, but there have been no reports of LLIN effectiveness being compromised at an operational level.",0
2,21,"The area of Ouidah-Kpomassè-Tori Bossito was found to be a mesoendemic area with an average EIR of 5.3 infected bites annually, according to the entomological findings. This EIR corresponded with a 21.8% annual prevalence rate of asymptomatic malaria in young children. The presence of the L1014F kdr allele in 50% of An. gambiae samples confirms previous studies in southern Benin. In line with mesoendemic areas, the infection rate increased with age. The high infection rate during the dry season may be linked to a peak observed at the end of the rainy season just after LLINs distribution. LLINs may have contributed to the constant parasite density of positive children among all age groups and seasons. Gradual immunity development against malaria could lead to a decrease in parasitaemia with increasing age.",0
2,22,"The optimal parasite pyrogenic cutoff at 2,000 P. falciparum asexual blood forms per μL was determined using the calculated AF of pathological episodes to malaria. Defining the pyrogenic parasite cut-off with AF allows for the best balance between sensitivity and specificity level. In areas with stable malaria, seasonal and age factors affect the malaria-AF of pathological episodes and the malaria case definition according to pyrogenic parasite density cutoff. In this study, however, parasite density remained consistent regardless of season or age, making the AF the same regardless of these factors. This cutoff value of 2,000 closely corresponds to the values of 1,000 found in mesoendemic areas on children under 3 years and to the values of 3,000 to 6,000 found in hyperendemic areas among children aged 0 to 12 years in the south of Benin.",0
2,23,"In the Ouidah-Kpomassè-Tori Bossito health district, one third of all disease cases were attributed to malaria. To prevent missing cases, the definition for malaria cases included symptoms that suggest malaria or a history of fever within 48 hours of the start of ACD, as recommended by McGuinness (33). The average annual incidence rate of falciparum clinical malaria was 1.5 per child per year. In areas with high levels of P. falciparum, the pyrogenic threshold for parasitaemia in individuals of a certain age is the same for all species of Plasmodium (56). Given the high parasite density, P. malariae could have been responsible for one case of clinical malaria with 2,360 parasites/μL, while P. ovale could have been responsible for two cases with parasitaemia of 4,800 and 9,800 parasites/μL, respectively.",0
2,24,"Before LLINs were nationally distributed in 2001, only 4.3% of households in the south of Benin possessed a treated net (ITN) and merely 2.4% of children under five slept under them. However, by 2006, possession of ITNs had increased to 25.6% and their utilization by children under five had risen to 21% in Ouidah. Since the national distribution of LLINs, ownership has surged to over 90%, which has remained consistent over the years. Unannounced and nocturnal inspections revealed that two out of three children slept under LLINs throughout the study's 12 months. The success of sensitization relied on community beliefs and behaviors, as well as medical staff and local village helpers that partnered with the study team. The 31% reduction in LLIN use during the dry season in Benin is similar to other West African countries.",0
2,25,"The health district of Ouidah-KpomassèTori Bossito is an area with moderate pyrethroid resistance of vectors and high heterogeneity of malaria infection between villages. Malaria infection and disease remained consistent throughout the year, but the use of LLINs was found to reduce malaria infection without affecting its morbidity.",0
3,1,"In recent decades, Porcine circovirus type 2 (PCV2) and the associated postweaning multisystemic wasting syndrome (PMWS) have caused significant losses in global agriculture. Detecting PCV2 rapidly is crucial for effective PMWS prophylaxis and treatment. To create a sensitive and specific assay for PCV2 detection and quantification, we synthesized specific primers and a probe in the open reading frame 2. Our assay was highly reproducible, linear, and had a broad dynamic range, detecting between 102 and 1010 copies of genomic DNA per reaction. The assay did not cross-react with porcine circovirus type 1, porcine reproductive and respiratory, porcine epidemic diarrhea, transmissible gastroenteritis of pigs, and rotavirus. The limits of detection and quantitation were 10 and 100 copies, respectively, and 39 out of 40 tested samples were accurately detected using this established real-time PCR system.",0
3,2,"PCV2 is prevalent among commercial swine [1-5] and is known to cause several diseases, including PMWS [6]. In China, PCV2 infection is widespread [7] and poses a significant challenge to the pig farming industry. Consequently, it is crucial to develop reliable and efficient techniques for detecting the virus.'",0
3,3,"Real-time PCR is a more efficient method for detecting target fragments with greater specificity and quantitative capabilities compared to conventional PCR and ELISA. This technique also effectively prevents false positives and contamination, making it the preferred pathogen detection method.",0
3,4,The synthesis of specific primers and a TaqMan probe for PCV2 was implemented for the purpose of this investigation. A precise and sensitive assay was successfully developed to detect and quantify PCV2.,0
3,5,"Based on the nucleotide sequences of open reading frame 2 (ORF2) obtained from GenBank (EU921257.1), the primer and TaqMan probe design utilized the PCV2 strain from China (BJ0804) as a reference. Primer Premier 5.0, Oligo Primer Analysis software, and DNAman 4.0 were used to create the primers and probe (refer to Table 1). The amplified product was 149 bp long.",0
3,6,"A PCR fragment was inserted into a pGEM-T Easy vector to create a standard plasmid following the manufacturer's instructions (Promega, Madison, WI, USA). The plasmid was propagated in Escherichia coli JM109 cells and then purified and quantified using an ND-1000 spectrophotometer (NanoDrop, Wilmington, DE, USA). The plasmid sample was diluted ten-fold to obtain 1010-100 per μL, which contained 100 ng/μL yeast tRNA, for real-time PCR. The dilutions were stored at -20°C, and the plasmids were stored at -70°C.",0
3,7,"The PCR amplifications were conducted using a 25-μL reaction volume that contained 1×PCR buffer, 200 μM of dATP, dTTP, dCTP, and dGTP, 1.25 U of DNA polymerase, 2 mM of MgCl2 from TaKaRa in Dalian, China, 200 nM of each primer, and variable quantities of plasmid DNA templates. The programmed amplification process involved a step of 94°C for 5 min, followed by 30 cycles of 94°C for 30 s, 60°C for 20 s, and 72°C for 20 s, and concluded with a final step of 72°C for 7 min. The 149 bp amplicons were segregated via a 2% agarose gel that contained 5% Goldview from SBS Genetech in Shanghai, China. Every reaction adopted both negative and positive reference samples.",0
3,8,"Real-time PCR was conducted on an ABI 7500 thermocycler (Applied Biosystems, CA, USA) using a 25 μL volume. The reaction mixture consisted of 1× PCR buffer, 400 nM primers, 200 nM TaqMan probes, 400 μM each of dATP, dTTP, dGTP, and dCTP, 1.25 U Taq DNA polymerase, and 4.5 mM MgCl2. Real-time PCR run was initiated at 95°C for 10 min, followed by 45 cycles of 95°C for 15 s and 60°C for 40 s. For the generation of a standard curve, serial dilutions ranging from 10 10 to 100 copies of the plasmid were used. The assay was conducted in duplicate, and two negative controls were included in each run.",0
3,9,"The assay's limit of quantitation (LOQ) was established by running triplicates of samples containing 107, 105, 103, and 102 copies per sample. Furthermore, the assay's limit of detection (LOD) was estimated by running samples containing 90, 80, 70, 60, 50, 40, 30, 20, 10 and 1 copy per sample.",0
3,10,"The real-time PCR's coefficients of variation (CVs) were assessed using a standard PCV2 plasmid containing 10^7, 10^5, and 10^3 copies. Both intra- and inter-assay CVs for Ct values were measured. The assay's specificity was tested by running plasmid samples containing 10^8 to 10^4 copies, along with cDNA and DNA of various porcine viruses, under optimal conditions. Negative controls were also included in the run.",0
3,11,"The samples included 3 PCV2-positive samples along with 37 unknown serum and tissue samples, which were tested using both conventional PCR and real-time PCR with ideal conditions. The results of conventional PCR were observed with the use of a 2% agarose gel.",0
3,12,'A standard curve was constructed using ten-fold serial plasmid dilutions. The Ct values were measured and plotted against the logarithm of the plasmid copy number (Figure 1). The standard curve had a broad dynamic range from 102-1010 copies/μL and showed a strong linear correlation (R2=0.9999) between the Ct value and the logarithm of the plasmid copy number.',0
3,13,"To ensure accurate measurement of results in optimal circumstances, around 100 template copies were deemed necessary to determine the LOQ of this assay. When the amount of template copies decreased below 100, the Ct values fell beyond the linear range (Figure 2). While the target sequence was detectable in all amplification reactions down to 10 copies, it was undetectable when just one copy was present (Figure 3). Therefore, these findings suggest that the LOD value was approximately 10 copies.",0
3,14,"The coefficient of variation (CV) for the Ct values varied from 0.59% to 1.05% within the same assay and from 1.9% to 4.2% across 10 different assays as shown in Table 2. None of the negative control and samples for PCV1, PRRS, PED, TGE, and RV showed any increase in fluorescence.",0
3,15,Table 3 and 4 demonstrate that the positive rates for PCV2 in unrecognized samples were 78.3% for conventional PCR detection and 97.3% for real-time PCR detection. The usage of real-time PCR increased the detection of PCV2 samples by 18% compared to conventional PCR.,0
3,16,"The majority of viral loads ranged from 10 to 1000 copies/μL in the samples, although some had as many as 108 copies/μL. The DNA extracted from serum samples contained 360 and 1560 copies of PCV2 per microliter in the PPV and PRV, indicating that the pigs from whom the samples were taken had co-infections of PCV2.",0
3,17,"Based on serological surveys, it has been revealed that farms and individual pigs in various parts of Europe, the United States, and Canada exhibit PCV2 seropositivity up to 100%. Likewise, in seven provinces and municipalities in China, it was identified through ELISA that the seropositive rate is as high as 42.9%.",0
3,18,"PCV2 is known to increase pig mortality from 2-3% to 14-30%. Thus, there is an urgent need for rapid and sensitive detection and quantitation assays for PCV2 in both the pig industry and research community. TaqMan real-time PCR is a more sensitive and less easily contaminated option compared to conventional PCR. Conventional PCR has the risk of contamination which leads to false-positive results, especially when examining products in gels. Real-time PCR is favored as it requires less time and has heightened sensitivity.",0
3,19,"The most suitable reference fragment to detect PCV2 is the major conserved region located in ORF2. This is because it displays a significant diversity between PCV1 and PCV2, and there are more sequenced isolates available from PCV2 than from PCV1. Previous studies have primarily utilized hybridization probes that exclusively bind to target products to detect PCV2, with high sensitivity and specificity. However, other methods exist to detect and quantify PCV2, including TaqMan probes, TaqMan real-time PCR, and SYBR Green I. These methods have been used by different researchers to quantify PCV2 in various tissues and serum samples.",0
3,20,"We devised various primers, a probe, and a real-time PCR system in this research to identify PCV2 through amplification of a 149-bp fragment. The real-time PCR technique boosted the recognition of PCV2 samples by 18% compared to conventional PCR. Our method's consistency was confirmed by tests on reproducibility, indicating stability and dependability. We executed a range of experiments to evaluate the assay's reproducibility, sensitivity, and specificity. The specificity of the assay was proved by detecting no cross-reaction signals while working with different swine viruses as templates. The real-time PCR system we designed could not only quickly and sensitively identify PCV2 but could also be applied to evaluate the efficacy of vaccines for PCV2. The real-time PCR detection system is a complementary and enhanced form of previous PCV2 detection and quantitation methods. Furthermore, it offers an alternative approach to identifying PCV2 specifically.",0
4,1,"According to research, approximately 110 million clinical cases of malaria are diagnosed each year in Nigeria, which means that around 50% of the adult population suffers from at least one malaria episode annually. Children are even more vulnerable, with two to four attacks per year. The country also experiences an extensive economic impact, with an estimated loss of around 132 billion Naira (or approximately 878 million USD) annually due to malaria. In response to the issue, the Nigerian government developed its first National Malaria Control Policy in 1996, followed by the introduction of the Roll Back Malaria (RBM) programme in 1999.",0
4,2,"In 2002, national drug efficacy trials were conducted in Nigeria and found that chloroquine and sulphadoxine/pyrimethamine (SP) were no longer effective as first-line treatments for malaria. In response, artemisinin-based combination therapy (ACT) was introduced in 2005, with artemetherlumefantrine becoming the recommended first-line treatment for uncomplicated malaria and artesunate-amodiaquine (AS + AQ) as an alternative. SP is now only used for intermittent preventive therapy (IPT) in pregnant women due to its high resistance level of up to 35%. Furthermore, SP and SMP have a similar structure, which may result in cross-resistance.",0
4,3,"Despite the introduction of ACT for uncomplicated malaria treatment several years ago, it is still underutilized in the field due to poor availability and/or high cost on the African market. The RBM strategy emphasizes quick access to appropriate treatment within 24 hours of symptom onset. An ideal anti-malarial drug for home use should be safe, effective, affordable, easy to administer, and available in a single dose package. Fixed-dose combinations (FDC) are preferred over co-blistered drugs as it prevents inadequate dosing and increases compliance, ultimately preventing drug resistance.",0
4,4,"In terms of the ideal characteristics for an antimalarial drug, the AS + SMP (artesunate and sulphamethoxypyrazine/pyrimethamine) combination could be a viable alternative treatment option if first-line drugs are not readily available. This particular drug has proven to be both simple to use and safe, with high efficacy rates observed in various endemic areas regardless of whether it is administered over 24 or 48 hours [3-5]. Previously offered as a co-blistered drug [6,7], it is now available as a fixed-dose combination (FDC), which requires only three tablets for administration, making it more convenient for malaria patients. Additionally, the SMP component offers a number of ancillary benefits due to its broad-spectrum antimicrobial activity, which could be helpful in treating other infections that may have been misdiagnosed as malaria [8,9].",0
4,5,"To assess the safety and effectiveness of the 24-hour treatment of AS + SMP FDC in south-west Nigeria, a group of children with uncomplicated malaria received either this ACT or a 48-hour therapy of AS + AQ FDC.",0
4,6,"The research was carried out at two hospitals in Ibadan, Oyo State, Nigeria - the University College Hospital and the Oni Memorial Children's Hospital, both of which are located in urban areas. Ibadan lies in the forest savannah woodland zone, with an annual rainfall ranging from 975-1474 mm/year. Malaria transmission in the region, caused mainly by Plasmodium falciparum, is endemic and peaks in August, lasting for six months (May-October). Anopheles gambiae s.l. is responsible for overall entomological inoculation rates ranging from 18 to 145 infective bites per person per year. In southwest Nigeria, seasonal entomological inoculation rates were reported to be 128.7 in 2001 and 131.3 in 2002.",0
4,7,"The Joint Ethics Committee of University of Ibadan and University College Hospital, Ibadan, Nigeria approved the study in compliance with the ICH Guidelines for Good Clinical Practice and the Declaration of Helsinki. The National Agency for Food and Drug Administration and Control in Nigeria (NAFDAC) granted clinical trial approval, while written informed consent was obtained from eligible children's parents or guardians prior to enrolment.",0
4,8,"""At each of the two study sites, children were screened to check if they met the eligibility criteria for participation in the study. The inclusion criteria were as follows: children had to be between the ages of 1 and 13 years and weigh between 6 and 40 kg; they needed to have a history of fever within the last 24 hours or a measured fever with an axillary temperature greater than 37.5°C; they had to have a mono-infection with P. falciparum and parasitaemia within the range of 2,000-200,000 asexual parasites per microlitre of blood. Additionally, they could not exhibit any general danger signs or show signs of severe and complicated falciparum malaria in accordance with the WHO guidelines [12].""",0
4,9,"A trial was designed using a randomized, controlled, open-label format to determine the efficacy of AS + SMP and AS + AQ in curing patients, with a PCR-corrected cure rate at day 28 as the primary endpoint. Based on the assumption that both treatments would achieve a 94% cure rate and taking into account a 10-15% loss to follow-up, a sample size of 250 patients was required for each treatment arm. This sample size would allow for the detection of a 6% difference in parasitological cure rates with 80% power and a one-sided alpha of 0.025. The sample size calculations were conducted using nQuery Advisor 5.0. Randomization codes were generated by a computer with stratification per treatment centre to assign patients to treatment groups.",0
4,10,"The enrolment process included a physical check-up, measuring weight and axillary temperatures, and collecting medical history from parents or guardians which included information about current medication and symptoms. A small drop of blood was collected through a finger prick for thin and thick blood smears and for parasite genotyping, the blood was blotted on filter paper. Moreover, a blood sample was collected to evaluate haematological and biochemical parameters.",0
4,11,"After determining eligibility, the children were randomly assigned to one of two treatment groups. Treatment was provided at the clinic by the recruiting physician. The first group was given three doses of crushed artesunate/amodiaquine tablets (Amonate®, Dafra Pharma ltd., Kenya) mixed with water at 0, 24, and 48 hours. The second group received crushed artesunate/sulphamethoxypyrazine/pyrimethamine tablets (CoArinate FDC ® Junior, Dafra Pharma Ltd., Kenya) mixed with water at 0, 12, and 24 hours. The dosage was based on the age of the child, with children under 7 receiving half a tablet and those 7 and over receiving a full tablet. The children were monitored for vomiting for 1 hour after the administration of the drug. If vomiting occurred within 30 minutes, the full treatment dose was repeated. Half the treatment dose was repeated if vomiting occurred between 30 and 60 minutes.",0
4,12,"Prior treatment was not provided, and the sole accompanying treatment given was antipyretic drugs to patients with temperatures equal to or greater than 38.5°C.",0
4,13,"Children whose second dose of medication fell at night on a 12-hour schedule were admitted for treatment compliance by the nurses on duty. Clinical and parasitological evaluation (thin and thick smears) was conducted on days 1, 2, 3, 7, 14, 21, and 28. Patients were also evaluated if they exhibited new complaints or symptoms during any follow-up day. A physical examination was executed during every visit, brief clinical records were gathered along with possible side effects assessment. The haemogram and biochemical analysis also done on days 0, 7, and 14 to identify significant abnormalities. Parasite genotyping filter paper blood samples were acquired on day 28 or earlier if the symptoms persist. Patients were disqualified from this study when they withdrew their consent, left the study's range, or reported taking antimalarial medicine during the follow-up time frame.",0
4,14,"Drug treatment response was evaluated using a modified WHO clinical classification system. As all patients were not febrile upon presentation, a temperature less than 37.5°C was not considered an exclusion criterion. Patients were tracked for a duration of 28 days in an area with intense transmission. The clinical classification system comprised of four categories: adequate clinical and parasitological response (ACPR), late parasitological failure (LPF), late clinical failure (LCF), and early treatment failure (ETF). Cure rates on day 28 were corrected based on PCR genotyping results of paired samples for patients who experienced recurrent parasitaemia after day 14 of initiating treatment.",0
4,15,"Blood samples were obtained by pricking a finger on multiple scheduled and unscheduled visits. Thick and thin blood smears were prepared from these samples on various days. After air drying, the slides were stained with Giemsa and examined by two technicians to determine parasite density. Parasite density was determined by counting the parasites against leukocytes found in 200 power fields, with an assumption that there were 6,000 leukocytes in each microliter of blood. Plasmodium parasite species were identified from thin blood smears. Discordant slides and those with a parasite density difference greater than or equal to 50% were examined by a third microscopist. To ensure quality control, 10% of the slides were randomly selected for independent examination by another microscopist who was not involved in the study.",0
4,16,"Filter paper blood samples were taken at different stages of parasitaemia. The genotype of the parasite population was determined using PCR techniques. Genetic polymorphisms were analyzed on paired primary and post-treatment parasites samples from two treatment groups, using parasite loci that exhibit repeated polymorphisms. The banding pattern of the post-treatment parasites was compared with the matched primary parasites. Specifically, block 2 of MSP-1, block 3 of MSP-2, and region II of GLURP were amplified by two rounds of PCR using primers and amplification conditions. The PCR products were resolved by electrophoresis on a 2% agarose gel and sized against a molecular weight marker.",0
4,17,"The completeness and accuracy of data collection in the case report forms were verified through double-checking. Two clerks performed dual data entry, which was later compared, corrected, and validated by the data manager. For data analysis, Epi Info version 6 and SPSS version 11 were used, where the primary analysis was a non-inferiority analysis based on PCR-corrected adequate clinical and parasitological response (ACPR) on day 28 as the primary efficacy endpoint. Secondary endpoints included parameters such as gametocyte carriage, fever and parasite clearance time, and packed cell volume levels. For statistical analysis, Chisquare and Fisher exact or Yate's correction tests were used for comparisons between the treatment groups. Skewed data was analysed using non-parametric tests, while normally distributed continuous variables were compared using Student's t test between two independent groups. Kaplan Meier was used to analyse the significance between the rates of reinfection in the two treatment arms. A two-tailed p-value of less than 0.05 was considered statistically significant. Finally, the Intention-To-Treat (ITT) population was included in the safety analysis, which consisted of all patients randomized to either treatment group and received at least one dose of study medication.",0
4,18,"Out of the total 3,500 children who were screened for malaria, only 500 were selected for the trial. These 500 were divided equally, with 250 being assigned to the AS + AQ treatment group and 250 to the AS + SMP group, as shown in Figure 1. Though 6.6% (33) of the children were lost in the follow-up process, with 21 lost from AS + SMP and 12 lost from AS + AQ, both treatment groups had similar baseline demographic, clinical, parasitological and laboratory characteristics, as Table 1 suggests.",0
4,19,"""In each treatment arm, there was one early treatment failure, resulting in a 0.4% failure rate. The PCR corrected cure rates for day 28 were 97.9% for the AS + AQ arm and 95.6% for the AS + SMP arm (p = 0.15). The re-infection rate was 1.7% for the AS + AQ arm and 5.7% for the AS + SMP arm (Table 2, 3 and Additional file 1) (p = 0.021).""",0
4,20,"The two treatment groups had similar median fever clearance time, with both AS + SMP and AS + AQ taking around 1 day (p=0.271). The median parasite clearance time was also similar, with AS + SMP taking 1-7 days and AS + AQ taking 1-3 days (p=0.941). The proportion of children with gametocytes was similar in both groups throughout the follow-up period. On day 0, 16 children in each treatment arm had gametocytes (7.0% for AS + SMP and 6.7% for AS + AQ), and on day 28, the proportion of children with gametocytes was reduced (2.2% for AS + SMP and 3.4% for AS + AQ, p=0.408). On day 14, the proportion of children with anaemia was reduced to 1.3% in both treatment groups (Figure 3).",0
4,21,"Adverse events were not serious and were reported in a similar proportion in both treatment groups. Some patients reported mild adverse events such as vomiting, excessive sleepiness, abdominal pain, and weakness. No patients needed to be hospitalized due to these events, and laboratory values remained normal throughout the follow-up period.",0
4,22,The effectiveness and tolerance of AS + SMP are being recorded in comparison to the recommended AS + AQ ACT to treat uncomplicated P. falciparum malaria in children living in a malaria-endemic area of south-western Nigeria. The study monitored the participants' progress for 28 days.,0
4,23,"Several African nations have embraced artemisinin-based combination therapies (ACTs) as the primary treatment for uncomplicated malaria. These treatments include artemetherlumefantrine (AL) and AS + AQ. However, field observations indicate the need to explore other options for ACTs to ensure suitable alternatives are available for patients requiring treatment. The study found that AS + SMP resulted in a 28-day cure rate of 95.6%, while AS + AQ had a cure rate of 97.9% (p = 0.151), suggesting both drugs had comparable therapeutic effectiveness.",0
4,24,"These results align with previous studies conducted on AS + SMP in both endemic and non-endemic malaria regions [3-7]. The observed cure rate for AS + AQ also matches rates reported in other studies [16-18]. The higher proportion of children under the age of 5 in the AS + AQ group may have contributed to a lower ability to clear malaria parasites due to their relatively weaker immune systems. Although the loss-to-follow-up rate was higher in the AS + SMP group (21 vs. 12), it was not necessarily linked to drug efficacy as it primarily resulted from changes in school attendance and other social factors. The need to screen 3,500 children to achieve the desired sample size of 250 individuals per treatment arm suggests that a considerable number of fever cases in children may be caused by bacterial instead of malaria infections [9]. Despite the lack of parasitological confirmation, the SMP component of AS + SMP may have offered clinical benefits to children with bacterial infections who were wrongly diagnosed with malaria.",0
4,25,"The gametocyte carriage rates were similar before and after treatment in both treatment groups, likely due to the effects of artesunate. While sulphadoxine/pyrimethamine has been shown to increase gametocyte carriage after treatment, this was not the case with SMP. In fact, Sowunmi et al found that AQ + SMP treatment did not lead to increased gametocyte carriage, despite slower clearance of sexual parasitaemia compared to AL treatment in children.",0
4,26,"Both treatment regimens, AS + SMP and AS + AQ, were well tolerated and there was no significant difference in the reported frequency of adverse events. It was challenging to distinguish adverse events from malaria-related symptoms. Notably, the occurrence of itching in patients treated with AS + AQ was low, consistent with a previous study. There were no reports of severe adverse events such as icterus or intravascular haemolysis. However, the follow-up revealed a lower packed cell volume in patients treated with AS + SMP, which may be due to a high prevalence of G6PD deficiency in the study area. Screening for G6PD deficiency in all patients would have substantiated this finding.'",0
4,27,"This study shows that giving AS + SMP FDC in three doses over 24 hours or AS + AQ FDC in three doses over 48 hours have similar effectiveness in reducing fever and clearing parasites in children with uncomplicated Plasmodium falciparum malaria in Nigeria. Both drugs are safe, but AS + SMP has a higher re-infection rate. AS + SMP could be a good alternative to first line treatments in areas where they are not available or too expensive. However, continued monitoring of drug resistance is needed due to potential cross resistance between SP and SMP.",0
5,1,"Chronic depression is a global public health problem. Despite the availability of several depression drugs, they often come with significant side effects and may not provide satisfactory results for many patients. The lack of complete understanding of depression's causes also impedes the development of more effective treatments. Research suggests a possible link between immunological changes and major depression. Studies have shown that systemic administration of certain pro-inflammatory cytokines or bacterial products to animals can trigger sickness behavior, ultimately leading to depressive behavior. This condition is characterized by decreased food consumption, social isolation, changes in the circadian cycle, and reduced locomotor activity.",0
5,2,"Toll-like receptors (TLR) are responsible for recognizing microbial structures, with Gram-negative bacterial lipopolysaccharide (LPS) commonly binding to TLR4 and activating intracellular pathways. Studies have shown that LPS-induced depression in rodents is linked to cytokine production, which is also elevated in depressed patients. Additionally, TLR activation following infection can lead to systemic inflammation and brain-controlled illness in rats.",0
5,3,"Kinins, a collection of peptides, are swiftly generated in response to various stimuli [9], activating two G protein-coupled receptors known as B1 and B2 once unleashed. B2 receptors are ubiquitously expressed in various tissues, while B1 receptors are typically not expressed under normal conditions, but are promptly upregulated after infection, trauma, or exposure to certain cytokines [10-13]. Previous publications have established the vital role of TNFa in the upregulation of kinin B1 receptors [14-17]. As a result, B1 receptors are likely to be induced under specific pathological circumstances and involved in various chronic inflammatory and pain processes [9,10].",0
5,4,"Previous research has shown that in animal models of peripheral inflammation, cytokine production from either E. coli or P. gingivalis can lead to a significant increase in kinin B1 receptor expression [14,15,18]. Recent studies have additionally linked kinin B1 receptors to CNS illnesses such as Alzheimer's disease, neuropathic pain, and epilepsy [19-21]. To test whether B1 receptor involvement might also play a role in depression-like behavior resulting from E. coli LPS in mice who undergo swimming sessions as a stressor, we conducted this study. This Protocol is based on the notion of increased susceptibility when external and internal stressors combine to produce allostatic overload [2,22,23]. We also used flow cytometry, ELISA, and real-time PCR to explore some of the mechanisms underlying B1 receptor induction in LPS-treated depressed animals. Immunohistochemical studies were also used to determine whether antagonism of kinin B1 receptors could influence glial activity.",0
5,5,"The drugs and reagents listed below were utilized in the study. Imipramine, LPS from E. coli serotype 0111:B4, aprotinin A, benzethonium chloride, EDTA, HTAB, hydrogen peroxide, PMSF, TMB and Tween-20 were all obtained from Sigma Chemical Company in St. Louis, USA. R-715 was generously provided by Dr. Domenico Regoli from the University of Sherbrooke in Sherbooke, Quebec, Canada. Meanwhile, SSR240612 was kindly supplied by SanofiSynthelabo Recherche in Montpellier, France, and FR173657 was donated by Fournier Laboratories in Dijon, France. The stock solutions of the drugs were stored in siliconized plastic tubes in PBS at -18°C, and then diluted to the desired concentration just before use.",0
5,6,"The study used male CF1 and C57/BL6 wild-type mice or TNFa p55 receptor knockout mice weighing 25 to 30 g. They were kept in optimal living conditions with a 12 hour light-dark cycle, 22 ± 1°C temperature, and 60 to 80% humidity. They had ad libitum access to food and water. CF1 mice were obtained from UFPEL, while C57/BL6 wild-type or TNFa p55 receptor knockout mice were supplied by UFMG. The experiments were conducted within a specific time frame and followed ethical guidelines for the investigation of experimental pain in conscious animals by Zimmermann (1983). Additionally, the experimental procedures were approved by the Animal Ethics Committees of SC and RS.",0
5,7,"As a preliminary stress inducer, the animals were made to swim forcefully for 5 minutes in water with a temperature of 23 ± 1°C. After that, injections of LPS from E. coli (serotype 0111:B4) were given to them intraperitoneally at the doses of 450 mg/kg (CF1 mice) or 1000 μg/kg (C57/BL6 wild-type, or TNFa p55 receptor knockout mice). The control groups were administered saline (0.9% NaCl solution, 10 ml/kg, i.p.). The required intake of LPS and the forced swimming method were chosen by carrying out pilot experiments (not displayed).",0
5,8,"After administering LPS, the animals' behavior was evaluated at different time points (6, 24, or 48 hours) depending on the experimental protocol. Trained experimenters who were unaware of the treatment groups evaluated all behavioral parameters. Separate groups of mice were euthanized at various time points after LPS injection to conduct biochemical, molecular biology, and immunohistochemical assays as described in later sections.",0
5,9,"To confirm whether kinin receptors are involved in the behavioral changes triggered by LPS from E. coli, the animals were given one of the following drugs prior to behavioral tests: SSR240612 (a selective antagonists of kinin B1 receptor) at 5 mg/kg (i.p., 30 min) or 10 mg/kg (p.o., 1 h), or R-715 (0.5 mg/kg, i.p., 30 min) or FR173657 (a selective kinin B2 receptor antagonist) at 30 mg/kg (i.p., 30 min). As a positive control drug, imipramine (a classical tricyclic antidepressant) was used at 10 mg/kg (i.p., 30 min). The corresponding schedules of treatment were followed for the antagonists and control animals received 0.9% NaCl solution (10 ml/kg). For molecular biology and immunohistochemical studies, animals were treated with SSR240612 at 5 mg/kg (i.p.) 30 min before LPS and were sacrificed at specific times, as described in subsequent sections. The doses of kinin antagonists and imipramine were based on previous publications [25-27].",0
5,10,"After administering LPS from E. coli to animals, depression-like behavior was evaluated using the tail-suspension model as per Steru et al. (1985) methodology. The animals were suspended using adhesive tape approximately 1 cm from the tip of their tails at different time points (6, 24, or 48 hours) after LPS treatment. The duration of immobility exhibited by mice over a period of 6 minutes was recorded in seconds.",0
5,11,"Anhedonia is a condition in which there is decreased pleasure sensation. In mice, this can be measured by observing a reduction in sucrose intake. The study's testing protocol was derived from the method developed by Strakaliva et al in 2004. The mice were given a 1% sucrose solution for three consecutive days, during which they were made to swim twice a day in cold water as a pre-stressful stimuli. After the last swimming session, the mice were given LPS from E.coli (450 μg/kg, i.p) and were deprived of food and water for 24 hours, consistent with the original protocol. The sucrose intake of the mice was then recorded for 12 hours, during which they were given access to two bottles, one containing 1% sucrose solution and the other with tap water. The weight differences of the bottles were used to calculate the consumption of sucrose using the formula: % sucrose intake = [sucrose intake (g)] × 100/[sucrose intake (g) + tap water (g)]. Prior to LPS injection, the animals were subjected to treatment with SSR240612, a selective kinin B1 receptor antagonist (10 mg/kg, p.o., 1 h), or the antidepressant imipramine (10 mg/kg, i.p., 30 min). Control animals were given saline solution using the same treatment schedule.",0
5,12,"To examine how swimming session followed by LPS treatment affects the locomotor activity, the animals underwent an open-field test [30] either 6 or 24 hours after being given endotoxin. The testing was carried out in a soundproof room with minimal lighting. The mice were placed in a 40 x 60 x 50 cm acrylic box and observed as they crossed the floor divided into 9 squares using all four of their paws. The recording of their movements was conducted for a duration of 6 minutes.",0
5,13,The temperature of the mouse's colon was measured with a Pro-check® thermometer that was coated in Vaseline and inserted approximately 0.5 cm into a mouse that was gently held by hand. The initial colon temperature was recorded at t = 0 and the body temperature of the mice was measured 6 or 24 hours after injection with LPS.,0
5,14,"Mouse hippocampi and cortex were harvested using a specialized device after euthanasia by decapitation at 1, 3, 6, and 24 hours after LPS injection. The Trizol reagent from Invitrogen was used to extract total RNA as per the manufacturer's instructions, and the concentration was measured by absorbance at 260 nm. For reverse transcript (cDNA) generation, 2 μg of total RNA were reverse transcribed using oligo(dT) as a primer (0.05 μg), Promega's 50 U of reverse transcriptase, Promega's dNTP (144 μM), reaction buffer [10 mM dithiothreitol (DTT), 3 mM MgCl2, 75 mM KCl, and 50 mM Tris-HCl, pH 8.3], and Promega's 2 U of RNAsin Plus, in a final volume of 12.5 μl. The cDNA was then obtained by warming the samples to 70°C for 5 min, cooling them to 4°C for 5 min, and then incubating them at 37°C for 60 min followed by 70°C for 5 min and a final round of cooling to 4°C for 5 min.",0
5,15,"Fluorescence-based real-time PCR was used to detect B1 receptor and BDNF mRNA expression. TaqMan-based chemistry with specific primers and FAM-labeled probes for mouse BDNF, B1 receptor, and GAPDH were used for amplification. The endogenous control for normalization was GAPDH. Amplifications were performed in a Thermalcycler for 50 cycles. The fluorescence was collected at each cycle, and the data were analyzed using the 2-ΔΔCt method for relative quantification. The target gene expression was normalized against conditions found in naive animals. Approximately 100 ng of cDNA was amplified in duplicates.",0
5,16,"Brain samples were fixed in a phosphate buffered saline solution with 4% paraformaldehyde after 24 hours of LPS treatment. These samples were then embedded in paraffin after undergoing standard histological procedures. CD68 antibody was used for immunohistochemistry to determine glial activity in the hippocampus sections that were cut at approximately 3 mm from bregma [2,31]. The slides were quenched with hydrogen peroxide and underwent high temperature antigen retrieval before being washed with PBS and incubated with a biotinylated secondary antibody. The Streptavidin-HRP reagent was processed according to the manufacturer's instructions, and sections were developed with DAB and counterstained with Harris's hematoxylin. Control and experimental tissues were prepared and processed under the same conditions.",0
5,17,"The Sight DS-5M-L1 digital camera was connected to a Nikon Eclipse-80i light microscope to acquire images. Image acquisition settings were the same for both control and experimental tissues. Four fields in the hippocampal sub-regions CA1, CA2, CA3, and DG were counted for CD-68 positive cells in mice using a 40X magnification.",0
5,18,"The animals were subjected to forced swimming and administered LPS from E. coli, as previously described. They were then euthanized at various time intervals after LPS administration (1, 3, 6, 12, and 24 hours) by decapitation. TNFa levels were measured in serum or whole brain using a standard sandwich ELISA technique following the supplier's recommendations (R&D Systems, USA). In the case of brain assays, the tissues were removed and placed in a PBS solution containing 0.05% Tween 20, 0.1 mM PMSF, 0.1 mM benzamethonium chloride, 10 mM EDTA, 2 μg/ml aprotinin A, and 0.5% BSA. The mouse brains were homogenized, followed by centrifugation at 3,000× g for 10 min, and the supernatant was used for ELISA analysis.",0
5,19,"CSF samples were collected from the cisterna magna of mice using a modified version of the method outlined by Liu and Duff. The mice were subjected to forced swimming and treated with LPS from E. coli, and were subsequently anesthetized and placed on a stereotaxic instrument. A sagittal incision was made below the occiput to aspirate the CSF using an insulin needle and a Hamilton syringe. The collected CSF was stored in an Eppendorf tube and frozen until use. Control samples were taken from naïve animals. Collection time points were at one, three, and twenty-four hours after treatment.",0
5,20,"The quantitative measurement of cytokines in the CSF was performed using the BD Cytometric Bead Array (CBA) and the CBA Mouse Inflammation Kit® from BD Bioscience in San Jose, CA. The assay simultaneously detected interleukin-6 (IL-6), interleukin-10 (IL-10), interferon-g (IFN-g), tumor necrosis factor alpha (TNFa), and interleukin-12p70 (IL-12p70). The medium range of 633 nm was used for flow cytometer readings with FACSCanto II red laser. The data were acquired using FACSDiva software and analyzed using FCAP Array software, both provided by BD Bioscience. The captured cytokines were detected using six different antibodies coupled to phycoerythrin (PE) via direct immunoassay. Standard curves were generated for each cytokine using the mixed cytokine beads standard provided by the kit with a concentration range of 20 to 5000 pg/ml. Five standard curves were plotted, and the concentrations of each CSF cytokine were determined using the MFI value of each cytokine with a four-parameter logistic curve fitting model. In cases where a sample had a cytokine concentration below the detection limit for the assay, a value of 0 was assigned for that concentration.",0
5,21,"Results for behavioral parameters and Elisa protocols were presented as the mean ± SEM of 6 to 8 animals, while results for real-time PCR, flow cytometry and immunohistochemical experiments were provided as the mean ± SEM of 4 independent experiments performed in triplicate. A one-way analysis of variance followed by Newman-Keuls post hoc test was conducted for statistical comparison between these values, and p values less than 0.05 (p < 0.05) were considered significant.",0
5,22,"The behavior of mice subjected to E. coli LPS administration after a swimming session is depicted in Figure 1a. According to the tail-suspension paradigm, depression-like behavior was exhibited by these animals over time. At 24 hours, there was a significant increase in immobility time (P < 0.01), which returned to control levels at 48 hours (P < 0.05). Imipramine, a popular antidepressant, decreased immobility time by 47 ± 16% (Figure 1a) in mice who had received it. B1 receptor antagonists R-715 (0.5 mg/kg, 30 min), SSR240612 (5 mg/kg, i.p., 30 min), and oral administration of SSR240612 (10 mg/kg, 1 h) all resulted in significant inhibition of LPS-induced depression-like behavior (Figure 1c), with inhibition percentages of 46 ± 6%, 33 ± 7%, and 30 ± 6%, respectively. However, FR173657 (30 mg/kg, i.p., 30 min), a selective kinin B2 receptor antagonist, did not significantly change immobility time in this model (P > 0.05; Figure 1b).",0
5,23,"The effects of LPS treatment on rodents have been extensively studied, and our research confirms previous findings. Administering E. coli LPS to mice (which had been forced to swim beforehand) led to a significant decrease in body temperature (as shown in Figure 1e), as well as a decrease in locomotor activity in an open-field arena. The reduction in locomotive activity was most pronounced six hours after LPS administration, but levels returned to normal after 24 hours (as seen in Figure 1f). Body temperature was also significantly reduced at the six-hour mark, but not at 24 hours. Interestingly, administering R-715 (at a dose of 0.5mg/kg) 30 minutes before the test did not significantly affect body temperature after 6 hours. We only used SSR240612 (which has good oral bioavailability) for subsequent experiments.",0
5,24,"The relationship between the effects of selective kinin B1 receptor antagonists and changes in B1 receptor expression in CNS structures was investigated by measuring B1 receptor mRNA expression in the hippocampus and frontal cortex of mice. After the mice were submitted to a session of forced swimming, they were given LPS administration. The results from quantitative real-time experiments showed a time-dependent, significant increase in B1 receptor mRNA levels in the hippocampus, which reached a peak at 1 h (about 2.5-fold increase) (Figure 2a). Similarly, in the cortex, this increase was almost 40-fold 1 h after LPS treatment (Figure 2b).",0
5,25,"Figure 3 shows that when mice were subjected to forced swimming prior to LPS treatment, there was a significant increase in CD68 immunoreactivity in the hippocampus, indicating higher glial cell activation. Interestingly, pre-treatment with the kinin B1 receptor antagonist SSR240612 (5 mg/kg, i.p.) 30 minutes before LPS administration almost completely inhibited CD68 labeling, whereas the antidepressant imipramine (10 mg/kg, i.p.) had no impact. These results suggest that imipramine and kinin B1 receptor antagonist have different mechanisms for achieving their antidepressant-like effects. Reduced expression of neurotrophic factors, such as BDNF, has been associated with depression. In our study, real-time PCR experiments revealed a significant reduction in BDNF expression in the hippocampus of mice subjected to our depression protocol, at both the 6- and the 24-hour time points (approximately 50% decrease). However, pre-treatment with the kinin B1 receptor antagonist SSR240612 (5 mg/kg, i.p.) 30 minutes before LPS administration had no significant effect on this parameter (Figure 4).",0
5,26,"The changes elicited by LPS were correlated with cytokine production by assessing levels of TNFa in the whole brain or mouse serum. The animals underwent a forced swimming session and were treated with E.coli LPS, resulting in a marked, time-dependent increase in TNFa production in brain or serum. TNFa levels peaked between 1 and 3 hours in serum and between 3 and 6 hours in the brain, returning to control values after 6 and 12 hours, respectively. CSF cytokines IL-6, IL-10, and IFN-g were below detection levels, while IL-12 concentration was similar to that observed in naïve animals. CSF TNFa levels peaked 1 hour after LPS injection and remained elevated until 3 hours later.",0
5,27,"We investigated the role played by TNFa in the depression-like behavior observed in our experimental paradigm due to its interrelation with B1 receptor upregulation. We used TNFa p55 receptor-deficient mice and found that the depression-like behavior caused by forced swimming plus LPS treatment was abolished in mice with genetic deletion of TNFa p55 receptors. We also observed that the increase of B1 receptor mRNA expression in mice submitted to forced swimming plus LPS treatment was completely absent in TNFa p55 receptor knockout animals. We used C57/BL6 mice and found that a dose of 1000 μg/kg of E. coli LPS was necessary to evoke a significant increase in immobility time in the tail-suspension test, comparable to that obtained with a 450 μg/kg dose in CF1 mice.",0
5,28,"In recent years, significant progress has been made in understanding the genetic, biochemical, and immunological factors involved in depression. Specifically, research has identified certain pro-inflammatory cytokines, including IL-6, IL-1b, and TNFa, as key molecules in depression-related behaviors following infection. These cytokines are believed to coordinate the body's inflammatory response to pathogens. In a study involving mice, administration of LPS after a swimming session led to reduced body temperature and locomotor activity, followed by an increase in immobility time in the tail suspension test - a depression-like behavior. Although sickness behavior is considered an initial normal response to infectious stimuli, depression-like states can persist even after the initial sickness has resolved.",0
5,29,"There has been no prior research linking kinin B 1 receptors with depression to our knowledge. Normally these receptors are not present in the peripheral nervous system but can quickly increase in response to stressful stimuli. However, they are present in the spinal cord and some brain structures including the cerebral cortex, hippocampus, thalamus, hypothalamus, amygdala, and choroid plexus epithelial cells. The role of kinins in the brain is not yet completely clear, but the presence of B1 receptors in the nervous system indicates a potential central role for them. This study aims to investigate the potential involvement of these receptors in the development of depression-like behavior due to pre-stressful and LPS stimuli.",0
5,30,"The antidepressant imipramine reduced the depression-like state observed in the tail suspension test, while B1 receptor antagonists were effective in inhibiting increased immobility. These findings suggest that B1 receptors play a role in depression-like behavior. In vivo experiments showed an increase in B1 receptor mRNA expression in the hippocampus and cortex of mice subjected to forced swimming plus LPS administration. This is the first demonstration that infection associated with a stressful stimulus might up-regulate B1 receptors in the CNS, leading to depressive behavior. The selective B2 receptor antagonist had no significant effect on immobility time in this paradigm.",0
5,31,"Functional data obtained from the tail suspension test was supplemented by results using the anhedonia paradigm of sucrose intake. SSR240612 was able to completely revert reduced sucrose consumption in LPS-treated mice, which is noteworthy because depression is often associated with anhedonic states. It was found that stressful forced swimming plus LPS administration decreased sucrose consumption in Swiss mice, a parameter that was reversed by the antidepressant imipramine, which adds to the reliability of the experiment. The B1 receptor antagonist R-715 did not significantly change sickness behavior-induced hypothermia. This suggests that blocking B1 receptors can reverse later depression-like symptoms without interfering with early sickness behavior coordinated mainly by cytokines.",0
5,32,"The CNS's major immunocompetent components include microglia and astrocytes, and their activation contributes to depression pathogenesis [43,47,48]. In mice, our data clearly show microglial activation following forced swimming and LPS treatment, evidenced by increased CD-68 immunostaining in the hippocampus 24 hours after LPS injection, when B1 mRNA levels return to baseline. Microglial activation due to various injuries results in the release of neurotoxic mediators, like pro-inflammatory cytokines [3,49]. The selective non-peptide B1 receptor antagonist SSR240612 virtually abolished CD-68 immunopositivity, although this parameter wasn't significantly altered by imipramine. Therefore, we suggest that B1 receptor antagonists' antidepressant-like effects are related to microglial activation inhibition, not imipramine's effects. These findings are significant and could lead to a better understanding of depression states, mainly those linked to infections.",0
5,33,"Depression is linked to changes in synaptic plasticity that lead to reduced BDNF function and other biochemical alterations. Stressful conditions can repress the BDNF gene, resulting in neuronal apoptosis in the hippocampus. Interestingly, BDNF infusion in certain brain regions can induce antidepressant-like effects in animal models. Many monoaminergic antidepressant drugs restore normal BDNF transcriptional levels. In our depression model, there was a sustained decrease in BDNF mRNA expression in the hippocampus for up to 24 hours. The selective B1 receptor antagonist SSR240612 did not significantly alter BDNF mRNA expression, despite preventing microglial activation. This suggests that SSR240612 has antidepressant-like activity through a different inflammatory pathway, rather than interfering with BDNF.",0
5,34,"Pro-inflammatory cytokines play a significant role in the development of depression. TNFa levels are elevated in patients with major depressive disorder, and treatment with TNFa antagonists improves symptoms and quality of life. The study confirmed the hypothesis by showing that LPS administration in pre-stressed mice results in an increase in TNFa levels in serum, CSF, and whole brain. The elevated TNFa levels in serum contribute to sickness behavioral changes, whereas the increased levels in the brain underlie depression-like behavior. The study also found an increase in TNFa levels in CSF.",0
5,35,"The communication pathway between the brain and immune system is supported by the presence of TNFa in the CSF. Macrophage-like cells in the circumventricular receptors produce proinflammatory cytokines when their toll-like receptors are activated. While cytokines cannot easily cross the BBB, the circumventricular organs lie outside it and cytokines could potentially enter the brain through volume diffusion or sites where the BBB is compromised. Kinins can also disrupt BBB functioning and lead to neuropathological conditions related to cytokine entrance into the brain, such as depression.",0
5,36,"Using TNFa p55 receptor-KO mice, we investigated the relevance of TNFa in our experimental paradigm. Our results revealed that both depression-like behavior and upregulation of B1 receptors induced by forced swimming plus LPS treatment were almost eradicated in TNFa p55 receptor-KO mice. Our group had previously established the significance of TNFa for B1 receptors upregulation [14-17]. Our study provides explicit experimental evidence that links the cytokine TNFa with the kinin B1 receptor upregulation in depression genesis. Moreover, the findings demonstrate that pro-inflammatory cytokine generation plays a vital role in LPS-induced B1 receptor upregulation, as previously demonstrated [14].",0
5,37,"Depression is considered a syndrome, and new research suggests that molecules released during peripheral inflammatory events may influence central factors controlling behavior. The involvement of kinin B1 receptors in depressive alterations seems to be related to microglial activation, with subsequent production of TNFa in the brain. A clinical trial with orally available selective B1 receptor antagonists may be a potential treatment for depression symptoms.",0
6,1,"Type I interferons (IFNs) have a crucial function in the innate immune response and the development of adaptive immunity in the fight against viral infections. The production of type I IFNs (IFN-a/b) [1, 2] is stimulated by viral infections, which in turn activates numerous IFN-stimulated genes (ISGs). These genes encode a range of antiviral proteins and cytokines, providing protection to the host from further viral infections [3, 4].",0
6,2,"In most mammalian nucleated cells, the main viral sensors are RNA helicases, retinoic acid-inducible gene I (RIG-I), and melanoma differentiation-associated protein 5 (MDA-5). These sensors can recognize viral single-stranded RNA (ssRNA) and double-stranded RNA (dsRNA). Toll-like receptor 3 (TLR3) can also recognize viral dsRNA in many cells. Once virus-derived nucleic acids bind to RIG-I, MDA-5, or TLR3, the transcription factor kappa B (NF-kB) interferon regulatory factor 3 (IRF-3) is activated, leading to IFN-b production in mammals.",0
6,3,"Despite the fact that host cells have developed multiple cellular signalling methods to detect and combat viral infection, viruses have mechanisms to evade these immune responses to varying degrees [7,11]. A multitude of viruses, for instance, have evolved methods to evade the IFN response by either inhibiting IFN synthesis or disrupting IFN functions [12].",0
6,4,"Research has demonstrated that the non-structural gene (NS) of influenza A viruses is accountable for the virus's ability to resist interferon (IFN) [13-16]. The NS gene that belongs to influenza A viruses contains the encoding for two proteins [17], one of which is a 26 kDa protein called non-structural protein 1 (NS1). This protein is formed through the translation of unspliced mRNA. The second protein, a 14 kDa nuclear export protein (NEP), earlier called NS2, develops after the translation of spliced mRNA [18].",0
6,5,"The NS1 protein prevents the activation of IFN-b [19,20] and hinders the functioning of various IFN-driven proteins like protein kinase R (PKR) and 2’-5’oligoadenylate synthetase (OAS) [21-23].",0
6,6,"The NS gene has two different pools of alleles, labeled A and B [24,25]. NS1 proteins have a 63-68% nucleotide identity and 66-70% amino acid identity between allele A and B. Allele A is more widespread and is the only subtype seen in mammalian-adapted strains. When comparing amino acid sequences between avian allele A and B viruses and human viruses, six amino acid motifs were found between human and avian allele A viruses, and 35 motifs were found between human and allele B viruses [26]. This indicates that allele B viruses have a greater difference from mammalian-origin viruses. Thus, the NS1 adaptation is a significant factor in the pathogenicity of avian influenza viruses in mammals.",0
6,7,"Based on our previous research, we discovered a correlation between amino acid differences in the NS1 protein and the varying pathogenicity of H10 avian influenza viruses in minks (Mustela vison). Further experiments utilizing polyinosinic-polycytidylic acid (poly I:C) stimulated mink lung cells showed that the NS1 protein of the influenza A virus isolated from minks (A/mink/Sweden/84 (H10N4)) had a greater impact on down-regulating type I IFN promoter activity compared to the NS1 protein from the prototype H10 virus (known as virus/N (A/chicken/Germany/N/49 (H10N7)). [27]",0
6,8,"The present investigation expands on our prior research by examining how the NS1 from diverse gene pools affects type I IFN promoter activity, IFN-b production, and the expression of IFN-b mRNA following exposure to poly I:C.",0
6,9,"We investigated the capacity of NS1 derived from ""mink/84"" and ""chicken/49"" to hinder the initiation of transcription of the IFN-b gene. To do so, we employed the ISRE-Luciferase model system and Poly I:C stimulation. This system depends on the expression of IFN and the resulting signaling from the IFN-a/b receptor, which prompts the expression of the ISRE reporter gene (luciferase). Although both NS1s displayed a noteworthy suppressive effect on luciferase activity, ""mink/84"" was much more potent, causing an average of 6.8 fold decline (85.3%) in A549 cells (Figure 1A). In comparison, ""chicken/49"" led to an average of 20.8% decrease in A549 cells.",0
6,10,"To determine whether the variation in inhibition of the IFNb promoter is caused by insufficient expression or difference in the NS1 proteins in A549 cells, western blot analysis was conducted to confirm the level of expressed NS1 proteins. Cells were lysed at various time points after transfection and the NS1 proteins from both constructs were expressed equally in high quantity. The level of allele A NS1 was comparable to that of allele B NS1 protein (Figure 1B). The western blotting revealed that the expressed protein from both “mink/84” and “chicken/49” was evenly accumulated in A549 cells and there was no noticeable difference between alleles in terms of NS1 production (Figure 1B). Therefore, the results suggested that the discrepancy in IFN-b induction in the presence of allele B NS1 protein was not due to differences in allele B NS1 protein expression and accumulation in the cells.",0
6,11,"It was uncertain whether the outcome was due to variations in the capacity to reduce IFN production or the impact on the ISRE transcription signaling path, or both. To resolve this, an ELISA was conducted to quantify IFN protein production.",0
6,12,"The protein IFN-b was found in the control cell medium after 2 to 4 hours of poly I:C stimulation, and it accumulated linearly in the cell culture supernatant. The highest levels in control cells were observed 16 to 24 hours post-stimulation. While low levels of IFN-b were secreted by cells transfected with different NS1s, there were significant differences between these NS1s, with ""mink/84"" virus producing at least 10 times less IFN-b than control cells. In these cells, IFN-b secretion reached its peak yield 8 hours after stimulation and then decreased rapidly. Conversely, cells expressing the NS1 protein of ""chicken/49"" were better producers of IFN-b, with a profile similar to the control cells. This suggests that in this system, NS1 suppresses IFN protein production rather than the signalling from the IFN receptor. (Figure 2A)",0
6,13,"In order to establish the cause of the decrease in IFN-b production, we evaluated the gene expression kinetics in A549 cells that were stimulated with poly I:C in the presence or absence of different NS1 proteins to assess if the IFN-b gene expression was being suppressed.",0
6,14,"In Figure 2B, IFN-b mRNA levels in the control cells increased throughout the experiment. This same pattern was observed in cells expressing the NS gene of ""chicken/49"" in Figure 2C. Transcript levels in the control cells were significantly higher 2 to 4 hours post-stimulation, reaching a plateau by the end of the experiment. Figure 2D shows that the NS1 protein of ""mink/84"" effectively suppressed IFN-b gene transcription in A549 cells 4 hours after stimulation. Transfection of plasmids carrying the NS gene of ""chicken/49"" resulted in increased levels of IFN-b mRNA, following a trend similar to the control cells.",0
6,15,The suppression of IFN-b gene transcription in A549 cells indicates that the NS1 protein of "mink/84" targets the induction of IFN. This was proven through RT-PCR analysis of the INF-b mRNA in stimulated A549 cells expressing NS1 of "mink/84" or "chicken/49".,0
6,16,"In order to evade host immune responses, influenza A viruses inhibit IFN-a/b expression or signalling to neighboring cells. This prevents the induction of an antiviral state through the stimulation of transcription from ISRE promoter-containing genes. The NS1 viral protein plays a crucial role in regulating innate immunity by inhibiting host immune responses through its two functional domains: an RNA binding domain and an effector domain. The effector domain interacts with cellular mRNA processing proteins, inhibits mRNA export and pre-mRNA splicing of host cell transcripts, and interacts with components of the nuclear pore complex and the mRNA export machinery. Meanwhile, the RNA binding domain binds to both single- and double-stranded RNA, inhibiting the activation and/or signalling of antiviral proteins, transcription factors involved in type I IFN and inflammatory cytokine signalling, and activators of mitogen-activated protein kinase.",0
6,17,"Our previous research has shown that the NS1 protein plays a crucial role in determining the pathogenicity of H10 avian influenza viruses in mink. To further investigate this, we utilized an expression plasmid system containing the ORF of NS1 from two avian influenza viruses, which differed in their pathogenicity levels in mink. These viruses also featured different NS alleles: one from A (""mink/84"") and the other from B (""chicken/49""). Analysis of the predicted amino acid sequences revealed 71 differences between the two NS1 proteins. However, important amino acid residues for NS1 protein function were found to be similar between the two, as previously identified in infected cells.",0
6,18,"There was a single difference found between the NS1 proteins of ""mink/84"" and ""chicken/49"", concerning the site responsible for interaction with the CPSF30 subunit. This interaction typically inhibits the processing of cellular premRNA at the 3' end. There are two domains involved in this function: one around residue 186 and the other around residues 103 and 106. The NS1 protein of ""mink/84"" had Glu186, Phe103, and Met106, while the NS1 protein of ""chicken/49"" had Tyr103. Mutations at these interaction sites were shown to drastically alter the NS1's ability to regulate host gene expression in a previous study.",0
6,19,"""Both NS1 proteins from ""mink/84"" and ""chicken/49"" exhibited a negative impact on the activation of the ISRE promoter, as observed through luciferase activity. However, the reduction was considerably stronger in cells transfected with the ""mink/84"" NS1 plasmid, resulting in an average decrease of 85.3% in A549 cells. In contrast, pNS-chicken/49 caused an average decrease of 20.8% in A549 cells. The precise mechanism underlying this interference remains unknown, but it may involve inhibiting IFN induction signals via RIG-I, MDA-5, or TRL-3, suppressing IFN mRNA processing, or affecting downstream effects of IFN receptor signaling or luciferase mRNA processing.""",0
6,20,"According to various studies, the N-terminal RNA binding domain present in the NS1 protein is responsible for blocking the virus-induced activation of IFN-b promoter. The NS1 protein's three-dimensional structure and its function of suppressing IFN-b promoter activation can be affected by the 71 amino acid differences between the two NS1 proteins.",0
6,21,"The study examined the induction of IFN-b promoter and its correlation with the production of IFN-b. The research team investigated the level of endogenous IFN-b mRNA and the amount of IFN-b secreted in the cell supernatant. The NS1 protein of “mink/84” was found to strongly suppress the expression of the IFN-b gene and secretion of IFN-b in the cell culture supernatant. Time course study revealed that IFN-b production had three distinct phases: an initial rapid increase, a peak, and a decline to lower levels. The production of IFN-b and mRNA transcripts during poly I:C stimulation revealed an early upregulation, with maximal yields observed at 16 to 24 h post-stimulation. A549 cells expressing the NS1 protein of “mink/84” showed an upregulation of IFN-b mRNA transcripts during the first 4 h post-stimulation. (Figure 2A)",0
6,22,"Further studies are needed to examine the precise molecular mechanism underlying this finding. To accomplish this, animal experiments may be essential, as well as techniques such as reverse genetics, genomics and proteomic tools that permit the comprehensive investigation of various parameters associated with the intricate interplay between NS1 and the host innate immune system.",0
6,23,"All the indications imply that the distinct abilities of nonstructural protein 1 (NS1) of influenza viruses, derived from allele A and B, are linked to their ability to inhibit the induction of IFN mRNA; however, the exact working mechanism is unclear. Additionally, the study outcomes establish that the function of NS1 protein from different genetic gene pools have an impact on the production of a vital cytokine, IFN-b.",0
6,24,"The interaction of NS1 with inducing pathways, either one or both, is possible. It is also possible that there is a blockage in mRNA processing. To study the latter, it is recommended to investigate another inducible gene that is not IFN-dependent.",0
6,25,"The NS1 constructs were tested twice for each experiment, and there were three independent experiments, with each experiment being executed on separate days, after setting up an assay protocol for different parts of the study.",0
6,26,"The NS1 sequences of influenza A viruses in the ""mink/84"" and ""chicken/49"" strains were amplified using the NS1Kpn 5' and NS1XhoI 3' primers. PCR mixes with a volume of 25 microliters were prepared, containing 1x Platinum Taq buffer, 200 μM dNTP, 2.5 mM MgCl2, and 3 μl cDNA (all from Invitrogen). The samples were then subjected to cycling conditions of annealing at 58°C for 60 sec, elongating at 72°C for 90 sec, and finally remaining at 8°C until later use, after being placed in a thermal cycler at 95°C for 2 min and cycled 35 times between 95°C for 20 sec.",0
6,27,"The PCR products, which were 690 bp in size, underwent digestion with Kpn and XhoI. They were then cloned into the mammalian expression vector pcDNA3.1 (Invitrogen, Carlsbad, CA, USA) at the Kpn and XhoI sites, resulting in two plasmids named pNS-mink/84 and pNS-chicken/49. These plasmids were verified to be intact through sequencing.",0
6,28,"The human adenocarcinoma type II alveolar epithelial cell line known as A549 cells (ATCC, CCL 185) were grown in a humidified atmosphere containing 5% CO2 at 37°C in Dulbecco’s modified Eagle medium (DMEM) supplemented with 10% FCS.",0
6,29,The A549 cells were used to assay transcriptional activity. Plasmids containing the NS gene of either "mink/84" or "chicken/49" were co-transfected with reporter plasmids that drove the expression of Firefly luciferase (pISRE-TA-Luc) (Invitrogen) under the control of the IFN-stimulated response element (ISRE). The pRen-Luc plasmid containing the Renilla luciferase gene (Invitrogen) was used as an internal control. The Renilla luciferase activity was used to standardize the activity of the reporter gene. The folds of luciferase activity expressed the inhibitory effect in cells expressing various NS1s.,0
6,30,"The plasmid transfection was carried out in six-well plates using FuGENE 6 reagent (Roche Molecular Biochemicals, Indianapolis, IN) and followed the manufacturer’s instructions. Preliminary experiments were performed to optimize the transfection efficiency. Cells were seeded into six-well plates at 1 × 10 5 cells per well one day prior to transfection, and the transfection group included six wells, with three of them treated with poly I:C and the other three mock-treated. Poly I:C stimulation was performed 24 hours after transfection of the pcDNA3.1/NS1 plasmid by adding 5 μg/ml poly I:C (mixed in 100 μl DMEM without serum) to the cells. After 24 hours, cells were harvested for luciferase assay using 300 μl lysis buffer for each well. Luciferase activities were measured using 20 μl of each sample according to the manufacturer’s protocol, and samples were kept on ice and centrifuged for 2 min at 14,000 × g before measurement to remove cell debris.",0
6,31,"All western blot transfections were executed following the same procedure and as previously stated. Cells were washed and lysed at various time points post transfection utilizing the Bio-Plex cell lysis kit (Bio-Rad Laboratories, Hercules, CA). After incubation and thawing-freezing steps, the lysates were centrifuged at 4500 rpm for 20 minutes. Protein quality and concentration were measured using Nanodrop ND1000 and SDS-polyacrylamide gel electrophoresis (SDS-PAGE) together with Coomassie blue staining. Following this, 50 μg of the cell lysate was separated by SDS-PAGE and transferred electronically onto PVDF membrane. Blocking buffer was subsequently applied to the membranes and NS1 and bactin proteins were identified using anti-NS1 polyclonal and anti-b-actin primary antibodies diluted in TBS-2% BSA at 4°C overnight.",0
6,32,"The VeriKine™ human IFN-beta sandwich ELISA kit (PBL interferon source, Piscataway, NJ, USA) was used to determine the concentration of IFN-b in stimulated A549 cell supernatants following the manufacturer’s instructions. The cell supernatants were collected at various timepoints post-poly I:C stimulations. Samples, standards, and blanks were incubated with microtiter strips, detection antibodies, and streptavidin conjugated to HRP. After incubation and washing steps, the TMB substrate solution was added to the wells, and the reaction was stopped by the addition of stop solution. The optical density was read using a microplate reader, and values for the samples were estimated from the standard curve.",0
6,33,"RT-PCR was utilized to examine the degree of IFN-b mRNA expression in Poly I:C-activated A549 cells while the housekeeping gene b-actin was used as a reference. Human IFN-b and b-actin mRNA-specific primer pairs were used for RT-PCR, generating a 550 bp product with IFN-b forward 5' GGCCATGACCAACAAGTGTCTCCTCC 3' and reverse 5' ACAGGTTACCTCCGAAACTGAGCGC 3', and b-actin forward 5' TGGGTCAGAAGGACTCCTATG 3' and reverse 5' AGAAGAGCTATGAGCTGCCTG 3'. A 25 microliter PCR-mix containing 1xPlatinum Taq buffer, 200 μM dNTP, 2.5 mM MgCl2, and 3 μl cDNA was used. The reactions underwent thermal cycling at 95°C for 2 min, followed by 35 cycles at 95°C for 20 sec, 63°C for 60 sec annealing, and 72°C for 90 sec elongation, and were kept at 8°C for later use.",0
6,34,"A549 cells were placed in six-well plates and then transfected with either pNS-mink/84, pNS-chicken/49 or an empty pcDNA 3.1 vector. After this, the cells were stimulated with a mixture of 5 μg/ml poly I:C in 100 μl DMEM without serum. For RT-PCR assays, RNA was taken from the cells at 0, 4, 8, 16 and 24 hours after being stimulated.",0
6,35,"RNA was extracted using TRIzol Reagent (Invitrogen) as per the manufacturer's guidelines. Subsequently, the RNA was treated with DNAse, and its quantity and purity were determined by measuring the OD260/280 using a Nanodrop ND1000 (Nanodrop Tec., Wilmington, DA, USA). The OD260/280 ratio of all RNA samples in water ranged between 1.9 and 2.1. For cDNA synthesis, 2 μg RNA was utilized, and Superscript II (Invitrogen) and oligo-dT primers (Invitrogen) were used in accordance with the manufacturer's instructions.",0
7,1,"Developing effective anticancer compounds is a fascinating challenge in cancer chemotherapy, and researchers globally are continuously seeking new leads. Prior research has extensively documented the anticancer properties of several substituted naphthalimides. Among these chemical compounds, Mitonafide and Amonafide have shown significant anticancer activity. However, despite undergoing Phase I-II clinical trials, both compounds had only limited success. Recently, researchers have identified promising antitumor activity in some new compounds of N-(2-chloroethyl) and N-(3-chloropropyl) naphthalimides. In their evaluation, they discovered that N-(2-hydroxyethyl) and N-(3-hydroxypropyl) naphthalimides had not yet been assessed for potential anticancer properties. As such, they conducted a study to evaluate their efficacy and concluded that 6-nitro-2-(3-hydroxypropyl)-1H-benz[de]isoquinoline-1,3-dione was the most effective compound in the series.",0
7,2,"Ten substituted 2-(2-hydroxyethyl) and 2-(3-hydroxypropyl)-1H-benz[de]isoquinoline-1,3diones (compounds 1a-j) (Figure 1) were synthesized using a standard procedure. Among these compounds, 1i was extensively studied. Mitonafide was a gift from Prof. M.F. Brana, University of San Pablo-CEU, Madrid, Spain, and anticancer drugs, propidium iodide, and annexin V-FITC detection kit (A2214) were purchased from Sigma-Aldrich Corporation, St. Louis, MO, USA.",0
7,3,"The human tumor cell lines used in this study were obtained from either the National Centre of Cell Science (NCCS), Pune, India, or the National Cancer Institute, Fredrick, MD, USA. The cell lines included Leukemia: acute lymphoblastic MOLT-4, promyelocytic HL-60; Lymphoma: histiocytic U-937; Breast: MCF-7; Neuroblastoma: IMR-32, SK-N-SH; Colon: 502713, COLO205, HCT-15, SW-620; Liver: Hep-2; Prostate: DU-145, PC-3 and Lung: A549. They were cultured in RPMI-1640 medium supplemented with 2 mM glutamine, 1% antibiotics, and 10% heat-inactivated fetal bovine serum (FBS) at 37°C in an atmosphere of 5% CO2/95% relative humidity in a CO2 incubator. Cell lines were routinely sub-cultured and trypsin (0.02%) was used for dislodging adherent type cells.",0
7,4,"For the MTT assay, compounds 1a-j were tested against U-937 and HL-60 cell lines using standard procedures. Additionally, compounds 1d and 1i were also tested on MOLT-4. Drug stock solutions were prepared in DMSO and serially diluted to obtain different drug concentrations. The final DMSO concentration ranged from 0.001% to 0.5%. Cells were seeded in 96-well plates and incubated with drug solutions for 96 hours. All vehicle controls contained the same concentration of DMSO. The plate was read at 540 nm, and IC50 values were calculated using Curvefit software. An IC50 value <10 μM is considered active according to the National Cancer Institute (NCI) protocol.",0
7,5,"The SRB assay method was used to evaluate the cytotoxicities of test compounds 1d and 1i against 11 human tumor cell lines, with the results shown in Table 2. Growth inhibition values of 50% or higher at a concentration of 1 × 10 -5M were considered active. Established anticancer drugs such as doxorubicin, 5-FU, cis-platin, BCNU, hydroxyurea, paclitaxel, and mitomycin C were also included for comparison, as listed in Tables 1 and 2.",0
7,6,"PBMCs were obtained from healthy human volunteers through heparinized venous blood and isolated using Ficoll-Paque density gradient centrifugation following the standard procedure [11]. PBMCs were cultured in complete RPMI-1640 media and treated with compounds 1d and 1i for 48 hours, followed by MTT assay. Curvefit software was used to calculate IC50 values.",0
7,7,"The impact of compound 1i on various stages of the MOLT-4 cell cycle was investigated using flow cytometry. MOLT-4 cells (1 × 10 6) were exposed to 10.0 and 16.7 μM of compound 1i for 24 hours and 5 μM of camptothecin for 3 hours. After being washed twice with ice-cold phosphate-buffered saline (PBS), the cells were gathered, fixed with ice-cold PBS in 70% ethanol, and then placed at -20°C for 30 minutes. After fixation, RNase A was used to incubate the cells at 37°C for 30 minutes, and they were then stained with propidium iodide for 30 minutes on ice in the dark. The DNA content was analyzed using a BD-LSR Flow cytometer, and data from 10,000 events were collected using Mod Fit 2.0 software (Figure 2).",0
7,8,"The MOLT-4 cells (1 × 106/well, 6-well plate) were subjected to the Annexin V-FITC/PI double staining method as per [13], after being incubated with 10.0 and 16.7 μM of compound 1i and 5 μM of camptothecin for 6 hr at 37°C (Figure 3). Additionally, a similar assay was conducted in HL-60 using another apoptosis detection kit (BD Biosciences Pharmingen, San Diego, USA). For this, HL-60 cells (5 × 105/well) were treated with compounds 1i, camptothecin, and cis-platin (10 μM concentration each) for 24 hr. The stained cells were processed following the manufacturer’s instructions and analyzed using Cell Quest software in a FACScan flow cytometer (Becton Dickinson, USA) at two wavelengths 515 and 639 nm. The controls used were unstained and stained [annexin V-FITC/PI] cells treated with vehicle (DMSO) (Figure 4).",0
7,9,"The colorimetric assay kit from R&D Systems, USA was used to measure the activities of caspase-3 and caspase-6 in MOLT-4 cells (2 × 106/ml) after they were incubated with compound 1i (3.3 16.7 μM) and camptothecin (5 μM) for different periods of time. A blank cell lysate control was also included, and the release of pNA through enzyme catalysis was monitored using a microplate reader at 405 nm (Figure 5A and 5B).",0
7,10,"MOLT-4 cells were treated with compound 1i (10 μM) in DMSO for varying time durations, while control cells received DMSO only (<0.5%). Both treated and control cells were washed with PBS, centrifuged, and fixed in 2.5% glutaraldehyde in 0.1 M phosphate buffer (pH 7.2) for two hours at 4°C. Subsequently, the pellets were post-fixed with 1% OsO4 in the same buffer for two hours, dehydrated with acetone, cleared in propylene oxide and embedded in Epon812. The morphology of the treated cells was observed at different time points under a light microscope (Olympus, Japan) after cutting semithin (1 μm) sections that were stained with toluidine blue. Photomicrographs were captured with an Olympus Digital Camera (C4000) (Figure 6). Ultrathin (60-90 nm) sections of silver color were cut on a LKB ultramicrotome IV, mounted on copper grids, and stained with uranyl acetate and lead citrate. These sections were viewed and photographed in a JEOL-100CXII electron microscope at 60 kV (Figure 7).",0
7,11,"S-180 tumor cells were kept alive inside Swiss albino mice and then used to incorporate 3H-thymidine and 3H-uridine, which had a specific activity of 1.0 mCi/ml each and were obtained from the Board of Radiation and Isotope Technology in Mumbai, India. This was done after treating the cells with compounds 1d and 1i at a concentration of 8 μM, which was previously described in [15]. Mitonafide was used at the same concentration for comparison.",0
7,12,"The mean ± S.E.M. (standard error mean) of three experiments were recorded for values. The experimental results underwent analysis through Student's t-test. For the values obtained for treated groups compared with the control group, a P value of less than 0.05 was deemed significant.",0
7,13,"In vitro tests were done to screen compounds 1a-j against U-937 and HL-60. It was discovered that compounds 1a-c, 1e-1h and 1j did not demonstrate effective activity as their IC50 values were greater than 10 μM. However, compounds 1d and 1i were cytotoxic, with IC50 values ranging from 0.7 to 6.0 μM in U-937, HL-60 and MOLT-4. These values were much lower than those of the reference compounds (doxorubicin, 5-FU, cis-platin, BCNU, and hydroxyurea), indicating stronger antitumor qualities for compounds 1d and 1i. As a result, further screening was done on human tumor cell lines, with compounds 1d and 1i being the chosen ones. The study found that compound 1d showed significant growth inhibition in two out of six cell lines tested, while compound 1i had significant growth inhibition in five out of ten cell lines tested (SK-N-SH; 502713, SW-620, DU-145, and PC-3). Overall, compound 1i was seen as the most potent member. All of this data is summarized in Tables 1 and 2.",0
7,14,"Compounds 1d and 1i demonstrated notable IC50 values of 698 and 273 μM, respectively, against human PBMC in vitro, indicating insignificant cytotoxicity against normal cells.'",0
7,15,"MOLT-4 cells treated with compound 1i at 10.0 and 16.7 μM for 24 hours had an increased sub-G1 fraction implying activation of cell death mechanisms. This effect was more noticeable at the higher concentration. Control and camptothecin-treated cells had sub-G1 fractions of 0.68% and 11.92%, while compound 1i had sub-G1 fractions of 4.69% and 21.02% at low and high concentrations, respectively (Figure 2). This suggests that compound 1i induces apoptosis in a dose-dependent manner. Cell cycle analysis also showed an increase in S and G2/M phases. The increase in S phase could be due to DNA synthesis stimulation or delay in cell movement from the S to G2/M phase. The increase in G2/M phase implies that daughter cells are delayed in exiting the mitotic cycle, leading to a reduction in tumor cell number due to a delay in cell turnover.",0
7,16,"The MOLT-4 and HL-60 cells were divided into control and treated groups, then stained with annexin V-FITC/PI and sorted into LR and UR quadrants, which represented early and late apoptotic cells, respectively. The percentage of cells in LR and UR quadrants was summed to determine the extent of apoptosis. Cells in LL and UL quadrants were classified as live and necrotic, respectively. The induction of apoptosis by compound 1i was compared to that of camptothecin (Figure 3) and camptothecin and cis-platin (Figure 4), which were used as standards. The untreated control MOLT-4 and HL-60 cells showed apoptosis rates of 3.61% and 2.54%, respectively.",0
7,17,"In MOLT-4 cells, camptothecin induced 8.89% total apoptosis at a concentration of 5 mM. However, compound 1i was more effective at inducing apoptosis with percentages of 27.54% and 30.86% at 10.0 mM and 16.7 mM concentrations, respectively. At these same doses, compound 1i also resulted in necrotic cell populations of 5.15% and 4.80%, respectively, as shown in Figure 3.",0
7,18,"Compound 1i displayed a much stronger ability to induce apoptosis in HL-60 at a dose of 10 μM, resulting in 98.62% cell death (with a lower range of 3.49% and upper range of 95.13%). In contrast, both camptothecin and cisplatin only managed to achieve 15.82% and 7.51% apoptosis respectively at the same dose. These results demonstrate that compound 1i is more effective than typical standards when it comes to inducing apoptosis in HL-60, as showcased in Figure 4.",0
7,19,"Treatment with compound 1i resulted in a significant increase in both caspase-3 and caspase-6 activities in MOLT-4 cells, confirming the occurrence of apoptotic cell death. Caspase-3 up-regulation was observed to be highest at 5.0 μM concentration, 12 hours after treatment, while caspase-6 activity peaked at the same concentration 24 hours after treatment. These effects were similar to those observed with camptothecin at 5.0 μM concentration. Figure 5a-b provides a graphical representation of these findings.",0
7,20,"The appearance of MOLT-4 cells was observed using light microscopy after being treated with compound 1i at concentrations of 5 and 10 μM for varying time periods. As the concentration of the compound and the incubation time increased, more apoptotic cells were observed. Figure 6b shows the characteristic features of apoptotic cells after incubating at a concentration of 10 μM for 36 hours, including chromatin margination, cell shrinkage, nuclear condensation/fragmentation, and cytoplasmic vacuole formation, which indicate apoptosis. Control cells, shown in Figure 6a, had larger nuclei with nucleoli.",0
7,21,"In the context of transmission electron microscopy, control cells of MOLT-4 were found to have a high ratio of nucleus to cytoplasm, with nuclear pores and nuclei that had finely dispersed chromatin. The mitochondria, rough endoplasmic reticulum, and ribosomes were visible in various sizes and shapes, including elongated and oval cristae (MC). Most cells had visible nucleoli. However, MOLT-4 cells exposed to 10 μM of compound 1i for 36 hours showed damaged mitochondrial cristae and significantly reduced rough endoplasmic reticulum, indicating apoptosis. No inflammation was observed in the nuclei and cytoplasm, and there was no evidence of necrotic events due to the absence of damage in the plasma membrane. There was vacuolization in the treated cells- observations that have been similarly reported in the scientific literature [16, 17].",0
7,22,"Studies were performed to determine if compound 1d and 1i, which share structural similarities with mitonafide, could inhibit tumor growth by inhibiting nucleic acid synthesis. To test this, tumor cells collected from mice were treated with the compounds and the amount of 3H-thymidine and 3H-uridine incorporation was measured. The untreated cells demonstrated linear incorporation patterns, but exposure to the compounds at 8 μM resulted in significant inhibition of both nucleic acids, comparable to that of mitonafide at the same concentration. After 1 hour of incubation, compound 1d and 1i inhibited 3H-thymidine incorporation by 96% and 95%, respectively, whereas mitonafide inhibited incorporation by 95%. The compounds demonstrated marked inhibitory effects on DNA synthesis, while inhibition of RNA synthesis was less spectacular.  3H-uridine incorporation was inhibited by 92%, 94%, and 89% for mitonafide, compound 1d, and 1i, respectively. (Figure 8).",0
7,23,"The importance of a substituent's nature and position on a molecule's antitumor property has been established. In this study on substituted N-(hydroxyalkyl)naphthalimide, five different substituents (R = H, 6-Br, 6-Cl, 6-NO2, 5-NO2) in the aromatic ring portion were considered. It was found that the 6-NO2 substituent is crucial in exerting antitumor activity, which aligns with previous findings on other (chloroalkyl) naphthalimide compounds where 6-nitro-2-(3-chloropropyl) naphthalimide was the most effective agent. [7].",0
7,24,"Compound 1i exhibited significant antitumor activity and was found to interfere with the S and G2/M phases of the cell cycle in MOLT-4 cells. The S phase is essential in preparing for cell division through DNA duplication. The flow cytometric measurements indicated that compound 1i hindered the S phase, thereby affecting DNA duplication of tumor cells before mitosis. This possibility was confirmed in S-180 cells where compound 1i inhibited 3 H-thymidine incorporation into DNA, indicating the suppression of DNA synthesis. Additionally, it also inhibited 3H-uridine uptake, concomitantly limiting RNA synthesis. These results suggest that the antitumor activity of compound 1i was attributed to the inhibition of DNA and RNA synthesis.",0
7,25,"Observations from flow cytometry revealed that treatment with compound 1i resulted in a delay in exit from G2/M, the final phase of the cell cycle, in MOLT-4 cells. This delay can occur when there are defects in DNA damage repair, spindle attachment to centromeres, and polymerization of spindle microtubules. Consequently, the compound seems to have a negative impact on the mitotic apparatus by up-regulating spindle checkpoint control, which causes a delay in the mitotic exit of daughter cells. Studies have shown that vinca alkaloids and paclitaxel create antitumor effects by interfering with spindle microtubules, and it is possible that compound 1i exerts a similar mechanism of action.",0
7,26,"Apoptosis or programmed cell death is a common mechanism for several antitumor agents to combat cancer (source 21). In the case of Compound 1i, its antitumor action is also carried out through this pathway. This can be confirmed from the increase in sub-G1 fraction, the morphological evidence of apoptosis from light and electron microscopic studies, and the significant rise in caspase 3 and 6 levels in treated cells. There are various cell signals that control apoptosis, which may be generated intracellularly through the mitochondria or extracellularly via death receptors located on the cell's membrane. These two pathways eventually converge and create an irreversible execution phase enabled by caspase 3 and 6. It is unclear whether the pro-apoptotic signal caused by Compound 1i activated the intrinsic (mitochondrial) or extrinsic (death receptor) pathway. However, damage to the mitochondrial cristae in treated cells was observed, as seen in the ultrastructural study, implying that Compound 1i probably activates the mitochondrial pathway. Similar findings were reported for many naphthalimides, including amonafide and its analogs (source 22, 23).",0
7,27,"The study revealed that compound 1i displayed remarkable antitumor properties against murine S-180 tumor cells and a range of human tumor cell lines in vitro. This outcome was due to the inhibition of cell proliferation and promotion of programmed cell death. Furthermore, as the compound didn't induce any cytotoxic effects on normal human PBMC, it has the potential to be developed as an antitumor agent.",0
8,1,"Erlotinib, which falls under the epidermal growth factor receptor (EGFR) tyrosine kinase inhibitors (TKIs), has proven to be active and relatively well tolerated in elderly patients with advanced non-small cell lung cancer (NSCLC) who have not undergone chemotherapy [1]. As per studies, image-guided stereotactic body radiotherapy (SBRT) and helical tomotherapy (HT) with hypofractionation is feasible and well tolerated for patients with early-stage medically inoperable NSCLC [2]. Similarly, for stage III NSCLC, hypofractionation has been observed to yield equivalent survival rates while avoiding often fatal symptomatic pneumonitis, as opposed to conventional radiotherapy [3]. Furthermore, the addition of standard-dose erlotinib to chemoradiotherapy is possible without increasing toxicity [4]. However, there is limited data on fatal pulmonary toxicity due to irradiation pneumonitis when erlotinib is given concurrently with SBRT and then used as maintenance therapy for NSCLC.",0
8,2,"The patient, an elderly man of 77 years, was diagnosed with stage IIIA NSCLC with cT2N2M0. A chest CT revealed a soft tissue mass of size 4 × 3.9 cm in the right upper lung, accompanied by mediastinal lymphadenopathy. The level of carcinoembryonic antigen (CEA) was elevated to 12.9 mg/dl. He was initially treated with oral erlotinib 150 mg/day but after three months, the level of CEA increased to 29.1 ng/ml. Therefore, erlotinib was concurrently administered with radiotherapy - 54 Gy given in nine fractions provided with SBRT using HT, at 95% of the prescribed isodose for the planned target volume. The prescribed split courses were three fractions per week. Targeting was conducted based on new CT scans for each split course. (Refer to Figure 1 and 2)",0
8,3,"In the first treatment course, the tumor volume was 116.1 ml and the right lung volume was 1282.9 ml while in the second treatment course, the tumor volume was 90.9 ml and the right lung volume was 1475.9 ml. Table 1 shows the V15 and V20 which represent the percentage of lung volume that received at least × Gy [5], along with the mean lung dose. The whole-course V20 and mean lung dose for the total lung were 10% and 10.24 Gy, respectively. The tumor shrank from 4 × 3.9 × 4.5 cm to 2.4 × 2.9 × 2.1 cm after 2.5 months of combination therapy, and erlotinib 150 mg/day was prescribed for maintenance therapy. However, the patient developed dyspnea three months later and was transferred to the medical intensive care unit. Image studies revealed opacities of a diffuse ground-glass pattern, subpleural bleb formation in the marginal areas, airspace consolidation, and fibrosis in bilateral whole lung fields, which were indicative of radiation pneumonitis. Despite receiving empirical antibiotics, steroid therapy, antioxidant, and supportive treatment, the patient died of respiratory failure four months after the combined therapy.",0
8,4,"Image-guided SBRT with hypofractionation and HT for early-stage, medically inoperable NSCLC has been shown to be feasible, with equivalent survival rates and no fatal pneumonitis observed when compared to conventional radiotherapy. Belderbos et al. reported safe radiation dose escalation up to 94.5 Gy in 42 fractions, with a mean lung dose of 13.6 Gy or less. Using LQ modeling, the equivalent dose for hypofractionation was determined to be 6 Gy per fraction (EQD6), with acute and late normal tissue effects equivalent to 72 and 54 Gy, respectively. Careful monitoring of the V20, V15, and mean lung dose can help prevent radiation pneumonitis. The Radiation Therapy Oncology Group 0236 protocol demonstrated safe and effective treatment when V20 was restricted to less than 10% to 15%. Table displays the V15, V20, and mean lung dose for each separate lung by divided course.",0
8,5,"Erlotinib is a type of EGFR TKI that has shown to be effective in treating NSCLC in elderly patients. While it can be used as a single agent in certain cases of advanced NSCLC, studies have found only a small percentage of patients developed interstitial lung disease when taking erlotinib. Additionally, when combined with chemoradiotherapy, erlotinib did not increase the risk of toxicities. However, it's important to note that prior tissue damage from radiation therapy may impact the response to erlotinib. Some studies have found that erlotinib can enhance radiation responses, including cell cycle arrest, DNA damage repair, and apoptosis induction, which may lead to altered cell responses when erlotinib is used after radiation.",0
8,6,"Although HT combined with SBRT can limit normal tissue exposure to high levels of radiation, there is a potential risk of harmful low-dose radiation affecting non-target organs at risk, such as the lungs, and causing toxicity. Recent research has shown that arc therapy may further exacerbate this phenomenon due to the low dose bath effect, which can be compounded by the presence of other agents known or unknown to cause recall effects. Additionally, both low-dose irradiation and the use of anticancer drugs can affect the pharmacokinetics of each other, which could lead to adverse effects even in off-target areas. In particular, studies have shown that EGFR inhibitors may enhance both the positive and negative effects of radiation, leading to issues like symptomatic pneumonitis and radiation recall dermatitis. This suggests that caution should be exercised in patients receiving concurrent treatment with radiation and EGFR inhibitors.",0
8,7,This is the inaugural report of erlotinib-associated radiation pneumonitis that arises with the combination of image-guided SBRT via HT with hypofractionation trailed by erlotinib for maintenance. Physicians should be mindful of the likelihood of serious lung toxicity that could occur as a result of this combined treatment. Any radiotherapy combined with targeting agents should only be carried out under well-structured clinical trials.,0
8,8,Consent for publishing this case report and its accompanying images was obtained from the patient's family through a written informed consent. The Editor-in-Chief of the journal can review a copy of the written consent.',0
9,1,"Classical swine fever virus, a member of the genus Pestivirus in the Flaviviridae family, causes highly contagious classical swine fever in swine and wild boars. CSF viruses are divided into three major groups and ten subgroups by genetic typing. Recent phylogenetic analyses suggest a shift in the virus population from historical group 1/3 to recent group 2 in many European and Asian countries. Notably, all live-attenuated vaccine strains belong to group 1, including the Chinese lapinized vaccine strain (C-strain) which has been used since 1954. Recent studies indicate that subgroup 2.1 strains have emerged in China, branching away from the vaccine C-strain.",0
9,2,"E2, which is the primary envelope glycoprotein on the surface of the virion, plays a crucial role in initiating virus attachment and entry into host cells, as well as determining cell tropism. This particular glycoprotein has been identified as a key virulence determinant and can also prompt the production of neutralizing antibodies that can provide protective immunity to pigs. The antigenic structure of E2 has been mapped using monoclonal antibodies, revealing two distinct antigenic units in the N-terminal half of the protein. Although the C-terminal half doesn't significantly impact antibody binding, the first six conserved cysteine residues and the antigenic motif 771LLFD774 are both essential components of E2's antigenic structure.",0
9,3,"The extensive study of genetic diversity of E2 among different groups has been done, indicating that the antigenic units could be under positive selection due to constant exposure to high immunologic pressure. The N-terminal half of E2 is more variable than the C-terminal half, and different patterns of reactivity with mAbs provided clues of antigenic variation of E2 among different CSFV isolates. Studies using neutralizing mAbs to select mAb-resistant mutants showed that single point mutations could lead to complete loss of mAbs binding. Variability by one or more amino acids within antigenic units may result in the antigenic variation of E2. All studies that attempted to resolve antigenic variation of glycoprotein E2 utilized mouse mAbs, and no attempt has been made to probe the antigenic variation or group-specific antigenic determinants using anti-CSFV sera from the pig, the natural host of CSFV.",0
9,4,"In this research, pig antisera were utilized to analyze the degree of antigenic variation within antigenic units of glycoprotein E2 by raising it against CSFV vaccine C-strain and a representative subgroup 2.1 strain QZ-07. To determine whether the antigenic variation of E2 leads to differences in cross-neutralization, rabbit polyclonal and mouse monoclonal antibodies were developed against recombinant E2 (rE2) protein from C-strain. Furthermore, a chain of variant C-strain rE2 proteins that contain single replacements based on amino acid variations between the C-strain and group 2 isolates were used to define residues that contribute to E2's antigenic variation.",0
9,5,"Prokaryotic-derived truncated rE2 proteins have been utilized in various applications such as antigen production, antigenic domain identification, and epitope mapping. In this particular study, two types of truncated rE2 proteins were expressed by E. coli Rosetta(DE3) cells, namely rE2-BC (aa 690-814) and rE2-AD (aa 690-865). The former covered N-terminal 123 residues known as the necessary antigenic domain for binding to pig anti-CSFV serum, while the latter contained both antigenic units B/C and A/D. Additionally, western blotting demonstrated that both proteins of the vaccine C-strain had the appropriate molecular weights of 20 and 25 kDa, respectively, and reacted strongly with pig anti-C-strain hyperimmune serum. As a result, prokaryotic-derived rE2 proteins were deemed appropriate for generating monoclonal and polyclonal antibodies, as well as for antibody binding assessments.",0
9,6,"To evaluate how different the E2 antigen is between the subgroup 1.1 C-strain and subgroup 2.1 field isolates, they analyzed the respective rE2-AD proteins using ELISA with antisera obtained from pigs at different time intervals after vaccination with the C-strain vaccine or infection with strain QZ-07. As shown in Figure 2, every serum had a much stronger reaction with the rE2-AD protein of the homologous strain (used to generate the serum) than the heterologous strain. Moreover, Figure 3 compares the binding efficiency of anti-C-strain and anti-QZ-07 sera (gathered at 78 days post immunization with the C-strain and 25 days post infection with strain QZ-07, respectively) to rE2AD proteins produced from C-strain and 8 subgroup 2.1 strains. The homologous binding efficacy was put at 100%, and the anti-C-strain serum revealed considerably poor binding efficiency to subgroup 2.1 rE2-AD proteins (less than 60% efficiency). The binding of anti-Q7-07 serum to the C-strain rE2-AD protein was even less effective (less than 20% efficiency), and the band on the blot was barely visible. The binding of anti-QZ-07 serum to heterologous subgroup 2.1 proteins was diverse.",0
9,7,"The pig antiCSFV sera showed that heterologous neutralization was less effective in a two-way neutralization analysis, especially with sera collected at the early days following vaccination or infection (Figure 4). The efficiency of neutralization also varied between subgroup 2.1 strains QZ-07 and HZ1-08. As variation in strains affects the ability of antisera to neutralize heterologous viruses, we investigated whether variation of glycoprotein E2 affects CSFV cross-neutralization. A rabbit antiserum and three monoclonal antibodies were raised against C-strain rE2-AD protein. The rabbit antiserum neutralized the QZ-07 virus less efficiently than the C-strain. Furthermore, mutagenesis of cysteine residues in the antigenic unit B/C affected the reactivity of mAbs 1E7 and 6B8 to E2, but not of mAb 2B6. These results indicate that cysteine residues are involved in the structural conformation of E2 and that mAbs 1E7 and 6B8 bind to conformational epitopes. Though mAb 2B6 only bound to C-strain, its neutralization efficiency was low. (Table 2).",0
9,8,The identification of the amino acid residues that cause the observed changes in antigenicity was done by aligning E2 sequences of 108 CSFV strains representing each cluster obtained from GenBank. The analysis revealed twenty significant variable residues in the antigenic units. The extent of variability of these residues between vaccine strains and group 2 representative strains is shown in Table 3.,0
9,9,"We performed site-directed mutagenesis to switch out amino acids in C-strain E2 protein with those seen in subgroup 2.1 proteins (as listed in Table 3, second to last row). Using binding ELISA, we assessed the binding of wild type and variant C-strain rE2 proteins to C-strain and strain QZ-07 antisera. The wells of plates were coated with equal amounts of proteins and the antibodies were saturated to prevent limiting antibody concentration. The wt C-strain rE2 protein binding served as a control at 100%. None of the substitutions altered the binding of the variant rE2 proteins to antiC-strain serum significantly (with binding efficiency between 80% and 130%), indicating that individual residues did not play a major role in the protein's overall binding to antibodies (as shown in Figure 5A). However, thirteen substitutions did result in increased binding of variant C-strain rE2 proteins to anti-QZ-07 serum (i.e., over 150% binding efficiency threshold). Substitutions of D705N, L709P, G713E, N723S, or S779A led to a significant increase in binding efficiency (over 200% threshold), whereas a mild increase was noted with D725G, N729D, N777S, T780I, D847E, M854V, T860I, or N863K substitution (with efficiency between 150% and 200%).",0
9,10,"The residues that led to notable or moderate improvement in the binding efficiency were divided into three separate clusters within the antigenic units, as shown in Figure 1A. The first group was located at the N-terminus of antigenic unit B/C, specifically at amino acid positions 702-731. The second cluster was situated at the boundary that separates the two antigenic units, spanning positions 774-799. The third and final cluster was in the C-terminus of antigenic unit A/D, covering positions 841-864. Interestingly, the analysis of hydrophilicity revealed that these regions contributed to the significant hydrophilic differences between the CSFV C-strain and strain QZ-07, as illustrated in Figure 5C.",0
9,11,"To gain more understanding about the evolution of antigenic units, the codon and amino acid diversity was examined using a variant Simpson's index. The results, depicted in Figure 6, reveal that thirteen residues linked to antigenic variation (as shown in Figure 5 and Table 3) are highly diversified due to a large accumulation of nonsynonymous mutations in their codons. These residues fall along the diagonal (x = y). However, the six cysteine residues and the residues in the 771LLFD774 motif exhibit high conservation, even though their codons have accumulated a moderate number of synonymous mutations. Consequently, they lie along the x-axis. Conversely, the antigenic residues revealed by the analysis of mAb-resistant mutants are mapped as having a random distribution (Figure 6).",0
9,12,"Phylogenetically, CSFV consists of three major groups, and recent studies have shown a shift in viral populations from historical groups 1 or 3 to group 2 in most European and Asian countries. The E2 glycoprotein, which is a principal target of neutralizing antibodies and an important immunogen, differs both genetically and antigenically in the three groups. Despite this variation, the molecular basis for it has yet to be clearly demonstrated.",0
9,13,"The data indicates that pig anti-C-strain and anti-QZ07 sera do not bind heterologous rE2-AD proteins as efficiently compared to homologous proteins, suggesting antigenic differences. Additionally, the E2 protein of vaccine C-strain is distinct from other subgroup 2.1 strains. This antigenic variation was also observed among subgroup 2.1 strains. The study further confirms previously reported antigenic differences detected by mouse mAbs in the context of pig anti-CSFV sera.",0
9,14,"The efficiency of antibody binding to rE2 proteins was tested through neutralization experiments in order to determine if it correlated with the ability to block CSFV infection. The results showed that pig anti-CSFV sera and rabbit polyclonal antibodies were less efficient at neutralizing heterologous strains, and two conformational anti-C-strain-rE2-AD mAbs had lower binding and neutralization efficiency against heterologous strains compared to C-strain. These differences suggest that antigenic variation in E2 glycoproteins may explain why subgroup 2.1 CSFV strains persist in China despite the use of vaccine C-strain, and antibody selection may be a factor in the switch of viral populations from group 1 to 2.",0
9,15,"Using site-directed mutagenesis, we introduced amino acid substitutions in the C-strain rE2 proteins to investigate whether variable residues (listed in Table 3) contribute to the observed antigenic variation in subgroup 2.1 strains. No significant effect on binding to anti-C-strain serum was found for any of the substitutions except for mutations in the antigenic motif 771LLFD774 that disrupted the structural integrity of E2 protein. This suggests that the recombinant proteins were not grossly misfolded and the substituted residues might not be crucial for the structural stability of glycoprotein E2. On the other hand, out of the 20 substitutions, 13 enhanced the binding of the variant C-strain rE2 proteins to anti-QZ-07 serum, with the most significant increase observed for the GtoE substitution at aa position 713. Interestingly, sequence alignment showed that all group 2 strains have residue 713E, while all vaccine strains have 713G, indicating that 713E is a common antigenic determinant for both groups 2 and 3. It was also recently reported that residues 713E and 729D are critical for the specificity of a group 3.4 field strain rE2 protein to mAbs.",0
9,16,"Our findings indicate that residue 729D was beneficial for binding to pig anti-QZ-07 serum, but residues 705N, 709P, 723S, and 779A had a more significant impact (Figure 5A). Of note, these same residues are present at positions 705 and 723 on E2 proteins of subgroup 2.1 and subgroup 3.4 strains. It is possible that these two residues may play a crucial role in the antigenicity of subgroup 3.4 glycoprotein E2 if examined with pig antisera against group 3 strains. In this study, we employed polyclonal sera from pigs that were infected with a field strain or immunized with the C-strain, which resulted in a full range of antibodies created as a result of immunization or infection. This is why these polyclonal sera were capable of uncovering more residues responsible for glycoprotein E2 antigenic variation than mouse mAbs [35]. Additionally, using a combination of polyclonal antisera against the group 1 C-strain and representative group 2 field strain allowed us to detect the residues responsible for antigenic variation between these two groups, which is yet another advantage over mAbs.",0
9,17,"According to the site-directed mutagenesis analysis (Figure 5A), it is not surprising that there is antigenic variation among subgroup 2.1 strains since each of the 8 strains used in this study has unique strain-specific substitutions (data not shown). The substitution of C737R in strain QZ2-06 affects binding the most, likely due to the critical role of the cysteine residue at this position for the antigenic structure of the protein. The E782V substitution in strain HZ1-08 may be the determinant of antigenic variation between this strain and the reference subgroup 2.1 strain QZ-07, as speculated.",0
9,18,"Three distinct areas of antigenicity within the E2 protein have been identified at amino acid positions 702-731, 774-799 and 841-864, as shown in Figure 1A. The 702-731 region appears to be the primary driver of antigenic variation, as evidenced by the clustering of antibody-resistant mutants and epitopes with increased binding in this area. The 774-799 region contains both a conserved antigenic motif (771LLFD774) and a linear epitope (772LFDGTNP778) that contribute to the overall integrity of the E2 antigenic structure. Substitutions at positions N777S, S779A, and T780I within this region have also been found to enhance binding to anti-QZ-07 serum, suggesting multiple functions for the 774-799 region in determining E2 antigenicity.",0
9,19,"We used E2 sequences of CSFV for comparative analysis of codon and amino acid diversification with respect to antigenic evolution. To quantify this diversity, we adopted a variant Simpson's index, previously used for influenza virus hemagglutinin glycoprotein. Our analysis revealed that the diversity of both codons and amino acid residues was equal for each of the thirteen residues associated with antigenic variation. This observation suggests a strong correlation between the genetic and antigenic evolution of the E2 glycoprotein in natural conditions. However, the antigenic residues identified by analysis of mAb-resistant mutants showed random diversification, indicating that in vitro selection may not be a valid explanation for natural selection in pigs. Along with extensive vaccination, co-diversification of codons and amino acids could be a mechanism adopted by CSFV to evade the immune system under immune pressure.",0
9,20,"This research displays how the glycoprotein E2 in CSFV can vary between the vaccine C-strain and group 2 field strains or even within the same group of strains currently circulating in China. The main determinants of this variation were substitutions found in the first region (aa 702-731) of the three identified regions. These substitutions affect cross-neutralization of CSFV, and further research is needed to determine whether these residues contribute to the observed differences in neutralization. The results of this study could be useful for the development of new serological assays and CSF vaccines that are more effective and immunogenic.",0
9,21,"ST cells were cultured in MEM supplemented with 10% FBS. Three CSFV strains were used, including the subgroup 1.1 vaccine C-strain from Zhejiang Jianliang Biological Engineering Company and two subgroup 2.1 strains (QZ-07 and HZ1-08) isolated from naturally infected pigs and replicated in the laboratory. The viruses were sequenced for the E2 gene and their stocks were stored at -80°C. The E2 genes of the other six subgroup 2.1 strains were cloned without isolation. Sequence data is available in GenBank and detailed molecular phylogenetic relationships can be found elsewhere. Table 3 lists the strains in GenBank.",0
9,22,"E2 sequences covering the entire antigenic region were obtained from the NCBI database and aligned using Clustal X software. Sequences with 100% nucleotide identity were removed, and the resulting dataset included 23, 82, and 3 sequences for groups 1, 2, and 3, respectively. This dataset was used to identify significant variable residues (as listed in Table 3) and to assess the codon and amino acid diversity (shown in Figure 6).",0
9,23,"Plasmids containing the complete E2 gene of the C-strain vaccine and eight subgroup 2.1 strains were utilized in this study and were previously described. Two primer sets, C-E2-AD-f/C-E2-AD-r and C-E2BC-f/C-E2-BC-r, were used to amplify the fragment covering the two antigenic units (B/C+A/D) and the fragment only containing antigenic unit B/C. Another primer set, QZ-E2-AD-f/QZ-E2-AD-r, was used to amplify fragments covering the two antigenic units of group 2 isolates listed in Table 1. The PCR products were digested with BamHI and XhoI restriction enzymes, gel purified, and then ligated into the prokaryotic expression vector pET-30a(+). To create the eukaryotic expression plasmid, a 1212-bp cDNA fragment that encoded the signal sequence and complete E2 of the C-strain was amplified and cloned into pcDNA3.1 after being digested with BamHI and XhoI.",0
9,24,"E. coli Rosetta (DE3) cells harboring various recombinant plasmids were grown until they reached an optical density between 0.6 and 0.8 at 600 nm. His-tagged rE2 proteins were induced by adding 1 mM isopropyl-b-D-thiogalactoside (IPTG, Sigma-Aldrich). The cells were then ruptured by sonication and centrifuged, and the inclusion bodies containing rE2 proteins were resuspended in 1/10 volume of a buffer containing 100 mM NaH2PO4·2H2O, 10 mM Tris-base, and 8 M urea. The supernatant was collected through centrifugation and purified according to the manufacturer's protocol using a Ni-NTA affinity column (Novagen, Madison, WI). Finally, the proteins were refolded by washing the column with 40 ml of Tris-buffered saline (TBS, pH 7.4) containing 1 M urea and eluted with 200 mM imidazole in TBS. The purified rE2 proteins were verified by Western blotting with mouse monoclonal anti-His-tag antibody (Sigma-Aldrich) and quantified using the Bradford assay.",0
9,25,"The laboratory previously prepared the pig hyperimmune serum for the CSFV vaccine C-strain, which was stored. The pig anti-C-strain and pig anti-QZ-07 were induced in CSFV-free pigs through intramuscular immunization with the attenuated vaccine C-strain and infection with 10 5 TCID50 of strain QZ-07 in a biosafety level III facility using a prime-boost strategy. The sera collected at different times post-vaccination or infection were stored at -80°C until use, and the highest titers of collected sera were used for binding ELISAs and Western blots in Figure 3A, 3B, 5A, and 5B, taken at 78 days post immunization with the C-strain and 25 days post infection with strain QZ-07 as shown in Figure 2.",0
9,26,"The production of rabbit antiserum to the rE2-AD protein of C-strain involved immunizing New Zealand white rabbits with 0.5 mg of purified rE2-AD protein of C-strain (expressed in E. coli) emulsified with complete/incomplete Freund’s adjuvant (Sigma-Aldrich). The rabbits were immunized and boosted twice, and once the maximum level of antibody production was reached, blood was drawn for antiserum preparation.",0
9,27,"For the production of monoclonal antibodies targeting the rE2-AD protein of C-strain, female specific-pathogen-free BALB/c mice aged 5 weeks received subcutaneous immunization of 0.1 mg purified rE2-AD protein of vaccine C-strain emulsified in complete Freund’s adjuvant. The mice subsequently received two intraperitoneal boosts of the protein emulsified in incomplete Freund’s adjuvant at 2-week intervals. After 2 weeks from the last boost, spleen cell harvest was carried out following the euthanasia of the mice. The harvested splenocytes were fused with SP2/0 myeloma cells using 50% polyethylene glycol. Through selection via immunofluorescence assay (IFA), hybridomas that secrete antibodies against rE2AD were selected, and then further clonally expanded. Antibody subtyping was carried out using mouse mAb Isotyping Reagents based on manufacturers’ instructions from Sigma-Aldrich. Ascites were then produced in pristine-primed BALB/c mice, and the animal experiments were approved by the Laboratory Animal Management Committee, who is responsible for upholding animal welfare ethics.",0
9,28,'The C-strain E2 gene in eukaryotic expression plasmid had its cysteine codons mutated to serine codons through site-directed mutagenesis as previously explained [22] to determine the antigenic units detected by mAbs.',0
9,29,"A series of procedures involving E2 sequence alignment and identification of variable residues was conducted. The antigenic units were analyzed and 20 major variable residues were identified, but KtoR or StoT substitutions were not counted among them. To exchange C-strain residues with those from group 2 isolates, individual mutations listed in Table 3 were incorporated into plasmids using site-directed mutagenesis. Depending on the location of the residue being substituted, the antigenic unit B/C or two units (B/C+A/D) of C-strain E2 protein were utilized.",0
9,30,"The QuikChange Site-Directed Mutagenesis Kit (Stratagene CA, USA) was utilized to perform all substitutions as per the manufacturer’s guidelines. The primers were developed using the QuikChange Primer Design Program found on http://www.stratagene.com. Each mutant's intended nucleotide modifications were validated via sequencing. Expression and purification of variant rE2 proteins were conducted as previously stated.",0
9,31,"All ELISAs were performed in triplicate to prevent non-specific reactions. Antibodies were diluted in phosphate-buffered saline (PBS) with nonfat dry milk and washed with PBS containing Tween 20. The rE2 proteins were added to 96-well microtiter plates and incubated overnight. The wells were then washed, blocked, and incubated with different antibodies. Afterwards, it was incubated with horseradish peroxidase and chromogenic substrate. The reaction was stopped and the OD450nm was measured using a microplate reader.",0
9,32,"The efficiency of the rE2-AD proteins from C-strain and 8 subgroup 2.1 strains binding to two pig antisera was standardized to the anti-His-tag binding and then presented as the proportion of antibody bound to each group 2 rE2-AD protein to that of C-strain or strain QZ-07, which was designated as 100%. Three separate ELISA tests were performed, and the average binding effectiveness of each protein was measured.",0
9,33,"The C-strain rE2 proteins in Figure 5A were substituted with rE2-BC proteins for A692S, D705N, E706K, L709P, G713E, N723S, D725G, N729D, S736I, V738T, T745I, N777S, S779A, T780I, R788G, and S789F substitutions as these residues are in the antigenic unit B/C. For D847E, M854V, T860I, and N863K substitutions which are in the antigenic unit A/D, rE2-AD proteins were used. The results were normalized to anti-His-tag binding and expressed as the ratio of their binding to the antibodies to that of binding to C-strain wild type rE2-BC or rE2-AD binding to the reference serum depending on the variant protein being compared. A relative binding of greater than 200% efficiency was significant, between 150% and 200% efficiency was moderate, and between 50% and 150% efficiency was considered to have limited effect on antibody binding.",0
9,34,"The antigenic reactivity of various rE2 proteins was evaluated via Western blotting. The proteins were separated by a 15% SDS-PAGE and then transferred to nitrocellulose membranes obtained from PALL Corp., USA. The next step involved blocking the membranes overnight at 4°C using blocking buffer (PBS/NFDM) before incubating them with diverse antibodies at 37°C for one hour. Following the incubation, the membranes were rinsed in PBS/Tween for 20 minutes, and then SPA-conjugated with horseradish peroxidase diluted at 1:2500 was used to detect bound antibodies. 4-chloro-1-naphthol (4-CN, SigmaAldrich) was used to facilitate color development.'",0
9,35,"The virus neutralization assay was used to determine the neutralization indices (NI) of antibodies against different CSFV strains. ST cells were seeded in 96-well plates and incubated overnight at 37°C. Different heat-inactivated sera were serially diluted two-fold and mixed with equal volumes of 100 TCID 50 virus suspensions. After 1 hour of incubation at 37°C, the mixture was transferred to ST cells in 96-well plates. The starting dilution of each serum was 1:50. Glycoprotein E2 was detected by immunofluorescence assay at 72 hours post-infection. The NI value is the log10 of the antibody dilution factor that protects 50% of the wells from infection. The detection threshold of the neutralization assay was 1.7 since the starting dilution factor was 50.",0
9,36,"Immunofluorescence assay (IFA) was employed for confirming the reactivity of CSFV strains or cysteine-mutated E2 proteins with distinct antibodies. In brief, cells which were either infected with CSFV strains at 72 h or transfected with cysteine-mutated recombinant plasmids at 48 h were fixed at room temperature for 60 min in 3.7% paraformaldehyde and permeabilized for 10 min by using 0.1% Triton X-100 in PBS. Post this step, the cells were incubated with different antibodies for 1 h, and subsequently stained with goat anti-rabbit antibody conjugated with Texas green or goat antimouse antibody conjugated with Alexa red (Molecular Probes Inc., USA) for another 1 h. Finally, an IX71 inverted fluorescence microscope (Olympus, Japan) was employed to examine the cells.",0
9,37,"Hydrophobicity profile was generated through the method of Kyte and Doolittle [44], using DNASIS software. Meanwhile, Plotkin and Dushoff's [41] information-theoretic method was utilized to perform an evolution analysis. To quantify the diversity of codons and amino acids found at each residue, a variant Simpson's index D = 1-pi2 was plotted against the relative frequency pi of the i-th codon or amino acid in the multiple sequence alignment.",0
10,1,"Breast cancer has both genetic and nongenetic causes. Genome-wide association studies have led to the identification of several common genetic susceptibility variants, such as single nucleotide polymorphisms (SNPs) at FGFR2, LSP1, MAP3K1, TOX3, MRPS30, COX 11, SLC4A7, and at chromosomes 8p24 and 2q35. The only SNP that has been associated with breast cancer risk with genome-wide statistical significance (P < 10 -7 ) from candidate gene approaches is CASP8. There is some equivocal evidence for SNPs in TGFB1 and ESR1, among others.",0
10,2,"Determining how common SNPs combine with other known risk factors is crucial in understanding the influence on breast cancer risk. These risk factors include age at menarche, parity, age at first birth and body mass index (BMI) [8,9]. By doing so, risk prediction models [10,11] can be improved. Additionally, identifying modifications of SNP associations by other risk factors can shed light on genetic variants' role in breast cancer etiology. Moreover, it has been observed that many of these SNPs and risk factors have differential associations with estrogen receptor (ER)-positive and ER-negative disease [1,4,5,7,12,13], and interactions between them may differ by disease subtype.",0
10,3,"The aim of our study was to evaluate the effect modification of 12 SNPs, out of which 10 were already linked to breast cancer risk, and the remaining 2 had less clear evidence. We considered several potential effect modifiers such as age at menarche, live births, BMI, and evaluated these interactions in susceptibility to different subtypes of breast cancer based on ER and PR status. We combined data from 21 case-control studies of white women of European ancestry who participated in the Breast Cancer Association Consortium (BCAC).",0
10,4,"Table 1 provides a brief description of the 21 case-control studies that participated in the pooled BCAC analysis, while more detailed information can be found in Additional Data Table S1 in Additional file 1. Out of these, 11 were population-based studies, and seven had at least 1,000 cases and 1,000 controls. Case and control self-reported data were collected on various factors such as age, race/ethnicity, BMI, age at menarche, and number of live births, with the time-point of assessment provided in Additional Data Table S1. Notably, information on additional risk and lifestyle factors were not available during the analysis, except for the CNIO-BCS and LMBC studies, which relied on medical records for their data. Finally, information on ER and PR tumor status was available for a subset of cases in 19 studies, with data mostly taken from medical records.",0
10,5,"Methods for genotyping have been previously explained in various studies, including five that utilized the MassARRAY system and iPLEX technology by Sequenom for most SNPs. Other genotyping was performed using Taqman® Assays-byDesignSM. It has been reported that SNP CASP8-rs17468277 is in complete linkage disequilibrium with CASP8-rs1045485, which has been linked to breast cancer. Measures were taken to ensure accuracy, including at least one blank well per assay plate, duplicates of at least 2% of the samples, and a common set of 93 samples from the Centre d’Etude Polymorphisme Humain (CEPH) that were utilized by the HapMap Consortium. Samples that repeatedly failed were excluded from the call rates and duplicate concordance rates calculated, both of which were greater than 95%. The concordance with CEPH genotypes was greater than 98%.",0
10,6,"Genetic associations for each of the 12 SNPs were analyzed by logistic regression, estimating odds ratios (ORs) and 95% confidence intervals (CI) for the risk allele assuming multiplicative per-allele effects (refer to Table 2). Logistic regression was used to assess the main effects of risk factors in the 11 population-based studies, with adjustments for age (categorical and continuous) and study (categorical). Risk factors evaluated include age at menarche (categorical and continuous), live birth history (yes or no), number of live births (categorical and continuous), age at first birth (categorical and continuous), and BMI (categorical and continuous).",0
10,7,"Given that BMI has been shown to have different associations with breast cancer risk in premenopausal and postmenopausal women, we looked at the impact of BMI separately for women aged below 55 years (considered as premenopausal) and those aged 55 years and above (postmenopausal). To do this, we used logistic regression models that adjusted for appropriate risk factors and included dummy variables to examine the per-allele odds ratios (ORs) for SNPs. We did not present estimates obtained using a younger age limit (50 years) since these were similar to those obtained using the age categories as surrogates for pre- and post-menopausal status.",0
10,8,"Logistic regression models were used to evaluate the interaction or alteration of genetic associations by other risk factors. Each model consisted of dummy variables for the study and three parameters: one for the per-risk-allele effect, one for the primary risk factor effect (all modeled as continuous variables, except for ever having had a live birth), and one for the interaction term, which is the product of the number of risk alleles and the value of the risk factor. A likelihood ratio test was performed to compare this model with and without the interaction term to test the statistical significance. In addition, the effect modification by BMI was analyzed separately for women who were age <55 and ≥55 years.",0
10,9,"A method called parametric bootstrap test was utilized to compute interaction P-values adjusted for multiple testing. For all 72 interactions tested, the team determined the probability of being a case for each subject based on the logistic regression model incorporating only main effects. To be exact, study (categorical), SNP (per-allele), and risk factor (continuous, except ever having had a live birth) were taken into account. Each bootstrap replicate included generating a dummy case-control status for each subject and fitting the interaction model mentioned above. The minimum P-value was recorded for 10,000 replicates, and adjusted P-values were calculated as the proportion of replication P-values below the corresponding unadjusted P-value. [15]",0
10,10,"The statistical analyses were conducted using Stata, Release 10 (Statacorp, College Station, TX, USA) [16], except for power calculations, which were performed with Quanto (University of Southern California, Los Angeles, CA, USA) [17,18].",0
10,11,"The sample included 26,349 cases and 32,208 controls of self-reported white European race/ethnicity from 21 participating studies. All participants had available data for at least one of the 12 SNPs considered and one of the other risk factors considered. Out of these, 17,603 cases from 18 studies were interviewed within two years of their breast cancer diagnosis, while 29,187 controls came from the same 18 studies. Roughly 46% of cases and 38% of controls were under the age of 55. Additionally, the ER and PR statuses were known for 19,561 and 16,962 cases, respectively. The details of the study are provided in Table 1. Overall, 12,822 cases and 19,703 controls with minimal data were included from 11 population-based studies, and 16,107 cases and 23,140 controls with minimal data were included from seven studies with at least 1,000 cases and 1,000 controls.",0
10,12,"The risk factors expectedly showed associations with breast cancer in population-based studies, except for one. With age and study adjustment, a 4% decrease in breast cancer risk was associated with each one-year increase in age at menarche, and parous women had a 16% decreased risk. Each additional live birth was linked to an 11% decreased risk for parous women, while a 7% increased risk was associated with every five-year increment in age at first birth. Obesity (BMI ≥ 30.0 kg/m^2) was linked to a 20% lower risk of breast cancer among women under 55 years old. The only unexpected observation was that obesity was not associated with breast cancer risk in women aged 55 years and older (OR = 0.96, 95% CI 0.88 to 1.04).",0
10,13,"Table 2 displays the per-allele ORs and their corresponding 95% CIs for the 12 SNPs examined in this study. It provides data for all included participants with genotype information as well as for subgroups of women categorized by the four risk factors being analyzed. The ORs for all groups were adjusted for study, and those for subsets were additionally adjusted for age and the relevant risk factor. The overall ORs and those for subsets were similar, indicating that there was no confounding by the risk factors or bias in OR estimates due to data availability.",0
10,14,The per-allele OR for the majority of SNP/risk factor combinations was not found to vary by category of the risk factor. These results were consistent across all studies and when analyses were restricted to population-based studies and those with high case and control numbers. Restricting analyses to studies with cases interviewed within two years of breast cancer diagnosis had little effect on the results. Results were also null when analyses were limited to ER-positive and ER-negative or PR-positive and PR-negative breast cancers. These findings are detailed in Additional Data Tables S2 to S8 in Additional file 1.,0
10,15,"The association between 11p15-rs3817198 (LSP1) and breast cancer risk may be modified by the number of live births a woman has had, with a stronger effect observed in women who have had four or more live births. This trend was seen in population-based studies and in studies with at least 1,000 cases and 1,000 controls. The interaction was significant for ER-positive and PR-positive breast cancer, but not for ER-negative and PR-negative breast cancer. However, since multiple tests were performed, the possibility of chance cannot be ruled out as an explanation for these results. The multiple-test-adjusted P-value for this specific interaction was 0.12, while all other interactions tested had adjusted p-values of ≥0.61.",0
10,16,"The post-hoc power calculations indicated that our study had 90% power at a significance level of 0.0007 to detect interaction ORs of at least 1.06, with the exception of the CASP8-rs17468277 locus, for which the minimum was 1.08. The study could also detect interaction ORs of at least 1.08 and 1.10 for BMI and the more common variants, respectively. For parity, the study had similar power to detect interaction ORs of at least 1.20 for the CASP8-rs17468277 locus and 1.16 for the other loci when considering live birth history.",0
10,17,"According to the analysis of over 25,000 cases and 30,000 controls, there is no conclusive evidence that factors such as age at menarche, parity, age at first birth, or BMI impact the established associations of breast cancer risk with various genetic variants. These variants include 10q26rs298158 (FGFR2), 8q24-rs13281615, 11p15-rs3817198 (LSP1), 5q11-rs889312 (MAP3K1), 16q12-rs2803662 (TOX3), 2q35-rs13387042, 5p12-rs10941679, 17q23rs6504950, 3p24-rs4973768, and CASP8-rs17468277. Additionally, there is no evidence that these factors impact potential associations with TGFB1-rs1982073 or ESR1rs3020314. These findings also hold true for disease subtypes defined by ER and PR status.",0
10,18,"The most compelling evidence of effect modification was found for the number of live births and a specific gene variant known as 11p15-rs3817198 (LSP1). However, the observed trend of increasing relative risk with increasing parity was not statistically significant once multiple testing was taken into account. It is important to note that the interaction odds ratio (OR) was only 1.05 per allele and per live birth, meaning that the estimated per-allele OR only increased from 1.04 for women with one child to 1.24 for women with four or more children, for a single nucleotide polymorphism (SNP) with an average OR of 1.08 across all levels of parity. The weak interactions observed here would only lead to very small differences in joint effects estimates when compared to models that assume multiplicative effects. This finding highlights the challenge of detecting modifying effects of this size in very large studies.",0
10,19,"A recent study conducted by Travis et al. found no interaction between breast cancer susceptibility, 9 genetic loci, and 10 risk factors, including age at menarche, BMI, parity, and age at first birth. This null result was replicated in our study, which had a larger sample size of women over age 50 and also included women under 50. Our study expanded on Travis et al.'s research by evaluating genetic loci such as 17q23rs6504950, 3p24-rs4973768, and ESR1-rs3020314, which were not originally included. Additionally, we used a more strongly associated SNP (rs10941679) for the susceptibility locus at 5p12 instead of rs981782. Lastly, Travis et al. found no evidence of interaction between 11p15rs3817198 (LSP1) and number of children.",0
10,20,"One advantage of the BCAC is the extensive sample size acquired through international collaboration. This has been beneficial in either confirming or ruling out association with breast cancer for common SNPs discovered through GWAS and candidate gene studies. The consortium has also been able to provide precise estimates of the odds ratios associated with susceptibility alleles, with consistency observed between the numerous studies that participate in the group, despite the range of study designs utilized. However, because multiple studies that recruited selected cases and/or volunteer controls were included, the primary effects of some risk factors may not be appropriately evaluated across the whole cohort. Nevertheless, potential selection bias in estimating primary effects should not affect the assessment of interactions. Nonetheless, we carried out sensitivity analyses considering only data from population-based studies and only data from studies with at least 1,000 cases and 1,000 controls and observed no significant change in the results obtained regarding interactions.",0
10,21,"Our study's limitation comes from the fact that there were varied data collection methods across studies. Structured questionnaires were used in all studies, except for two which were not population-based. These questionnaires were administered through various means such as in-person interviews, phone interviews or self-administration. However, while some heterogeneity in data collection methods may have affected our results for BMI, other measurements such as age at menarche, ever having had a live birth, number of live births and age at first birth should be reliable despite these variances. We did conduct standardized measurement within studies and adjusted for study as a covariate to limit any systematic bias. We also excluded cases interviewed before or more than two years after their breast cancer diagnosis and obtained similar results, indicating that varying reference times for BMI reporting did not affect our study. Nonetheless, we did find our study's limitation in not collecting information on hormone therapy (HT) use to evaluate interactions between SNPs and BMI in older women.",0
10,22,"Through the largest collaborative analyses of gene-environment interactions that have been carried out so far, it has been observed that there is no conclusive evidence for the modification of per-allele relative risk associated with common breast cancer susceptibility variants by age at menarche, parity, age at first birth or BMI. The results are in line with the findings of a recent smaller prospective study. Therefore, the combined effects of these common susceptibility alleles and other established risk factors are assumed to be multiplicative in risk predicted models for breast cancer.",0
11,1,"Anopheles funestus is the primary carrier of malaria in the southern African region. According to early research, it was responsible for transmitting the Plasmodium falciparum parasite at an alarming rate of 22% in South Africa [1]. However, in more recent studies, the infection rate has dropped to 11% in Tanzania [2] and 5% in southern Mozambique [3].",0
11,2,"An extensive indoor residual spraying campaign using DDT in the 1950s resulted in the eradication of An. funestus in South Africa. This species was only recorded once during a small malaria outbreak in the north of the country over the next 50 years. However, in 1999/2000, An. funestus reappeared during the worst malaria outbreak since the use of IRS. It was found in northern KwaZulu/Natal, just south of Mozambique, with a P. falciparum parasite rate of 5.4% and resistance to both pyrethroids and carbamates.",0
11,3,"According to later studies conducted in southern Mozambique, it was revealed that the group of An. funestus with insecticide resistance expanded beyond the capital Maputo [7-9]. The latest research indicated that this resistance is also present in An. funestus from Chokwe [10], located about 200 kilometers north of the capital, even though this group was once believed to be susceptible [8].",0
11,4,"Evidence of insecticide resistance in An. funestus has been discovered in an island located in Lake Malawi, which is significantly farther north compared to any previous records of resistance.",0
11,5,"A survey was conducted on Likoma Island in Lake Malawi (12°04’S, 34°44’E) from 10 - 14 May 2010 (Figure 1) to collect data on mosquitoes. The island is made up of several rocks, and the residents mainly engage in fishing and small-scale subsistence farming, living in scattered homesteads. The researchers searched a large number of houses for mosquitoes but were mostly unsuccessful. However, they discovered a significant population of An. funestus in a few houses near a small area where rice was being grown.",0
11,6,"Mosquitoes were captured while at rest indoors using a hand-held aspirator. A portion of the specimens were promptly employed for WHO susceptibility trials, whereas the remainder were packaged and transported to Johannesburg to procure egg clusters. These eggs were subsequently nurtured into F-1 adults.",0
11,7,"To identify the species, the procedures outlined by Koekemoer et al. [11] and Scott et al. [12] were employed for the An. funestus group and An. gambiae complex respectively. Enzyme-linked immunosorbent assay (ELISA) [13] was used to examine malaria parasite infection in female specimens from the wild.",0
11,8,"In order to determine the efficacy of insecticides, the WHO [14] standard test kits and treated papers from the WHO Collaborating Centre in Penang, Malaysia were utilized for conducting insecticide susceptibility tests. The insecticides tested and their corresponding discriminating doses are presented in Table 1 and 2.",0
11,9,"One hundred and eleven female An. funestus from the wild with unknown ages were assessed for resistance to insecticides in field conditions without regulating temperature or humidity. Approximately 6 female An. gambiae complex mosquitoes, along with over 120 female and male An. funestus, and a small number of An. gambiae larvae, were collected and transported to a laboratory in Johannesburg.",0
11,10,"A total of 223 An. funestus were tested using molecular assays, which included all wild adult mosquitoes used in susceptibility tests (n = 111), as well as live females brought back to the laboratory for egg laying (n = 112). Out of the total, 97.3% were successfully identified as An. funestus s.s. (five specimens did not amplify a PCR product and one specimen was identified as An. funestus-like). All males and females in the An. gambiae complex, including both wild adults and those that were reared from larvae (n = 89), were identified as An. arabiensis.",0
11,11,"Out of the 81 female An. funestus that were examined for the presence of parasites, 4.9% tested positive for P. falciparum through the ELISA technique.",0
11,12,"The results of the initial tests carried out on the island involve insecticide susceptibility. Wild female An. funestus of unknown age was used, and the outcomes are shown in Table 1. To correct the results, Abbott's formula [14] was used as the controls yielded >5% mortality. The results showed 77.8% mortality on deltamethrin and 56.4% on bendiocarb. Furthermore, the field papers were checked in the laboratory with a susceptible An. gambiae colony, and all samples and replicates (n = 100 for each insecticide) showed 100% mortality.",0
11,13,"The laboratory performed the second cycle of insecticide susceptibility tests, using 1-5 day old An. funestus females that were pooled from around 120 egg batches, and conducted the experiment at 25°C and 85% RH. They tested nine insecticides from each of the four categories, and the test outcomes can be found in Table 2.",0
11,14,The susceptibility tests could not be conducted in a significant way since there were only 42 female specimens of An. arabiensis that were bred from larvae.,0
11,15,"The difference in deltamethrin susceptibility tests between wild females in the field and laboratory reared F-1 progeny, aged 1-5 days old (p <0.005), can be explained in two ways. Firstly, exposure to high temperatures can affect the survival of mosquitoes, causing high mortality rates in field samples. Secondly, An. funestus may exhibit age-dependent susceptibility to this sub-class of pyrethroids. As the survey was conducted at the end of the transmission season, it is likely that aging wild-caught females in the field were more susceptible to insecticides. However, Hunt et al. report that blood-fed, mated females did not show any decrease in resistance over time, and aging wild populations are likely to be mated and have had several blood meals.",0
11,16,"It is evident from the susceptibility findings that a plan for resistance management is necessary to tackle malaria on Likoma Island. To control resistance, pyrethroid treated bed nets should be distributed extensively, accompanied by IRS with an organophosphate or DDT. However, carbamates cannot be used due to their high survival frequency. An. funestus seems entirely susceptible to DDT, suggesting that DDT could be used for IRS in rotation with one of the organophosphates.",0
11,17,"The island already has a high usage of bed nets, which vary in age and effectiveness. Despite their availability, many residents do not use them consistently. To implement a bed net and IRS combination approach successfully, education and monitoring of net usage is crucial. When mosquito populations decrease, some individuals may abandon net use. Additionally, fishermen may repurpose nets for their livelihood. (Refer to Figure 2 for more information.)",0
11,18,"The discovery of pyrethroid and carbamate resistance in the An. funestus population approximately 1,500 km north of its current known distribution in southern Mozambique is the most worrying aspect of this survey (Figure 1) [10]. An earlier report by Casimiro et al. [9] in 2006 showed that An. funestus had greater than 95% mortality to pyrethroids and carbamates in central Mozambique. While this percentage of susceptibility requires further investigation per the WHO criteria, it is unlikely that a control program would change its policy based solely on this frequency of resistance/susceptibility.",0
11,19,"Likoma Island, situated in Lake Malawi and nearby Mozambique, potentially introduces mosquitoes through wind or boats to its mainland. The resistance of An. funestus population in Northern Mozambique must also be considered, hindering current malaria control efforts in the region. Similar to the southerly populations, both pyrethroid and carbamate resistance is present in the Likoma population, spreading through gene flow in An. funestus populations as opposed to genetic mutation events. The lack of physical barriers to gene flow suggests that resistance will progress northwards into southern Tanzania and westwards into Zambia and Zimbabwe. Conversely, the resistance found in An. funestus from Uganda differs from that observed in southern African populations. This variation is apparent in susceptibility tests and molecular characterization of P450 genes.",0
11,20,The rapid spread of insecticide resistance in An. funestus in southern Africa is a serious issue that this paper emphasizes. There is an urgent need for resistance management strategies within malaria vector control programmes in the region.',0
12,1,"Angiogenesis is the generation of new blood vessels from existing ones, which is firmly managed by specific molecules that either stimulate (proangiogenic factors) or suppress (antiangiogenic factors) the process. However, solid tumors exhibit abnormal hyperactivity of angiogenesis due to hypoxia or a lack of oxygen. To conquer the lack of oxygen and nutrients after reaching a specific burden, almost all solid tumors eventually trigger angiogenesis. Vascular Endothelial Growth Factor (VEGF-A), created by tumor cells after identifying low oxygen levels, is one of the most essential mediators of hypoxia-induced angiogenesis. VEGF-A expression may also be caused by non-hypoxia-mediated initiation, such as Ras signaling.",0
12,2,"VEGF-A, which is overexpressed in most solid tumor types, is a crucial player in tumor-induced angiogenesis. Its effect is mediated by its cognate receptors VEGFR1 and VEGFR2, present in endothelial and bone marrow-derived cells. The VEGF pathway is a major target for blocking tumor angiogenesis, and several molecules that inhibit different components of this pathway have been developed in recent years. Examples include bevacizumab, a monoclonal antibody that binds and inactivates VEGF-A, and sunitinib, a tyrosine-kinase inhibitor that blocks phosphorylation of several tyrosine-kinase receptors including VEGFR1 and VEGFR2. These agents have already reached clinical practice.",0
12,3,"The VEGF-A gene has 8 exons, producing 5 main alternatively spliced isoforms (VEGF121, VEGF145, VEGF165, VEGF189, and VEGF206), with the potential for longer isoforms. The importance of these isoforms is uncertain. Recently, a novel set of isoforms, referred to as ""b-isoforms"" or ""VEGFxxxb"" isoforms, have been identified. These isoforms code for polypeptides of equal length to classical isoforms, with exon 8 substituted by an alternatively spliced exon of the same size (exon 8b). Functionally, the ""b-isoforms"" may act as antagonists of VEGF-A receptors due to the substitution of exon 8, which is known to be important for receptor activation. Some reports suggest VEGF165b may have anti-angiogenic properties, while others suggest it may act as a VEGF-A receptor agonist.",0
12,4,"A potential variance in expression of ""angiogenic"" and ""antiangiogenic"" isoforms in diseases associated with abnormal vasculature development, such as cancer, is an intriguing topic. Prior investigations, using semi-quantitative RT-PCR techniques on a limited number of samples, have demonstrated significant expression of VEGFxxxb isoforms in regular prostate, colon, and kidney tissues when compared to their malignant counterparts. The theory suggests that neovascularization in pathological states would modify alternative splicing of VEGFA, causing an increase in the expression of ""b-isoforms"" (possessing anti-angiogenic potential) at the expense of the classical angiogenic isoform counterparts. A significant finding, as the VEGFxxxb/VEGF ratio expression may indicate the presence of angiogenic disease, making it an interesting area for further research.",0
12,5,"Given that the therapeutic application of recombinant VEGFxxxb proteins is attractive yet the biological activity of such transcripts remains unclear, the objective was to generate VEGF121b and VEGF165b proteins through Pichia pastoris yeast and develop expression vectors to overexpress these isoforms. This was done to better understand their function in cancer models. Furthermore, the study examined the protein expression of VEGFxxxb and overall VEGF in normal mammary glands as well as 50 breast cancer samples, utilizing previously characterized antibodies.",0
12,6,"Oligonucleotides were purchased from Sigma-GenoSys (Sigma, St. Louis, MO, USA). To clone the VEGF121b isoform, the VF (5'GAAACCATGAACTTTCTGCTGTCTT3') and V121bR (5' TTAAGCTTTCAGTCTTTCCTGGTGAGAGATTTTTCTTGTCTTGCTCTATC3') primers were used in PCR into the pCR2.1 vector (Invitrogen). Cloning of VEGF165b used VF and V165bR (5' TTAAGCTTTCAGTC-TTTCCTGGTGAGAGATCTGCAAGTACGTTCGTTTAACTC 3'). The initiation codon is underlined in VF, and both reverse oligonucleotides have HindIII restriction sites (bold). VEGF121b and VEGF165b coding sequences were subcloned into pCDNA3.1(-)Neo expression plasmid, followed by cloning of VEGF121b and VEGF165b coding sequences lacking the signal peptide (ΔPSVEGFxxxb) into the pPICZalphaC vector (Invitrogen) using the VPPF (5' GGTCTCGAGAAAAGAGAGGCTGAAGCTGCACCCATGGCAGAAGG 3') primer, together with V121bR or V165bR. These constructs were used to produce recombinant proteins in the yeast Pichia pastoris, where the alpha-factor signal peptide was used to achieve extracellular expression of the VEGFxxxb sequences.",0
12,7,"After linearizing and purifying the pPICZalphaC plasmids carrying the ΔPS-VEGFxxxb sequences, they were mixed with Pichia pastoris cells and electroporated in 1 mm-wide Bio-Rad electroporation cuvettes using preset yeast conditions. Following electroporation, the cells were transferred to sterile microtubes with 1 M sorbitol and incubated for 2 hours at 30°C. The zeocin-resistant colonies were grown in YPD medium and transferred to BMGY medium to grow for 30 hours at 29°C. The yeasts were then resuspended in BMMY medium to induce protein production.",0
12,8,"Supernatants obtained after 24 hours of incubation at 29°C were analyzed by SDS-PAGE to identify the best clone for each VEGF121/165b isoform. Selected clones were cultured in 2L of BMGY for 2 days and then transferred to BMMY medium for expression. Nickel-affinity chromatography was used for purification, with the Pichia pastoris supernatants containing recombinant VEGF121/165b proteins being diluted in binding buffer and loaded into an HPLC system containing a Hi-Trap chelating column connected to an AKTÄ HPLC device. Elution buffer containing increasing proportion of elution buffer was loaded and gradually mixed with binding buffer. Collections of 1mL fractions were generated throughout the process.",0
12,9,"The eluted proteins that were purified using affinity chromatography were removed from the eluting medium and converted to PBS through dialysis with the usage of Pierce's Slide-A-lyzer cassettes that had a 10 KDa threshold pore. The cassettes were filled with the eluted protein and placed in 3L of PBS solution for overnight. This process of changing to new PBS was continued for 6 more hours. Later, the dialyzed proteins were taken out from the cassettes using syringes and frozen quickly.",0
12,10,"Cultured cells were destroyed by RIPA buffer containing various ingredients including protease inhibitor cocktail. The protein concentration of samples was measured by the bicinchoninic acid protein assay. For conditioned culture media, supernatants were concentrated using 15-KDa Amicon Ultra centricons.",0
12,11,Proteins were subjected to electrophoresis in Bis-Tris buffered gels from Novex Gels (Invitrogen) under reducing or non-reducing conditions following standard protocols. A 20 μg protein solution (in RIPA buffer) was mixed with Laemmli sample buffer and heated for 5 minutes. Electrophoresis was conducted at room temperature for 90 minutes at 130V in 1X running buffer. Proteins in the gel were either stained with Coomassie blue or transferred to PVDF membranes for immunodetection. VEGFxxxb proteins (90 μM) were deglycosylated and treated with 0.8 mM Endo F1 for 1 hour at 37°C. SDS-PAGE monitored the breakdown.,0
12,12,"The western blot membranes were washed twice with PBS-tween before being blocked using PBST plus 5% skim milk at room temperature for half an hour. Primary antibodies against various proteins, including VEGF, VEGFxxxb, pKDR, total KDR, pERK1/2, total ERK1/2, and GAPDH, were added and allowed to incubate. Horseradish peroxidase-labelled secondary antibodies were then used, and the chemoluminescent Lumi-lightPLUS kit from Roche was applied to visualize the immunoreactive bands.",0
12,13,"HUVECs, PC3, and A549 cell lines were obtained from ATCC. PC3 and A549 cells were kept in complete medium, which consisted of RPMI-1640 growth medium supplemented with 10% heat-inactivated FBS, 100 U/mL penicillin, and 100 μg/mL streptomycin. HUVECs were kept in EGM-MV2 medium containing human recombinant EGF, VEGF, FGF, IGF-1, hydrocortisone, ascorbic acid, and 2% FBS. To analyze cell supernatants by western blot, the cell culture medium with 1% serum was used.",0
12,14,"The method used to introduce purified plasmidic DNA into mammalian cells was cationic lipid-based transfection with Lipofectamine 2000, following the manufacturer's guidelines. Transfected cells were maintained with complete medium plus either 300 μg/mL (PC3) or 500 μg/mL (A549) G418 after selection.",0
12,15,"The MTT assay and VEGF-related inhibitors were used to evaluate cell proliferation. Cells were initially seeded in 96-well plates containing 2% FBS growth medium and assessed following overnight incubation. Various compounds, including recombinant human VEGF165, VEGF 121 b, VEGF 165b, and the VEGFR inhibitor GW654652 were added to the culture plates. An MTT solution was added to each well at each time point, and the plates were incubated for an additional 3 hours before absorbance was measured at 550 nm using a microplate reader. Control wells containing only complete medium were also included. Each experiment consisted of three trials, with six replicates per drug concentration. The experiments were carried out using different VEGF- and VEGFR-related inhibitors to evaluate their impact on cell proliferation.",0
12,16,"The second technique involved assessing DNA synthesis by adding a modified nucleotide called EdU, followed by the Click-it reaction using Invitrogen's guidelines. At 50% confluence, cells were treated with either 50 or 100 ng/mL of rhVEGF 165, VEGF 121 b(pp), VEGF 165 b(pp), or bFGF overnight. Following that, cells were treated for 1 hour with a 5mM EdU solution, washed, trypsinized, fixed, permeabilized, and incubated with Alexa-Fluor-647 dye in the presence of copper for catalysis of the Click-it reaction. EdU incorporation was assessed by analyzing the cells with a FACScalibur flow cytometer.",0
12,17,"Nu/Nu mice with a Balb/C genetic background that were specifically bred to have no thymus were purchased from Harlan Laboratories in Barcelona, Spain. These mice were kept under Specific Pathogen Free (SPF) conditions. In order to initiate tumor growth, either one million PC3 cells or five million A549 cells were used. These cells, along with their corresponding transfectants, were injected subcutaneously into the flanks of Nu/Nu mice that were in their exponential growth phase. Precision callipers were used to measure tumor growth, and in order to ensure that tumors did not exceed 1.7cm in diameter, the mice were sacrificed. The experiments were conducted according to the guidelines for ethical use of animals of their Institution (CIMA-University of Navarra), which were approved beforehand. The harvested tumors were fixed overnight in 10% buffered formalin, embedded in paraffin, and sectioned for analysis. The primary tumor volumes were calculated using the formula: V = length × (width)^2/2.",0
12,18,"For conducting Matrigel plug assays, a mixture of 400 μL Growth Factor Reduced Matrigel (BD) and either 100 ng of rhVEGF165, VEGF121b(pp), VEGF165b(pp), or bFGF (as positive control) in 100 μL PBS was injected subcutaneously in Nu/Nu mice. After one week of cell inoculation, the mice were retro-orbitally injected with either 100 mL Fluorescein-labelled dextran (3 mg/mL) or with Alexa-647labelled isolectin B4 (100 μg/mL). After a 15-minute wait period, the mice were sacrificed, and the Matrigel plugs were taken out and examined under a Zeiss Axiovert confocal microscope.",0
12,19,"Tissues from in vivo experiments, either xenografted tumors or matrigel plugs, were fixed in 10% buffered formalin and embedded in paraffin. AccuMax (Seoul, Korea; catalogue # A202(I)) provided the Tissue Microarray (TMA) slides which contain 100 breast tissue cores from 50 patients and 8 tissue cores from 4 normal breast tissue obtained by mammoplasty. The TMA consists of 33 infiltrating ductal carcinomas, 7 papillary carcinomas, 3 phyllodes tumors, 4 infiltrating lobular carcinomas, and 3 samples corresponding to other breast cancer tumor types.",0
12,20,"To prepare for immunohistochemistry, the slides were first deparaffinized and hydrated. Endogenous peroxidase activity was quenched with 3% H2O2 in water for 10 minutes. An antigen retrieval method was used to detect the antibodies. Different primary antibodies were used at various dilutions: Caspase 3 (Cleaved Caspase-3 Asp 175, Cell Signaling) at 1:200, CD-31 (Dianova) at 1:20, PDGFRb (Cell Signaling) at 1:100, VEGF (Santa Cruz) at 1:200, and VEGFxxxb (R&D) at 1:50. The primary antibodies were incubated at 4°C overnight except for CD31, which was incubated for 1 hour at RT. Tissues were washed with TBS and then incubated with the corresponding secondary antibodies. The EnVision™ antirabbit detection system (Dako) was used for each slide, followed by peroxidase activity with DAB (Dako). The slides were then counterstained with hematoxylin, dehydrated, and mounted. To quantify the images, 10 random images (200×) per mouse were captured with a microscope (Leica, Wetzlar, Germany) equipped with the Analysis™ software. Positive cells were then quantified with Image J (NIH, Bethesda, MD, USA).",0
12,21,"For the quantification of FITC-dextran and Alexa-647 Isolectin B4 in Matrigel plug sections, we used an Axiovert epifluorescence microscope (Carl Zeiss, Germany) to analyze slides, capturing 10 random pictures of each Matrigel. The labelled area was then measured using the ImageJ software.",0
12,22,"The normal distribution of the data sets was assessed using Shapiro-Wilks and Kolgomorov-Smirnoff tests, and homogeneity of variances was verified using Levene's test. ANOVA was used to test for differences among groups for normally distributed data sets, while non-parametric tests such as Kruskal-Wallis and Mann-Whitney's U-test were used for non-normal distributed data sets. Bonferroni correction was used for post-hoc comparisons in the case of variance homogeneity, while Tamhane's correction was applied when Levene's test was positive. Wilcoxon's test was used for dependent sample data. SPSS software was utilized to run these tests. Significance was determined by p-value, with results having a p-value < 0.05 considered significant (*), those with a p-value < 0.01 (**), very significant, and those with a p-value <0.001 (***), extremely significant.",0
12,23,"A schematic in Figure 1 illustrates the various exons present in both the “classical” VEGF-A isoforms and “VEGFxxxb” isoforms. The coding sequence for VEGF121b and VEGF165b, devoid of their native human signal peptide, was inserted into the pPICZalphaC plasmid. The yeast alpha-factor signal peptide was used in place of the native human signal peptide for these constructs, as it is an efficient secretion inducer in Pichia pastoris. To ensure high-quality recombinant proteins, nickel-affinity chromatography was utilized to isolate VEGFxxxb from Pichia pastoris culture supernatants, as illustrated by the chromatogram in Figure 2A. VEGF121b was eluted using a 20% imidazole gradient. The bands, depicted in Figure 2B, corresponding to the anticipated size of VEGF121b were stained using Coomassie blue and were identified around peak 2. These observations indicate the effectiveness of nickel-affinity chromatography to extract VEGFxxxb proteins from Pichia pastoris culture supernatants.",0
12,24,"Figure 2C displays the electrophoresed culture media from Pichia pastoris clones that were electroporated with the linearized VEGF 121b or VEGF 165b sequence-containing pPICZaphaC plasmids and selected with zeocin for one week. The bands of predicted molecular masses were detected in the clones' supernatants. Pichia pastoris exposed clearly visible ectopic protein amounts among the total secreted proteins. The clones that overexpressed higher recombinant VEGFxxxb proteins were chosen for large-scale production. Crucially, the Pichia pastoris-derived recombinant proteins reacted positively to the commercially available (and previously validated) VEGFxxxb antibody from R&D (Figure 2D).",0
12,25,"The recombinant human VEGF121/165b isoforms expressed in Pichia pastoris had a band pattern similar to that of the native VEGFxxx isoforms, which has been previously described. Under non-reducing conditions, VEGF121b forms dimers that can be detected in the gel as three bands. These three bands most likely correspond to dimers of glycosylated-glycosylated, glycosylated-non-glycosylated and non-glycosylated-non-glycosylated proteins, which is consistent with the VEGF-A classic isoforms. When the same culture supernatants were run under reducing conditions, only two bands were visible, indicating the ability of these proteins to dimerize. The same pattern was seen for VEGF165b, although the bands were not as clear as for VEGF121b. Recombinant VEGFxxxb proteins also formed larger complexes, including tetramers and octamers, particularly for VEGF165b.",0
12,26,"The glycosylation status of the VEGFxxxb recombinant proteins produced in Picha pastoris was assessed using endoglycosidase F1 in both reducing and non-reducing conditions. Additional file 1 Figure S1 was referred to for this purpose. The deglycosylation of VEGF121/165 b resulted in an electrophoretic shift for both isoforms. The observed molecular weights for the glycosylated and deglycosylated proteins were in line with those of VEGF121 and VEGF165, as reported in references [20, 21].",0
12,27,"The laboratory-produced VEGF121b(pp) and VEGF165b(pp) recombinant proteins were initially tested on endothelial cell proliferation in vitro, as well as a VEGF165b recombinant protein (VEGF165b(hs)) produced in mammalian CHO cells to eliminate any potential yeast-glycosylation-derived effect. The MTT assay was used in a first experiment, and it was found that exposing HUVECs to commercial VEGF165 (from R&D) at a dose of 100 ng/mL caused a 63% increase in proliferation compared to untreated cells. Similar proliferative induction was observed when co-administering VEGF165 with either VEGF121b(pp), VEGF165b(pp), or VEGF165b(hs) at the same dose. Each of the recombinant ""b-isoforms"" alone resulted in around a 40% increase in proliferation. Administering the VEGFR-targeting compound GW654652 alone or with VEGF165b(hs) led to rates of HUVEC proliferation similar to that of untreated control cells, which demonstrated the specificity of VEGF165b in inducing VEGFR-mediated endothelial proliferation. Comparable results using the VEGFR inhibitor were obtained for VEGF121b(pp) and VEGF165b(pp) (results not shown).",0
12,28,"The team utilized a separate technique to verify their results on cell proliferation by tracking DNA incorporation into cells. Their findings, presented in Figure 3B, indicated that the administration of bFGF and VEGF 165 caused a threefold increase (p < 0.001) in DNA incorporation into HUVECs compared to untreated controls. Additionally, exposure to VEGF165b(pp) and VEGF121b(pp) resulted in a nearly twofold increase (p < 0.01) in DNA incorporation into HUVECs. The results obtained from this method mirror those obtained with MTT testing, which demonstrated that the VEGFxxxb variants induce cell proliferation, albeit with less potency than VEGF165.",0
12,29,"The addition of all VEGF-A proteins to HUVECs resulted in the phosphorylation of Flk-1/KDR (also known as VEGFR2) and the intracellular kinase ERK1/2. VEGF165 was expected to cause the phosphorylation of KDR and ERK1/2, which it did within 10 minutes of treatment in serum-free conditions. VEGF121/165b proteins were also found to induce KDR phosphorylation in HUVECs. Both VEGF121b and VEGF165b, produced in mammalian cells or in Pichia pastoris, stimulated similar levels of ERK1/2 phosphorylation. Co-administration of VEGF165 and VEGF121/165b did not prevent VEGF165-induced KDR or ERK1/2 phosphorylation. The specific receptor inhibitor, GW654652, prevented the activation of the KDR-ERK pathway by VEGF165b(pp), VEGF 121 b(pp), and VEGF165b(hs). The results obtained were similar across all proteins tested, apart from VEGF165b (hs), which was not shown.",0
12,30,"Matrigel plug assays were utilized to investigate the influence of VEGF121/165b isoforms on endothelial cell function in vivo. The Matrigel was mixed with bFGF, VEGF165 (from R&D), VEGF121b(pp), or VEGF165b(pp). The identification of blood vessels within the Matrigel plugs was accomplished by administering systemically an Alexa-647-labelled isolectin B4 (Figure 5A) before the sacrifice. In contrast, no signal from the Alexa-647-labelled lectin was seen in the Matrigel controls, while plugs that carried any VEGFxxxb isoforms displayed a strong signal attesting to angiogenesis in vivo (Figure 5A). To scrutinize vascular permeability, FITC-labelled-dextran was injected under similar experimental conditions into another group of mice with Matrigel plugs (Figure 5B). Significantly, the control plugs exhibited almost no fluorescent signal, whilst Matrigels pre-loaded with bFGF or especially with VEGF121b exhibited a significant increase in the fluorescent signal. The Matrigel plugs carrying either VEGF165 or VEGF165b showed similar fluorescence, which was about ten times higher than in the controls.",0
12,31,"The study selected two cell lines, one with high total VEGF expression (PC-3) and the other with low expression (A549) for in vivo assays. VEGF 121/165 b isoforms were overexpressed in both models to investigate their effects on tumor growth and angiogenesis. Western blot analyses confirmed high expression of either VEGF121b or VEGF165b in the selected cell pools. In PC3 xenografts, there were no statistical differences between control tumors and those overexpressing either or both isoforms, although VEGF121b-overexpressing cells tended to form bigger tumors. However, in A549 xenografts, both VEGF121b and VEGF165b overexpression led to significant increases in tumor volumes compared to controls. Thus, overexpression of VEGF121/165 b isoforms did not cause tumor shrinkage but instead led to tumor growth in these models.",0
12,32,"Angiogenesis analysis showed that A549 tumors were less angiogenic than PC-3 tumors, and there were no differences between controls and experimental groups. VEGF121b overexpressing tumors in PC-3 showed significantly higher vascularization than the other experimental groups. Analysis of PDGFRb levels by immunohistochemistry and image analysis did not reveal any decrease in PDGFRb+ cells in either PC-3 or A549 xenografted tumors. Apoptotic cells were also quantified, and no changes were observed in A549 xenografts. In PC-3 xenografted tumors, there was a reduction in the number of apoptotic cells when VEGFxxxboverexpressing cells were injected compared to controls.",0
12,33,"Previous research has indicated that VEGFxxxb isoforms may be expressed differently in normal versus pathological conditions. In order to investigate whether this was also true for breast cancer, a TMA containing core biopsies from both patients with breast cancer and normal breast tissue was utilized. In conducting this research, a thoroughly validated antibody that detects total VEGF-A (including all VEGF-A isoforms) was employed (R&D systems), as well as the sole verified anti-VEGFxxxb antibody that recognizes all VEGFxxxb proteins (also R&D systems) [18]. Currently, there is no antibody available that is specific to ""non-b"" isoforms (i.e. VEGFxxx).",0
12,34,"Representative images of malignant and normal breast tissues stained with the anti-VEGFxxxb and anti-total VEGF-A antibodies are shown in Figures 8A and 8B. The results show a strong staining for VEGFxxxb in tumor cells of infiltrating ductal carcinoma (IDC) samples, as well as in other types of tumors, including papillary carcinoma (Pap), phyllodes (Phy), infiltrating lobular carcinomas (ILC), and ductal carcinoma in situ (DCIS). However, no VEGFxxxb was detected in any of the normal breast tissue (NBT) samples. All tissues analyzed were positive for total-VEGF-A, including the normal breast epithelium. Semiquantification of the staining revealed that both total VEGF-A and VEGFxxxb protein levels were significantly higher (p < 0.05) in IDC than in normal breast tissues, as shown in Figures 8C and 8D. Additionally, a significant (p = 0.033) positive correlation index (r = 0.404) between VEGFxxxb and total-VEGF-A was observed, implying the degree of co-staining. Therefore, we conclude that VEGFxxxb levels are not reduced in malignant breast cancer but, on the contrary, tend to increase in the tumor samples and are significantly higher in infiltrating ductal carcinomas.",0
12,35,"The exploration and documentation of VEGF-A's importance in normal and pathological angiogenesis has been widespread in recent decades. VEGF-A has become a key focus for cancer therapy in solid tumors, and drugs targeted at VEGF, such as bevacizumab and sunitinib, are currently being utilized in patients. Nonetheless, the biology of VEGF-A spliced isoforms remains poorly understood. Specifically, comprehending how the various VEGF-A isoforms are generated through alternative splicing may be significant in developing more targeted and effective molecular therapies.",0
12,36,"In 2002, researchers discovered a new family of VEGF-A isoforms through alternative splicing that were named VEGFxxxb isoforms. These isoforms incorporate a different exon, exon 8b, than the classical exon 8a found in angiogenic transcripts. The inclusion of exon 8b is believed to enable VEGFxxxb to bind VEGF-A receptors without causing strong downstream signalling activation, resulting in VEGFxxxb's hypothesized antiangiogenic properties. Notably, overexpressing VEGF 165 b or VEGF 121 b in tumor cells transplanted into nude mice was found to inhibit growth. Furthermore, VEGFxxxb isoforms may be differentially expressed in pathological tissues compared to normal tissues, potentially aggravating aberrant angiogenesis-linked disease by reducing the amount of VEGFxxxb isoforms expressed in normal tissues.",0
12,37,"The present study aimed to create VEGF 121 b and VEGF165b recombinant proteins in Pichia pastoris yeast to test their antiangiogenic and antitumor properties in vitro and in vivo. The PCDNA3.1 plasmid was also utilized to generate cancer cells overexpressing VEGF121/165b. The yeast expression system was selected due to its ability to glycosylate proteins and purify them without contamination from endogenous proteins. Additionally, it is faster, easier, and more cost-effective compared to mammalian systems. Moreover, yeasts do not code for any form of VEGF, eliminating the possibility of exon 8-containing VEGF-A contamination and exons 8 and 8b heterodimer formation.",0
12,38,"Recombinant VEGF121b and VEGF165b proteins, similar in structure to classical VEGF121 and VEGF165, were successfully produced with the capacity to form dimers/multimers and react with commercial antibodies formulated against exons 1 to 5, common to all VEGF-A isoforms. Moreover, both recombinant proteins showed immunoreactivity with a validated antibody recognizing exon 8b from R&D [18].",0
12,39,"To evaluate the performance of these isoforms in vitro, HUVECs were treated with recombinant proteins generated in yeasts, VEGF 165 b created in mammalian cells, or the “classical” VEGF165 angiogenic protein (as a control). All the treatments were conducted in serum-free media. We observed that VEGF121/165b isoforms induced HUVECs' proliferation and phosphorylation of VEGFR2 and its downstream transducer ERK. However, the effect of VEGF121/165b isoforms was less potent than that of VEGF165: Proliferation of HUVECs was stimulated with VEGF121/165 b isoforms by approximately 50% less than recombinant VEGF165. Nevertheless, the degree of ERK activation was similar for all tested proteins, 10 minutes after stimulation. This intracellular mediator was phosphorylated particularly by VEGFRs, as proved by the restriction of this process in the presence of the VEGFR1 and VEGFR2 tyrosine-kinase inhibitor GW654652.",0
12,40,"VEGF165b has distinct functional properties compared to other VEGF isoforms. Kawamura et al. [16] found that VEGF165b is a weaker agonist of VEGFR2 compared to VEGF145, but can still induce phosphorylation of VEGFR2 in HUVECs. VEGF165b, like VEGF121, does not bind to neuropilin-1 (NRP1) or induce complexes between NRP1 and VEGFR2. It promotes cell migration, but does not induce endothelial sprout formation. Interestingly, VEGF165b cannot phosphorylate VEGFR2 at Y1052 and may block transphosphorylation by preventing full rotation of the receptor's intracellular tail upon binding. Additionally, Glass et al. [17] have shown that VEGF165b transiently activates VEGFR1 to increase vascular permeability. Taken together, these findings suggest that VEGF165b may have weaker downstream signaling effects in endothelial cells.",0
12,41,"To confirm the angiogenic properties of VEGF 121/165b observed in traditional laboratory tests, we conducted experiments in vivo using Growth Factor Reduced Matrigel. This substance has significantly reduced levels of angiogenic cytokines such as VEGF. When we added recombinant VEGF 121 b, VEGF 165 b, or VEGF 165 to the Matrigel, we noticed the recruitment of blood vessels compared to the control group loaded with PBS. These findings indicate an angiogenic effect. We must note that Matrigels containing VEGF121b had high levels of dextran-FITC signal both inside and outside of the vessels (similar to bFGF results). This indicates an increase in vascular permeability, which matches the vascular permeability described for VEGF121 [27].",0
12,42,"During our study, we conducted tests to determine if VEGF121/165b overexpression in xenograft models could inhibit tumor growth in vivo. To do this, we chose two different cancer cell lines: The low-VEGF-expressing lung adenocarcinoma A549 cell line and the PC-3 prostate cancer cell line, which secretes a higher amount of VEGF. Our goal was to investigate any potential differences in VEGFxxxb behavior based on the endogenous VEGF expression. These tests were conducted without the use of any additional exogenous VEGF stimulation, such as transfection of VEGF. In PC3 xenografts, there were no statistical differences between the control group and VEGF121/165b-expressing tumors. However, we did observe a tendency for VEGF121boverexpressing tumors to grow at a faster rate than the other groups. Vascular density was significantly higher in the VEGF121 b-overexpressing PC-3 tumors than in the other groups, and apoptotic levels were significantly lower. As previously described, A549 xenografts grew slowly and formed small tumors after subcutaneous implantation in nude mice.",0
12,43,"The findings presented here contradict previous research indicating that VEGF 165 b has anti-tumor properties. However, it is suggested that this discrepancy may be due to the levels of VEGF expression in the in vivo models studied. When VEGF levels are high, VEGFxxxb and VEGFxxx compete equally for receptor binding, leading to reduced tumor growth when VEGFxxxb is overexpressed. However, when VEGF expression is low, overexpression of VEGFxxxb may actually stimulate tumor growth to some degree. This hypothesis is supported by the observation that no difference in tumor growth was detected between parental and VEGF165b-overexpressing CAKI cells when VEGF levels were around 900 pg/mL.",0
12,44,"It is plausible that VEGFxxxb protein therapies could be effective in tumors with high levels of endogenous VEGF. However, using this therapy in tumors with low VEGF levels that rely on other angiogenic factors (such as bFGF, IL-8, etc.) for growth could potentially worsen the tumor's progression. Hence, administering VEGFxxxb protein as a therapy raises doubts about its use in unselected patients. It is critical to exercise caution and stratify patients based on their VEGF production levels to identify those who can benefit from VEGFxxxb-based therapies. Future clinical trials need to consider this aspect.",0
12,45,"There are still many unknowns regarding the biology of VEGFxxxb and before proceeding with therapy translation, these aspects need to be clarified. One surprising finding is that VEGF121b, which was discovered to inhibit endothelial cell migration, actually provided cytoprotection for endothelial cells in serum starvation experiments in a similar way to VEGF165 by activating VEGF receptors and downstream signalling. Another unexpected result is that in some xenograft models, co-overexpression of VEGF165 and VEGF165b actually results in smaller tumors than overexpression of just VEGF165b. There are also other key questions to answer, such as whether VEGFxxxb proteins can heterodimerize with members of the VEGFxxx angiogenic family.",0
12,46,"In this study, we investigated whether VEGFxxxb isoforms are expressed differently in malignant (human breast cancer) and healthy tissues (normal mammary gland). Using validated antibodies specific for VEGFxxxb isoforms and transcripts, we performed immunohistochemistry experiments. Our findings showed that both total VEGF and VEGFxxxb levels tended to increase in breast cancer tissues (n = 50) compared to normal tissues (n = 8). We observed statistically significant increases in intraductal carcinomas (IDC). Additionally, there was a significant correlation between the expression of total VEGF and VEGFxxxb, suggesting that both families of VEGF follow a similar pattern of expression.",0
12,47,"Previous investigations have examined the expression of the VEGFxxxb isoforms in a restricted number of samples. Although the total VEGF mRNA levels in colon carcinoma samples (n=6) were significantly elevated compared to controls, VEGFxxxb mRNA levels remained unchanged [18]. This suggests that the rise in total VEGF is attributed to the VEGFxxx angiogenic isoforms [18]. By analyzing protein levels with isoform-specific ELISAs, a similar result was obtained [18]. VEGF165b was discovered to be present in 17 of 18 normal kidney samples but only in 4 of 18 paired malignant tissues, as indicated by RT-PCR analysis [19]. The immunohistochemical analysis of 19 melanoma samples (9 metastatic and 10 non-metastatic) using the VEGFxxxb-specific antibody discovered a decrease in VEGFxxxb expression in neoplastic tissue (particularly in metastasis) relative to normal skin [25].",0
12,48,"The characterization of the expression pattern of VEGFxxx and VEGFxxxb proteins in normal and malignant tissues is impeded due to the absence of suitable antibodies. To evaluate if VEGFxxxb expression can be used as a cancer biomarker, future studies using a larger sample size, along with quantitative real-time RT-PCR and immunohistochemical analyses, would be required.",0
12,49,"The findings indicate that VEGF121/165b are not antiangiogenic; rather, they are slightly pro-angiogenic forms of VEGF-A that could facilitate the development of tumors and angiogenesis in vivo. Additionally, it was discovered that VEGFxxxb isoforms, along with overall VEGF concentrations, are elevated in breast cancer compared to non-cancerous breast tissue.",0
13,1,"Severe acute respiratory syndrome (SARS) is a disease caused by a highly virulent strain of coronavirus [1]. Unlike other coronaviruses that cause only mild illness, this strain of the virus, called SARS-CoV, has a high mortality rate. Because strains of the virus exist in animal reservoirs, there is a risk of SARS re-emerging. Therefore, developing safe and effective vaccines is a high priority. The genome of SARS-CoV is made up of single-stranded RNA and codes for four main structural proteins: spike (S), membrane (M), envelope (E), and nucleocapsid (N) proteins [2]. The S protein plays a critical role in both recognising and attaching to receptors on target cells, allowing the virus to enter and infect them [3].",0
13,2,"In the pursuit of developing vaccines for different pathogens, DNA vaccines have been extensively researched. These vaccines can trigger both humoral and cellular immune responses, as per numerous studies [4]. Several studies have also shown that DNA-based vaccines can produce a protective immune response to various viruses [5,6], but their incapability to induce immune response in mice when administered through the intranasal (i.n.) route [7] remains an issue. Given that most respiratory infections enter through the mucosal surface, it is imperative that a vaccine can induce both systemic and mucosal immune responses. Mucosal immune responses are crucial as a frontline immune defense in combating an influenza virus infection, and parenteral immunization alone does not suffice to trigger protective immunity [9]. Secretory IgA plays a vital role in facilitating mucosal immunity [8].",0
13,3,"Polyethylenimine (PEI) has been widely used as a nonviral vector both in vitro and in vivo because of its high transfection efficiency and buffering capacity. Recent studies have revealed that mucosal administration with PEI can serve as a potent mucosal immunostimulator, while also being an effective gene delivery vehicle for lung transfection, producing high antibody titers against encoded proteins. In the present study, the researchers examined the immune responses of BALB/c mice immunized with the SARS DNA vaccine via the intranasal route.",0
13,4,"'The ability of a gene carrier to condense DNA into nano-sized particles is widely acknowledged to influence its transfection efficiency [13]. As anticipated, PEI successfully condensed the DNA into such particles, which indicates their potential for endocytosis (as shown in Figure 1A).'",0
13,5,"The spherical shape and size of the PEI/pci-S nanoparticles were observed and confirmed through energy-filtering transmission electron microscopy (EF-TEM) and dynamic light scattering, respectively. The cell viability of RAW 264.7 cells decreased slightly with increasing N/P ratio of PEI/pci-S complexes. Rhodamine labeled pci-S DNA was utilized to visualize the uptake of the complex by the cells, and RT-PCR analysis revealed that both pci-SDNA and PEI/pci-S nanoparticles can transfect the cells, with the latter inducing stronger S mRNA expression than naked DNA.",0
13,6,"To assess the impact of PEI on adaptive immunity to SARS-CoV S protein, mice were given SARS-CoV DNA vaccine intranasally and specific antibody responses were observed. High levels of SARS-CoV S-specific serum IgG antibody were produced in mice immunized with PEI/pci-S complexes, whereas mice immunized with SARS-CoV S DNA alone did not produce similar results. To determine the balance of Th1/Th2 response, SARS S-specific IgG1 and IgG2 levels were examined, with SARS S-specific IgG1 antibody greatly increasing in mice given the SARS-CoV S DNA vaccine with PEI, suggesting a Th2 dominant response. Mucosal antibody production was analyzed as well, with SARS S-specific IgA antibody response increasing notably in lung wash from mice given PEI/pci-S complexes.",0
13,7,The proliferation ability of B220+ cells was measured to evaluate B lymphocyte response to SARSCoV spike protein. It was further confirmed that antibody responses were enhanced at 1 week after the last vaccination. B220+ cells from mice immunized with PEI/pci-S complexes were found to have a high level of proliferation after being re-stimulated with SARS-CoV S protein in vitro (Figure 2C).,0
13,8,"The expression of markers on the surface of DCs increases during their maturation, including molecules for co-stimulation and MHC class. In order to investigate the impacts of DNA vaccination on DC maturation, mice were given PEI/pci-S complexes through intranasal immunization. The DCs of the mice who received the PEI/pci-S complexes showed significantly higher levels of CD80 and CD86 co-stimulatory molecules on their surfaces compared to those who were only given the SARS-CoV DNA S vaccine. This was also true for MHC class II, I-Ad, expression, which was significantly up-regulated in the group who received the PEI/pci-S complexes compared to those who only received the SARS-CoV DNA vaccine. (Figure 3).",0
13,9,"Cytokine profiles were analyzed using intracellular cytokine assays to investigate T cell immunity to the SARS-CoV S DNA vaccine. Lung cells obtained 6 days post-immunization were used for the study. Prior research has indicated that T cells that produce IFN-g, IL-2, IL-17, and TNF-a provide effective protection. The number of IFN-g-producing cells increased in both CD4+ and CD8+ T cells in mice vaccinated with PEI/pci-S, while the number of IL-17-producing cells increased only in CD4+ T cells. However, CD8+ T cells from mice vaccinated with PEI/pci-S did not produce IFN-g, IL-2 or IL-17. After restimulation, CD4+ and CD8+ T cells from mice vaccinated with PEI/pci-S produced TNF-a and TNF-a and IL-2 in larger amounts. Additionally, IFN-g and IL-17 were found to be produced together more frequently in the PEI/pci-S group than in the pci-S group. Notably, no IL4-producing cells were detected in the lung or spleen.",0
13,10,"In the 21st century, an emerging infectious disease known as SARS posed a significant threat to public health and the global economy [1]. The virus infected over 8,000 individuals in 26 countries, resulting in 774 fatalities [15]. Research revealed that the SARS-CoV spike protein (S) played a crucial role in virus entry, attachment, and receptor recognition [16], which made it a prime target for vaccine development [6]. To prevent SARS outbreaks, numerous vaccine studies focused on the S protein, including fragment DNA, full-length DNA, and receptor binding domain vaccines [17]. Studies showed that a DNA vaccine encoding the full-length S protein produced humoral, cellular, and protective immune responses against SARS-CoV [6]. This study explored the immunogenicity of intranasal immunization in mice using PEI/pci-S.",0
13,11,"The enhancement of transfection efficiency and immunogenicity in mammalian cells has been linked to PEI/DNA complexes according to previous reports. This study aims to use the PEI/pci-S complex in mucosal DNA vaccination. The complexes were found to be approximately 200 nm in size. The impact of these complexes on transfection, gene, and protein expression was tested on RAW 264.7 cells by measuring mRNA and protein expression. Based on these results, the study moved forward to in vivo trials for mouse immunization through intranasal administration of PEI/pci-S complexes.",0
13,12,"Several studies have attempted to create SARS DNA vaccines using systemic routes, such as intramuscular injection. However, targeting intranasal immunization may be more effective, as SARS is a respiratory pathogen. In particular, using PEI/pci-S complexes for intranasal immunization induced stronger antigen-specific serum IgG responses than using just pci-S. This method also increased antigen-specific IgG1 and IgA responses, suggesting a Th2 dominant response. Additionally, B cell proliferation was enhanced after in vitro re-stimulation with the spike protein. Garzon's study found that antigen-specific antibody and T cell responses increased in mice immunized with DNA vaccine up to 100 μg, but in this study, each mouse was only given 20 μg of DNA, which was still able to induce both systemic and mucosal immune responses.",0
13,13,"Dendritic cells (DCs) have a crucial function in effectively triggering immune responses specific to antigens. DCs are present throughout the body and act as the first line of defense against pathogens [21]. When DCs encounter pathogen-associated molecular patterns from microorganisms, they become mature and acquire the capacity for antigen presentation, leading to increased expression of MHC proteins [22], cytokines [23], and a higher number of co-stimulatory molecules such as CD80, CD83, and CD86 [24]. Therefore, DC maturation is critical for initiating appropriate subsequent adaptive immune responses [22]. The present study confirms that PEI/pci-S complexes stimulate co-stimulatory and MHC class II molecules on DCs in cervical lymph nodes following intranasal immunization.",0
13,14,"The immune responses of cells are controlled by both CD4+ and CD8+ T cells. Studies show that these antigen-specific T cells produce cytokines, such as IFN-g, TNF-a, IL-2, and IL-17, after re-stimulation with SARS spike peptides. IFN-g activates macrophages and DCs while inhibiting viral infections; TNF-a inhibits viral replication and regulates immune cells; IL-2 maintains memory T cells and expands T cells, while IL-17 causes the production of antimicrobial peptides and immunoglobulin to neutralize viral infections. It has also been found that antigen-specific CD4+ and CD8+ T cells secrete IFN-g, TNF-a, IL-2, and IL-17 in nonlymphoid tissues like the lung. Multiple cytokine-producing cells also increase when mice are immunized with PEI/pci-S. These cells are believed to be responsible for protection if the host becomes infected with SARS-CoV after vaccination. Multi-cytokine producing antigen-specific CD4+ T cells are more effective in protection than single-cytokine producing cells. Studies have shown that multi-cytokine producing T cells have excellent results against the infection of Leishmania major.",0
13,15,"PEI has been shown to be successful in transporting DNA to the mucosal surface, promoting dendritic cell maturation, and enhancing the immune response to DNA vaccines. Our findings suggest that PEI could serve as an effective vehicle for mucosal administration of DNA vaccines and contribute significantly to both B cell and T cell immunity.",0
13,16,"The SARS-CoV spike (S) protein gene lacking the transmembrane domain (amino acids 14-1154) was artificially constructed. The gene sequence was optimized for expression in mammalian cells and the natural signal sequence was replaced with the leader sequence of human tissue plasminogen activator (tPA). Subsequently, using Nhe I and Not I, tPA-S gene and pci-neo were cleaved and then joined together to generate a plasmid expressing SARS-CoV S protein.",0
13,17,"PEI/pci-S nanoparticles were created by combining polymer and pci-S DNA in a solution with an N/P ratio of 10. The size of the nanoparticles was determined using an electrophoretic light scattering spectrophotometer (ELS8000, Otsuka Electronics, Osaka, Japan), while their morphology was observed via EF-TEM (LIBRA 120, Carl Zeiss, Germany).",0
13,18,"The pci-S DNA was labeled with rhodamine using the Label IT® Tracker™ CX-Rhodamine kit from Mirus, WI for cell uptake observation. RAW 264.7 cells were seeded and the PEI/Rhodamine-labeled pci-S DNA nanoparticles were incubated for an hour and then washed. ProLong® Gold antifade reagent with DAPI from Invitrogen, Carlsbad, CA was used to mount them. Confocal laser scanning microscope (Carl Zeiss-LSM510, Thornwood, NY) was employed to observe the cell uptake images.",0
13,19,The researchers analyzed the expression of SARS-CoV S in RAW 264.7 cells using both transcriptional and protein level methods. The cells were transfected with naked pci-S DNA or PEI/pciS nanoparticles at an N/P ratio of 10 and the resulting cells were lysed with either Trizol or cell lysis buffer. Reverse transcription was performed with Superscript III reverse transcriptase and the cDNA was amplified by PCR with primers for pci-S and glyceraldehyde 3-phosphate dehydrogenase (GAPDH). The amplification products were analyzed by electrophoresis.,0
13,20,"Equal amounts of lysates were separated by SDS-PAGE and then transferred onto a nitrocellulose membrane (Amersham Biosciences, Piscataway, NY) for the Western blot assay. The membranes were blocked using 5% non-fat milk, and then the spike protein primary antibody, obtained from Chiron, and the horseradish peroxidase-conjugated secondary antibody (Santa Cruz Biotechnology, Inc., Santa Cruz, CA) were successively incubated with the membrane. Detection of the antigen-antibody interaction was performed using an ECL fluorescence system. For control purposes, b-actin was used.",0
13,21,"Female BALB/c mice (Orient, Korea) aged six to eight weeks were given anesthesia before immunization. Each group consisted of five mice who were given 20 μg of pci-mock, pci-S, or PEI/pci-S complexes in a total of 25 μl ultrapure water on days 0, 14, 28, and 42 i.n. The International Vaccine Institute (Seoul, Korea) approved all studies.",0
13,22,"Samples of Sera and mucosa were obtained approximately a week after the last immunization. Blood was gathered via the retro-orbital plexus. Fecal extracts were dissolved in a solution of phosphate-buffered saline (PBS) plus 0.02% sodium azide. For the remaining samples, the mice were anesthetized, and vaginal and nasal washes were harvested by pipetting with PBS. Additionally, lung washes were achieved by flushing and sampling the lungs with PBS.",0
13,23,"Microtiter plates from Nunc in Denmark were used to coat with 2 μg/ml of S protein from the Protein Sciences Corporation located in Meriden, CT. These plates were then blocked with 5% skim milk before diluting serum (1:20) or mucosal samples (1:2), with the exception of lung wash which required no dilution, in the blocking buffer. Goat-anti mouse IgG, IgG1, IgG2a or IgA conjugated with horseradish peroxidase from Santa Cruz Biotechnology Inc were added to each well in the blocking buffer followed by the application of 100 μl samples into separate wells. The color was developed using TMB solution from Sigma in the dark and the reaction was stopped by 0.5N HCl. Lastly, the absorbance at 450 nm was measured in a microplate reader from Molecular Devices Corp. in Menlo Park, CA.",0
13,24,Splenocytes from mice were collected after they had been vaccinated and labeled with CFSE. The cells were then stimulated with SARS-S protein for 5 days and B cells were identified using anti-B220-PerCP. The extent of cell proliferation was measured using FACSCalibur and FlowJo software was used to analyze the results.,0
13,25,"On day 3 after the final vaccination, the cervical lymph nodes (CLN) were eliminated. After creating a single cell suspension, CD11c-APC and CD80-PE, CD83-PE, CD86-biotin, or I-A d -biotin antibodies were used for staining (BD Biosciences). The expression level was assessed by flow cytometry utilizing the FACSCalibur. All cytometric data were calculated employing FlowJo software and were presented as MFI (mean fluorescence intensity).",0
13,26,"After taking out the lungs of mice six days after their final vaccination, the lungs were turned into single-cell suspensions. These cells were then placed onto a 96-well plate at a rate of 2 × 10^5 cells per well and stimulated again with SARS peptide from Peptron at a 5 μg/ml concentration for 12 hours. Following the manufacturer's directions, an intracellular cytokine staining assay was performed. The cells were next stained with different antibodies such as anti-CD4-PerCP and anti-CD8FITC alongside either anti-IFN-g-APC and -IL-17-PE, or anti-TNF-a-APC and -IL-2-PE (all from BD Biosciences). By employing flow cytometry - FACSCalibur, the percentage of cells with fluorescence was identified. Finally, using FlowJo software, all cytometric data was analyzed.",0
13,27,Statistical analysis was conducted using a Student's t-test and a significance level of less than 0.05 was deemed significant.,0
47,1,"This research evaluates the economic knowledge of students who undergo structured economic education during their senior year of high school. We selected our sample from seven high schools within two school districts in Orange County, California. All students were enrolled in the mandatory, semester-long economics course, a requirement for graduation. Our chief measure of performance is the Test of Economic Literacy (TEL). The results indicate that students' initial understanding of economics is inadequate. However, their TEL scores improved by an average of 12.3 percentage points, after one semester of formal economics instruction, as revealed by a pretest-post-test design.",0
47,2,"It is becoming more common for the media to discuss the importance of economic and financial literacy, indicating that policymakers and educators recognize its significance for children, teenagers, and young adults. There have been two national summits on economic and financial literacy and a substantial amount of academic literature highlights the importance of economics education in high school, with continued research exploring issues surrounding economics teaching and learning at both the high school and college levels.",0
47,3,"Our investigation in Orange County, California revealed the economic literacy of high school students. In 1985, California included one semester of economics in high school graduation requirements. This course is taken in the senior year and covers micro and macroeconomic analyses. California is one of the 17 states that mandate formal principles of economics instruction at the secondary level. However, no empirical study has focused on the effectiveness of formal economics instruction in improving economic literacy in California high school students. Our study aims to address this gap.",0
47,4,"Our research has implications for two major policy concerns. The first pertains to the effectiveness of high school economics education in fostering economic literacy. As stated in the following discussion, evidence from a national level indicates that high school economics classes have a positive impact on students’ performances on standardized economics tests. By adopting a research design that employs a single county, single state approach, and includes a comprehensive set of control variables derived from our survey and school records, we refine the focus on this issue. The second policy concern centers on the influence of gender and ethnicity/race on economic literacy. Previous studies, predominantly at the national level, reveal significant gender differences in economic knowledge prior to taking an economics course, but are inconclusive regarding gender-related effects on economics learning. Although research on the impact of ethnicity and race on economic knowledge is limited, studies suggest that differences do exist. Using our research design, we address both ethnicity and gender effects on economic literacy before and after students take high school economics.",0
47,5,"Due to the complexity of factors affecting student achievement in economics, our research focuses on one state and one county to investigate more effectively. Differences in funding and instructional emphasis on economics vary greatly between states and counties, and our design mitigates these variations and enables us to better understand the impact of student characteristics on achievement.",0
47,6,"Despite the practical limitations imposed on our research design discussed in the Study Methodology, Data, and Characteristics of the Sample section, the demographics of Orange County are still significant to this study. According to the California Department of Education (www.cde.ca.gov) for 2003-2004, Orange County had the second largest grade 12 enrollments in the state, making up more than 8 percent of all high school seniors in California. Additionally, Orange County stands out as one of the most diverse populations in the state with higher percentages of Asian and Hispanic students enrolled in 12th grade than the corresponding percentages for the state.",0
47,7,"Based on evidence from various studies, it is more effective to have students take an economics course to improve their economic literacy compared to infusing economic content in the K-12 curriculum. Students who were enrolled in economics courses performed better on the Test of Economic Literacy compared to those who were enrolled in social studies classes with no economic content or some economic content. Moreover, studies suggest that nationwide, students who took an economics course obtained higher scores on the TEL multiple choice examination. Controlling for selection bias further supports the positive effect of economics courses on post-test performance. (Mask used: Paraphrase)",0
47,8,"According to studies in the literature, there have been investigations into discrepancies in economic literacy between genders. Siegfried's [1979] article is often referenced, in which he discusses the gender gap in students' performance and notes that males tend to have a slight advantage in understanding economics at a specific time. Recent works have confirmed this gender gap, with high school students' point-in-time measures of economic knowledge generally favoring males. Studies by Watts [1987], Heath [1989], Walstad and Soper [1989], Evans [1992], and Walstad and Robson [1997] all support this finding.",0
47,9,"There is limited proof that women are inferior in learning economics when factors affecting economic comprehension and knowledge accumulation are accounted for, according to Siegfried. When using a pretest-posttest design to gauge improvements in economic knowledge, the initial disadvantage of female students does not increase over time, indicating that both genders learn at comparable rates. This finding is also observed in more recent research by Jackstadt and Grootaert, Watts, and Allgood and Walstad. Although Walstad and Soper discovered that there are significant differences in learning rates that favor males, this outcome was replicated in a subsequent study by Becker and Walstad.",0
47,10,"The impact of race and ethnicity on test scores has received limited attention in academic research. However, some studies have examined this issue. Evans [1992] and Harris and Kerby [1997] have both analyzed the impact of race and ethnicity on test scores. Evans suggests that black students tend to score lower than white students, while Hispanics perform at a similar level to whites. In contrast, Harris and Kerby's study found that black students are at a significant disadvantage compared to white students, and both Hispanics and Filipinos tend to have lower test scores than whites. On the other hand, Asian students tend to score higher than white students, but the difference is not statistically significant. Additionally, Walstad and Soper [1989] found that black students tend to perform worse on the TEL compared to other students. In addition, the US Department of Education’s National Center for Education Statistics conducted a national assessment of economic literacy for grade 12 students in 2007, revealing that a greater percentage of blacks and Hispanics scored below the basic level compared to whites.",0
47,11,"The county of Orange, California has a total of 15 school districts that are overseen by a county superintendent. We reached out to the county superintendent’s office to acquire a comprehensive list of high schools in Orange County and the contact details for each district’s superintendent. The assistant superintendent for the county wrote a letter to the superintendents of the districts, showing their support for our project.",0
47,12,"We appealed multiple times to the superintendents of the districts to gain their support for the project. Eventually, two significant school districts, Fullerton and San Juan Capistrano, agreed to collaborate with us. Seven schools from these districts participated in the research, with a total of 1,343 students enrolled in the mandatory economics courses for the fall semester of 2005. The sampling limitations found in previous studies on economic education at the pre-college and college level prevail, regardless of the sample size or financial resources available to the researchers [e.g., Walstad and Soper 1988, p. 28; 1989, p. 24]. It's vital to note that the reported 1,343 figure represents the quantity of students enrolled in the classes surveyed as of the census date. As we'll explain later, the actual number of students who attended the classes and submitted complete data was lower.",0
47,13,"To evaluate students' initial economics knowledge and subsequent learning, we use the TEL as our key performance measures. The TEL is a standardized test, which assesses pre-college economic literacy and was developed by the National Council on Economic Education. It consists of 40 multiple choice questions on basic core, micro, macro, and international economics concepts. We administer the test to our students at the beginning of the semester as a pretest and again in the last week of the course as a post-test.",0
47,14,"We required information on students’ characteristics to evaluate their performance on the TEL examination. This was obtained from a student questionnaire we designed along with official records of the school, entailing details of their demographics, family background, and academic performance. The questionnaire contained information on their race, ethnicity, gender, primary language, working hours outside of school, study hours, and parents’ educational background. GPA records (excluding physical education) were obtained from official school records. Some schools also provided standardized mathematics and reading scores. The pretest was given to students prior to the commencement of their economics course, with no prior formal training in economics. Our survey questionnaire was administered in the first fortnight of classes.",0
47,15,"Table 1 displays the descriptive statistics from the multiple regression analysis of pretest and post-test scores presented in the Analysis of Test Scores section. The sample size used for the analysis was 514 students who provided complete information on test scores and survey responses. The sample size decreased due to students who did not attend the class, students who refused to answer individual questions, or those who were absent on the day of the pretest, post-test, or survey administration.",0
47,16,"The initial column of Table 1 displays demographic, academic and work performance, and background information of students, including pretest and post-test TEL scores. The second column of the table presents frequency distributions for categorical variables and means and standard deviations for continuous variables. Our sample data show that females constitute a larger percentage compared to males (53.9 percent vs. 46.1 percent). Additionally, approximately 70 percent of the student population is white, 17.7 percent Hispanic, and 5.3 percent Asian. Approximately 4 percent of students report a language other than English for reading, writing, and speaking, and 9 percent are foreign-born. Furthermore, 10.6 percent of students speak languages other than English at home. Our data also indicate that more fathers have a college education compared to mothers, and 73 percent of the students in our sample live with both their mothers and fathers mostly.",0
47,17,"Table 1's final section presents an overview of students' attributes, such as academic performance, test scores, and work effort. The average academic GPA is 3.02, and 65.4% of students took at least one advanced placement or honors class. Moreover, 21.2% of students were part of an economics class taught at the advanced placement level. The average scores for mathematics and reading are 246 and 230, respectively, out of a possible 300. On average, students dedicated a bit under 9 hours weekly to studies and around 10.4 hours weekly to paid work. Finally, the students' TEL scores showed an increase from 52.9% accuracy on the pretest to 65.2% accuracy on the post-test.",0
47,18,"The post-test regression includes both pretest scores and student characteristics that determine pretest scores. Therefore, the coefficients for student characteristics in the post-test regression show the effects of these characteristics on post-test scores, after accounting for their impact on pretest scores. The aim is to understand how these variables influence the value-added from economics instruction.",0
47,19,"Table 2 displays data regarding pretest scores and the changes made in test scores. The information is organized based on categories such as race and ethnicity, gender, and academic performance. The first two rows of data indicate a detailed account of pretest scores and the difference in scores before and after the test. However, the data for African-American students is not included due to a limited number of observations. The third and fourth, and fifth and sixth rows exhibit the same sort of data segregated by gender and whether students have taken honors or advanced placement classes. The probability values for univariate tests of significance in each case are shown within the table.",0
47,20,"Table 2 displays that there are significant gender differences in pretest scores, albeit minor. On average, male students exceed female students by approximately 3.5 percentage points. According to Walstad and Rebeck [2001b], there exists a gender gap of 4 percentage points in favor of male students who have not had formal economic education. Additionally, students who have taken at least one advanced placement or honors class have performed better on the TEL than those who haven't. Similar findings have been reported by Evans [1992] and Walstad and Rebeck [2001a, b].",0
47,21,"In Column 1 of Table 3, it is observed that the pretest scores of Hispanic and Asian students are significantly lower than those of white students. However, multiple regression analysis shows a decrease in the white-Hispanic gap in scores, which suggests that the performance gap can be partly explained by family background, performance, and work effort characteristics. The negative effect on African American students is significant, but caution is advised when interpreting the result for Asian and African American students due to small sample sizes. This is consistent with the findings reported in Table 2.",0
47,22,"The results presented in Table 3 reveal contrasting gender effects. According to Column 1, males have a 6.4 percentage point advantage, which is 83 percent more significant than the gender difference shown in Table 2. This variation can be attributed to males performing below females in academic performance measures, but managing to score better than females on the TEL. Consequently, taking academic performance factors into account amplifies the disparity between male and female test scores.",0
47,23,"Further findings suggest that individuals who identify English as their primary language for writing and speaking are likely to achieve scores approximately 5 percentage points higher on the pretest compared to those who do not. Similar trends are observed for students who live with both parents, with an expected score increase of around 3 percentage points. Unsurprisingly, academic performance is positively associated with pretest success, with every one-point increase in academic GPA linked to approx. 9.12 percentage point increase in pretest scores. Furthermore, students enrolled in advanced placement economics classes are likely to score almost 4 percentage points higher on the pretest. Notably, the variable controlling for whether students have ever taken AP or honors classes is unimportant in the pretest regressions.",0
47,24,"Adding math and reading scores to the pretest regression analysis (Table 3, Column 2) has minimal effect on the ethnic and gender effects previously reported in Column 1. A reading score increase of ten points results in a slightly over 4% increase in pretest scores. By factoring in math and reading scores, the impact of academic GPA lessens from 9.12 percentage points to 7.42 percentage points. However, the impact of currently being enrolled in advanced placement economics increases from 3.88 percentage points to 5.78 percentage points.",0
47,25,"Our study supports previous research regarding factors that influence a student's economic knowledge in high school. As discussed in the literature review, multiple studies have found significant differences by gender, with males performing better than females. Our gender effects are even larger than those reported in previous studies, except for one by Heath. Similarly, academic ability, as measured by GPA or AP course enrollment, has been found to be a significant predictor of economic knowledge. Other studies have also shown that variables such as grade level, GPA, and holding a part-time job have a significant impact on students' scores. Additionally, ethnicity has been found to be a factor, with Hispanics and Filipinos scoring significantly lower than whites on multiple choice exams. Our study, focused on a single county, suggests even larger ethnicity and gender differences than those reported in previous studies, although the results for Hispanic students may be influenced by factors specific to Orange County.",0
47,26,"The initial knowledge of economics among high school students in the sample is not strong. Based on descriptive statistics, white students had the highest pretest TEL scores (55.5%), followed by Asians (48.9%) and Hispanics (44.1%), while males performed better than females by about 3.5 percentage points (54.8% and 51.3%, respectively). Ethnicity and gender were significant determinants of pretest scores, with Hispanic students showing a reduced gap with whites in pretest scores when academic performance and family background characteristics were controlled.",0
47,27,"The pretest score gender differences are interesting as they show that although males have a slight advantage in initial economic literacy, the gap widens when accounting for academic performance factors. Females appear to perform worse in economics compared to other subjects, potentially suggesting that introducing economic reasoning to young girls at a younger age may improve their performance. Additionally, academic performance, including GPA and standardized mathematics and reading scores, significantly influences pretest scores.",0
47,28,"The evidence suggests that teacher quality is a crucial factor in determining students' learning. The teacher-specific effects have been found to be largely significant, implying that good teachers play a vital role in enhancing students' test scores. Although there may be some common factors among students in the same classroom that lead to peer effects, the impact of teacher quality on changes in students' performance cannot be overlooked.",0
47,29,"The results suggest that effective policy intervention should target specific ethnicities and genders. Improving economic literacy for Hispanics requires addressing factors that impact their overall academic performance compared to whites. This can be achieved via better learning opportunities in all subjects, including economics, at a younger age. The discrepancy between white and Hispanic pretest scores indicates earlier exposure to economic concepts may differ due to income and community characteristics. Additionally, female students have less economic knowledge than their male counterparts, even with similar overall academic performance.",0
47,30,"It seems that more needs to be done to cultivate basic economic knowledge among students throughout the K-11 curriculum, based on our analysis of 12th graders' initial knowledge of economics, albeit limited to a specific region. Although the California History/Social Science Standards have incorporated an Economics Strand into the K-12 program since 1998, necessitating the inclusion of fundamental economic principles and ways of thinking over an 11-year period before completing a one-semester economics course during high school, this ""infusion"" requirement does not seem to have resulted in a strong grasp of economic literacy among young Californians entering 12th grade. Nevertheless, we discovered that 12th-grade formal economic instruction does enhance students' economic literacy.",0
48,1,"Classical economists gave great importance to the accumulation of capital and growth. This focus on growth and accumulation can be traced back to Adam Smith's book, The Nature and Causes of the Wealth of Nations. Many scholars have noted that Smith's work provided a formal description of economic development, in which various economic forces interacted and drove the commercial economy forward in a dynamic process.",0
48,2,"In terms of the matters related to economic evolution, there is more to the story. To comprehend it comprehensively, we require to consider the study of history as well. According to Smith, studying history is crucial to understanding mankind and society. History serves as a means to create a stable system of social science. Additionally, Smith describes the historical advancement of society from feudalism to the emergence of contemporary European states in Book III of the Wealth of Nations.",0
48,3,"In his essay on the history of astronomy, Smith highlights that science aims to identify the mechanisms that contribute to regularities between events and phenomena. Smith emphasizes that the goal of scientists is to discover the ""connecting principles of nature"" or the ""invisible chains that bind together all these disjointed objects."" Similarly, moral philosophy is seen in the Wealth of Nations as a ""science that investigates and explains these connecting principles."" Smith dedicated himself to uncovering the ""chains and mechanisms"" or ""connecting principles"" that could be used to make inferences about social events. As a result, Smith's moral philosophy, which covers natural theology, ethics, jurisprudence, and economics, is often regarded as a social science system today.",0
48,4,"Smith's historical account has been interpreted by some as a nomothetic approach to history, rather than an idiographic one. This means that history is viewed as less of a narrative description of past events and more of a systematic examination of main issues, starting from a theoretical framework. Smith's historical discourse began with the system and used historical evidence to support his theory, rather than starting with the facts and forming a theory from them.",0
48,5,Scholars studying Smith found it intriguing that he claimed in 1776 that the true progression of economic growth in Europe was completely reversed. This spurred Smith to dedicate chapters two through four of Book III to exploring the reasons behind this divergence. Some individuals have since contended that Smith could not reconcile his theoretical perspective on history with the facts of the past.,0
48,6,"For the current intention, it is crucial to note that the theoretical progression described in the initial chapter of Book III relies on an economic theoretical model that assumes a set of institutional, legal, and political factors as steadfast.",0
48,7,"Smith's theoretical history of economic progress may have an extended dimension that involves the integration of politico-economic modeling alongside economic modeling. This would involve examining the principles and structures of legal rules and incentives at the level of the polity and their relationship with economic forces. Smith attempts to do this in much of Book III and IV of the Wealth of Nations, yet the presentation of this theoretical history of economic change may not be immediately apparent.",0
48,8,"Smith believed that political economy is not solely concerned with economics but is also influenced by political activities. He considered it as a branch of the science of a statesman or legislator, which may be referred to as a theory of the state. Moreover, he believed that natural jurisprudence, which is a theory of the general principles that should underpin the laws of nations, could be considered as a precursor to the theory of the state.",0
48,9,"Smith's politico-economic model in economic history suggests that his theories of the state and positive economics serve as sub-theories. According to Smith's historical account of Europe's progress, the model shows that the interaction between the polity and the economy is affected by governmental actions and legal institutions created by public policy, leading to either favorable or unfavorable economic performance.",0
48,10,"Smith acknowledged that various factors play a significant role in the growth and decline of wealth in the actual historical process. He emphasized that defense, climate, culture, terrain, and luck are some of the forces that affect economic performance and social transformation.",0
48,11,"According to Smith's 1776 book, the principle of self-love, known as the desire to improve one's circumstances, is an innate, lifelong drive. Smith posits that this drive is what propels individuals to save and as a result, contributes to capital accumulation at the macro level, ultimately leading to increased national income and higher employment.",0
48,12,"Smith's economic history includes an examination of institutional elements, like political regulations, property rights, and contracts, which are regulated by the state. These human institutions serve as formal limits to daily life and serve as a critical facilitator of human interaction. If structured properly, a polity type and property rights structure can allow individuals to confidently engage in economic activities, allowing for a more efficient use of resources.",0
48,13,"""Starting from Book III, Chapter 2 of the Wealth of Nations, Smith chronicles the growth of wealth and the shift to the contemporary economy, which primarily took place in Europe following the decline of the Roman Empire. According to Smith, this time period marked an agricultural stage. Thus, Smith's depiction of history centers around the development of agriculture.""",0
49,1,"The study examines the extent to which institutional environment contributes to global variations in economic growth and development by using a novel approach based on the institutions-augmented Solow model. Regression equations are employed to estimate the model empirically, and data from 180 countries during the 1993-2012 period is used for the analysis. Results show that higher quality institutional environments significantly influence economic development across all five institutional indicators, namely two indices of economic freedom, the governance indicator, the democracy index, and the EBRD transition indicator for post-socialist countries. The study concludes that differences in human and physical capital and institutional environment account for about 70-75% of global disparities in economic development. Nonetheless, the institutions-augmented Solow model performs relatively poorly in explaining differences in economic growth rates. Only the index of economic freedom has a statistically significant impact on economic growth.",0
49,2,"There are multiple influences that impact economic growth and development, encompassing theoretical and empirical perspectives. By categorizing these factors, it can be concluded that they are either demand-side or supply-side determinants. The demand-side group includes aggregate demand components like investment expenditures, government spending on goods and services, and net exports (while consumption is excluded due to its dependence on output). Whereas, the supply-side group encompasses variables like physical capital, human capital, labor, and technology that affect potential output. Both of these categories can be further subcategorized as per their type, including multiple types of investments or government spending, or capital. As these factors directly transform inputs or expenditures into output, they are termed as direct determinants.",0
49,3,Economic growth and development rely not only on direct determinants but also on deep factors of production. These deep determinants impact the direct determinants and ultimately affect the macroeconomic performance. Institutions are considered deep determinants as they facilitate interactions between measurable inputs and output.,0
49,4,"The significance of institutions in driving economic growth and development is vast. Yet, determining which institutions play the most pivotal role in economic growth and measuring them quantitatively for empirical studies poses two main questions. Firstly, identifying the most vital growth-contributing institutions and secondly, quantifying institutions to include in empirical evaluations. The complexities of addressing these inquiries indicate that there is much scope for theoretical and empirical research that investigates the link between institutions and economic growth.",0
49,5,"The term 'institution' has a vast scope, with countless variables representing various types of institutions. Sulejewicz's study from 2009 illustrates this concept with numerous institutional categories. Meanwhile, Persson defines institutions as the mechanisms of the 'game,' sustained by legal and social norms or dominance by powerful groups. Informal institutions, such as trust and loyalty, exist alongside more formalized institutions like limited liability corporations which necessitate legal input. Markets require multiple types of institutions, from property rights to economic stabilization measures, social insurance, and strategies for conflict management, including the rule of law, high-quality judicial systems, representative political bodies, free elections, independent labor unions, social partnerships, and minority group representation. Rodrik's 2007 work identifies these fundamental institutions as essential for functioning markets.",0
49,6,"The research hypotheses and objectives of the paper encompass various aspects. Firstly, the paper seeks to expand the neoclassical growth model by incorporating institutions. Secondly, it aims to evaluate the impact of institutions on the economic development of countries across the globe through empirical analysis. Thirdly, the paper investigates the empirical impact of institutions on the global level of economic growth. Lastly, the paper intends to estimate the production function on the basis of the aforementioned results.",0
49,7,"It is not feasible to analyze all possible types of institutions in one empirical study, so constraints must be introduced regarding the number and type of institutional indicators. The study focuses on four indices reflecting different aspects of the institutional environment: economic freedom, governance, democracy, and transition. GDP per capita at PPP measures economic development, while its growth rate reflects economic growth. The study covers 180 countries, but models may be estimated based on a smaller number of countries depending on data availability.",0
49,8,"The article consists of five sections. The second one, situated after the introduction, outlines the methodology by briefly explaining the Mankiw-Romer-Weil model as well as the institutions-augmented Solow model, and by examining the literature, describing other chosen studies on the connection between institutions and growth. Subsequently, the next section depicts the utilized data. After that, the findings of the investigation are demonstrated and talked about. Lastly, the conclusion is provided.",0
49,9,"We will be comparing the Solow model, which has been expanded to include human capital, known as the Mankiw-Romer-Weil (MRW) model, with our own model, the institutions-augmented Solow model. We will only be presenting the most crucial assumptions and implications in this section to maintain brevity. Próchniak [2013] delves deeper into some of the topics.",0
49,10,"According to the Solow model augmented with institutions, Equation (21) indicates that economic growth is influenced by both institutions and standard factors. Economic growth is more rapid with better institutions. By using linear regression to estimate Equation (21), we can empirically verify the impact of institutions on economic growth, subject to certain assumptions regarding the regression model and estimation methods. Bia?owolski, Kuszewski, and Witkowski [2010] assume that all macroeconomic relationships are linear.",0
49,11,"There are different ways of finding the variables that affect economic growth besides the estimation of the regression equation. One alternative method is growth accounting, which calculates the impact of measurable factor inputs and technology on economic growth. The Solow residual represents the unexplained part of growth that is attributed to technical progress or total factor productivity. However, we cannot distinguish the contribution of institutions from other factors using this method. Estimating the regression equation and growth accounting require different econometric methodologies, and therefore cannot be directly compared. If interested, see Rapacki and Próchniak [2006] for studies using the growth accounting exercise.",0
49,12,"It is well documented in literature that there is no singular approach to measuring institutions, hence a plethora of empirical studies have been conducted to assess their impact on economic growth or development. The sheer volume of these studies makes it unfeasible to cover even a small proportion in a single paper. Therefore, we present a concise overview of selected empirical studies in Table 1. These studies evaluate the influence of institutional environment on macroeconomic performance using a range of indicators including economic freedom, level of democracy, and political stability.",0
49,13,"The methods of analysis in the literature review are diverse and include various theoretical models, institutional indicators, samples of countries and time periods, and econometric modeling. While some clear tendencies have been observed, such as the positive impact of economic freedom on economic growth, some questions remain unanswered, such as whether the impact of institutions on growth is linear or nonlinear. This leaves much room for further empirical studies. Our paper aims to test the suitability of the institutions-augmented Solow model in explaining differences in economic growth rates and levels of development, and use these findings to estimate the macroeconomic production function.",0
49,14,We will examine the institutions-augmented Solow model in this section to demonstrate how it explains the distinctions in economic development and growth across various countries. The investigation starts by identifying the factors that determine economic development before switching to examine the factors accountable for economic growth.,0
49,15,"Based on Table 2 data, the institutions-augmented Solow model performs exceptionally well in explaining global variations in income levels. Regardless of the institutional indicator used, all regression equations exhibit high R-squares, and estimated coefficients align with theoretical analysis and our expectations. For example, variant A indicates that differences in physical capital accumulation, human capital accumulation, population growth, and economic freedom explained about 75% of global differences in economic development. All explanatory variables were statistically significant except for population growth, which had a positive sign contrary to theory. If the Fraser Institute's index of economic freedom was used as the institutional indicator, the results were similar, with human capital and institutions remaining significant, but physical capital becoming insignificant. Variant C, where the institutional variable was the world governance indicator compiled by the World Bank, yielded similar results to variant B, except for physical capital, which was completely insignificant.",0
49,16,"Based on theoretical analysis, there is a negative relationship between the rate of economic growth and the initial GDP per capita level, which indicates convergence. As countries experience a catching-up effect, income disparities between them decrease. Furthermore, physical capital and human capital accumulation, as well as institutional factors, have a positive impact on the rate of economic growth. On the other hand, population growth has a rather negative relationship with output dynamics.",0
49,17,"The Solow model, extended for institutional variables, is more effective in explaining worldwide differences in economic development than differences in economic growth rates. This is because institutional factors, investment rates, and human capital accumulation are related to the supply side of the economy, influencing potential output significantly. Additionally, economic growth rates are influenced by many demand-side factors and other forces, which do not accurately reflect fluctuations in potential output. Institutional factors have long-term effects on economic development, while economic growth rates do not reveal long-term tendencies. Therefore, the institutions-augmented Solow model can better explain differences in economic development than rates of economic growth.",0
49,18,"When analyzing the outcomes, it is assumed that the past explanatory variables affect the current level of economic development. However, some macroeconomic correlations have mutual causation, which is due to the endogenous nature of particular variables. For instance, being wealthy enables a country to have better prospects for saving, investing in human capital, and favorable regulations and institutions. Nevertheless, to examine endogeneity, more advanced econometric techniques are necessary and could be explored in future studies.",0
49,19,"The formulas above present somewhat conflicting results. The first formula highlights the significant role of human capital in economic development, while the latter places greater importance on physical capital accumulation. This could be because the former formula was derived from the determinants of economic development, where human capital proves more influential. Economic well-being stems from long-term economic growth, which largely depends on human capital accumulation from the past few decades. Consequently, countries with surplus human capital tend to achieve higher levels of economic development.",0
49,20,"In medium-term economic growth, physical capital appears to be more crucial. Investing in physical capital results in rapid economic growth, whilst the accumulation of human capital takes more time to have an impact. Therefore, physical capital is deemed to be a more significant variable in the process of economic growth. This perspective is shared by some economic growth models, such as the Uzawa-Lucas model, which suggests that a weaker economy's pace of development primarily depends on whether the nation is scarce in physical or human capital.",0
49,21,"Institutions are a crucial factor in determining GDP, irrespective of the model employed. On average, the institutional elasticity of output is either 0.55 or 1.05, implying the significance of institutions in determining output. Moreover, most of the individual models also substantiate this conclusion.",0
50,1,"The study focused on examining the idea of an economic man as a key figure in economic ethics by exploring the behavior of individuals in economic settings. We considered traditional economic theories and drew inspiration from M. Weber’s and S. N. Bulgakov’s depiction of the Christian economic man. Instead of exploring various approaches to economic ethics, we utilized Weber and Bulgakov’s definition to scrutinize the hypothesis of a rational economic man, and debated L. von Mises’s and A. Sen’s positions on the freedom and character of an economic man. One of the essential issues that need to be studied among scholars interested in economic ethics and business ethics is how to reconcile the self-interest and altruistic tendencies that often coexist in an economic man, with the goal of creating more altruistic economic agents.",0
50,2,"In the late 19th century, China faced a challenge from the capitalist powers of Europe and America and the influence of Western civilization. China first encountered the West's military might in the form of ships and guns, which prompted a realization of the advantages of laws and institutions in Western capitalist countries. As a result, Neo-Confucianism reinvented the traditional Confucian concept of 'external enrichment' to harmoniously blend Confucianism, capitalism, and democracy. Similarly, when Peter the Great westernized Russia, the amalgamation of Russian and Western civilizations was an important issue. As Russia enters the 21st century with a 'westernized' capitalist market economy, the issues of reconciling Western civilization with the inherent Russian culture and promoting a mature and incorruptible democracy are yet to be fully addressed. This topic is worthy of academic attention.",0
50,3,"In the 1950s, various researchers such as Pye (1982), Mead (2001), Almond and Verba (1963), Lipset (2001), McClelland (1987), among others, made significant contributions to research techniques used at that time. From the 1970s to the 1980s, several Asian countries came under the influence of Confucian culture, primarily after the economic success of the Four Asian Tigers (Hong Kong, Singapore, South Korea, and Taiwan). Thus, scholars like Landes (1998), Fukuyama (1995), Huntington (1993), Porter (1990), Radelet and Sachs (1998), based their studies in Confucian ethics and culture's part in economic growth. Consequently, since the 1990s, there have been many studies on the interaction between culture and economic/political development. Although Confucian ethics are a significant foundation of Chinese culture, the Eastern Orthodox Church's religious culture and ethics have heavily influenced Russian culture. Despite this, there have been few studies examining the Russian Orthodox ethics culture's impact and interaction with economic development. Therefore, it is of great significance to study the operation of Russian-style capitalism, driven by the Eastern Orthodox Church's culture rooted in ethical beliefs.",0
50,4,"This study aims to employ Amartya Sen's economic ethics theory to develop Russia's capitalist market economic ethics by comparing the economic ethics of Protestantism and the Eastern Orthodox Church. The Russian Orthodox Church's culture and tradition have significantly influenced the country's development, as demonstrated in A. Leroy-Beaulieu's 'The Empire of the Tsars and the Russians' and J. F. Hecker's 'Religion under the Soviets,' where Russians are referred to as 'apostles of God' and 'those who yearn for God.'",0
50,5,"The primary objective of this study is to explore the economic system of the Russian capitalist market along with the ethical principles that the Eastern Orthodox Church follows in business management. Additionally, it extends Max Weber's ethical musings on the capitalist economic system in his famous work ""The Protestant Ethics and the Spirit of Capitalism."" Besides, it examines how the religious and cultural background affects economic development and business operations.",0
50,6,"Bulgakov's 'Eastern Orthodox Church-The Orthodox Dogma' discusses the connection between religions and economic activities in a person's soul, and the intriguing topic of the types of economic man in Christianity, including Puritan, Lutheran, Reformed, Quakers, and the Eastern Orthodox Church. He believes that the branding of 'economic man' is unavoidable in religion. This study focuses on examining the relationship between the Eastern Orthodox Church's economic man and the capitalist market economy and identifying the differences with other types of economic man.",0
50,7,"The section titled ""The Development of Economic Ethics and Sen's Claim of Economic Ethics"" explores economic ethics and economic systems through Sen's ideas about human freedom, development of capabilities, and lifestyle choices. Within Sen's words, there are underlying suggestions about the concept of an ""economic man"" based on his understanding of freedom. This concept of the economic man is revisited in the concluding section of the paper.",0
50,8,"Bulgakov, a renowned Russian Orthodox theologian, was unique in that he also had expertise in economics, having taught Marxist economics at both the Lomonosov Moscow State University and the Taras Shevchenko National University of Kyiv. However, he gradually became more interested in Orthodox theology and was ordained as an Orthodox priest in 1918. His political beliefs eventually resulted in his expulsion from the Soviet government in 1922, after which he established the Institute Saint-Serge in Paris, France, where he taught dogmatics until his death in 1944. Bulgakov's diverse background allowed him to investigate various issues, from Orthodox ethics to alternative economic systems and economic development, often drawing on the Christian economic ethics of M. Weber. As a result, his ideology has influenced modern business ethics and capitalist economic ethics. In this course on capitalist economic ethics, we will delve further into Bulgakov's life, academic pursuits, and contributions.",0
50,9,"Bulgakov grew up as a devout Orthodox Christian in a family of Russian Orthodox priests. However, during high school, he became an atheist and a Marxist. He gained recognition as a Marxist specialist with the publication of his monograph on ""Production in a Capitalist Market"" in 1896. After returning from Western Europe in 1901, Bulgakov was influenced by the works of Kant and Schelling and began to question Marxist economics, particularly the contradiction between the rule of concentrated production and rural production, leading him to publish his Master's thesis on ""Capitalism and Agriculture"". He then underwent a transformation, believing that human life and society were based on absolute values such as truth, goodness, and beauty, and subsequently published ""From Marxism to Idealism"" in 1903 to explain his ideological shift. Bulgakov confessed that he initially saw himself as a pure social scientist, but he was eventually compelled to explore issues of righteousness, truth, and the existence of God when investigating the foundation of the social system. As a result, he became interested in the relationship between Christian ethics and the economy or society, which became a major focus of his research.",0
50,10,"Bulgakov explored the idea of a man-God and analyzed aspects of pseudo-Christianity found in both materialistic atheism and Marx's socialism. For instance, he compared the prophecy of socialism's development and the fate of capitalism to the eschatology found in Christian theology. Additionally, the proletariat's mission mirrored that of God's chosen people, who had specific vocations, while capital was seen as Satan. Bulgakov wrote two essays on this topic - ""Pristine Christianity and Last Socialism"" in 1909 and ""Apocalypse and Socialism"" in 1910. Regarding economic ethics, Bulgakov argued that Marx's socialism or atheist pseudo-religion was centered around a self-righteous man-God, akin to Christ or a saint but hostile towards Christianity and God-man saints. This man-God goes against the unique personality and soul of Christian economic man. (Adapted from Lossky 1952, pp. 200-202).",0
50,11,"The dissertation 'Philosophy of Economy: the World as Household' by Bulgakov delved into not only the concept of an economic man but also human economic behaviors. Bulgakov viewed the correlation between labor and the realistic world as the focal point of economic endeavors. Economy was seen as a bridge that connected a living person with the realistic world, which could not be accessed by the dead who lost their ability to communicate with it. For a Christian, a person's rebirth and immortality meant he or she could continue to consume in the realistic world. Production was viewed as the labor rights and responsibilities of an individual in the realistic world (Bulgakov 2000; Valliere 2000, pp. 253–278).",0
50,12,"Bulgakov extensively discussed economic ethics and the concept of Christian economic man in various works such as ""The Soul of Socialism"" (1932-1933), ""Social Teaching in Modern Russian Orthodox Theology"" (1934), and the monograph ""The Orthodox Church"" in ""Orthodox Church and Economic Life"" (1935). As an economist and Russian Orthodox theologian, Bulgakov explored the relationship between Christianity and socialism, ultimately contending that socialism was soulless. In his thinking, he considered the properties of an economic man in Christian terms following the Orthodox style, and then discussed the foundation of economic ethics from a Christian viewpoint in both socialist and capitalist economic systems.",0
50,13,"Economic growth in Economics originates from Adam Smith's ""An Inquiry into the Nature and Cause of the Wealth of Nations"" and was further scrutinized by J. M. Keynes' ""The General Theory of Employment, Interest and the Money"", which had a profound impact on academic reexamination of economic growth. Scholars such as R. F. Harrod, E. D. Domar, R. M. Solow, N. Kaldor, J. Tobin, and others analyze economic growth based on labor productivity, capital accumulation, and advancements in production technology.",0
50,14,"The Supply-Side School prioritizes reducing government control and taxes, as well as controlling inflation to boost the aggregate supply function and stimulate economic growth. Nonetheless, Amartya Sen's 1998 Nobel Prize win has shifted the focus of economic growth research and increased consideration of the ethical and moral components linked to economic development.",0
50,15,"According to Sen (2000), economic development can only be achieved when factors that hinder free will are eliminated. He also emphasized the importance of critical thinking in Economics and credited economists such as Sir William Petty, Leon Walras, Francois Quesnay, David Ricardo, and Augustine Cournot for pioneering engineering analysis in the field. Furthermore, Sen (1987) and Evensky (2007) noted that the relationship between Economics and ethics was established when ethical considerations were given weight by notable economists like Adam Smith, John Stuart Mill, Karl Marx, and Francis Edgeworth.",0
50,16,"Christianity places great importance on the concept of human freedom, which is valued by various divisions such as the Eastern Orthodox Church, Catholicism, and Protestantism. The question of 'who is man?' and 'what is the relationship between man and God?' arises when discussing human freedom. The term 'Imago Dei' from the Old Testament's Genesis is used to explain who man is, where man's inherent characteristics of rationale, free will, and morality are used to describe man's reflection of God and their special relationship. Karl Rahner, a Catholic theologian, describes man as the receiver of the Word of God to explain the relationship between man and God. However, it is unclear whether man's mirror image of God, which was destroyed by Adam, can be restored through salvation or whether it only came into existence after the Original Sin, with some parts intact and others damaged.",0
50,17,"Luther spoke about the virtue of having faith amidst the uncertainty and limited freedom. Christians with faith can freely pursue their needs without feeling compelled to please God or gain recognition from him. On the other hand, those without faith are unhappy and worrisome. Salvation comes through complete trust and wholehearted waiting for God, with a complete abandonment of self-directed activities. Consequently, only after redemption can man truly be free to serve God. (Althaus and Schultz 1972, pp. 37–39; p. 55; Brendler 1991; Hummel 2003).",0
50,18,"Eastern Orthodox Theology emphasizes the Eastern origins of Christian religious rites and beliefs due to the fact that the majority of early churches were located in the East. Additionally, Orthodox theologians assert that the Greek language more accurately conveys Christian doctrine and that Latin terminology cannot fully convey the subtle differences in concepts expressed in Greek theology.",0
50,19,"Sen's economic development theory focuses on the correlation between human liberty and development. True freedom renders individuals capable of tapping into their potential and expertise to attain a particular position, occupation, or social standing, such as volunteers, doctors, soldiers etc., referred to by Sen as 'being.' This concept differs from Weber's religious notions of 'calling' or 'Beruf.' According to Weber, Calvinist Puritans aimed to become Berufsmenschen, serving God's kingdom through austerity and reshaping the world. Capitalists can efficiently utilize voluntary productivity, resulting in increased labor productivity, according to Weber. However, the capitalist mode of production eventually replaced humans with machines, eliminating the need for asceticism, which led to the Beruf concept evolving into wealth acquisition without any spiritual or ethical connotations. Asceticism gave birth to capitalism but slowly declined with the rise of capitalism.",0
50,20,"Bulgakov proposed a fusion between man's role as Logos in the economic world and asceticism, as well as the responsibility of governing and abandoning the world, since he considered man as the Logos and creator of this world. The new economic man motivated by this labor mechanism could increase productivity. Bulgakov's 'homo economicus' differs from Calvinist's 'Berufsmensch' as the former has an ascetic nature and exists only as an identity of Logos, while the latter assumes his profession as a calling and regards his work as a lifetime mission bestowed by God upon him. Man collaborates with the Holy Spirit to deify the world and governs it after creation.",0
50,21,"The Logos of the economic world is how man is defined in the Eastern Orthodox concept of the new economic man. According to this concept, God assigns man to govern and create while also endowing him with labor rights and obligations to participate in God's mission of world divinization. This context makes ""instrumental freedoms"" seem beneficial for economic convenience and freedom, as well as basic human rights and economic rights for free trade in the market. Utilizing Sen's proposed development strategy to create a good environment and safeguard freedom could be most beneficial to Russia's overall economic development.",0
50,22,"Bulgakov's views on Christian economic man were examined in relation to Sen's arguments about the connection between human economic behavior and economic systems. The study also looked into theological concepts like human freedom, God's calling, predestination, justification, mysticism, deification, and economic ethics within a particular economic system. The research also touched upon Weber's work on the man working in a calling within the context of Lutheranism and Calvinism.",0
50,23,"Bulgakov's rejection of Marxism was elaborated in his statements about the economic man from 1903 to 1911, and his later works, including 'Philosophy of Economy', were influenced by Weber's concept of a Christian economic man. Bulgakov discussed various interpretations of this concept within different Christian contexts, but it did not receive as much attention as the traditional economic view of the economic man. This suggests that there is potential for further research in this area.",0
50,24,"Sen's investigation of shifting the rationale and self-interest-focused economic man to a liberated economic man falls short of capturing the essence of an economic man's soul, as explained in von Mises's works on the first chapter's portrayal of economic behavior and the third chapter's discussion of free will, which is considered an essential aspect of analyzing a person's economic conduct (von Mises, 2006). In comparison, Bulgakov's depiction of a Christian economic man and Weber's idea of a man laboring with a purpose, referred to as a Calvinist economic man by Bulgakov, are more aligned with von Mises's idea of an economic man.",0
50,25,"Bulgakov and Weber both focused on the connection between an economic system and religious ethics. While Weber highlighted the influence of Calvinist economic ethics on an economic man, Bulgakov expanded this concept to include an economic man in Christianity. Additionally, both authors discussed the idea of a soulless economic man. Bulgakov believed that a materialist economic man in Marxism would lack a soul, while Weber argued that many workers in the last stage of capitalism had lost their Protestant ethics and become soulless.",0
51,1,"The aim of this article is to make clear the underlying assumptions that were presented during a recent discussion regarding the feasibility of utilizing computer models for economic planning. Furthermore, it seeks to present extra points in relation to the debate on economic calculation.",0
51,2,"The article presents further evidence to support the idea that computing in a controlled economy involves dealing with limitless, uncountable domains. Furthermore, it refutes the criticisms made by certain scholars in 2007 against Murphy's theories.",0
51,3,"The practical significance of computation and calculation within an economic system cannot be overstated. The economic calculation problem plays a critical role in determining institutional settlements and policies. Certain institutional frameworks may hinder the ability to rationally allocate resources through economic calculation. Therefore, the conclusions of the economic calculation debate hold immense importance. When defining institutions and policies, economists and philosophers must consider the possibility of computation and calculation within an economic system.",0
51,4,"The question of whether economic problems can be solved using computability theory is the focus of computability in an economic system. While modern computing devices have immense calculating power, we cannot always assume that any problem, including economic ones, can be solved with enough time and resources.",0
51,5,"The economic problem involves the rational allocation of resources in a system. Even individuals with self-sufficient lifestyles must address this issue, as there are typically more wants and needs than available resources. The scarcity of time is a significant example of this problem, as prioritizing objectives is crucial for this limited resource.",0
51,6,"Von Mises argues that even if a collective form of property lies at the core of an economic system and the planner possesses all the necessary information, economic calculation still cannot be carried out. For the sake of his argument, von Mises assumes that the planner has complete technological knowledge of that time and holds an inventory of all the production factors. A group of experts provides all the essential information, and every individual of the society agrees on the common goals. However, the planner faces an insurmountable problem of selecting the best method or project from an enormous amount of options available to achieve the desired ends. For instance, in constructing a house, there exist different methods, each with its benefits and drawbacks regarding the final product, resource consumption, and production time. The planner is compelled to compare diverse variables such as labor, production time, productivity of tools and machines, quality of building materials, and resource consumption to determine the optimal approach in a scenario where everything is the same.",0
51,7,"In a complicated economy, the production methods come in a variety of forms. The means of production fall somewhere in between specific and non-specific. If every means of production was either specific or non-specific, then deciding on the method of production and the means to be used would be a technological problem rather than an economic one. Even in a simple economy, making a rational choice between diverse means and methods of production would have some limitations. In a complex economy, the main difficulty doesn't come from deciding what final goods to produce. This can even be resolved in a socialist economy. However, the real issue arises when choosing the most favorable means and methods of production to reach the ultimate goal. This becomes an insoluble problem for the planned economy (von Mises, 1998, pp. 207-8, 13).",0
51,8,"The significance of market prices lies in how they allow for reasoned decision-making when it comes to choosing the most suitable means and methods of production among numerous available options. This is made possible through monetary calculation based on market prices, which are formed within a private property system where entrepreneurs bid for the goods they require, both final and intermediate. Overall, this approach constitutes the solution to the economic issue of resource allocation.",0
51,9,"Abba Lerner and Oskar Lange acknowledged the significance of market prices in economic calculation, but they dismissed the notion that a free market, based on private property, is an essential prerequisite for economic calculation. They argued that planners can emulate any market outcome. Lange, in his papers of 1936 and 1937, advocated for market socialism. He maintained that three types of data are essential for calculation- individual preferences, prices, and knowledge about available resources. An important contrast between von Mises and Lange is their conception of prices. Lange believed that prices could be determined by knowing individuals' preferences and the quantity of available resources. He recommended a trial and error process or a Tatonnement solution for identifying the ""correct"" equilibrium prices of goods. Conversely, von Mises believed that price determination can only occur in a market economy that is based on private property.",0
51,10,"Lavoie (1981) revised the argument made by von Mises against socialism and argued that the critiques are not nullified by the advocates of market socialism. The basis of Lange's solution was the Walrasian model of static equilibrium, which according to von Mises was not a suitable framework as it did not account for dynamic adjustment and discovery amidst constantly changing conditions such as technologies and preferences. Lavoie maintained that von Mises did not deny socialist economic calculation in static conditions, but this is not applicable in reality. Economic calculation in a collective economy is impossible in principle, and the computation argument is underplayed as the equations cannot be set up from the start.",0
51,11,"In the upcoming section, we'll examine a recent discussion about the boundaries of computability within an economic system that relies on central planning and collective property ownership. Robert Murphy, who took on a revised stance in the economic calculation debate, put forth a fresh argument to bolster his thesis that the computational models can't solve the economic problem in theory (Murphy, 2006). On the other hand, Cottrell et al. (2007a, b) held to the standard stance in the economic calculation debate and challenged Murphy's argument.",0
51,12,"According to Murphy, the argument is not formulated in one step. The first point highlighted is the continuous innovation by entrepreneurs in the market process, which means that the list of goods to be produced is always open-ended. To mimic the market process, the central planning unit must take into account all possible future goods and commodities that may appear in the market, including fiction books, movies, services, and intermediate goods. Consequently, the central planner must have the corresponding lists of prices of all final goods and implicitly of all intermediate goods necessary for producing consumer goods.",0
51,13,"Considering an application of Cantor's diagonal argument to prove the existence of an uncountable set, Hunter (1996) finds it helpful in illustrating why the number of prices is uncountably infinite.",0
51,14,"Cottrell et al. (2007a, b) argued that R. Murphy failed to provide evidence that the set of market prices is either infinite or uncountable. They claimed that every commodity is produced from a finite number of other commodities, and therefore, the number of all commodities must also be countable. This is because every commodity can be represented by a unique integer identifier based on a Godel number composed of the number of atoms of each element it contains. Based on this reasoning, Cottrell et al. concluded that all possible commodities could be enumerated, and therefore, the set of commodities is finite and countable. Since the set of commodities is countable, so is the set of corresponding prices (Cottrell et al., 2007a, b).",0
51,15,"Cottrell et al. (2007a, b, p. 3) posed a thought-provoking question about the notion that although there may be infinite uncountable prices in a market economy, individuals do not need to consider all of them to make economic decisions successfully. If they did, the problem of economic calculation would be insurmountable. Therefore, it seems unclear why Murphy insists that a central planning unit must take into account all possible prices, goods, and services, even those which may not exist yet.",0
51,16,"Taking into account all possible prices is not only motivated by the innovation problem, but also by the nature of private property in a market economy. In this system, individuals express their preferences through market exchanges but are limited by the finite amount of possessions they have to exchange. In contrast, in a society with collective forms of property, individuals have unlimited preferences which the central planning unit must take into account. Mimicking market processes requires the planner to consider all the virtually infinite preferences of individuals resulting in an infinite set of prices, which aligns with the theory of subjective value.",0
51,17,"The initial query about whether it is truly an infinite uncountable range of prices remains unresolved. Rather, we emphasized that the group of possible individual preferences is boundless as there are no restrictions on individuals expressing their preferences.",0
51,18,"The utilization of Cantor's diagonal argument displays that the set of prices the planner must consider is not only infinite but also uncountable. The reasoning begins by defining each good and its price through equations that utilize a set or a subset of preferences. It is also assumed that the set of potential preferences of individuals is infinite (p1, p2...pn). By applying the technique of changing each ""Yes"" to ""No"" and each ""No"" to ""Yes"" on the diagonal, a new subset of preferences, unlike any other existing or future subsets, can be defined. Hence, there is a one-to-one correspondence between the set of all potential preferences and the set of natural numbers, but there is no such correspondence between the set of all subsets of preferences and the set of natural numbers. Consequently, the number of subsets of preferences used to define prices of goods is an uncountable infinite set (Table III).",0
51,19,"The issue of the infinite uncountable set of preferences cannot be solved by the consumer goods market alone, even if the consumer preferences are finite. This is because the preferences of managers and entrepreneurs are still an infinite uncountable set. The market often sees managers and entrepreneurs supplying products that are not specifically requested by consumers. Entrepreneurs' investment preferences are also restricted by the capital they possess. Alternatively, in a planned economy, the central planning unit still has to determine the prices of intermediate goods while taking into account an infinite uncountable set of prices. As an example, The Matrix by the Wachowski brothers was not written in response to consumer demands.",0
51,20,"In the debate on economic calculation, Lange suggested that the planner must rely on market prices for consumer goods to deduce the prices of intermediate goods. However, von Mises countered that this would not solve the problem because the planner would face the same challenge at the intermediate goods level. von Mises argued that the prices of intermediate goods are not determined by a technical method, as production factors are not entirely specific or non-specific, and there are many ways to produce final goods using intermediate goods. While the prices of intermediate goods may partly depend on individual preferences for final goods, entrepreneurs ultimately bid for different amounts of intermediate goods to establish prices. Market prices for intermediate goods assist entrepreneurs in finding the most profitable solution. As a result, the planner will confront a similar problem at the intermediate goods level as they did with consumer goods.",0
51,21,"After reviewing Murphy's arguments, we utilized Cantor's theorem from set theories to refine and rephrase our points. Our thesis is that for a planned economy, a computational model must consider an uncountably infinite set of equations and prices. It follows that the central planner would struggle to establish all the necessary calculus equations, rather than compute the vast number of equations required. With this in mind, we believe computational models cannot replicate the market process.",0
51,22,"The economic calculation debate relies heavily on the concept of price formation, which is influenced by the prevailing theory of value. As such, the presuppositions surrounding value are crucial in this debate. However, Cottrell and colleagues' objections failed to take into account the true conception of value and price formation in the Austrian School of Economics. Consequently, we have dismissed their objections to Murphy's (2006) theses.",0
52,1,"The study examines citizens’ economic expectations during the 2008-2009 global economic crisis, which are identified as crucial for political attitudes. Unlike previous research which took place during stable economic times, this study considers the impact of information on economic evaluations during severe crises. Using a three-wave panel study and media content analysis, the study provides a dynamic assessment of media influences on changes in economic evaluations. Results show a significant effect of media exposure on expectations regarding the future development of the national economic situation, but not on personal economic expectations. The study also reveals that media dependency exacerbates the magnitude of the media effect. The authors discuss the disparity between personal and national economic evaluations regarding mass-mediated economic information.",0
52,2,"The economic expectations of citizens are shaped by information about the economy, which can be influenced through personal experience, interpersonal communication and media coverage. This article narrows its focus to the impact of media coverage on changing economic expectations during times of crisis and which specific expectations are affected. The study primarily focuses on the influence of the media on assessments of the national economy, rather than personal economic expectations. It is hypothesized that mediated information largely shapes evaluations of the national economy.",0
52,3,"The research analyzes how feedback changes over time, cautiously estimating the impact of information. Additionally, it draws on previous studies that suggest media effects vary in intensity for different audience segments. To refine our insight into the correlation between economic media coverage and citizens' assessments, the study integrates media content and poll data, associating media coverage indicators with diverse economic evaluations. It also considers the potential moderating effect of news dependency on media outcomes.",0
52,4,"According to existing literature, citizens' economic expectations in established democracies have primarily been studied during periods of economic stability. Therefore, this study is one of the first to examine economic perceptions during times of rapid and unequivocal deterioration. In times of an economic crisis, individuals often experience uncertainty about their economic future, which may prompt them to engage in information-seeking behavior. Additionally, heightened media attention during difficult economic times may further emphasize the importance of mass-mediated economic information.",0
52,5,"Rational choice theorists argue that citizens are not expected to possess complete information about the economy all the time, and instead, they are ""rationally ignorant"" about general affairs (Downs, 1957). However, several studies indicate that citizens possess significant knowledge relating to economic topics such as the unemployment rate, mainly during election periods (Paldam and Nannestad, 2000). Nonetheless, there are various reasons why citizens' perceptions of economic conditions may differ from reality (Hetherington, 1996). First, citizens may use different criteria to evaluate economic condition (Kinder et al, 1989). Second, citizens' preferred party may impact their perception of favourable economic conditions, biased towards a particular party being in power (Kramer, 1983; Wlezien et al, 1997; Van der Eijk et al, 2007). Lastly, the study focuses on the role of mass media as a central information provider influencing the citizens' perception and evaluation of the economy.",0
52,6,"The political impact of the economy is often studied through citizens' perceptions and evaluations of it, known as the subjective economy. Previous research on this topic has looked at the role of the mass media in shaping these perceptions and ultimately influencing voting behavior. Studies have found that subjective assessments of the economy, rather than objective indicators, have been successful in explaining election outcomes, highlighting a potential distortion between the perceived and actual state of the economy. Examples such as the 1992 US Presidential elections and the 2001 UK General elections illustrate this phenomenon. Therefore, it is important to consider the subjective economy when examining the intersection of politics and economics.",0
52,7,"Media's effect on economic assessments has been mainly studied on a macro-level. Mosley's (1984) study revealed that media's perceptions of economic situations have a stronger influence on economic assessments than official economic indicators. Sanders et al. (1993) and Goidel and Langley (1995) also found that the tone of economic news coverage affects public assessments in the UK and the US, respectively. However, negative news coverage alone impacts public evaluations according to Soroka's (2006) recent analysis, which agrees with Ju's (2008) findings. However, some studies, such as Haller and Norpoth's (1997) and Wu et al.'s (2000), didn't find any notable impact of economic news on assessments.",0
52,8,"The authors argue that media effects are more likely to occur in sociotropic evaluations of the national economy rather than egocentric evaluations of personal economic situations. While citizens may experience noticeable economic changes in their immediate surroundings, national economic developments are often unobtrusive and require media or social interactions to become aware of. Mutz (1992) found that media coverage of unemployment uniquely identifies perceptions of unemployment as a social problem, while personal experience with unemployment contributes to perceptions of it as a personal problem.",0
52,9,"It is important to consider how positive and negative economic news coverage can affect public opinion differently. Research has shown that people tend to pay more attention to negative information and are more likely to draw on it when forming opinions. This is consistent with prior studies that indicate negative information and threat frames have stronger effects on public opinion than positive information. Additionally, classic persuasion studies show a prevalence of threats and negativity. Recent studies suggest that people are more likely to pick up negative information about the economy, so it is expected that negative economic news will have a stronger impact than positive news.",0
52,10,"The idea that mass media equally affects all citizens is oversimplified, as recent political communication research suggests. In our study on media effects on economic assessments, we take this contingency approach and consider how an individual's reliance on media can impact their opinions and evaluations. Media system dependency theory argues that those who rely heavily on news for information are more likely to be affected by media messages. This theory has been supported by experimental research on health communication effects.",0
52,11,"The primary objective of this research is to examine how the media affects the way people evaluate the state of the economy. Specifically, we are looking into the possible effects of media reporting tone, specifically future economic prospects communicated through mass-media channels, on how citizens assess the economy from a societal, future-oriented perspective. This inquiry builds on previous scholarly works such as Soroka (2006).",0
52,12,"Based on a news content analysis and a three-wave panel survey, we investigate the expectations mentioned earlier. Respondents disclosed their exposure level to outlets that underwent content analysis, and the survey data and media content were combined. This approach enables us to examine the economic information that respondents were exposed to and how this exposure influenced changes in their economic outlook between different timeframes.",0
52,13,"Due to practical limitations, we had to use a more restricted group of media outlets for the second phase. However, the descriptive findings show significant similarity between outlets in that phase. For example, two of the three most negative outlets in the first phase are still the most negative in the second phase (Metro phase 1: -2, NRC Handelsblad phase 1: -1.78, Metro phase 2: -2, NRC Handelsblad phase 2: -1.69). In addition, in the first phase, 9 of the 11 outlets assessed for national economic assessments fall between -1 and -2, and this is true for seven of the eight outlets assessed in the second phase. Furthermore, repetition of the analyses for the first phase, which only considered those outlets available in the second phase, produced very similar findings. This gives us confidence that our more limited selection of outlets for the second phase is sufficient.",0
52,14,"Data for testing the hypotheses comes from a three-wave panel survey of Dutch citizens who are eligible to vote. From a pool of 143,809 citizens in an online panel, 2,400 individuals older than 17 are randomly selected and invited to complete an online questionnaire. Of the selected individuals, 1,394 completed the questionnaire, resulting in a 58% response rate (RR1). Comparison of the census data from the Dutch electorate indicates that groups underrepresented in our sample include men (47.0% vs. 49.4%), young citizens (30.8% vs. 34.2%), and those who have intermediate vocational education (31.3% vs. 48.0%).",0
52,15,"We conduct multiple OLS regression analyses to evaluate the hypotheses. We provide four models each for sociotropic and egocentric expectations, where we regress economic expectations at t2 and t3 on previously mentioned variables, while adjusting for economic expectations at t1 or t2. This lagged variable emphasizes the change of the dependent variable between two waves, and including prior economic assessments as controls reduces the chances of models being underspecified, as it includes predictors of static economic evaluations with the lagged term. This approach is similar to Markus (1979).",0
52,16,"Interestingly, our findings indicate that changes in sociotropic expectations were not influenced by personal economic circumstances, while changes in egocentric expectations were somewhat linked to household income. Given that household income can serve as a substitute measure for data on individuals' economic status, these results suggest that people draw upon various sources of information (such as personal experience versus mass media) when creating distinct types of economic expectations.",0
52,17,"During our study, there was no significant change in the egocentric expectations at the aggregate level. Despite the worst crisis in half a century, people still believed that their personal finances would not be affected. This trend is not unique to the Dutch population but seen all over Europe. The reason for this may be a lack of experience with severe economic crises or a psychological phenomenon of people not believing that misfortune can happen to them. Additionally, the crisis takes time to translate into individual financial considerations, as economists have noted. Overall, citizens do not link macroeconomic figures to their personal finances.",0
52,18,"Our research contradicts prior studies that found a negativity bias in media effects on economic perceptions. This could be because the news coverage during our research period was overwhelmingly negative, meaning an increase in negative news did not significantly impact the independent variable. However, it is important to note that previous research only established a negativity bias on a macro-level, and it is possible that micro-level dynamics operate differently, especially during times of economic crisis when the news environment is highly negative. Additionally, we cannot compare our findings to a positive economic news climate, and future studies should explore how media effects differ in times of crisis compared to times of economic growth.",0
52,19,"This research expands on previous studies by considering the conditional nature of news effects. Our results support the idea that media dependency plays a significant role in moderating media influence. Specifically, we found that individuals who rely more heavily on the news have a stronger reaction to positive and negative economic information, confirming our third hypothesis (H3). These results align with the findings of Ball-Rokeach et al (1984), who discovered that media effects were most pronounced among individuals with high levels of dependency. To improve our understanding of why people rely on the media for information, future research should explore factors beyond our current model. Additionally, our findings imply that, while outlet-specific exposure was crucial in the first period, media dependency had a direct impact on expectations in the second period.",0
52,20,"Despite these limitations, our findings have contributed to the comprehension of economic evaluations and their relationship with media coverage. It is crucial to recognize that media representation of the economy can influence political outcomes. If a positive economic outlook results in more votes for a particular party and vice versa, then the negative depiction of economic prospects in the media is hazardous for those in power. This could also have a spiral effect on the economy if individuals who have a pessimistic view of the future are less likely to consume and thus impact economic conditions. Although our study was conducted during a unique economic period, these dynamics have relevance beyond the crisis we investigated.",0
52,21,"Joost van Spanje works as an Assistant Professor in Political Communication and Quantitative Methods at the University of Amsterdam's Amsterdam School of Communication Research and the Department of Communication. His focus is on political behaviour, electoral studies, and media, with a special focus on anti-immigrant parties and European election voting.",0
53,1,"A knowledge economy relies on the use of knowledge to produce goods and services, making economic models important for understanding how it functions. The financial system plays a crucial role, as any failure can halt progress. Due to the complex nature of society, cross-disciplinary approaches are necessary for a comprehensive understanding. The failure of mainstream economic theory during the first decade of the 21st century demonstrated the need for a new, valid theory. However, the schools of economics did not collaborate, leading to scholastic conflict. To reexamine economic theory, both exogenous and endogenous modeling from conflicting economic schools can be used to model different parts of the economic system.",0
53,2,"Economic theory failed to explain empirical reality in the years following the financial crisis of 2008, and there was disagreement among economists on how to construct valid theory. Despite this, there was a contentious debate instead of an immediate rush to change economic theory. Mainstream economic theory assumed a perfect market, but the financial market was far from perfect. This was exemplified in 2012 when Jean-Claude Trichet, then president of the European Central Bank, complained that the available models were of limited help during the crisis.",0
53,3,"Davies previously held positions as Director of the London School of Economics, Chairman of Britain’s Financial Services Authority, and Deputy Director of the Bank of England. As an economist and banking authority, he criticized how contemporary economic theory was applied to real-world situations. Davies believed that the previous approach to regulation was flawed, as it relied heavily on financial institutions to control risk. He noted that this was demonstrated during the financial crisis, resulting in stricter regulation. Davies emphasizes the importance of reevaluating current intellectual models to establish a stable relationship between financial authorities and private firms. (Davies 2012).",0
53,4,"In 2010, it was reported that many academic economists agreed that the financial and economic crisis had exposed flaws in their subject, and urgent ideas were needed to keep economics relevant. Despite the participation of five Nobel prize-winners in economics at the inaugural conference of the Institute for New Economic Thinking, held at King's College, Cambridge and sponsored by billionaire financier George Soros, there was disagreement on the cause and necessary remedies for the crisis. Some argued for tighter regulation due to asset price bubbles, while others believed that price swings were fundamental to the beneficial forces of capitalism. Michael Goldberg from the University of New Hampshire disagreed that the price swings were necessarily a bubble. (Giles 2010).",0
53,5,"Charles J. Whalen stated that the financial crisis of 2007-2009 not only affected the world economy, but also highlighted the limitations of traditional economics. Paul Krugman and other scholars and policymakers also recognized these shortcomings publicly in lectures and articles. The Great Recession forced many individuals to acknowledge these issues. (Whalen 2012).",0
53,6,"In 2009, Paul Krugman examined the state of economics and noted that there was a time when the discipline was highly successful, both theoretically and practically. According to economists, internal disputes had been resolved and the ""central problem of depression-prevention"" had been solved. This led many to celebrate a ""golden era"" for the profession. However, in 2008, the financial crisis hit, revealing that many economists were blind to the possibility of catastrophic market failures. The field's predictive failure was not as important as its collective belief that markets were inherently stable and assets always priced correctly.",0
53,7,"Macro economists continue to be divided on this issue. Some argue that free-market economies never go astray, while others assert that economies may deviate from their path of prosperity, but can be corrected by the Federal Reserve. The reality of an economy that goes off the rails, despite the best efforts of the Fed, was not considered by either camp. In the aftermath of the crisis, Krugman observes that the fault lines among economists have become even more pronounced.",0
53,8,"According to Krugman, the persistence of the fault line can be attributed to the economics profession's over-reliance on aesthetics. Economists mistook beautiful, mathematically-clad theories for truth and clung to the idealized vision of capitalism being a perfect or near-perfect system. This vision proved unsustainable when faced with mass unemployment, but economists fell in love with it again as memories of the Great Depression faded. Unfortunately, this romanticized view of the economy caused economists to ignore the potential dangers of human irrationality, institutional problems, market imperfections, and inadequate regulation by regulators. (Krugman 2009).",0
53,9,"When the supply of a commodity increases in an economy, the price (dotted line) will decrease as a result of business competition and more goods flooding the market. Conversely, if the demand for a product (solid line) increases, the price will rise due to limited supply. The ideal price of a product (commodity) is achieved when the supply equals demand, resulting in an equilibrium price where no control over pricing is required as the market sets the optimal price.",0
53,10,"Neo-Keynesians contended that the Neo-Classical Synthesis School's economists had a limited perspective regarding an economy, viewing it only as a production system. Ben Bernanke noted that economists had overlooked the significance of a healthy financial system for economic growth and the function of financial conditions in short-term economic dynamics. Economic theorists in the decades following World War II prioritized developing broad equilibrium models of the economy with complete markets, ignoring market ""frictions"" like imperfect information or transaction expenses. However, financial markets have little rationale for existence in the absence of such frictions.",0
53,11,"Minsky contended that incorporating a time dimension in the economic model was crucial. In 1936, Keynes had already introduced the concept of time in economics, which included finance as an element of the model. Keynes aimed to create a model of the economy where money was never neutral to pricing by establishing a model where the price level of financial assets is determined in financial markets. The price of money is an asset that derives its value from liquidity, and each capital and financial asset yields an income stream with carrying costs and varying degrees of liquidity. The relative value of assets' liquidity and income determines the assets' price level. (Minsky 1993)",0
53,12,"In a Keynesian financial model, time plays a crucial role in determining the value of a capital asset, which is an investment that generates income and can be sold in the future. The two key concepts here are present-income and future liquidity, which refer to the income stream generated by the asset in the present and its potential value when sold later. This time dimension is represented by T1 (present-income) to T2 (future liquidity), and it is facilitated by the exchange of credit and debt in a financial system. Borrowing and lending is the foundation of capitalist economies, and it involves exchanging money in the present for money that will be paid back in the future, with interest and principal included in the contract. (Minsky 1993)",0
53,13,"The time dimension of any financial system consists of the past (credit), present (interest payments), and future (debt repayment). This temporal process is essential for economic models according to Keynesians. Financial markets determine the liquidity of capital assets based on their value. Each asset has an income stream, carrying costs, and a certain level of liquidity. The price of assets is determined by their relative value in the future and their current liquidity. Financial markets allow credit-debt contracts to be sold in the future through providing future liquidity. Capital assets require both current income and future liquidity.",0
53,14,"The Neo-Classical Synthesis School centered on the production subsystem, where the current commodity price played a crucial role in controlling it. On the other hand, the Neo-Keynesian School focused on the financial subsystem, where the future price of a capital asset controlled it. The modeling challenge lies in integrating both theories in a complementary framework, which can be achieved through a meta-framework like societal dynamics theory. The topological systems model of a society is used in this meta-framework, where the economy is an economic subsystem consisting of production and financial sub-subsystems. For more details, refer to Betz (2011).",0
53,15,"In a model of how society functions, there are four types of subsystems that make up the major systems of an industrialized society: economic, cultural, political, and technological. These subsystems can be shown as stacked planes. In economics, the traditional view is that an economy has three parts: producing, distributing, and consuming goods and services. The production subsystem takes material and energy resources and turns them into goods and services financed by a financial system. These goods/services are then consumed in a market. So, any economic system can be divided into four subsystems: production, market, finance, and resources. The exogenous school's model is seen within this broader societal context as the production subsystem of the economic system, while the endogenous school's model is viewed as the financial subsystem of the economic plane.",0
53,16,"Next, we will integrate economic models from various social science fields to create a comprehensive cross-disciplinary economic system, bridging the partial models of the endogenous and exogenous schools. The aim is to understand how the societal economic subsystem functions as a whole.",0
53,17,"To differentiate between micro and macroeconomics, we begin by integrating partial models from other disciplines into microeconomics. To construct a model for a productive economic agent, we turn to management science and adopt the standard ""enterprise model"" introduced by Michael Porter. The productive organization can be represented as a system that acquires resources and labor from its environment and converts them into value-added products that are then made available to the consumers. This portrays an open system model of a firm, which functions by taking in inputs from the environment and then selling its products back into it.",0
53,18,"The supply-demand equilibrium pricing model is only useful for certain products in a particular area of the industrial supply chain. The first arrow shows that a company's model is part of a specific industry sector, while the second arrow indicates that the supply-demand curve is specific to that sector.",0
53,19,"For the supply-demand model to be empirically valid, data must be industry-specific, as demonstrated by situating the exogenous school's supply-demand model on a societal model topological plane, with real supply-demand data input, and valid price information output.",0
53,20,The information for a combined account is gathered by collecting revenue data reported by each individual firm and organizing it based on the type of goods produced. It should be noted that data does not automatically transfer between each segment of the model and must be collected independently.,0
54,1,"The impact of economic freedom, civil liberties and political rights on growth is analyzed in this research. A system of three equations is utilized to determine the ways in which these institutional aspects impact economic growth, including improved efficiency and increased investment in human and physical capital. The study incorporates 79 countries and covers six periods from 1976 to 2005. The findings reveal that institutional quality plays an important role in economic growth through resource allocation and the encouragement of investment in physical and human capital.",0
54,2,"The determinants of economic growth and the variations in real incomes between nations are a primary focus for economists. Despite a plethora of literature on this topic, empirical research has only partially been successful in uncovering the factors driving economic growth and inequality. Consequently, more and more explanatory variables have been added to growth models, including institutional factors in addition to traditional variables like labor, physical and human capital, and technology used in neoclassical and endogenous growth models. (Olson 1982, 1996).",0
54,3,"In recent years, many researchers have incorporated institutions into growth models, including Ak?omak and Weel (2009), Barro (1996), Easterly and Levine (2003), Hall and Jones (1999), Mauro (1995), Rigobon and Rodrik (2005), Stroup (2007), and Yang (2008). While most of these studies have found a positive and significant effect of institutional quality on economic growth, the results are not conclusive. Economic freedom and political freedom have been the most studied dimensions of institutional quality (Aixalá and Fabro 2009). Therefore, this study focuses on analyzing the impacts of these two aspects on growth.",0
54,4,"Civil liberties and political rights are often merged as political freedom, but they have distinct meanings that affect economic growth differently. Civil liberties allow for expression, media freedom, organization, the rule of law, and personal autonomy. Political rights enable political engagement, such as voting freely, competing for office, joining parties, and electing accountable representatives who impact public policies.",0
54,5,"""Regarding various concepts of freedom, Milton Friedman (2002) suggests the use of three classifications instead of only two: economic, civil, and political freedom. According to him, political freedom encompasses the configuration of the political structure, right to vote, and democracy as a system where civil servants are elected through citizens' votes. On the other hand, civil freedom includes human rights such as freedom of speech, assembly, and expression. Hong Kong provides an example of this distinction, where citizens had high civil freedom but lacked political freedom under British rule. It is possible for a country to have high levels of civil and economic liberties without political freedom, but achieving political freedom without economic freedom seems difficult. In China, the promotion of economic freedom may lead to more political freedom.""",0
54,6,"Ariel Benyishay and Roger Betancourt assert that the safeguarding of civil liberties as a means of protecting human rights is a crucial measure of the extent to which the rule of law exists in a society. The curtailment of human rights, whether through more overt violations like the loss of life or imprisonment, or through subtler means like limiting one's capacity to make choices or exercise one's liberties, ultimately results in the deprivation of property rights. According to the authors, civil liberties play a vital role in enabling markets to function robustly, as they are socially constructed and thus contribute to fostering long-term economic growth.",0
54,7,"The paper aims to clarify how institutional quality influences economic growth by utilizing a system of three simultaneous equations. To analyze the direct and indirect effects on growth, investment in physical capital and human capital were added to the growth equation. Panel data techniques and weighted two-stage least squares were used to overcome heteroskedasticity and endogeneity issues. The paper also accounted for the time that elapses between institutional changes and their impact on growth by introducing lag variables.",0
54,8,"Scholars who support the property rights school, along with some of North's ideas, argue that economic freedom boosts productivity by reducing transaction costs. This, in turn, encourages the accumulation of human and physical capital stocks, promotes specialization and economies of scale, fosters business innovation, and creates more efficient organizations. To function properly, the market requires well-defined and precise property rights because without them, negotiating the allocation and distribution of resources would become prohibitively expensive. High transaction costs limit market opportunities by causing a lack of transparent information and entry barriers that discourage new competition and international trade. Economic freedom is widely acknowledged as the institutional characteristic that has the most significant and positive impact on growth. This idea has received support from various sources, including Azman-Saini, Baharumshah and Law (2010), Carlsson and Lunsdtr?m (2002), Dawson (2003), De Vanssay and Spindler (1994), Easton and Walker (1997), International Monetary Fund (2003), Justesen (2008), and Stroup (2007).",0
54,9,"One aspect of economic freedom that has garnered attention recently is regulation, with studies showing it has a negative impact on growth. Cole et al. suggest that Latin America's low TFP is due to competition barriers and stagnant relative TFP is the main determinant of income and productivity stagnation. Dawson argues that reducing regulation positively affects growth through investment and TFP channels. Licerio, Fullerton, and Clark show that deregulation leads to per capita income gains.",0
54,10,"Robert Barro's (1996) argument is that the relationship between democracy and growth is non-linear. He claims that in countries with lower levels of political freedom, higher levels of democracy can encourage growth because it limits government abuse. However, high levels of democracy can hinder growth when there is already a moderate level of political freedom. Barro suggests that widening political freedom may actually slow down growth once a certain threshold is reached, partly due to the emergence of redistributive pressures.",0
54,11,"Amartya Sen (1999) proposes that to have a satisfactory conception of freedom, we must recognize their interconnectedness and their role as both intrinsic and instrumental. He argues that political and social freedoms are desirable and conducive to economic growth. Sen emphasizes the importance of economic development as an integrated process that expands substantive freedoms encompassing economic, social, and political considerations. This broad approach allows us to appreciate the vital roles of various institutions, including markets, governments, political parties, education programs, and civic institutions, in the development process.",0
54,12,"The acknowledgment that economic freedom promotes growth is widespread. However, it is essential to recognize the significance of not only markets but also economic, social, and political freedoms in enhancing and improving people's overall capabilities. From an instrumental perspective, Sen identifies five types of freedom: political, economic, social, transparency, and security, all of which are interconnected. Promoting these various instrumental freedoms can aid in achieving public policy objectives that foster human capacity and substantive freedoms. Development analysis must recognize the empirical connections between these freedoms to strengthen their collective importance. In essence, understanding the instrumental role of freedom requires recognizing the vital connections between them.",0
54,13,"According to some empirical papers (Giavazzi and Tabellini 2005; Persson and Tabellini 2006), economic liberalization must precede the expansion of political rights for growth to occur. Closed economies with fledgling democracies encounter conflicts of redistribution, while open economies with established democracies prioritize economic efficiency. Moreover, economic liberalization fosters the rule of law and improved protection of property rights, both necessary for democracy to generate growth (Giavazzi and Tabellini 2005).",0
54,14,"Political freedom is often measured through civil liberties and political rights in empirical research (Farr, Lord, and Wolfenbarger 1998; Helliwell 1994; Wu and Davis 1999). However, the results obtained are diverse and less robust compared to economic freedom due to the conflict between costs and benefits as pointed out by theory. Some studies indicate that democracy has an overall positive impact on economic growth (Gwartney, Lawson, and Block 1996; Hanke and Walters 1997; Rigobon and Rodrik 2005; Rodrik 1999a; Scully 1988; Varsakelis 2006). But, others find that this relationship is weak and not significant (Alesina et al. 1996; Ali and Crain 2002; Barro and Sala-iMartin 1995; De Haan and Siermann 1995, 1996; Mulligan, Gil, and Sala-i-Martin 2004), and some studies show a slightly negative correlation between political freedom and economic growth (Helliwell 1994; Tavares and Wacziarg 2001).",0
54,15,"The timing of complex causal relations between institutional factors and economic results is often not considered in empirical research. While some effects may be immediate, others have a delayed structure. Economic freedom is an example of this, as it may require time before producing a tangible outcome. In such cases, credibility becomes a crucial aspect in growth processes. This is particularly relevant in countries with a history of inconsistent policies and strong opposition to liberalization policies.",0
54,16,"It is important to consider the distinction between direct and indirect impacts of institutional quality on growth, as this has been frequently overlooked and polarized opinions. The impact of economic freedom on growth has been debated, with some arguing that it primarily affects productivity rather than the accumulation of productive factors while others claim it promotes growth through better total factor productivity and the accumulation of both human and physical capital. Some critics believe that growth is only stimulated through increased resource allocation efficiency while others prioritize investment as the driving force behind growth.",0
54,17,"In terms of political liberty, some scholars suggest that while promoting the accumulation of human capital, democracy could also facilitate growth (Mariscal and Sokoloff 2000). The proof for physical capital, however, is not so decisive. Philipp Harms and Heinrich Ursprung (2002), Matthias Busse (2004), and José Tavares and Romain Wacziarg (2001) have discovered that democratic countries draw foreign direct investment, whereas Adam and Filippaios (2007) contend that democracy might reduce private investment. In the case of physical capital investment, José Aixalá and Gema Fabro (2009) indicate that only economic liberty is important, but for human capital investment, economic and political freedoms are applicable.",0
54,18,"In order to gain a better understanding of the economic growth processes, it is important to clarify these channels. Additionally, if the accumulation of human and physical capital is used as explanatory variables, one should keep in mind that the institutional variable coefficient may not reflect the complete effect on economic growth and could lead to incorrect conclusions. To address this issue, simultaneous equation models can be used, although they are rarely utilized (with the exception of studies by Alesina et al. 1996; Faruk, Kamel and Véganzonès-Varoudakis 2006; Leite and Weidman 2002; Rigobon and Rodrik 2005).",0
54,19,"Institutional change can be challenging and slow as institutions are often deeply ingrained in a country's history and culture. Moreover, those who resist change may oppose comprehensive reforms. However, in developing countries, institutional changes can occur rapidly. The IMF has shown that since the mid-1980s, there has been significant progress in the establishment of the rule of law globally, particularly in the early 1990s. Central and Eastern European nations, which have undergone political and economic reforms, have experienced a comprehensive strengthening of their institutions. The IMF has also identified radical changes in ""post-conflict"" states like Afghanistan and Kosovo.",0
54,20,"The institutional data used in this paper are the civil liberties and political rights indices annually published by Freedom House since the early 1970s. These indices provide strict evaluations from regional experts, human rights specialists, academics, journalists, and political figures. Additionally, the world economic freedom index published by the Fraser Institute is referred to in this paper, which mostly includes quantifiable and objective data but still involves some subjective evaluations from researchers and experts (refer to Appendix 1, p. 1077).",0
54,21,"The reason for selecting economic freedom, civil liberties, and political rights indices is due to the reputation of the organizations that issue them. Furthermore, they accurately depict the concepts they intend to measure, and their extensive coverage of time and countries makes them ideal for applying panel data techniques and examining lags in the variable to analyze the time delay with which these freedoms influence growth. The World Development Indicators database of the World Bank was utilized for the other variables such as growth of per capita GDP (PPP), investment in physical capital, rates of enrollment in primary and secondary education (as investment in human capital), trade, and initial income.",0
54,22,"Institutional dimensions have expected signs and are generally significant when considered individually. Neoclassical theory predicts negative sign for initial income in growth equation and it is significant in eight of nine estimations, confirming convergence hypothesis. Physical and human capital investment variables have positive coefficients and statistical significance in all estimations except for human capital which is not significant in three equations. Explanatory variables rate of enrollment in primary education and openness have expected positive sign and are highly significant in all estimations for investment in physical and human capital equations.",0
54,23,"The findings regarding the institutional variables studied indicate that economic freedom (as shown in Table 1) has a notable effect on growth because it enhances resource allocation and encourages investment in physical and human capital. Economic freedom is found to be highly significant in all three equations of the system (systems 1 and 2). When the analysis includes two lags (system 3), economic freedom remains significant in the physical capital investment equation, leading to an improvement in the model's explanatory power.",0
54,24,"The notions of the property rights school and the contributions made by North (1990) and Olson (1982) that were later incorporated by growth theory, regarding the significance of economic freedom in promoting the accumulation of physical and human capital, decreasing transaction costs, and increasing productivity, are supported by the empirical evidence obtained. The presence of civil liberties (Table 2) and political rights (Table 3) has a crucial role in improving resource allocation and investment in physical and human capital (systems 1, 2, and 3), thereby facilitating growth. When two lags of the variables are taken into account, the importance of civil liberties and political rights persists across the three equations, and the explanatory capacity of the models is enhanced.",0
54,25,"Further studies (Gwartney, Lawson and Holcombe 1999; Hanke and Walters 1997; Stroup 2007) validate the perspective on economic freedom having a more significant impact on growth than civil liberties and political rights. As indicated in Table 4, superior coefficients for this institutional dimension are observed when current values are considered. Nonetheless, it's worth noting that in the case of human capital, civil liberties have a coefficient almost as large, and when variable lags are incorporated, economic freedom's supremacy diminishes.",0
54,26,"This study aimed to reveal the significance of institutional aspects such as economic freedom, civil liberties, and political rights on economic growth. Additionally, it aimed to distinguish between their direct and indirect impacts. The findings indicated that the quality of institutions is crucial for the economic advancement of countries as it promotes a better distribution of resources and investment in physical and human capital. Furthermore, the study showed that economic freedom has the most significant impact on economic growth, closely followed by civil liberties in terms of investment in human capital. However, when considering lags, civil liberties and political rights remain highly significant, while economic freedom loses its relevance.",0
55,1,"The objective of the investigation is to study the effects of economic liberalization on economic growth in Pakistan from 1971 to 2011, both in the short and long term. Economic liberalization encompasses changes in financial and trade liberalization. This study is unique in that it synthesizes an economic liberalization index by utilizing principal component analysis. Based on our findings, we discovered that economic liberalization policies have a favorable effect on economic growth in the short term. Nevertheless, trade liberalization had a negative influence on economic growth in the long term. Additionally, the rolling window analysis found that the effect of economic liberalization on real GDP was unstable during the chosen sample. The study proposes that policymakers should focus on human capital development through increased spending on the educational sector. Similarly, introducing financial reforms, such as sectoral credit allocation, can foster economic growth.",0
55,2,"Recent growth theories have resulted in researchers focusing on the relationship between economic liberalization (EL) and economic growth (EG). Following the endogenous growth theory model, several developing countries embraced liberalization in the 1980s to promote EG. Full liberalization entails the liberalization of both the financial and trade sectors. Nevertheless, there is no definitive empirical data on the impacts of liberalizing both the financial and trade sectors.",0
55,3,"Pakistan initiated the process of liberalizing its financial sector during the late 1980s with the aim of enhancing the effectiveness of financial markets, devising market-oriented and operationally more robust monetary and credit policies, and augmenting the capacity and efficacy of capital and market-based financial institutions.",0
55,4,"The aim of this research is to analyze the effects of economic liberalization (EL) on economic growth (EG) of Pakistan, spanning from 1971 to 2011. In order to contribute to the literature, the study develops an economic liberalization index (ELI). The paper employs an error correction model, JJ cointegration, and full modified OLS method to estimate the short-run and long-run association. The second section of the paper presents a literature review, followed by the methodology and different estimations. The empirical findings are presented in section four and conclude with policy recommendations.",0
55,5,"Based on the empirical literature, the majority of studies have utilized three proxies to examine the effect of trade openness on economic growth - export/GDP, import/GDP, and export plus import/GDP. The benefit of these proxies lies in the accessibility of data. A lower value of these indicators is presumed to signify a greater level of government involvement in trade policies.",0
55,6,"The PCA method was used to calculate the essential weights. Table 2 shows that the first principal component explains approximately 65% of the total variation in the data. The second component explains an additional 35%, while the last component explains no variation. The first component has the highest degree of variation compared to other variable combinations. The first eigenvector value was used as a weight in our research to create a composite measure of trade openness, referred to as TLI. TD, M, and X contributed to 71.6%, 54%, and 44.2%, respectively, in the standardized variance of the first principal component.",0
55,7,"The SBC method is used to determine the optimal lag order before estimating cointegration tests, as the JJ Cointegration approach is highly sensitive to the lag order employed. The results from Table 5 indicate the presence of a cointegration relationship in models 1-12, as indicated by the trace test. However, the cointegration vector differs across the models; models 1, 3, 4, 9, and 10 have one cointegrating vector, while models 2, 5, 6, 7, 11, and 12 have two cointegrating vectors. Only in model 8 are three cointegrating vectors discovered.",0
55,8,"The purpose of rolling window regression is to evaluate the consistency of variable coefficients over a specified data period. Unlike available cointegration econometric methods that assume model coefficients to be constant throughout the sample, the real economy fluctuates frequently due to changes in economic indicators. Hence, the estimated coefficients of these indicators cannot remain unchanged throughout the sample.",0
55,9,"The FLI, trade openness index, and ELI for Pakistan covering the period 1971-2011 were constructed in this paper. The order of integration was determined using augmented Dickey-Fuller unit root tests. To estimate the long run and short run relationship, the JJ cointegration, Fully Modified Least Squares and error correction model were utilized. The stability of the coefficients was verified using the rolling window regression method.",0
56,1,"The study investigates the connection between economic growth and the stock market, as well as bank financing in Portugal between 1993 and 2011. The analysis involved the use of Vector Autoregressive (VAR) modeling, along with Granger causality, variance decomposition, and impulse response function. It was discovered that Portugal's integration into the European Monetary Union resulted in a change in economic regimes, and that the subprime crisis had an impact. In terms of causality, there was evidence of bidirectional linkage between economic growth and the stock market, but no evidence of causality from bank financing to economic growth.",0
56,2,"The correlation between economic growth and the financial system, including stock markets and the banking system, has been the subject of research for many years by scholars such as Beck and Levine (2004), Capasso (2008), Goldsmith (1969), Keynes (1973), Levine (1991), and Schumpeter (1982). Generally, Anglo-Saxon nations depend more on capital markets for corporate financing, whereas non-Anglo-Saxon nations rely mostly on the banking system, as noted by Marini (2005) and Lee (2012).",0
56,3,"The relationship between the financial system and growth can be better understood by using long series and controlling for structural changes. In the case of smaller economies, like Portugal, structural changes can have a stronger impact, making it an ideal case study. By examining the interaction of variables during the 1990s and 2000s, a period of significant economic and political change, we can gain valuable insights. As a non-Anglo-Saxon country, Portugal's banking system is expected to be more influential in the economy than the stock market.",0
56,4,"According to the findings, the growth of the economy is influenced by the stock market, as it shows Granger causality. However, there is no confirmation of such causality from the banking system to the economic growth. The study provides insights into the formulation of effective economic policies for the financial sector, highlighting the significance of the stock market and banking segments.",0
56,5,"The definition of stock market development is not clear, however, Demirgu?-Kunt and Levine (1996) suggest four indicators for studying it: 1) market capitalization, 2) volatility measured by standard deviation of stock market, 3) indicators of institutional development, and 4) regulation indicators. It is important to consider the banking system, which can be measured using the ratio of domestic credit to GDP or the ratio of monetary aggregate M2 to nominal GDP. Inflation is also commonly used in the model for robustness.",0
56,6,"There have been discussions and studies on the relationship between the financial system and economic growth, primarily in quantitative terms through cross-country, panel data, and time series analyses. Several studies have shown causal relationships between stock markets and economic growth, and the direction of causality can be from stock market to economic growth, economic growth to stock market, bidirectional, or non-existent. The analysis of causality has been extended to include the short and long run as well as strong causality, which could have a significant impact on economic policy decision making.",0
56,7,"Financial development resulting from endogenous growth processes has been extensively studied in literature (e.g. Bose and Cothren, 1997; Greenwood and Jovanovic, 1990). It is expected that variables are interdependent and interact, leading to an endogenous adjustment effect. The VAR technique is useful in evaluating these relationships, as it treats variables as potentially endogenous without the need to differentiate between endogenous and exogenous variables like in the simultaneous equations model. This technique was applied by Caporale et al. (2004) and Tsouma (2009) in analyzing the link between developed stock markets and economic growth.",0
56,8,"Based on the results, in order to accurately analyze the impact of the stock market on economic growth, it is necessary to consider certain variables as exogenous, such as the constant, seasonal dummies, one impulse dummy in the second quarter of 2000, and two shift dummies. Additionally, it is important to control for the physical introduction of the euro notes and coins/integration in Euronext, as well as the subprime crisis in Portugal which occurred from the last quarter of 2008. The VAR results also indicate that the physical introduction of the euro had a greater impact on the economy than the integration in Euronext, as shown by the highly statistically significant negative signal of the shift dummy in the GDP and stock market equations.",0
56,9,"The VAR estimation is carried out by determining the optimal lag structure using a series of tests such as the sequential modified LR test, the final prediction error, and the Akaike information criterion. All these tests consistently show three lags, highlighting a parsimonious model with no signs of the omission variable bias. Further evaluation of the VAR model is conducted through diagnostic tests that include the Jarque Bera test for normality, LM test for autocorrelation, and the White test for heteroskedasticity (without cross terms), as shown in Table 3.",0
56,10,"The main objective of this paper is to analyze how stock markets and bank financing systems contribute to economic growth, and it emphasizes the importance of comprehending this relationship when creating economic policies. If one of the systems shows a more significant response to innovation, policymakers should prioritize action towards that system.",0
56,11,"The Granger causality, variance decomposition, and impulse response function have proven that the competing systems are different. When there is innovation in one system, there is a decrease in the relative weight of the other system, as shown in Fig. 3. The response of bank financing to innovation in the stock market is faster and more pronounced, compared to the reverse. Generally, bank financing is more inward-looking than the stock market. This result was unexpected because Portugal is a non-Anglo-Saxon country, and bank financing is expected to be common among corporations, and therefore play a significant role in Portuguese economic growth.",0
56,12,"The outcomes presented in Table 5 align with the findings obtained through the exogeneity tests. Evidently, all factors exhibit a dynamic pattern that is a prerequisite for endogeneity (refer to Table 5 and Fig. 3). Concerning DLY, after a lag of two-quarters, triggering events to DLY elucidate approximately 85% of the variability in the forecast error. However, this influence lessens to around 59% by the end of the 10-quarter period. A comparison between the consequences of DLS and DLB shows that DLS has a significantly higher impact on the forecast error variance than DLB, i.e., around 15.5% and 3%, respectively, at the end of the ten-quarter period. Shocks to DLI intensify persistently, leaping from roughly 2.5% to 5.8% in explaining the forecast error variance. As projected, when concentrating on models that incorporate financial determinants, controlling for nominal effects is necessary. Indeed, at the end of ten-quarters, events that stimulate DLP clarify around 16.6% of the variance in the forecast error.",0
56,13,"The article examines the impact of stock market development on economic growth in Portugal (1993-2011), which is a small economy that experiences significant effects due to structural changes. It also compares the effects of two financing systems - stock market and bank financing - on economic growth. No cointegration relationship was found. The study used a VAR model with impulse and shift dummies, which proved to be suitable for analyzing the contribution of stock market and bank financing to economic growth. However, the analysis should include Portuguese idiosyncrasies. The absence of these controls could distort causal relationships among variables, leading to incorrect conclusions.",0
56,14,"It has been observed that there are two distinct behaviors within the financial system's components. Firstly, there is a positive causal relationship between economic growth and stock market development, which is bidirectional. Secondly, the banking system seems to benefit from economic growth but is not driving it. Therefore, economic policies should focus on promoting stock market development rather than bank financing for economic growth. Future research should aim to understand the transmission channels between financial markets and economic growth.",0
56,15,"The Portuguese reality was proven through the use of control variables. The results showed that investment did not have significant multiplier effects, and there was a clear loss of economic price competitiveness. Unique factors specific to Portugal were also taken into consideration, including the break in the GDP series in 2000, the currency change to the euro, and the subprime crisis. These factors are crucial for a complete understanding of how finance impacts the economy.",0
57,1,"During times of financial crisis, we examined economic voting using survey data from the 2008 and 2011 Canadian Election Studies. It is suggested that the economy's impact on incumbent voting during a crisis can be twofold. The first impact is based on retrospective evaluations of national economic circumstances, which are necessarily unfavorable given the crisis. The second impact is based on perceptions of the parties' ability to manage the economy, and the competence effect can offset incumbent vote losses resulting from poor economic conditions depending on these perceptions. By analyzing competence-based issue ownership, we can introduce a neglected valence component to the economic voting model in broader terms.",0
57,2,"According to the theory of voting behavior, the economy is a typical valence issue (Stokes, 1963). In democratic societies, all parties and voters generally agree that economic growth is a desirable objective. In other words, there is a virtual consensus among parties and voters regarding their stance on this issue, since society as a whole has a shared view of what needs to be achieved economically. What mainly concerns voters is whether the government achieves this goal or not. A government that delivers on this goal has a higher probability of being re-elected at election time, while failure to do so poses a severe risk of being voted out of office.",0
57,3,"The concept of 'traditional economic voting' expectation was introduced by Lewis-Beck in 1988, which forms the foundation of a valence model of economic voting, as explained by Lewis-Beck and Nadeau in 2011. This model suggests that voters assess the government's previous economic record and make their decision based on it, thus holding the government responsible for the country's financial condition.",0
57,4,"The current formulation of the valence model of economic voting focuses primarily on voters' retrospective evaluations of economic conditions. However, it is reasonable to assume that voters also consider the issue-handling capabilities of the competing political parties. The reputation of parties as competent political actors is an essential aspect of the valence model of political choice. Therefore, recent studies have examined the impact of perceptions of party competence in managing the economy on voters' choices.",0
57,5,"We aim to incorporate both aspects of economic voting, namely retrospective economic evaluations and issue ownership, into a single model for incumbent vote. Previous research on the valence model of economic voting has largely disregarded the latter dimension, with few exceptions. Considering both of these dimensions is crucial, especially during an economic crisis. In such times, economic voting can be expected to have a dual impact. Firstly, there will be the typical effect based on retrospective economic evaluations, which will inevitably be negative. Secondly, there will be an impact based on perceptions of the parties' economic management competence. The degree of influence that this has will depend on the public's perceptions at the time, but it may be able to counteract losses in incumbent vote resulting from the bad economic situation.",0
57,6,"Through survey-based analyses of the vote for/against the incumbent Conservative Party of Canada in the 2008 and 2011 federal elections, we have provided empirical evidence of the dual effects. Despite the economic crisis context, the Conservatives won both elections, indicating that the traditional economic voting hypothesis alone may not fully account for the role of the economy as a valence issue in determining election outcomes.",0
57,7,"In Canada, five federal elections coincided with or followed serious economic crises. Interestingly, the incumbent party won three of them (1974, 2008, and 2011), while facing defeat in the other two (1984 and 1993). This contradicts the economic voting theory, which suggests the incumbent should lose in all such situations. To explain these results, the authors propose distinguishing between two valence dimensions of economic voting - the classic dimension and issue ownership dimension - and explore them in two of the elections more closely. The following sections elaborate on their theoretical considerations and expectations.",0
57,8,"According to the principle of government accountability, incumbent politicians are held responsible for the economy, and citizens will reward or punish them accordingly. This relationship has been explored extensively in the United States, as well as in other Western democracies. Recent studies have considered factors such as institutional arrangements and voters' levels of awareness to better understand the connection between the economy and voting patterns. Notable studies in this regard include Powell and Whitten (1993) and Anderson (2007).",0
57,9,"The 'valence' model of economic voting is the fundamental expectation that Lewis-Beck and Nadeau (2011) propose. They differentiate it from policy-oriented economic voting and patrimonial economic voting. Policy-oriented economic voting pertains to voters' varying opinions about economic policies, while patrimonial economic voting is influenced by individuals' financial assets. Economic voting, as per Lewis-Beck and Nadeau (2011), is not a single-dimensional phenomenon. Our argument in this article is the incorporation of a second valence dimension to the valence model of economic voting, party competence. Therefore, we assert that the valence model of economic voting is multidimensional.",0
57,10,"The valence interpretation of economic voting posits that voters are primarily concerned with the incumbent party's economic performance in the recent past when casting their ballot. Valence models of political choice suggest that voters also take into account the incumbent's reputation and comparative performance. Recent studies have further highlighted the importance of political parties' perceived competence in dealing with the economy in shaping voters' choices. This perspective has been explored by a growing number of researchers, including Sanders, Bellucci, Butt, Smith, Martinsson, Bélanger, and Gélineau.",0
57,11,"During times of financial crisis when the economy does not provide an advantage to the incumbent party, they may choose to focus their campaign on a different issue, as suggested by Vavreck (2009). Alternatively, they may still emphasize the economy but present it in a more positive light to project a favorable image of themselves compared to their opponents, according to Nadeau et al (2010). Therefore, an incumbent party's economic competence can become a crucial element of their campaign message.",0
57,12,"The second aspect of the economy's valence dimension is focused on looking back. However, it differs from the typical dimension as it takes a comparative approach. Instead of just measuring the current party's economic record, the competence dimension assesses their economic performance in comparison to other countries. This means that voters ask if the nation's economy is doing better than comparable economies, even in tough situations. If it is, then the incumbent party is seen as having done well and may still receive support despite the crisis. This cognitive process is called benchmarking and is conceptualized by Duch and Stevenson as voters extracting signals about the government's relative economic competence. (Kayser and Peress, 2012).",0
57,13,"Issue ownership's competence-based component is determined by the performance of parties in handling specific issues, which can be assessed through comparison and benchmarking, particularly in the economy. It differs from the ""associative"" component, which depends on the history of attention given to specific issues by parties and their policy priorities. This distinction between valence and policy dimensions of issue ownership is similar to the one we discussed earlier between the traditional economic voting hypothesis and Kiewiet's policy-focused view of economic voting. For further information on this essential distinction, refer to Walgrave et al's 2012 study.",0
57,14,"Issue ownership is a crucial factor in explaining why incumbents may not face consequences for poor economic performances, according to our argument along with Martinsson (2009, p. 230). Previous studies have focused on institutional and contextual factors without considering the parties' perception as economic managers. We believe that issue ownership is an essential component in understanding economic voting.",0
57,15,"The influence of competence on incumbent voting is expected to have affected the results of the 2008 and 2011 Canadian federal elections. If voters saw the incumbent party as the most competent at managing the economy, they were more likely to support the Conservative Party, while seeing an opposition party as the most competent would decrease support. Bélanger and Gélineau studied similar effects in the 2008 Quebec election, while Martinsson investigated the issue of unemployment in six Swedish national elections. Our study focuses on competence in the economy, broadly defined, for two consecutive Canadian national elections.",0
57,16,"We utilize two measures to gauge the sociotropic economic evaluations retrospectively. Initially, we employ the customary measure based on a standard question asking if the Canadian economy has improved, worsened, or remained stable over the previous year (better = +1, same = 0, worse = ?1). This measure helps to capture the conventional economic voting effect. However, Gidengil et al (2012, p. 77) found a weak impact of this measure in their study on economic voting in the 2008 Canadian election. They propose that many voters didn't hold the Conservative government responsible for the economic downturn as the financial crisis primarily erupted in the United States (Gidengil et al, 2012, pp. 79–82). Hence, we devise a second measure of retrospective economic assessments that accounts for responsibility attribution. This measure weighs the original variable of economic perceptions based on whether the respondent attributes responsibility for favorable (or unfavorable) national economic conditions to the government's policies.",0
57,17,"The study's measure of political parties' competency as economic managers is derived from respondents' answers to the question 'Which party do you believe would be most effective in dealing with the economy?' The coding of the competence variable takes into account a dichotomous dependent variable where a response in favor of the Conservative Party is coded as +1, while naming another party as competent is coded as -1. No competency named, all parties seen as equally competent, or unsure responses are coded as 0. In the 2008 survey, the question is asked only to half of the sample, while the other half is asked about job creation. The researchers also consider job creation as relevant to economic crisis context as it is additional evidence of economic voting. The methodology in the study is similar to previous studies by Bélanger and Meguid (2008); Bélanger and Gélineau (2011).",0
57,18,"Prime Minister Stephen Harper called for the 2008 Canadian federal election just before the economic crisis in the American housing and financial markets. Canadians realized that their economy started to slow down and might collapse over the coming months. CES data indicates that 81% of respondents outside Quebec believed that the economy issue was crucial in that election, and 17% said it was relatively important. It was not surprising that 46% of respondents felt that Canada's economy had deteriorated over the past year, with 39% felt no changes, and only 14% believed that it had improved. Based on the traditional economic voting hypothesis, we would expect that these negative economic evaluations would have harmed the incumbent Conservatives.",0
57,19,"The 3-point measure of past economic assessments in the first model is replaced by the 5-point economic responsibility measure in the regression model presented in Column 2 of Table 1, although both indicators have been standardized to run from ?1 to +1. The economic voting is still significant with the use of the economic responsibility indicator, which aligns with Gidengil et al's (2012) intuition about economic voting in the 2008 Canadian election. During a global economic crisis, the incumbent government cannot be fully responsible for a country's worsening economic conditions, only those voters who blame its policies would vote against it, which is what the economic responsibility indicator attempts to capture. Economic voting did occur in 2008, and it impacted the incumbent party since most Canadian voters believed that economic conditions had declined, or at least had not improved. However, it occurred most strongly among the smaller group of people who attributed credit or blame to the government's policies, everything else being equal.",0
57,20,"Although the two models in Table 1 have a very small difference in terms of model fit, responsibility attributions do contribute to the traditional economic voting effect to some extent. However, it is not a significant increase in the explanatory power of the model. The article argues that focusing solely on retrospective economic perceptions is insufficient for understanding economic voting, particularly during financial crises. As predicted, party competence in economic management can either counteract or reinforce perceptions of the economy in hard times.",0
57,21,"The impact of the two valence dimensions of economic voting on the probability of supporting the incumbent party, while everything else remains constant, is being studied. To demonstrate this impact more concretely, the findings are converted into marginal effects obtained through logistic regression results. The enhanced valence model of economic voting estimated for 2008 is used as a basis for this purpose, and the results are similar for the other models. The retrospective national economic evaluations and party competence on the economy are altered while all other independent variables remain constant to assess their impact on the predicted probability to vote for the incumbent party, and these simulation results are tabulated in Table 8.",0
58,1,"The traditional neoclassical method of economic theorizing does not consider economic emergence and entrepreneurship. We explore why entrepreneurship, a crucial economic behavior, has been disregarded in mainstream economic theory. However, evolutionary economists have recognized the significance of emergence, and we discuss the advancements made in this field. We propose that evolutionary economics can progress by adopting a more 'naturalistic' approach to economic evolution. This requires full integration with complex economic system theory, explicitly dealing with how people react to uncertainty. We argue that 'knowledge' is partly conjectural due to uncertainty and linked to our emotional states. Economic behavior is also affected by our status as dissipative structures, leading us to introduce 'energy gradients' and 'knowledge gradients' as essential concepts in understanding economic emergence and growth.",0
58,2,"Neoclassical economics assumes that economic decision making is based on logic and constrained optimization, but this rule only works in simplistic contexts with certainty or quantifiable risk. It cannot accurately predict behavior in situations of uncertainty where significant changes can occur, leading to economic emergence and the formation of new network structures.",0
58,3,"Evolutionary economics has directly addressed the concept of economic emergence. This field is concerned with how economic systems undergo transformations from within. As evolutionary theory is based on change, it encompasses a range of behavioural rules adopted by economic decision-makers. Nelson and Winter (1982) highlight the significance of behavioural routines. This is because economic agents need to operate in historical time, with all the uncertainties it brings. In evolutionary economics, economic agents reduce the uncertainty they face and achieve their economic goals by adhering to bundles of rules. Economic emergence occurs through the formation of radically new bundles of rules that contribute to capital goods, productive networks, contracting systems and human skills. The process of 'self-organization' shapes this emergence, honed by 'competitive selection', where various technologies, organizational structures, institutions, and procedures dominate.",0
58,4,"In order to understand economic emergence, it is necessary to consider both genetic and culturally acquired drivers of human behavior, as well as how these interact with the energetic requirements of living systems. To analyze economic behavior, it is also important to understand the institutional rules that govern different cultures and how these change with circumstances. This does not mean traditional economic analysis should be discarded, but rather that the limits of calculative behavior must be recognized. Evolutionary theories prioritize diversity of behavior over uniformity, so the question of whether behavior is optimal based on logical criteria is less important than understanding the range of individual responses to available information.",0
58,5,"The article is structured into different sections. Section 2 gives a historical overview on the challenges economists have faced in capturing emergence in economic analysis. Although heterodox economists may already be familiar with the content, younger mainstream readers will benefit from this. Section 3 covers how evolutionary economists have tackled economic emergence, highlighting the main points of differentiation from the mainstream. Section 4 focuses specifically on entrepreneurship, which is considered to be the leading catalyst of economic emergence by evolutionary economists. Section 5 explores the motivation behind taking large entrepreneurial risks in uncertain situations and how this can be studied using complex adaptive systems theory. The article concludes with some final remarks in Section 6.",0
58,6,"In the 1950s, economics shifted towards a logical framework that could not accommodate emergence. This overlooked crucial factors driving economic growth and instead relied on a force field representation of a fully connected network system from 19th century physics. The neoclassical tradition remained dominant in microeconomics, but the Keynesian Revolution raised questions about its adequacy in representing economic behavior. Though macroeconomics took on a non-neoclassical flavor, with medium-term multiplier-accelerator models and Harrod's theory serving as the baseline for economic growth and development planning.",0
58,7,"Neoclassical economists focused on improving the microfoundations of macroeconomics instead of addressing technological change in their growth models. This perspective was popularized by the neoclassical synthesis interpretation of Keynesian economics, which paved the way for neoclassical economists to gain ground in the fields of business cycle and growth theory. However, the complex mathematical models that emerged from these areas were challenging to deal with and lacked empirical evidence, leading neoclassical economists to rely on simple analytical foundations based on representative optimizing agents. Unfortunately, these theories failed to account for economic emergence as they did not consider the role of entrepreneurs, differentiated firms, or the Marshallian flux that characterizes economic activity.",0
58,8,"The focus of economics shifted in the latter half of the 20th century to constrained optimization as a way to appear more scientific. This shift came at the expense of considering economic emergence and behavioral traits that did not fit with narrow neoclassical rationality. This resulted in economists ignoring warning signs of the 2008 financial crisis. John Maynard Keynes' insight on 'animal spirits' influencing business investment was also dismissed by neoclassical synthesis, which simplified the Keynesian narrative as labor market failure in an otherwise well-functioning non-neoclassical world.",0
58,9,"In the early 1990s, endogenous growth theorists argued that Solow's unexplained residual could be explained by adding 'knowledge' as a production factor with unique features that lead to economies of scale and externalities. This theory is based on neoclassical ideas, where a 'stock' of knowledge is produced by research and development, which produces innovations that can be transformed into new capital equipment for sale to consumer goods producers. However, this theory only tells us what we already knew: investment in education and training is crucial, promoting innovation is critical, and patents are helpful, but too much protection can be harmful. The equilibrium endogenous growth theory does not explain the process of economic emergence, although it aims to be explanatory. Furthermore, the primary driver of economic growth, entrepreneurship, is practically disregarded.",0
58,10,"Although mathematical representations can capture ""weak"" emergence in processes such as competition and innovation, they do not fully account for ""strong"" emergence, which refers to more radical innovations and entrepreneurship. For economic growth to occur, there must be a deterministic component in emergent processes, as economic systems are dissipative structures that need to remain structurally coherent over time. This structural persistence can be estimated through econometrics, but it is an incomplete representation of an evolution process that involves structural change. Therefore, the statistical residuals in a logistic diffusion model estimated econometrically contain all the non-deterministic components of an emergent process, in addition to normal Gaussian stochasticity.",0
58,11,"Evolutionary economists have successfully addressed weak emergence in their theories and empirical applications. They also acknowledge the importance of strong emergence as the foundation for economic evolution and growth. Despite Joseph Schumpeter's influential work on the role of entrepreneurship in generating novelty, it remains analytically challenging for evolutionary economists. Further development is needed before a comprehensive treatment of economic emergence can be achieved.",0
58,12,"Emergence involves the concept that wholes are greater than the sum of their parts, which is an old idea recognized in mainstream economics. Evolutionary economics and business strategy analyze this process through the operation of entrepreneurship. Entrepreneurial individuals or groups set up networks of connections between machines and people, use organizational rules, and access energy sources. The field has seen contributions from evolutionary economists using case studies or agent-based simulation.",0
58,13,"The success of a company's physical, cultural, conceptual, and organizational structure often leads to a historical lock-in that limits the firm's ability to adapt. This creates an evolutionary dilemma, where tighter specialized connections in networks increase efficiency but make adaptation more difficult as specialized organizations are less flexible. Industries as whole have more adaptive potential than individual firms, making an overly rational neoclassical approach a handicap. IBM is a notable example of a highly efficient but non-adaptive organization that required a separate branch to innovate and create personal computers. Complexity theory recognizes that optimizing a system often involves suboptimal behavior in individual components.",0
59,1,"The policy structure of India has undergone changes due to the recent efforts towards liberalizing the economy and reducing government intervention. This study aims to assess if economic freedom leads to higher economic growth in India, which is a federal system with varying business regulations, taxation, and government spending across states. A pooled linear regression model is used to analyze categorical data containing economic freedom and its components as independent variables, and income per capita and gross state domestic product growth rates as the dependent variable for 20 states across three time periods- 2004/2005, 2006/2007, and 2009/2010. The study considers variables like initial income per capita, literacy rate, sectoral composition, and inflation rate as control. The results indicate that economic freedom has a significant positive impact on economic growth, with the size of government, strong rule of law, and flexible regulations governing credit, labor, and product markets being the key factors positively influencing income growth.",0
59,2,"Market-oriented reforms have been widely recognized as a catalyst for economic progress (Berggren 2003). The establishment of market liberalization and institutions to promote the market forms the basis of the Washington Consensus (World Bank 2002). The International Monetary Fund (IMF) and the World Bank have introduced adjustment programs under this consensus to decrease government intervention in economies. Market-based institutions play a significant role in conveying information effectively, ensuring property rights and contracts, and promoting competition, which foster economic development (De Vanssay and Spindler 1994; Alesina 1998; De Haan and Siermann 1998; Nelson and Singh 1998) according to the World Bank (2002). These institutions are intended to promote economic freedom by providing incentives for growth, such as low taxes, an independent legal system, and private property protection (Murphy et al. 1991; Gwartney 2009). They also stimulate dynamic and organized economies, where effective regulation encourages free and fair competition while suppressing the number of government companies (Johansson 2001).",0
59,3,"""Starting from the late 1980s, India's economy underwent a gradual transformation with the implementation of trade liberalization, slow but steady deregulation, and controlled output. In 1991, the country shifted from a state-led development model to a neoliberal approach, resulting in significant changes both internally and externally. The greater visibility of the free market economy has led to impressive growth rates in India's national and per capita incomes. Subsequent efforts towards further opening up the economy and reducing government control have brought about changes in various policy structures, including the size of the government, legal structure, regulation of labor and business, and security of property rights.""",0
59,4,"""Economic freedom refers to the extent of a market economy, governed by principles of voluntary exchange, competition, and safeguarding of property and individuals. The central aim is to define the institutional structure as a key element in economic policy. The rewards and encouragements provided to economic agents such as businesspersons, inventors, investors, and manufacturers are heavily reliant on institutional establishments, which may or may not function efficiently.""",0
59,5,"Economic freedom, as defined by the Fraser Institute, includes five key elements: the size of government, legal framework and security of property rights, access to sound money, freedom to trade internationally, and regulation of credit, labor, and business. These elements contain several sub-components and 42 different variables. The Economic Freedom of the World Report rates each component and sub-component on a 0-10 scale and averages them to determine a country's economic freedom. The Heritage Foundation and Wall Street Journal also produce an annual economic freedom index, with similar underlying principles.",0
59,6,"There has been a long-standing belief, dating back to Adam Smith, that economic freedom can lead to growth and prosperity. This freedom, as defined by Hayek, refers to the absence of coercion. Evidence shows a strong correlation between economic freedom and growth, as competition in free economies tends to promote faster growth. Additionally, liberal economies provide more opportunities for entrepreneurship and private investment. While economic freedom is an important indicator, its individual components can have varying impacts on the overall health of the economy.",0
59,7,"According to Parente and Prescott (2000), the importance of security of property rights for economic growth is widely agreed upon. This is because having secure and transferable rights to assets and contracts encourages investment and leads to growth, as owners are confident that they will benefit from their investments. The efficient allocation of assets that comes with security of property rights also contributes to growth (World Bank 2002), as savings can be directed towards activities with high expected profits. Rodrik (2000) suggests that security of property rights, when complemented by a well-functioning legal system, can act as a necessary institution for economic freedom.",0
59,8,"Access to a stable currency is another aspect of economic freedom that mainly focuses on controlling inflation. High and unstable inflation can hinder economic growth, but moderate inflation can make it easier for prices and wages to adjust to market shocks. Inflation also allows for greater flexibility in real wages, leading to lower long-term unemployment rates. However, the impact of inflation on growth is still uncertain based on empirical evidence.",0
59,9,"There could be efficiency effects from trade liberalization, indicated by the freedom to trade internationally. This interaction with the global market may lead to the dissemination of technology. When exchange is based on comparative advantages, free trade can enhance the productivity of domestic firms with the presence of international competition. However, the relationship between trade liberalization and economic growth remains inconclusive, with some studies reporting positive linkage while others are skeptical. Sachs and Warner (1995) and Rodriguez and Rodrik (2001) hold differing opinions, and Greenaway et al. (2002) provides evidence in support of a positive relationship. Yanikkaya (2003), on the other hand, remains skeptical.",0
59,10,"Regulating labor, credit, and business is considered a crucial aspect of economic freedom. Research suggests that reducing regulations can promote growth and benefit businesses (Calmfors and Driffill 1988; Baumol et al. 2007). Unfavorable labor laws and disputes can impede business operations. Inadequate infrastructure and raw materials can also hinder business performance. High transaction costs limit trade and economic activities, which restrict the economic freedom of individuals (Debroy et al. 2011).",0
59,11,"The analysis of economic freedom at state-level in India drew from the Economic Freedom of Indian states, 2011 (Debroy et al., 2011) report which covers the years 2005, 2007 and 2009. The index used for economic freedom in India was derived from three key indicators - size of government, legal structure and property rights protection, and business and labor regulation. The study focused on 20 states as data for those states were available.",0
59,12,"The Economic Freedom of the World Report by the Fraser Institute serves as the basis for the areas used to construct India's economic freedom index, ensuring the comparability of measures with those of other countries. However, due to India's specific conditions and division of responsibilities between the states and the central government, only three dimensions are deemed appropriate for the index. These dimensions allow state governments to directly impact economic conditions and institutions. The rating scale ranges from 0 to 1, with 1 representing the highest degree of economic freedom. Per capita gross state domestic product (GSDP) and GSDP growth rate are used to measure the impact of economic freedom on economic growth, with data collected from the Central Statistical Office (CSO) of the government of India.",0
59,13,"The study focuses on the economic freedom index rather than its change, although examining the latter may have been more beneficial. Unfortunately, data for the freedom index in the Indian context is only available for three years, and analyzing changes would reduce the data period to two, thereby decreasing the number of observations. Previous research has also concentrated on the level of economic freedom rather than the change. Based on prior empirical evidence, the study assumes that economic freedom affects growth, but not the other way around. No endogeneity testing is conducted in the proposed linear multiple regression model.",0
59,14,"Higher rates of economic growth are linked to greater levels of economic freedom. This connection could be explained by the ""productivity effect,"" which is related to the fact that many of the freedom index variables are measures of price distortion that impact the allocation of resources and efficiency. As a result, economic freedom has positive impacts on economic growth, as noted by Cole in 2005.",0
59,15,"It could be suggested that a smaller government, improved legal provisions and property rights security, and increased flexibility and state intervention in credit, labour market and business will lead to higher economic growth in India. According to Solow-Swan and Ramsey's neoclassical growth models, a higher value of the rule of law indicator will elevate the steady-state level of output per effective worker, and a higher ratio of government consumption to GDP will lower it, which reduces the growth rate. In the former case, the growth rate will rise, while in the latter, it will decrease, given values. (Barro and Sala-i-Martin 2004).",0
59,16,"The level of economic freedom is decreased when the government interferes with the economy by producing and providing goods and services or redistributing resources. As government expenditure increases, it may lead to distortions in private decision-making and have adverse effects on public finance. Economic freedom is meant to encompass the idea that the government's role in a free economy is only to provide protective and productive functions. When the government goes beyond these functions and transfers resources between taxpayers, it is seen as impinging on economic freedom. Essentially, a small government size is needed to increase economic freedom, while a large size reflects more resource reallocation and intrusion into the private market which may lower freedom. In creating the freedom index, the non-linear relationship between government size and economic freedom was considered.",0
59,17,"Flexibility within the labor market is crucial for achieving success in any business venture. This trait highlights an entrepreneur's ability to adapt to changes necessary for the growth of their enterprise (Altman, 2007). Offering entrepreneurs the liberty to streamline their labor base and depart from the market can also bolster their abilities. Obstacles such as limited infrastructure and raw materials may impede entrepreneurs and lead to their failures (Debroy et al., 2011).</Mask>",0
59,18,"There may be uncertainties in the money market due to volatility, which is indicated by inflation and macroeconomic instability. The role of inflation in output growth is a subject of conflicting views, with the ""grease effect"" and ""sand effect"" creating different effects. While developed countries exhibit a predominant grease effect, developing countries show a significant sand effect. High inflation rates may lead to inefficient allocation of resources, decreasing real net return on investment and resulting in a decline in investment and economic growth in the long run. On the other hand, favorable impacts of inflation due to money acting as a capital substitute cannot be overlooked. Hence, the impact of inflation on economic growth remains an empirical question.",0
59,19,"The significance of the economy's structure in relation to economic growth cannot be overlooked. The industry mix, which is reflected in the sectoral composition, is a useful indicator in this regard. Structural changes that favor fast-growing sectors may enhance growth and per capita income. While previous studies have investigated the role of services in compositional effects, in the Indian economy, the fast-growing service sector and manufacturing sector, which is an employment-generating sector, play significant roles. Two independent factors, the shares of employment for the secondary and tertiary sectors, are used to understand compositional effects. However, the expected sign of each variable is unclear and dependent on the relative size of each sector and employment dynamics in all other sectors. Therefore, the impact of shares of industry and services on growth in India remains an empirical question.",0
59,20,"Investing in human capital is another key factor that drives economic growth. Studies show that increasing investment in human capital can lead to higher growth rates until reaching a steady state. Human capital can help overcome the constraint of diminishing returns to physical capital and generate long-term per capita growth without the need for technological progress. Therefore, producing human capital can serve as an alternative to improving technology to drive long-term growth. The growth rates are affected by the balance between human and physical capital, with abundance of human capital relative to physical capital resulting in higher growth rates. In times of crisis, recovery is faster if physical capital is destroyed rather than human capital. A country with greater availability of human capital can adopt sophisticated techniques at a lower cost and achieve higher returns.",0
59,21,"Since 1991, India has implemented various liberalization measures that can be categorized into two phases, commonly known as first and second generation reforms. The first phase mainly focused on external sector reforms introduced by the central government, while the second phase emphasized domestic economic reforms that primarily fall under the purview of the state government. First generation reforms also included product market agendas, while second-generation reforms primarily addressed the markets for land and labor. This information was sourced from Jha in 2009 and Debroy et al. in 2011.",0
59,22,"The scores of economic freedom have significantly improved over time due to the reforms, with values increasing from 5.1 in 1990 to 6.4 in 2008 (Table 1). All individual indicators of economic freedom, except for 'access to sound money,' have constantly improved. These indices measure the extent of freedom from government-imposed restrictions on various pertinent aspects (Debroy et al. 2011). It is intriguing to note these changes.",0
59,23,"It is evident that India, being a vast country, showcases distinct contrasts among its constituent states, primarily owing to their differing social, political, and institutional frameworks. Thus, the current national scenario may not accurately reflect the individual state's conditions. Additionally, the implementation of economic reform policies has not been uniform across all states. While some states embraced the reform agendas with fervor, others have been sluggish in their adoption. Consequently, certain states enjoy greater economic freedom and growth rates than others. Therefore, studies on economic freedom and growth must concentrate on these inter-state differences.",0
59,24,"The study focuses on economic freedom and its indices as important variables. Table 2 displays the impact of overall economic freedom on economic growth, reflected in column 1. A positive and significant correlation exists between the overall economic freedom index and economic growth across the states, suggesting that higher levels of economic freedom lead to better economic growth.",0
59,25,"The second, third, and fourth columns of Table 2 illustrate the economic freedom indices for three different components. The economic freedom index for the size of government suggests that reduced government intervention, indicating a higher level of economic freedom, may lead to increased economic growth. The coefficient for this index is positive and significant, showing that states with smaller government spending as a share of the total, less government enterprise sector, and lower marginal tax rates are likely to achieve greater economic growth. Additionally, the legal structure and security of property rights coefficient is positive and significant, suggesting that ensuring law and order and protecting property is a vital area of governance. The regulation of labor and business directly affects economic growth, with this aspect of economic freedom reflecting state intervention in labor markets, bureaucratic and procedural costs, including physical infrastructure. It may be said that high flexibility in the labor market enhances output growth. The three economic freedom indices are also tested simultaneously to check the model's robustness (Table 2, column 5), and the results are generally consistent.",0
59,26,"India's per capita income growth is directly impacted by the share of employment in the tertiary sector. However, the secondary sector's share appears to be irrelevant. The reason for including both sectors in the growth model is to analyze the compositional effects of people transitioning from low-productive agriculture to high-productive secondary and tertiary sectors. Currently, India's growth is largely due to the growth of the tertiary sector, evidenced by its increasing share in the country's GDP. This growth is led by information and communication technology, highlighting ICT's pivotal role in India's growth.",0
59,27,"The role of literacy rate, as a measure of human capital, in determining economic growth is significant. The positive coefficient of the initial literacy rate suggests that states with a stronger human capital base at the beginning are more likely to experience higher growth rates. It implies that human capital can complement physical capital, thereby delaying the onset of diminishing returns to reproducible capital, according to Barro and Sala-i-Martin (1991).",0
59,28,"It is interesting to note that the per capita income growth rate of Indian states is positively correlated with their initial levels of per capita income. This implies that states with higher initial per capita incomes tend to grow faster compared to their counterparts with lower per capita incomes, corroborating Rao et al.'s findings. This finding contradicts the neoclassical growth theory's prediction of diminishing returns to reproducible capital, as proposed by Solow in 1956. Instead, the results suggest an increase in returns to reproducible capital and a widening gap in economic growth between the Indian states (Rao et al. 1999).",0
59,29,"The data shows that economic freedom contributes positively to India's economic growth. It is interesting to note that all three aspects of economic freedom are important for the states of India. Therefore, it would be wise for the country and its regions to reduce the government's size and interference in the market, as well as to have flexible regulations for credit, labor, and product markets. Moreover, strengthening the legal structure would create a more business-friendly atmosphere throughout India's states, fostering growth.",0
60,1,"The influence of economic freedom and culture on economic growth is discussed in this paper, with the argument that both factors play a crucial role in determining economic prosperity. The study used the World Values Surveys to measure culture and found that economic institutions associated with economic freedom were also essential for growth. It was discovered that economic freedom had a more significant impact, indicating that culture and economic freedom could substitute or complement each other. The paper further suggests that culture becomes more important for growth when economic freedom is lacking and reduces in significance when economic freedom is established.",0
60,2,"Economic growth and development rely heavily on key economic institutions, such as private property, the rule of law, and contract enforcement. North (1990) defines institutions as the ""rules of the game,"" which are manifested in both formal (codified structures) and informal (cultures, norms, and conventions enforced by social custom) ways. While economists acknowledge the importance of both formal and informal institutions for growth and development, the relative impact of each remains uncertain. Therefore, we argue that both economic institutions and culture must be taken into account when analyzing economic growth.",0
60,3,"The objective of this research is to integrate 'cultural capital' into the freedom-growth framework and contribute to understanding how institutions impact economic development. By controlling for economic institutions and culture, the study separates and evaluates their individual effects on economic outcomes. The analysis sheds light on whether economic freedom and culture complement or substitute each other, with a major emphasis on their relative effects on economic prosperity rather than their feedback or interaction.",0
60,4,"Using a fixed effects model from 1970 to 2004 and including various robustness checks, we found that culture and economic freedom both play a role in economic prosperity. However, when considering both factors simultaneously, the relationship between culture and growth weakens, while economic freedom continues to have a positive and highly significant impact on economic growth. This suggests that culture and economic freedom may act as substitutes, with culture providing key institutional functions in the absence of economic freedom, but becoming less necessary with credible economic institutions.",0
60,5,"The literature has extensively scrutinized the strong correlation between economic freedom and growth, as mentioned earlier. The theoretical fundamentals supporting this connection are also firmly established. De Haan and Sturm (2000: 3) state that economists and economic historians have been advocating that the freedom to choose and supply resources, competition in business, trade with others, and secure property rights are crucial factors in advancing the economy, ever since the era of Adam Smith, if not before.",0
60,6,"To deepen our understanding of how culture impacts economic growth, we limit our scope to a particular set of cultural indicators that are deemed significant for economic interactions and transactions. Referred to as 'economic culture,' this subset is defined by Porter (2000: 14) as ""the convictions, attitudes, and principles that shape the economic behavior of individuals, organizations, and other institutions."" This focused approach facilitates a more detailed examination of the correlation between culture and economic growth (Patterson 2000).",0
60,7,"The variable for our economic culture is based on the methodology outlined in Tabellini (2008a, 2009). It identifies four categories of culture that should influence behavior related to social and economic interaction, thereby affecting economic growth and development. These categories are trust, respect, individual self-determination, and obedience, all of which govern interaction between individuals in markets and entrepreneurship. Trust, respect, and individual self-determination encourage economic interaction, while obedience constrains it by reducing risk-taking, which is crucial to entrepreneurship.",0
60,8,"Self-determination is a way of measuring the level of control individuals have over their lives and their choices. If an individual has a high level of self-determination, they are more likely to see economic success or failure as a result of their own efforts. This motivates them to work harder and increase their productivity, ultimately leading to an increase in their overall welfare. Banfield (1958) argues that the greater an individual’s ‘locus of control,’ the higher the economic development of their country will be.",0
60,9,"The correlation between culture and economic freedom can work in either direction, as substitutes or complements. Economic growth is influenced by both culture and economic freedom. If one of them surpasses the other in significance when included in the same regression, they can be considered as substitutes. However, if both remain significant, it suggests that culture and freedom are complementing each other to promote economic growth.",0
60,10,"The formalization of informal institutions associated with economic freedom in a culture may promote economic growth. As a result, informal norms and mechanisms like trust networks may no longer be necessary. In this scenario, economic freedom becomes more important than culture in the growth regression, indicating a substitution effect.",0
60,11,"The argument for considering culture and economic freedom as complementary and important factors in growth regression is strong. While each factor may contribute to economic growth independently, their combined impact is likely to be much stronger than either alone. For instance, a trusting culture can facilitate some exchanges, but the enforcement of laws on property rights and against predation by a government is essential for sustainable economic growth. A number of studies have suggested that culture and economic freedom mutually reinforce each other, supporting this argument (references omitted).",0
60,12,"We use the Economic Freedom of the World Index developed by the Fraser Institute to measure economic freedom. The index rates the level of economic freedom from zero to ten, with ten being the highest, based on 42 different components that can be classified into five main groups. These groups are the size of government, monetary policy and price stability, legal structure and security of private ownership, freedom to trade with foreigners, and regulation of credit, labor, and business. Each of these categories contains a subset of variables used to create the overall index of economic freedom.",0
60,13,"We have included the investment share as one of our standard control variables due to the well-established positive correlation between the rate of investment in physical capital and the rate of growth (Levine and Renelt 1992). However, we acknowledge that including both economic freedom and the investment rate in the same regression may lead to an endogeneity problem, as pointed out by De Haan et al. (2006). Numerous studies demonstrate that economic freedom enhances growth both directly through a productivity-promoting channel and indirectly through an investment effect (Dawson 1998; Bengoa and Sanchez-Robles 2003; Gwartney et al. 2004). Although we include investment in our primary specification, we address the endogeneity issue in a later section.",0
60,14,"The third column of the regressions combines culture and economic freedom to differentiate between the substitutability and complementarity of the two variables. In the OLS regression, the significance of culture disappears when controlling for economic freedom. However, in the fixed effects regression, culture is significant at the 10% level. Economic freedom remains strongly and positively significant in both specifications. The joint significance of the F-statistics from all three columns is highest when controlling for both culture and freedom. The results support the idea that economic freedom is a stronger contributor to economic performance than culture.",0
60,15,"The insignificance of culture is observed in all five regression specifications, whereas economic freedom is found to have a positive and significant impact at the 99% level, further supporting the substitution theory. According to regression (1), a one unit increase in the freedom index leads to an increase in growth by 1.40 percentage points. When controlling for educational attainment, the coefficient on freedom almost doubles and the R-squareds go from 0.28 to 0.93, indicating severe endogeneity. Education has a strong positive and significant relationship with growth, while all other variables, except for culture, are also significant in this specification. Investment, population growth, and area are significant only in this regression while urban population is significant in three out of four regressions, albeit with a switch in signs. Geography and legal origin turn out to be insignificant.",0
60,16,"Despite the fact that the extra control variables do not provide much explanation to the model, as implied by the comparable R-squareds to the baseline specification (except for education), we acknowledge that our model only accounts for roughly 25% of the variance in growth. We attribute this to our prudent handling of our control variables.",0
60,17,"Based on our benchmark and core analysis, it appears that culture and economic freedom could act as substitutes. Our findings indicate that economic institutions that uphold private property rights, the rule of law, and contract enforcement play a significant role in determining economic growth. This outcome is consistent across various regression models. Although we observe a slight positive link between culture and economic growth, our analysis shows that culture only has a statistically significant impact in one of the seven regressions when we control for economic freedom. This outcome seems to support the substitution hypothesis and suggests that the relationship between culture and economic growth may be more complex than previously believed.",0
60,18,"To test reverse causality more directly, we conduct a simple check that involves the use of both lagged and future values of changes in freedom, changes in culture, and our growth rate. If our results are being driven by reverse causality, we anticipate that changes in income will subsequently result in changes in freedom and culture, or both. However, if freedom or culture is contributing to growth, then we expect changes in these variables to be correlated with growth in the following period. Consequently, we examine changes in these variables, not their levels, for this specification only.",0
61,1,"The article highlights that extreme economic inequality is not only a violation of social justice, but also a dysfunction to the U.S. economy and a factor linked to the recent economic crisis. The changes in ideology, market economy, and government policies since the mid-1970s are identified and contrasted with the preceding post-World War II decades. The analysis reveals how increased economic inequality and political consequences contributed to the economic meltdown, which had devastating effects, particularly on the social work clientele. The article has implications for social reform and calls for social movements to broaden the constituency of social justice in pursuit of reducing economic and political inequality. It also explores the ways social workers can contribute to such movements.",0
61,2,"During the period of 65 years following World War II, economic inequality can be divided into two parts. The first three decades saw a decline in inequality, whereas the next 30 years saw the rise of inequality, leading to an economic crisis. The article focuses on the differences between the two periods in terms of income and wealth distribution, wages, unemployment, and poverty. It then elaborates on the democratic system of government's relationship with capitalism during the first period, in which a concept of ""new capitalism"" emerged, characterized by the national income's rise benefiting individuals who were previously unable to share in the prosperity through their earnings. During this time, efforts were also made towards the conscious pursuit of full employment, which aided in the earning of higher incomes. This era, seen retrospectively, may have been an anomaly in the history of capitalism, resulting from the federal government's active role in the economy in response to the Great Depression and World War II's incredibly exceptional events in the United States.",0
61,3,"It's not surprising that economic inequality has increased over the past 30 years, but the extent of the divide can still be shocking. Inequality is evident in numerous areas, including wages, income, wealth, poverty, and unemployment.",0
61,4,"The income gains of the top 1 percent of households are particularly outrageous and disproportionate. In 2007, just before the financial collapse, the average after-tax income of these wealthiest Americans was $1,319,700, which is an increase of $976,120 over the 1979 average. This is a stark comparison to the middle and bottom quintiles, who only saw increases of $11,200 and $2,400, respectively. Analyzing data from the CBO, Sherman and Stone of the Center on Budget and Policy Priorities discovered that after-tax income gaps between the richest 1 percent and the middle and poorest fifth of the country increased more than threefold between 1979 and 2007. The data suggests that income concentration at the top of the income scale has reached levels not seen since 1928, the eve of our previous, catastrophic financial crash.",0
61,5,"Wealth is highly skewed towards the top and has experienced a recent surge in concentration. From 1995 to 2004, just about all of the gains in household net wealth went to the highest quartile of income earners. In 2004, the wealthiest 10% possessed over 70% of private wealth. Edward Wolff, a renowned scholar in the field, authored a study entitled Top Heavy to describe the mounting inequality in wealth in the United States.",0
61,6,"Unemployment was relatively low during the period of shared prosperity, with an average of 4.8 percent from 1949 to 1973, compared to an average of 6.5 percent from 1974 to 2008, which has led to stagnant wages in times of high unemployment. This not only results in lost income and increasing inequality but also leads to the loss of potential output for the economy. Conversely, when the labor market tightens, wages and benefits rise, particularly for low-wage workers, as seen in the 1990s. The impact of unemployment is not limited to reduced incomes and tax revenues but also contributes to government budget deficits through increased outlays to benefit jobless workers.",0
61,7,"During the Great Depression and World War II, the government took on a more active role in the economy, resulting in a larger and more involved government. By enacting policies that reduced the severity of recessions and distributed income more equitably, the government became more accepted by Americans. The expansion of social welfare programs, particularly unemployment compensation, helped stabilize the economy during times of economic downturn by reducing the contraction of consumer spending. The government also implemented regulatory policies to prevent another stock market crash and maintained higher tax rates in peacetime to support rising real wages and labor peace. Despite criticisms of violating free-market economics, economist Robert Kuttner argued that this system produced nearly 30 years of egalitarian economic growth at an average annual rate of 3.8%, highlighting its benefits.",0
61,8,"Instead of investing in productivity and innovation to reduce their competitive disadvantage, businesses opted for alternative strategies that increased inequality (Harrison & Bluestone, 1985). This included squeezing labor through wage freezes and flexible work arrangements, globalization through transferring operations to lower-wage countries, and abandoning production for paper profits resulting in job losses. Companies like General Electric and General Motors shifted their focus to more profitable financial services. Another strategy was lobbying for tax and regulation reductions.",0
61,9,"In 1980, the Republicans successfully brought together their fiscally conservative, pro-business base with a group of the Democrats' New Deal coalition. These voters were turning away from the Democratic party due to issues like affirmative action, expanded welfare, school busing, women's liberation, gay rights, abortion, and high taxes. Former Democratic supporters, including blue-collar workers, felt that the party no longer represented their interests and prosperity. This was noted by Edsall (1991).",0
61,10,"Despite projecting a progressive and populist image, Democrat Bill Clinton oversaw the elimination of AFDC and the GlassSteagall Act, a key New Deal banking regulation. This repeal allowed for the merging of commercial and investment banks and the continuation of high-risk investment practices. Clinton also maintained Republican policies of globalization, neglecting workers' rights and environmental protection.",0
61,11,"President-elect Bill Clinton's abandonment of his campaign promise to prioritize the needs of the people over the financial sector highlighted the influence of the latter. Despite pledging to create an economy that prioritized the well-being of ordinary citizens, Clinton acknowledged that the wealthy controlled the economy and that lowering deficits would benefit bondholders but harm his supporters. Robert Rubin, a co-senior partner at Goldman Sachs and a member of Clinton's National Economic Council and Treasury Secretary, was among the advisors who advised the president-elect to prioritize deficit reduction.",0
61,12,"Economist Arthur MacEwan (2009) stressed that a combination of factors led to the economic meltdown, including the concentration of power among the wealthy, the dominance of a pro-market ideology, and growing inequality. MacEwan's perspective considers the entire economic landscape, from the highest levels to the lowest. This ""nexus of factors"" gave rise to specific developments such as the increase in credit, the lack of regulation, and the housing bubble, which will be examined in more detail later.",0
61,13,"In the United States, the increasing ""media monopoly"" contributed to a limitation on the spectrum of viewpoints available to the public. Between 1983 and 2004, there was a drastic decrease in the number of corporations controlling most of the newspapers, magazines, radio and television stations, book publishers, and movie companies, from 50 to just five. The nonprofit organization Fairness and Accuracy in Reporting (FAIR) noted that mergers in the news industry had accelerated, further narrowing the range of perspectives that could access mass media. Ultimately, the views expressed by the media were heavily influenced by the agendas of their owners.",0
61,14,"The different perspectives on agency and choice align with the belief that the political economies of capitalist countries are not uniform. Various countries are less apprehensive about ""big government."" Research indicates that wealthy capitalist countries differ significantly in poverty prevention and the size and scope of their welfare states. Even though most welfare states have faced cutbacks in recent years, the relative poverty rates across countries vary widely. For example, in 2000, France and Germany had poverty rates of 7.3% and 8.4%, respectively, while the United States had a poverty rate of 17.0%. The United Kingdom and Canada had lower poverty rates of 13.7% and 12.4%, respectively, compared to the U.S. Several countries like the Netherlands, Denmark, Finland, Norway, and Sweden had even lower rates, which ranged from 5.4% to 6.6%. (Luxembourg Income Study, n.d.).",0
61,15,"Derivatives were utilized as a means of reducing the risk associated with subprime mortgages. However, these financial instruments were central to the housing bubble, its inevitable collapse, and the subsequent financial bailouts. Banks purchased credit-default swaps, a derivative that insured mortgage loan packages, in an attempt to minimize their risk. Since insurance was heavily regulated, these packages were named ""credit default swaps"" to avoid further regulation. Nearly a decade prior, the head of the Commodity Futures Trading Commission suggested regulating these derivatives, but notable figures such as Clinton's Treasury Secretary Robert Rubin, his Deputy Lawrence Summers and Federal Reserve chief Alan Greenspan, strongly opposed regulation.",0
61,16,"The analysis suggests that in order to address economic inequality, there is a need for reregulation of the financial sector, reducing the influence of economic elites in politics, and a stronger labor movement. Policies to reduce inequality include increasing social welfare, guaranteeing living-wage jobs to all who want to work, as well as providing better access and affordability to health care, housing, child care, and public transportation.",0
61,17,"Job creation similar to the New Deal work programs designed by social workers Harry Hopkins and Aubrey Williams requires improvement as women and minorities were not employed according to their needs. To enhance the New Deal model, it is crucial to emphasize job opportunities in social fields like child and elder care, education, and health care, coupled with physical infrastructure. A new industrial policy promoting U.S. manufacturing could boost job opportunities and reduce reliance on the financial sector. However, these modifications require significant participation from the federal government. (Rose, 2010; Pollin & Baker, 2009).",0
61,18,"The ideology of the free market and hands-off government may be declining, but financial interests still hold a significant amount of power on Wall Street. Despite the global financial crisis caused by their failures, the money changers remain in the temple. The stock market may have recovered, but unemployment remained high for months. Financial interests are opposed to reregulation, and lobby heavily to weaken regulatory reform. However, Congress enacted the first regulatory legislation in a generation with a powerful consumer protection component. The effectiveness of the new law will ultimately depend on successful implementation, which financial interests are actively lobbying against. (Johnson & Kwak, 2010) (Lichtblau, 2010)",0
61,19,"Social workers have historically focused more on welfare than job creation, despite some involvement in government job creation in the 1930s. However, with the ongoing issue of unemployment and its far-reaching effects, social workers can play a role in reducing inequality by supporting organizations that advocate for direct job creation by the government. They can also support living wage campaigns and the strengthening of the labor movement, including advocating for the Employee Free Choice Act of 2009, and by joining unions themselves to advocate for reforms that benefit all workers.",0
61,20,"The fact that many families with incomes above the median, including social workers, struggle to afford basic necessities highlights the high cost of living. These families are consequently at risk of falling prey to predatory lending. It begs the question, who is responsible for safeguarding them against these financial predators? In the past, settlements took up this task and advocated for consumer protection and regulatory laws. Therefore, social workers not only need to educate consumers about financial literacy but also push for the enforcement of new consumer protection laws.",0
62,1,"In 2001, Greece became a part of the Eurozone and experienced a brief period of economic prosperity before facing a major financial crisis in 2010. The economic situation transformed drastically between the country's entry into the Eurozone and their acceptance of a shared IMF/EU rescue package. To test the economic voting theory, I utilize this scenario. I examine the relations between macroeconomic indicators and the incumbent party's vote share, as well as sociotropic assessments of the state of the economy and support for the incumbent party, using longitudinal aggregation data from 1981 to 2009 and individual-level data from 2004 to 2009. The findings reveal that sociotropic economic assessments are linked to government party backing, but when the economy is at its worst, the incumbent has little chance of victory and should only anticipate support from long-time loyalists.",0
62,2,"The Greek economy faced its most difficult period in recent times in 2009, which has since made news headlines worldwide. This unexpected development came following Greece's acceptance into the Eurozone alongside its booming economic activity and falling unemployment rates in the early 2000s. The conservative ND party's win in the 2004 election ended PASOK's eleven-year rule and exposed signs of corruption in the government, prompting Karamanlis to promise reform and fight against corruption.",0
62,3,"In 2009, Greece was facing a serious problem as its debt and budget deficit had reached an alarming level. Prime Minister Karamanlis decided to hold a snap election due to the difficulties facing his government in handling the effects of the global recession, as well as a series of scandals that led to the resignation of three ministers within a year. During the electoral campaign, Karamanlis refrained from making promises regarding the economic policy his party would follow, and instead presented himself as sincere about the actual economic situation of the country, attributing it to the global financial crisis. However, despite his efforts, PASOK won the election comfortably, with the justification that the economy had not been managed well by the previous government.",0
62,4,"Voters are not considered fools and they make rational judgments about the past performance of the economy, according to the idea of economic voting. Although prospective evaluations are relevant, they are not as easy as reminiscing. Voters' perceptions and appraisals of policy and performance are driving forces behind their decisions, argued Key. Fiorina extended Key's argument about retrospective evaluations. Even uninformed voters have a hard bit of data - what life has been like during the incumbent's administration. Based on such evaluations, voters can hold the government accountable by rewarding and re-electing it or punishing it and voting for the opposition.",0
62,5,"There is limited knowledge on economic voting in Greece, and the existing research is based on a comparative study by Freire and Costa Lobo (2005) and their analysis of the effect of objective and subjective economic indicators on voting behavior in Greece, Portugal, and Spain from 1984 to 1999. Their findings suggest that in Greece, personal financial perceptions correlate with GDP changes. Additionally, the authors used Eurobarometer data to examine the importance of the economy on party choice from 1985 to 2000 and found that ideology was the most significant factor. However, there is a need for empirical testing of economic evaluations for recent elections, which will require examining aggregate as well as individual-level data.",0
62,6,"Macro performance is connected to support for the current party via the reward-punishment hypothesis. This hypothesis suggests that voters evaluate a government's economic performance based on major indicators, such as unemployment and inflation, and then reward or punish the current party based on these evaluations. Essentially, the government is held accountable for its economic policy decisions. Opposing political parties can also gain support if voters deem the incumbent party's performance inadequate. This concept was discussed by Sanders in 2000 and previously by Lewis-Beck in 1988 and Powell and Whitten in 1993.",0
62,7,"Research on German and British data corroborates Mueller's theory that voters only respond to economic circumstances when they experience a sudden downturn (referencing Nannestad and Paldam, 1997, p.85). However, can this hypothesis be applied to individual-level analysis? Previous attempts to test the ""grievance hypothesis"" at the individual level (as cited in Kiewiet, 1983 and Lewis-Beck, 1988) have been unsuccessful except for when examining the Danish electorate (Nannestad and Paldam, 1997). In contrast, a study conducted by van der Brug et al. (2007) found evidence supporting the ""grievance asymmetry"" hypothesis which posits that economic voting depends on the direction of economic change. These authors had a more liberal definition of what constituted an asymmetry, which resulted in substantial variations in the impact between improving and deteriorating economic conditions (van der Brug et al., 2007, pp. 142-159).",0
62,8,"In Greece, previous simulations at the individual level regarding the effects of economic changes on elections showed that voters tended to reward the governing party when the economy improved, with rewards being slightly stronger than punishments. The lack of coalition governments in Greece makes it a high-clarity country, as voters can easily identify the party accountable for government policies. Stable single-party governments have been a characteristic of Greece's party system, partly due to the disproportional electoral system, known as ""reinforced proportional representation,"" which has been modified multiple times since democracy was restored in 1974. With the exception of the quasi-caretaker coalition governments of 1989-1990, ND and PASOK have taken turns in government, while all other parties remained in opposition.",0
62,9,"The scatterplots depicted in Fig. 1 (with bandwidth 0.7) display a rather mixed outlook, with some evidence suggesting an asymmetry between the fluctuations in the state of the economy and the vote share for the ruling party. Upon closer examination of each macroeconomic indicator separately, it can be observed that declines in the GDP are linked to declines in the incumbent party's vote share and vice versa, but there seems to be a threshold at 2.5% change where incumbents are no longer rewarded for improving growth indicators. With regard to inflation, it appears that increases in the inflation rate up to around 17% are not associated with a decline in the incumbent vote share; voters are, in fact, slightly rewarding the party. However, after this threshold, there is a substantial decline in the vote share for the incumbent. The same is true for changes in the unemployment rate, where alterations between ?1% and 1% do not seem to impact the incumbent vote share. But there is a steep decline in the vote share for the incumbents after the threshold, indicating a punishment for them, although there are very few observations beyond this point.",0
62,10,"I conducted a logistic regression analysis to understand how economic variables impact support for the incumbent party. The dependent variable was coded as 1 if the respondent intended to vote for the incumbent party and 0 if they intended to vote for any other party at the opposition, based on previous studies (Lewis-Beck and Nadeau, 2000; Evans and Andersen, 2006). Logistic regression allowed me to estimate the probability of a voter selecting the incumbent party and how this probability changed with changing economic perceptions. However, in line with most studies, vote choice was considered a function of temporary effects such as economic evaluations, long-term effects such as party identification and ideology, and demographics such as age and gender (Clarke et al., 2004).",0
62,11,"Fig. 2 indicates that the percentage of voters who negatively evaluated the economy increased by almost 20% when comparing the 2004 and 2009 elections. In 2004, which was five years before the economic crisis, 24.4% of voters evaluated the economy as a lot worse. In 2009, a few months before Greece agreed to a bailout package with the IMF/EU, this percentage increased to 43.9%. However, for economic considerations to play an important role in voters' decision-making, the economy must be a salient issue for them. Issue salience was measured in both surveys by an open-ended question asking respondents to name the most important problem facing the country, with the option to mention up to two issues in 2004 and three in 2009. For both elections, economic issues were by far the most significant in voters' minds, with the Greek public mentioning the economy in general, inflation and unemployment in particular, as the most critical issues. There was a significant increase in the importance of the economy from 2004 to 2009, followed by a decrease in the significance of unemployment as an issue.",0
62,12,"Table 1 presents the findings of the study. The economic variable coefficients are statistically significant and aligned with the initial hypothesis. In the 2004 election, voters identifying with the left side of the ideological spectrum showed more support for the socialist governing party, PASOK, as did those who believed that the economic situation had improved in the previous year and those who identified with the incumbent. None of the sociodemographic factors were found to have a significant impact. Similar patterns were observed in the 2009 election. Those who held a favorable view of the economy were more likely to vote for the incumbent, which happened to be the conservative ND. As a result, voters on the right side of the political spectrum also inclined towards ND. These results suggest that economic assessments have a significant bearing on support for the incumbent party. Despite the favorable performance of the economy in 2004, retrospective evaluations of the economic situation correlated with support for the incumbent.",0
62,13,"It is challenging to address endogeneity in cross-sectional data regression models since we lack suitable exogenous instruments. Instead, a counterfactual argument is offered: if we consider endogeneity as an omitted variable problem, we must assess the effect size of this variable to nullify the results presented in Table 1. Considering the powerful predictors included in the model (party identification and left-right self-placement), it is hard to imagine another explanatory variable that could predict incumbent party support with an odds ratio of at least 1.8.3. Thus, we can safely assert that while economic evaluations' impact on support for the incumbent might be overestimated, such an effect undoubtedly exists.",0
62,14,"The article aims to analyze the correlation between the economy and voting behavior in Greece during the 2004 and 2009 elections, with a focus on how it affects support for incumbent parties. The research suggests that, similar to other countries, the Greek electorate tends to punish the ruling party during economic downturns rather than reward them for improvements. However, the non-parametric methods used limit the ability to draw definite conclusions. A multilevel analysis that considers individual-level covariates indicates that rewards are equally as likely as punishments in Greece. While there is a lack of Greek electoral data, future research should continue to examine the concept of ""grievance asymmetry.""",0
62,15,"The probability of voting for the incumbent party increases as positive evaluations about the economy increase, as shown in Figs. 4 and 5. However, confidence intervals between adjacent plots for different levels of evaluation overlap, indicating that any changes in mean evaluations among the electorate would not significantly impact the probability to vote for the incumbent party, with the exception of the shift from ""much worse"" to ""much better"" evaluations in 2004. Figs. 4 and 5 also suggest that the position of the party on the Left-Right scale may affect the gain from positive evaluations about the economy. The centrist position of PASOK allows it to make gains across the ideological spectrum, but right-wing ND faces uncertainty when trying to gain support from the left. The expert surveys used in this study include the 2003 Benoit and Laver (2006) survey for the 2004 election and the Vowles and Xezonakis (2009) survey for the 2009 election.",0
62,16,"The results do not suggest that there was no economic voting in 2009. Economic evaluations did have an important role in both elections, but the evidence from Figs. 4 and 5 shows that this role did not have a substantial impact on electoral returns for the party in government. This was particularly evident in the parliamentary election of October 2009, where the high odds ratio for party identification in Table 1 indicated that only the most loyal supporters of the conservatives intended to vote for the incumbent ND. Ultimately, this resulted in the worst electoral result for ND in its 35-year history.",0
63,1,"The literature on economic voting demonstrates that successful economic performance improves the chances of incumbents being re-elected. However, there is still disagreement as to whether voters in economically insecure situations are more inclined to cast economic votes. This article suggests that the degree of exposure to economic risks is a significant factor in explaining individual-level discrepancies in economic voting, as the level of risk exposure determines the importance of the economy in voting choices. The article focuses on job insecurity and employability as crucial factors in economic voting patterns. It postulates that voters who are more vulnerable to unemployment and have fewer employment prospects in the event of job loss are more likely to engage in economic voting. The test, which employed a dataset combining survey data on incumbent support with occupational unemployment rates and other exposure measures to economic risks, corroborated the hypotheses.",0
63,2,"The relationship between economic factors and electoral outcomes has been extensively researched in political science. Despite some areas of debate, the idea that macroeconomic performance is critical in democratic elections is now widely accepted by the general public and the media. However, recent years have seen challenges to this understanding in two areas: individual differences in information processing abilities and institutional factors that may affect economic voting. Studies have shown that individuals vary significantly in how they acquire information about the economy, while political institutions can affect how voters hold incumbents accountable for economic outcomes.",0
63,3,"This article presents two novel ways to advance economic voting literature and understand individual-level differences in voting behavior. Firstly, it incorporates political science literature to investigate the mediating factors between macroeconomic performance and incumbent support. Specifically, it explores the significance of 'skills' and professional job insecurity, which have been recognized as key sources of social policy preferences and welfare state arrangements. Secondly, it provides fresh empirical evidence that indicates how voters react to changes in macroeconomic performance based on their position in the labor market. The study shows that macroeconomic performance tends to be more critical to voters employed in professions that face higher risks of unemployment or rely on specific professional skills.",0
63,4,"In the upcoming section, an overview of the recent literature on economic voting is provided, focusing on the investigation of individual-level differences in economic risk exposure. A model of economic voting is then introduced, highlighting the importance of levels of exposure to the economic cycle in shaping voting behavior. Afterwards, this study shares the data used and details the research strategies employed in empirical testing. Lastly, the regression analysis results are discussed, followed by conclusions regarding possible directions for future research.",0
63,5,"In the study of economic voting, there has been reluctance to address the question of how individual economic conditions affect voting patterns. The economy is typically viewed as a 'valence issue', with all voters preferring a good economy. Scholars have primarily focused on responsibility attribution, assuming a lack of variation in economic performance's salience. Nevertheless, some classic studies, such as Hibbs (1977), have laid theoretical foundations for understanding how group differences in responsiveness to macroeconomic signals can shape economic voting patterns.",0
63,6,"This article makes two key contributions to the debate. Firstly, it advocates for a close integration of research into economic voting and literature on social policy preferences. The article argues that an individual's position in the labour market not only determines their preferences for social insurance but also shapes economic voting patterns. At a macro level, the resulting disparities in risk exposure generate significant differences in voting behaviour across occupational groups. Secondly, the article conducts the first empirical test of this argument using occupational unemployment data - a crucial concept in the discussion on social policy preferences and the welfare state's origins. Additionally, a range of alternative measures of risk exposure are presented for testing and verifying the study's results.",0
63,7,"The results from these significant articles indicate the need for a closer fusion of the economic voting literature and the knowledge from a different well-known branch of political science. Academic studies on the determinants of social policy preferences have offered extensive proof that the distribution of economic risks among the electorate is incredibly unequal. Such divergences are responsible for differences in choices concerning redistribution as well as in the macro-level welfare state arrangements. Two categories of individual-level aspects decide the exposure to the economic cycle of individual voters. One analysis highlights professional skills acquired through education and professional practices, which correlates positively with the degree of risk exposure. This is because employees with non-transferable skills are more prone to extended unemployment after a job loss. Another perspective proposes that job insecurity, instead of employability, is the primary factor that determines risk exposure. Industry association influences job security via various channels.",0
63,8,"The core principles of the economic voting model propose that there are two primary reasons for voters to be concerned with the macroeconomic state. Firstly, the success of the economy may be seen as valuable in its own right, and economic voting may follow a 'sociotropic' trend, in which voters support incumbents only if they have enhanced the financial well-being of their country as a whole (Kinder & Kiewiet 1981). Secondly, economic performance is also important because the future financial outcomes of individual voters depend, to some extent, on the country's economic health. For the argument outlined in this piece, it is vital to assume that economic voting is, at least in part, motivated by ‘pocketbook’ anxieties about the future implications of macroeconomic performance on an individual level. If voters didn't have concerns about how aggregate economic activity affects their personal finances, susceptibility to economic risk would not be a relevant factor in economic voting.",0
63,9,"To comprehend why this is so, we must examine a factor that has been significantly under-researched in the literature on economic voting - that is, the prominence of the economy and how it varies among the populace. This article assumes two critical hypotheses about the relationship between economic salience and voting behavior. Firstly, it assumes that voters have considerable cognitive limitations in how they receive and interpret information on specific political issues. This means that individuals, under different constraints, tend to consider only a few items from their broader spectrum of preferences while making decisions. Second, voters do not evaluate candidates based on their performance in all policy areas but only on those they consider of particular interest. Therefore, this is important for economic voting because although all voters may prefer a competent economic manager, some might prioritize other attributes of the candidate.",0
63,10,"The literature on economic voting has evolved to better understand the connection between macroeconomic performance and voting behavior. While economic voting is recognized as important, recent studies reveal differences among individuals and countries. Responsibility attribution and individual-level characteristics also influence economic voting. However, this article highlights an overlooked aspect - social policy preferences and welfare state development. Categorizing voters by their vulnerability to economic fluctuations can lead to a deeper understanding of economic voting. The analysis shows that voters with higher job insecurity are more likely to support incumbent governments with good macroeconomic performance.",0
63,11,"However, the positive findings presented in this study need to be considered in light of certain limitations of the research design. These limitations present opportunities for further research into the relationship between economic risk and economic voting. Firstly, the argument outlined in this article should be validated by analyzing actual voting data, as opposed to the measure of public opinion used in this study. Although the study has controlled for respondents who expressed the intention to vote, discrepancies between such intentions and actual voting behavior, including non-voting, have not been addressed. Secondly, the sample size is inadequate, as it is limited to a small number of advanced economies. By including a larger number of clusters in the sample, potential methodological issues in the estimations of standard errors for macro-level variables can be resolved, and interaction effects between cluster-level covariates can be investigated. Additionally, campaign-specific dynamics and political communication strategies, which were not examined in this study, are critical in determining the significance of the economy in electoral contests. Finally, the proposed causal mechanism was not verified through this study.",0
63,12,"Figure 3 depicts a visual presentation of the variation between the two groups by plotting two distinct curves that predict the probabilities of incumbent support based on GDP growth. The solid curve represents the low-skill respondents, which is noticeably steeper than the dashed curve that represents the high-skill respondents. This difference implies that macroeconomic fluctuations have a more significant impact on the support for the incumbent among low-skill respondents. For instance, during a terrible economic situation like a -1% growth, the predicted probability of incumbent support would decrease by 0.21 (from 0.45 to 0.24) for low-skill respondents while it would only reduce by 0.08 (from 0.39 to 0.31) for the high-skill group. Also, the chart reveals that the variation is more significant during economic crises than economic booms, which implies that the two groups vary more in their reluctance to penalize incumbents for poor economic governance than their enthusiasm to reward them for good performance.",0
63,13,"The models numbered 3 to 5 use different measures of job insecurity to estimate the model in Equation 3. Model 3 combines macroeconomic growth with a dummy variable to evaluate the impact of unemployment on economic conditions. The outcomes of the estimation reported in Table 2 reveal a positive coefficient for the interaction term, but it is not statistically significant in either the simple logistic or random effect model. Model 4 examines whether employment in the public sector provides job security, but the coefficient is positive and small, which is contrary to the expectations. This coefficient is nearly significant in the random effect model and insignificant in the simple regression model, demonstrating that there is no observable difference in economic voting behaviour between public and private sector employees. Finally, models 5 and 5r reveal that union membership is a significant factor in economic voting behaviour.",0
64,1,"The transformation process in Hungary from 1989 to 2004 is analyzed and evaluated in this paper. The paper's goal is to analyze the transformation process in Hungary, and the structure of the paper follows this general goal. The economic development of Hungary before the fall of the communist regime is analyzed first, as it determined the entire process that followed. Next, political development, which had a significant impact on the transformation process and its results, is briefly mentioned. The paper then focuses on the main steps in economic transformation, specifically on aspects such as privatization. Lastly, the main economic indicators of this period are analyzed. The conclusion drawn is that the transformation process met its main economic goal, with the economy's growth ability increased. However, the transformation process also created an environment for subsequent economic problems.",0
64,2,"The aim of this paper is to examine and assess Hungary's transformation process. According to the author's perspective, the primary objective of this transformation was to move from a centrally planned system to a market economy. We believe that this objective was generally accomplished with Hungary's accession to the EU, which is why we limit our analysis to the period up to 2004. This serves as indirect evidence that a functioning market economy had been established, as it was a requirement for accession. However, it is important to understand how this was achieved as other transforming countries continue to struggle. The second goal of the transformation process was to shift the overall trend of economic development. The centrally planned system was not sustainable, leading to a decline in economic growth, and Hungary was falling behind market economies. Without improving growth, any change in the economy would be meaningless. This paper evaluates the progress made towards achieving this objective.",0
64,3,"We will begin by outlining the political progress in Hungary over the long-term, which had an impact on the state of the Hungarian economy towards the end of the 1980s. This will be analyzed in the second chapter. Subsequently, we will focus on the political developments during the transformation era, which we consider to be the period between 1990 and 2004 (i.e. accession to the EU). We believe that the accession to the EU serves as evidence for the state of the Hungarian economy. The main economic developments will be analyzed in the following three chapters. We will focus on the sequence of reforms first and foremost, following which we will examine the process of privatization. These two chapters will provide an in-depth insight into the key economic steps taken. Finally, in the last chapter, we will summarize the economic results during the aforementioned period. Specific subchapters will delve into an analysis of economic growth, the economy's structure, inflation, unemployment, and external relationships.",0
64,4,"During the paper's development, we faced challenges regarding data. Specifically, we encountered issues with the duration of consistent data series as identifying relevant and uniform data that spanned the entire transformation period was incredibly arduous. This compelled us to use abbreviated series. We believe that the data we utilized are the most optimal that were obtainable.",0
64,5,"The main focus of this text is on Hungary's development during the transformation process. However, to fully understand the country's history, it is important to examine its broader perspective. Hungary's long-term economic development can be traced back to the aftermath of the First World War, when the country lost a significant portion of its land to neighbouring states. This event had a profound impact on the Hungarian populace, and the government's primary objective during the interwar years was to reunite all Hungarians under a single state. To this end, Hungary allied itself with fascist Germany in the 1930s, a move that was deemed necessary to achieve their goal.",0
64,6,"The relaxation of political tensions increased over time and resulted in the emergence of an opposition in the mid-1980s. Negotiations were held at the round table in 1989, which brought about a constitutional change to ensure a transition to democracy, market economy, human rights, and the prohibition of a single-party government (even when the party has a parliamentary majority). This change was ratified on October 23, 1989, and marked the beginning of a new democratic era for Hungary. The country avoided pseudo-democracy or national unity government, and went straight to democratic elections in March 1990.",0
64,7,"Political changes had an immediate effect on the growth of the Hungarian economy, which had a centrally planned system implemented after the Second World War. Although the system had some unique features in comparison to other centrally planned systems in the region, the backbone of the system was similar. The Hungarian system was generally not as stringent as that of Czechoslovakia, but significant differences arose as reforms were introduced after 1968.",0
64,8,"Hungary incorporated value added tax into the tax system in 1988, making it the first country in Central Europe to do so. By 1989, 63% of all prices had been liberalized. The forint underwent continuous devaluations, decreasing from 45.8 to USD in 1986 to 63.2 in 1990 (Vintrová, 1992).",0
64,9,"According to Bethkenhagen (1989), the private sector accounted for 3% of the national product in 1970. By 1989, this had increased to over 25% (Holman, 2000), and two-thirds of Hungarians had secondary income from private activities while being employed by a state company or a cooperative. Although significantly higher than Czechoslovakia's figures, these numbers are still far from reflecting a fully developed market economy.",0
64,10,"In Hungary during the communist reign, the economy experienced fluctuations in growth that were more pronounced than in Czechoslovakia. Although strong growth was achieved in the 1950s, this declined in subsequent decades to very low growth during the 1980s. Economic reforms did not lead to an improvement in the trend of economic growth, but instead resulted in worsening economic results. A figure provided in the text clearly shows this general trend.",0
64,11,"In March/April of 1990, the first free elections occurred. A central-right post-communist government was established by Jozsef Antall (1932-1993), consisting of Christian and national parties. With a parliamentary majority of 60%, the government enjoyed a secure position. One of its successes was the departure of Soviet forces from Hungary in 1991. Additionally, an association agreement with the European Community was signed that year.",0
64,12,"In 1994, the MSZP, a left wing party with post-communist roots, won elections by a large margin. However, due to economic difficulties, they had to implement stringent measures. The following election in 1998 resulted in a right wing coalition led by Fidesz and Hungary entered NATO. Fidesz secured a victory in 2002 but was unable to form a government, which was instead formed by left wing parties.",0
64,13,"Hungary generally upheld democratic principles throughout the entire period and joined the European Union in 2004. However, there has been a persistent dissatisfaction with the country's transformation process and overall quality of life. A survey conducted in 2006 revealed the extent of this dissatisfaction, as shown in the table below. While there is no clear explanation for this attitude, it may be attributed to the high expectations of Hungarians in the late 1980s and their general satisfaction with the semi-capitalist system of goulash communism.",0
64,14,"The discussion of reforms in Hungary during the transformation period was similar to that in other countries. However, the fact that the communist party had started reforms before the regime's fall made Hungary unique. Hungarians believed that radical reforms were not necessary, as they could achieve the same results with slower reforms. However, some proponents of shock therapy did not trust the government's ability to establish a market economy. The first period of Hungarian transformation is often described as gradualist, but there are debates over its definition. Some Hungarian measures, such as the bankruptcy law, were considered extremely radical. The second subchapter focuses on reforms that occurred in the mid-1990s, while the third subchapter concentrates on the period after the turn of the century.",0
64,15,"The Hungarian economy experienced macroeconomic imbalances, as previously stated. Laki (1993) identified three main tasks of the Antall government which included maintaining the country's creditworthiness, reducing inflation, and addressing the growing public deficit. However, reducing the public deficit was the most challenging task as the fall of the communist regime led to a decline in state income while the government struggled to decrease expenditures. Additionally, the government took on the responsibility of late state companies that provided social services to the public, resulting in further spending increases (Allen, Hass, 2001).",0
64,16,"The Hungarian government proceeded with reforms in the business and financial sectors alongside improvements to the legal system, privatization efforts, and antitrust policies. However, the tough new bankruptcy code implemented in 1992 challenged the efficacy of Hungarian gradualism, leading to 5,000 subjects going bankrupt and around 500 large companies being transferred into private ownership. While this privatization method negatively impacted affected banks due to the growing number of classified credits, the Czech Republic's bankruptcy legislation remained weaker during the same period, with the first law approved in 1993 only and not applicable to companies awaiting privatization.",0
64,17,"The economic performance of Hungary during this period was negative. Despite the country's approach of implementing gradual reforms, it could not prevent a transformation recession. Hungary experienced a comparable or more severe decline than other Central European nations, leading to a high unemployment rate. Unlike other countries after price liberalization, inflation did not exhibit a dramatic spike but stayed consistently high. However, the foreign capital inflow was relatively high due to the previous liberalization that had made foreign investors familiar with investing in Hungary. Nevertheless, the country faced a current account deficit.",0
64,18,"The purpose of taking these actions was clear; the government sought to decrease deficits in public finance and the trade balance while increasing competition in the economy. The outcomes of these policies were harsh, with government spending decreasing by 10% of GDP, real wages declining by 12% in 1995 and 4% in 1996, and economic growth slowing to just 1% in both years. However, the trade deficit decreased between 1994 and 1996, while the government deficit (excluding privatization income) dropped from 8.4% to 3%. The average deficit was relatively high at 5.5% of GDP between 1990 and 2004, with the results being the worst among Central European countries. The following figure illustrates the overall development of public finance during the first decade.",0
64,19,"After the implementation of the Bokros package, the economic development was viewed positively. However, this period of prosperity only lasted for a brief period, and Hungary encountered various challenges at the beginning of the new century. The government's expenditures were blamed for creating fiscal issues, with public sector wages increasing by 12-13% in 2002. The public finance deficit grew, as illustrated in the previous chart. Additionally, trade deficits increased, reaching 6-8% of GDP due to a decline in competitiveness caused by the escalating wages and slowdown of the European economies. This information is according to Gabrisch and H?lscher (2006).",0
64,20,"The central bank responded to lasting inflation pressures by implementing a monetary restriction, which included widening the fluctuation band in May 2001. The summer of that year saw the introduction of inflation targeting and the currency became fully convertible. In October, the crawling peg was abandoned and the central parity of the forint was fixed. Although the central bank shifted its focus to inflation targeting, the central parity and fluctuation zone remained in place. This meant that the central bank attempted to control both inflation and exchange rates using interest rates, which was made more complex by the free movement of capital. Despite declining inflation and lower pressure on the nominal exchange rate, Hungarian authorities decided to fix the currency.",0
64,21,"Higher inflation, as discussed earlier, led to a rise in foreign currency indebtedness over the years. This was particularly concerning for households that frequently acquired mortgages in Swiss francs or euros. The following chart highlights the percentage and progression of this form of debt. The primary reason for this trend was the discrepancy between interest rates in Hungary and developed countries, along with the surging inflation rate. However, this borrowing practice only caused problems if the exchange rate remained constant or increased, which was a precarious situation.",0
64,22,"The high government deficits mentioned in Figure 2 did not result in growing government debt during the period, as shown in the chart below. However, the negative trends of indebtedness in foreign currencies and growing government debt led to severe problems for the Hungarian economy in the latter half of the 2000s.",0
64,23,"The central European countries were different at the start of their transformation process, with Hungary being more accepting of the role of state company managers compared to Czechoslovakia where they were seen as high-ranking communists. As a result, Hungarian managers were able to take control of numerous companies by the late 1980s, earning the term ""spontaneous privatization.""",0
64,24,"The public's attitude towards privatization was not clear cut according to the survey. Hungary had low support for restitutions (re-privatization) and relatively high resistance to privatization overall, which was one of the highest in Eastern Europe. However, the survey showed the highest support for selling companies for the highest price offered. Laki (1993) reported that in a survey from the middle of 1991, 34% of respondents were against privatization, but as many as 55-60% were against privatization of their own company. Additionally, there was strong opposition to foreign investment and returning land to previous owners.",0
64,25,"The transformation of state companies into joint-stock companies in Hungary was made possible by the 1988 act. This significant event gave the management the power to control the companies. At the beginning of the following decade, the insiders continued to play a crucial role in the Hungarian privatization. Earle and Estrin (1996) noted that the government was unable to sell or keep full ownership of a company without the consent of insiders. Unfortunately, this important role played by the management was accompanied by scandals and embezzlement, which resulted in the public turning against the privatization process. This hindered the entire privatization process and led to a slowdown (Srholec, 2001).",0
64,26,"In 1990, the state Property Fund (SPA) was established as a vital agency for privatization in Ukraine. It controlled almost 2,000 state-owned companies, primarily in industry and agriculture. As per Earle and Estrin (1996), SPA was critical in avoiding more significant abuse of the situation because it had the authority to approve all sales. This led to the establishment of an institutional environment.",0
64,27,"In the meantime, the government initiated the small privatization process. The first undertaking, called pre-privatization, commenced in May 1990 and was focused on retail with the aim of halting impulsive privatization. Between 1991 and 1993, roughly 10,000 units were either sold or leased, predominantly being small shops and restaurants that were auctioned. A crucial aspect of this type of privatization was that the employees of the respective shops gained the majority of the property. The ensuing table outlines the changes in property ownership.",0
64,28,"Until mid-1995, SPA sold 75% of its ownership, which represented only 35% of state property. The government still owned certain industries like gas distribution, railways, airlines, telecommunication, banks, and chemical companies. However, this changed when the Bokros package was implemented. The government needed to reduce fiscal deficits urgently, and, therefore, decided to sell all the state-owned property except railways, post office, and national parks. The allocation for privatization was around HUF 1.3 trillion, out of the overall state ownership of HUF 1.6 trillion. The privatization process included direct sales to foreign investors, which resulted in a huge flow of foreign direct investment in Hungary. The government sold properties worth HUF 790 billion, and the debt decreased from 86% of GDP in 1995 to 60% in 1998.",0
64,29,"The figure demonstrates the economic growth observed in Hungary. Comparable to other central European nations, Hungary underwent a transformational recession. Its gradualist approach to reform did not prevent the downturn, leading to a discernible deceleration following 1995. Despite this, the overall trend remains positive. A comparison of results yielded by the HP filter under communist and post-1990 conditions illustrate Hungary's capacity to achieve 3 to 4 percent growth following its transformational setback.",0
64,30,"Hungary experienced an increase in unemployment during the initial stages of transformation, despite adopting a more gradual approach. The rate reached a maximum of 12% and then gradually decreased. In contrast, the Czech Republic had minimal unemployment until 1997 when it grew due to currency and economic crises. However, by this time, Hungary's unemployment rate had already been steadily decreasing. It is important to note that both countries had relatively low unemployment rates compared to other post-communist countries such as Poland. However, there was a significant drop in employment levels in Hungary that impacted the figures.",0
65,1,"The current literacy tests on economics prioritize theory and neglect the actual economy. To address this, the researchers aim to evaluate how well students are learning empirical information. Economic literacy is a worthwhile objective and the existing teaching methods aim to foster an economic mindset, but the authors do not intend to criticize the present literacy campaigns. Rather, they seek to spark a discussion within the discipline about the importance of teaching students fundamental economic facts. The study involved administering surveys to hundreds of introductory economics students, and some initial insights about their capacity to comprehend basic facts have been tabulated.",0
65,2,"Objective economics provides learners with a factual understanding of their economy, enabling them to make informed decisions and normative assumptions about its direction. Instructors must play the dual role of presenting various economic models and providing basic information on economic variables. This study emphasizes the latter role, as students' ability to make informed economic decisions is greatly enhanced by factual knowledge of real economic variables. The selection of which models to teach is not addressed in this text.",0
65,3,"There has been some debate about whether defining literacy in this way is appropriate. In 2002, Hansen, Salemi, and Siegfried published a paper proposing ways to rearrange college courses to improve literacy at that level. They argue that current introductory courses, which place a heavy emphasis on technical literacy, do not benefit the majority of students who will never receive further economics training. Hansen, Salemi, and Siegfried cite a study in which college economics course-takers scored 9 on a 15-point survey, high school economics course-takers scored an 8, and those who took no economics scored a 7 (2002, 463). In their paper, they suggest revising the introductory series to allow for more focus on real-world problems and more opportunities to practice economics. (468).",0
65,4,"It appears reasonable to suggest that those who promote the idea of ""practicing economics"" have genuine intentions of enhancing student comprehension, but what precisely does this statement entail? Does it involve instructing pupils to think in terms of utility maximization? If so, does this imply that utility maximization is not inherent and, instead, necessitates education? Does it mean just presenting our learners with the most efficient models currently available and stopping there? As mentioned at the start, introducing students to these models is critical, but failing to provide them with a fundamental grasp of genuine economic variables can have negative consequences down the line. This would be like helping students create a car but neglecting to mention that fuel is necessary for the car to run. Given the persuasive potency of basic economic analysis, it seems reasonable that we have a duty to provide our pupils with the information from which these tools are derived, as well as teaching them how to apply this knowledge effectively to whichever models we teach.",0
65,5,Colleagues are currently conducting a project that aims to investigate the American public's knowledge of economic variables. The project is predicated on the notion that informing people with factual information is more effective than using abstract economic models that lack empirical evidence. This essay is a part of this ongoing project.,0
65,6,"The selection of facts that fall under the category of ""economics"" is crucial as it sets the boundaries of the subject. Consequently, fact-based economic education has lost its significance. While some macroeconomic topics such as GDP, inflation and unemployment are universally considered important, other economists might prioritize poverty, income distribution, and interest rates. Additionally, individual interests influence the emphasis given to different topics. Nonetheless, the pertinent matter is whether we are providing our students with precise empirical statistics and dependable information about major economic issues.",0
65,7,"The aim of the working group is to assess the level of comprehension of economic variables among individuals in the economy. Since it is an ongoing project, the procedures and techniques are expected to evolve as we progress. The group undertook a survey of 341 new introductory economics students using a set of questions that emphasized significant variables. We present some initial results that we consider could be valuable to the field.",0
65,8,"The working group members acknowledge that the wording of the question on GDP may cause confusion between GDP and GDP/person. They are working to improve the survey. Nevertheless, even with the faulty question, the current data shows that people can learn and remember figures such as GDP/person, as evidenced by students who received instruction from the working group instructors and answered accurately.",0
65,9,"We conducted a survey to assess the students' level of knowledge about income distributions in the US. The survey included questions on the income required to be among the top 5% and 20% of earners in 2007, which turned out to be approximately $166,000 and $87,000 respectively. The results were presented in Figure 1 and Figure 2, indicating the percentage of students who answered within a specific income range.""",0
65,10,"The students on average believed that an income of $20,056,314 was needed to be in the top 5% and $887,906 to be in the top 20%. However, 80% overestimated the income needed for the top 5% and 70% overestimated the income needed for the top 20%. More than half of the respondents, 56% for the top 5% and 35% for the top 20%, provided an answer that was at least double the actual number. This indicates that many students have a skewed perception of income distribution in the US. These findings may explain why some politicians are able to claim that raising taxes on households earning over $250,000 would affect middle-income earners.",0
65,11,"Based on the respondents' formal training, we can analyze their responses and obtain interesting results. The data suggests that those with more formal training provide more accurate responses for the 20% level. However, for the 5% level, there seems to be no difference between individuals with ""no high school"" and ""college"" backgrounds (refer to Table 1). In fact, the study indicates that high school classes have a negative impact on understanding. It's worth noting that although the instructor's past students performed remarkably well, their average responses were still far from the actual numbers.",0
66,1,"This study examines the connection between economic freedom, foreign direct investment (FDI), and economic growth in a group of 85 countries. The study employs the generalized method-of-moment system estimator to arrive at the empirical findings which demonstrate that FDI does not have an independent (positive) influence on output growth. Rather, the impact of FDI is determined by the level of economic freedom in the receiving nations. This implies that countries that endorse greater economic activity freedom benefit considerably from the presence of multinational corporations (MNCs).",0
66,2,"The relationship between foreign direct investment (FDI) and economic growth has been extensively discussed in the economic literature. Policymakers have increasingly focused on attracting more FDI inflows in recent years, coinciding with the lifting of many restrictions on foreign capital flows by countries, including developing ones, since the early 1980s. As a result, global FDI inflows have significantly increased over the past few decades, with the growth rate exceeding that of both world trade and GDP. The positive effects of FDI, such as productivity gains, technological transfers, introduction of new processes and management techniques, employee training, and international production networks, have led to heightened interest in attracting FDI. Furthermore, FDI is considered less volatile than other forms of capital and thus less destructive.",0
66,3,"This research paper looks to deepen the understanding of the connection between foreign direct investment (FDI) and economic growth by taking into account the role of institutions. Recent literature has brought attention to the importance of economic freedom in facilitating FDI spillovers, which refers to how multinational corporations transfer knowledge and technology to host countries. The lack of economic freedom can hinder a nation's ability to assimilate this new knowledge and technology, which can subsequently impede economic growth. Although previous studies have also highlighted the importance of economic freedom, they have mainly focused on its direct impact on economic growth. Therefore, this article contributes to the existing literature by examining the role of economic freedom in creating wealth.",0
66,4,"In this paper, we examine the potential correlation between economic freedom and growth by utilizing the index of economic freedom (EF) provided by the Fraser Institute. This index is a measure of institutional quality that grants insight into the factors of an atmosphere conducive to prosperity. Looking at the index components, we expect that countries with higher levels of EF will have superior absorptive capacity, allowing them to reap the benefits of FDI spillovers. Less regulation is generally agreed upon by the profession as good for economic advancement. A free and competitive market presents more opportunities for entrepreneurs to pursue new ideas and incentivizes firms to take on risky ventures such as FDI-related activities for high investment returns. Conversely, a heavily regulated market will not function efficiently, leading to inadequate allocation of resources. If financial markets are extensively regulated, activities related to FDI will be impacted as firms need external funding to finance the adoption of new technology. (Alfaro et al., 2004)",0
66,5,"The reason behind providing tax incentives and subsidies, as well as adopting policies that encourage Foreign Direct Investment (FDI), is due to the belief that FDI will bring significant benefits to the receiving countries. Multinational Corporations (MNCs) are associated with advanced technologies, patents, trade secrets, brand names, management techniques, and marketing strategies, as well as being renowned for their significant R&D expenditure. Additionally, they hire a considerable number of technical and professional employees. FDIs provide instant access to innovative technology that can benefit not only those receiving the foreign capital but also other businesses in the host country, similar to domestic investments. FDIs may also assist in rectifying the balance-of-payment deficits, increase job opportunities, and provide crucial training for managers and workers. Furthermore, export-oriented FDIs might promote exports by establishing assembling plants and supporting local businesses in accessing foreign markets for exports.",0
66,6,"The necessity of skilled labour to handle new technologies has been debated, and Borensztein et al. discovered that FDI inflows had a minor effect on growth. However, in countries where the human capital surpassed a certain threshold, it positively contributed to growth when interacted with FDI. In contrast, the same interaction effect was not significant for domestic investment, which could reflect the technological distinctions between FDI and domestic investment. This proposes that developed countries, with higher human capital, are more likely to benefit from FDIs. Xu's study supported this standpoint, finding that technology transfer by MNCs from the U.S. contributed to productivity growth in developed countries but not developing countries. However, Alfaro et al. disagreed with this notion, stating that human capital did not mediate FDI inflows. Instead, they suggested that the financial sector's development was more important than human capital for FDI spillovers.",0
66,7,"Although the evidence regarding the relationship between FDI and growth is inconclusive, the evidence supporting the role of institutions in the development process is more persuasive. According to North (1990), who is well-known as an economic institutionalist, institutions are the limitations or guidelines created by humans that establish political, economic, and social interactions. Essential components of these institutions include formal rules such as constitutions, property rights maintained through the legal system and law enforcement, as well as informal constraints (e.g. tradition, cultural norms, behaviors, and customs). The structure of these institutions, he notes, establishes the motivation for an economy. As the structure develops, it directs economic evolution towards growth. In essence, institutions affect the investment security, corruption rates, skewed or extractive policies, and ultimately, are influential on the urge to invest in the human and physical capital, which contributes to economic growth.",0
66,8,"Institutions play a vital role in economic development, as affirmed by several recent studies. Knack and Keefer introduced the use of property right security indicators as proxies for institutional quality in growth literature, with indices such as ICRG and BERI. These markers include the quality of bureaucracy, property rights, and political stability. Cross-country analyses reveal a strong, positive correlation between these factors and economic performance. Barro adds that secure property rights encourage investments and increase investment productivity, thereby enhancing growth. Furthermore, Demetriades and Law suggest that strong institutions have more impact on output per capita in low-income nations compared to financial developments. Rodrik et al. show that the quality of institutions is more important than geography and integration for explaining cross-country income differentials. Finally, Acemoglu et al. measure the efficacy of current institutions using the ICRG's protection from expropriation risk index.",0
66,9,"empirical research on the relationship between FDI and growth is limited, particularly in terms of the impact of economic freedom on FDI spillovers. It is suggested that countries with more economic freedom benefit more from the presence of MNCs, but there is no concrete evidence to support this claim. Further empirical evidence is needed to advance the literature on FDI and growth.",0
66,10,"The use of GMM estimators can be in one- and two-step variants, with the latter being more efficient in large samples but problematic in small ones due to instrument proliferation. Windmeijer's simulation analysis shows that the two-step GMM estimator with numerous instruments can result in biased standard errors and parameter estimates, while Bowsher notes that numerous instruments may weaken the overidentification test. To address these issues, Roodman suggests reducing the dimensionality of the instrumental variable matrix.",0
66,11,"The empirical findings using three different approaches discussed in Section 5 are presented in this section. Tables 1-5 report the empirical results. Table 1 reports a preliminary analysis on the effects of FDI and EF on growth. Table 2 presents coefficient estimates obtained from the baseline specification, which used an interaction term constructed as a product of FDI and EF index. Table 3 reports the coefficients estimate from a specification that uses dummies to capture the contingency impact of FDI on growth at different levels of EF. Table 4 displays the estimated coefficient obtained using sample splitting under which linear growth-FDI relationships are estimated using two different subsamples. Finally, the results on the interaction specification using the components of EF index are displayed in Table 5. The objective is to indicate whether the component of the EF index yields qualitatively similar results to that of the aggregate index.",0
66,12,"""Several studies have explored the relationship between FDI and economic growth, but their findings are inconsistent. In newer research, it seems that the recipient nations' absorptive ability is the primary factor contributing to this uncertainty. This study aims to investigate a new component of absorptive capacity, EF, which looks at whether the degree of economic activity freedom in host nations influences the marginal impact of FDI on growth.""",0
66,13,"Using panel data from 85 countries over the period 1975-2004, our empirical analysis draws three important conclusions. Firstly, FDI alone has no direct impact on output growth, which supports previous studies. Secondly, EF is identified as an important driver for countries' long-term growth, and this finding is consistent with prior research. Finally, the impact of FDI on growth is determined by the level of EF in the country. Our study shows that countries promoting economic freedom benefit significantly from MNCs' presence as firms can more easily absorb and adopt new technology and other benefits associated with FDI inflows. This finding suggests that EF is a crucial element of a nation's absorptive capacity, which has been somewhat neglected in earlier research.",0
66,14,"Cross-border exchange of goods and services can benefit domestic companies and their ability to sell products in international markets. Exporting involves expenses such as building distribution networks, transportation systems, and an understanding of overseas consumer preferences, which multinational corporations (MNCs) are often better equipped to handle. Domestic companies can reduce their costs by emulating or collaborating with foreign firms that are already exporting. These benefits can lead to greater operational efficiency for domestic companies. International trade also provides domestic companies with access to more diverse intermediate goods and capital equipment, which can increase productivity.",0
66,15,"Reducing regulatory constraints such as labor, business, and credit is crucial for encouraging spillovers in FDI. For instance, relaxed regulations on the hiring and firing of workers in the host country can lead to increased labor mobility, with workers from MNCs transferring their knowledge and technological expertise to domestic firms. The level of regulatory restrictions on business operations can also impact FDI spillovers by affecting market competition. If the industry is highly competitive due to fewer regulations, MNCs may be more willing to share their technology with domestic suppliers in order to secure intermediate goods at competitive prices. Access to external funds is also crucial for technology upgrading, and reducing regulatory constraints can enhance the success of domestic firms in acquiring new technology. This was documented by Alfaro et al. (2004).",0
66,16,"Policymakers need to balance the cost-effectiveness of policies aimed at attracting FDI versus those focused on improving EF. It is advisable to prioritize policies that enhance economic freedom since they are likely to produce greater benefits in the long run. Countries that fail to adopt these strategies will fall behind in the global competition. Policymakers should establish easy-to-understand policies for potential investors before turning to other incentives to attract investment. Nonetheless, implementing these reforms can be a daunting task that requires a strong commitment in the long term. While political resistance may arise in certain countries in the short term, the eventual economic benefits could be considerable.",0
66,17,"Despite the significant findings, it is important to note some limitations. Our main specification's interaction term forces FDI's impact on growth to increase or decrease monotonically with the level of EF. However, it is possible that a certain level of EF is necessary before FDI can affect host countries. Only countries with high absorptive capacity are likely to benefit from foreign capital, while countries with low absorptive capacity experience less or no benefits from FDI. This implies the need for a more adaptable specification that can account for different types of interactions between FDI, output growth, and economic freedom. A possible solution is to use a regression model based on threshold effects to capture the presence of contingency effects. We will further explore this in future research.",0
1,1,"According to previous studies, the age at which someone first has sex may influence their life history strategy (LH), and this could be due to experiences and cues during early development. This study looked at whether the experience of sexual debut itself could continue to influence LH strategy throughout adolescence, and found that women who had their first sexual experience between ages 14-18 showed a faster LH speed compared to those who did not. However, this effect weakened by age 23, suggesting that LH-related behaviors can change over time. While other factors may also play a role, the timing of sexual debut may impact LH trajectory and could be further explored in future studies.",0
1,2,"LH theory was developed to explain how organisms' reproductive strategies change under environmental constraints. When constraints are loose, organisms tend to have rapid or quantity reproductive strategies, while they adopt more restrained quality reproductive strategies as constraints tighten. This theory applies to various species, including humans, where individual differences in LH strategy covary with factors such as maturation rate, sexual debut, and parental investment. Faster LH strategies involve earlier maturation and sexual debut, more frequent sexual intercourse with less stable pair bonds, and reduced parental investment, while slower LH strategies involve later maturation and sexual debut, lower frequency of sexual intercourse with more stable pair bonds, and increased parental investment.",0
1,3,"The earliest models of LH strategy development emphasized the role of childhood experiences in shaping LH-relevant environmental factors across human ancestral environments. Belsky et al. (1991) suggested that the quality of parental attachment in childhood determines whether an individual will be inclined towards a fast or slow LH strategy. Early secure attachment leads to a slow LH strategy focused on delayed maturation and sexual debut, while insecure attachment leads to a fast LH strategy characterized by early maturation, unstable pair bonds, and low parental investment in offspring. Belsky et al. (1991) emphasized that early childhood experiences, particularly within the first 5-7 years of life, play a critical role in determining an individual's developmental trajectory towards a fast or slow LH strategy.",0
1,4,"Our theory suggests that one of the main purposes of early life experiences during the first 5-7 years is to teach children about the consistency and reliability of resources available in the environment, the trustworthiness of other people, and the importance of strong interpersonal relationships. Understanding these concepts will impact how individuals distribute their reproductive efforts.",0
1,5,"The idea that LH strategy is set and unchangeable by a certain age may not be entirely accurate. While there is evidence of heritability in LH strategy, further research suggests that environmental and somatic cues can also influence LH strategy and that plasticity in LH strategies may persist beyond the first decade of life. However, it is still a debated issue whether early experiences are more important than late experiences in shaping LH strategy. Some studies indicate that environmental predictability in the first five years of life can have a significant impact on LH strategy later in life, while experiences in later childhood and adolescence may not have the same effect.",0
1,6,"The theory proposed by Del Giudice in 2009 outlines the impact of factors beyond the age of seven on LH strategies. Early adolescence, specifically adrenarche, is suggested to be an additional switch point that affects the development of LH strategies. This idea has been further extended by Ellis et al. and Del Giudice and Belsky, suggesting the period of cue-based plasticity extends through puberty and into later adolescence. Dunkel et al. found evidence supporting the idea that LH strategies may continue to be adjusted throughout development, even beyond the age of 5 to 7, and that maternal authoritative parenting during adolescence predicts later LH strategy.",0
1,7,"The authors of the current investigation are looking at how LH strategy in adolescence continues to evolve through plasticity. They decided to study the age of sexual debut as a potential factor in the development of LH strategies during adolescence. While sexual debut has been used mostly as a dependent variable, it may also serve as an LH cue that can impact LH speed. A study by Vigil et al. (2005) found that childhood sexual abuse can accelerate LH speed, potentially because the act of intercourse itself plays a role in LH development. Women who were victims of childhood sexual abuse also had earlier menarche, earlier first intercourse, and earlier first childbirth.",0
1,8,"The main idea of the study is that starting sexual activities speeds up the LH (life history) strategy. The hypothesis is that this response is due to internal cues associated with the experience of having sex, which were functional and relevant for reproductive success in the past. The study suggests that internal cues may be more reliable predictors than external cues from the environment. Consequently, the loss of virginity may trigger a shift in investment from growth towards increased reproductive effort, promoting the acceleration of LH speed.",0
1,9,"The costs of losing virginity are higher for females than males and this tradeoff between growth and reproduction is more noticeable for ancestral women. Therefore, we predict that the start of sexual activity will affect LH (life history) speed more in adolescent females than males. This prediction is based on data from a longitudinal study conducted by Block and Block (2006a), which includes information on LH strategy and timing of sexual debut.",0
1,10,"The Block and Block study, conducted over a 30-year period, involved multiple waves of data collection and testing. The files and documentation for the study were downloaded from the Henry A. Murray Research Archive. Participants were recruited from two preschools in Berkeley, CA, and demographic information was collected during the first wave of data collection, including sex, ethnicity, and socioeconomic status.",0
1,11,"The study analyzed data from three different waves of participants' lives, at ages 14, 18, and 23. The researchers were interested in how participants' LH strategy changed over time, so they used the age 14 data as a starting point. There were 106 participants at age 14, with slightly more females than males. The majority were White, with a small percentage of Black, Asian-American, and ""Other"" participants. Since there were very few non-Black minorities, these participants were grouped together with the White participants for analysis.",0
1,12,"The California Q-sort (CAQ) was used to measure the LH strategy by sorting a set of 100 items based on their description of an individual. A template was created by Sherman et al. to measure LH strategy using this method, which was later validated and modified by Dunkel et al. using the Block and Block data.",0
1,13,"Between the ages of 14, 18, and 23, trained raters used a personality test called the CAQ to rate each participant's personality. These ratings were then compared to a LH strategy template, and participants were given a score based on how closely their ratings matched the template. Higher scores indicate a slower LH strategy, with items like ""sympathetic/considerate"" reflecting slow LH speed and items like ""unable to delay gratification"" reflecting fast LH speed.",0
1,14,"At 18 years old, the participants were asked if they had engaged in sexual activity in the past three years. 42 participants said yes while 60 participants said no.",0
1,15,"The study included three demographic covariates: sex, ethnicity (classified as White and nonWhite due to limited sample size), and socioeconomic status (measured by Warner's Index of SES at age 4).",0
1,16,"The study included four additional variables besides demographic factors, including intelligence, parenting style of both mother and father, and the level of intimacy with the partner with whom the participants lost their virginity. Intelligence was measured at age 18 to control for the impact of cognitive ability on decision-making about sexual consent. Authoritative parenting was also included as a covariate as it affects the development of LH strategies during adolescence. Finally, the level of intimacy with the partner was measured to explore its impact on the effect of losing one's virginity.",0
1,17,"The article presents data in Table 1 showing mean and standard deviation of LH scores by age, sex, and sexual debut. The LH scores increase after age 14, indicating normative development from adolescence to adulthood. Males exhibit a faster LH strategy at all ages. A repeated measures ANOVA confirms the within-subjects effect of age and the between-subjects effect of participant sex. The interaction between variables is not significant. Correlations between sexual debut and LH strategy at the three focal ages vary.",0
1,18,The study aimed to investigate if early sexual debut accelerates LH speed and if it affects females more than males. The researchers used partial correlation to examine the relationship between sexual debut and LH strategy at ages 18 and 23 while controlling for the variance in both variables. Partial correlation was chosen as it was a more suitable method than repeated measures ANOVA or regression in testing the hypothesis.,0
1,19,"The study first adjusted the partial correlations for LH speed at age 14 and then added additional covariates one by one such as SES, ethnicity, IQ, maternal and paternal authoritative parenting, and intimacy level with partner. The results were recorded in Table 2. It was found that when only controlling for LH strategy at age 14, there was a correlation between LH strategy at age 18 and sexual debut, but not at age 23. Moreover, the association between sexual debut and LH strategy at age 18 changed as more covariates were added.",0
1,20,"The analysis revealed that when looking at females specifically, the relationship between sexual debut and LH strategy remained consistent at age 18 and appeared to strengthen as additional factors were considered at age 23. Researchers also computed change scores to assess the impact of sexual debut on LH speed over time. Results showed that those who had sexual intercourse during adolescence experienced slower LH speed compared to those who did not, but statistical power was limited in between-subjects change score comparisons. These findings helped to interpret the significant correlations observed in the study.",0
1,21,"Recent research has suggested that plasticity in the development of life history strategies continues beyond early childhood. Studies have hypothesized that the timing of sexual debut can affect the development of LH strategies, specifically accelerating LH speed during adolescence. It was also theorized that females may be more impacted by this effect. To test these hypotheses, the connection between sexual debut and LH strategy at ages 14, 18, and 23 was investigated.",0
1,22,"The research results present multiple options. The study found that for females, having their first sexual experience could impact the trajectory of their LH strategy. When controlling for various factors and LH strategy in early adolescence, girls who had sex during their teenage years had a faster LH speed in late adolescence and young adulthood. These findings are interconnected with the raw LH score's developmental changes over time, where the score increases with age. Furthermore, those who did not engage in intercourse during adolescence showed a smaller increase in LH scores compared to their counterparts who did have sex.",0
1,23,"The idea that sexual debut prompts women's engagement in risky tactics of intrasexual competition and/or mate attraction in line with a fast LH strategy, which depends on an individual's degree of investment in mating effort. Sexual intercourse would have served as a cue for progressing into a LH stage, during which acquiring reproductive benefits would have become a crucial adaptive problem. However, it is unclear whether virginity loss results in a longer-lasting developmental shift toward a fast LH speed that persists into adulthood. Women's sexual debut between 14 and 18 initiates a temporary shift toward investment in mating effort, subject to further recalibration as developmental events unfold. Further life stage-linked shifts in LH after age 18 are expected to weaken the association of events in early adolescence with later outcomes.",0
1,24,The study suggests that LH variation is regulated by early and later cues during development. Biometric measures have previously been used to indicate different LH strategies in individuals. Correlational findings support the idea that sexual debut may influence LH speed and investment in mating effort. The timing of sexual debut and LH development in adolescence appear to be connected.,0
1,25,"Nonetheless, there are certain restraints that must be acknowledged. While several factors were taken into account, the role of genetics in both the timing of sexual initiation and LH strategy cannot be completely ruled out. Additionally, considering that LH strategy at 14 years was one of the controls, genetic factors must look beyond fundamental additive models, and additive impacts seem to account for most of the heredity in psychological traits. Another limitation is that the influence of sexual debut on LH strategy velocity tends to fade away as individuals progress into adulthood. Therefore, future research is essential to explore the associations between biometric and psychosocial events and the evolution of LH strategy from adolescence to later adulthood.",0
1,26,"The Henry A. Murray Research Archive, located at Harvard University's Institute for Quantitative Social Science, made this project possible. The data used in this study came from a 30-year longitudinal study conducted by Jack and Jeanne H. Block, which involved assessing the personality and cognitive life of 128 3-year-old boys and girls through nine assessments that consisted of different measures such as observational, test, and self-report measures.",0
2,1,"The latest technology for recording pigeons' pecking behavior are contact switches and touch screens. However, other behaviors require different sensors, and some behaviors are difficult to record. To address this issue, a novel image-based approach that utilizes Microsoft's Kinect sensor is presented. This approach can detect and count other pigeon behaviors besides pecking, such as feeding activity. The system, called BehaviorWatch, was tested on five pigeons and showed reliable results. Consequently, BehaviorWatch could be an excellent solution to record multiple behaviors in pigeons.",0
2,2,"Documenting the pecking behavior of pigeons by using a pigeon key that is connected to a contact switch is a typical method for studying animal behavior and learning. This method only documents whether a peck happened or not at a particular moment and place. Nowadays, touch-sensitive screens that provide more precise information about the location of the peck are frequently employed. Additional information could be obtained if a video were used, including:'.",0
2,3,"The relevant factors during pecking, such as when it starts, how fast it moves, head position during and after, pecking behavior towards the key, and attempted pecks. Additionally, the overall body and head posture, including head, body, and feet positions. Lastly, the subject's behavior in response to stimuli, such as turning and flapping wings.",0
2,4,"The sensing technology used is noncontact and reduces the occurrence of mechanical wear. This allows for sensing to be done at different locations without the need for specific instrumentation, thus allowing for flexible experimental design. Touch screens are an alternative, but they may not be able to prevent visible damage to the screen or other forms of wear. There are also additional costs associated with touch screens, and software for learning experiments is not readily available. Aside from all this, both touch screens and pigeon keys can only detect certain behaviors, limiting the scope of studies to pecks and other behaviors, like treadle pressing, head bobbing, and so on. Other forms of naturally occurring behaviors are challenging to study.",0
2,5,"The use of a standard video camera for automated behavior counting is complicated due to loss of depth information of objects in the scene. The intensity of each pixel in the image is created by light arriving along a single ray, making it difficult to determine the distance at which the object rests. To address this issue, a carefully calibrated camera with precise extrinsic and intrinsic parameters should be used. However, loose animal hair or dirt may affect the calibration, thus requiring frequent repetition.",0
2,6,"Despite the challenges of using image analysis to track animal movements, there have been some successful attempts at automating video information extraction from a camera. For instance, image recognition criteria have been used to monitor pigeon behaviors like courtship, while image analysis has been utilized to classify avian observations according to species. However, computer vision packages like the Sensory Orientation Software (SOS) have been found to be sensitive to disturbances of camera pose during measurements. Recently, a more affordable and versatile solution has been developed in the form of the Kinect, a camera and distance sensor that generates both visual and depth images by registering pixel coordinates from both images.",0
2,7,"An image can be represented by a map of its intensity called I, where I(u,v) represents the intensity at row u and column v. The depth image retrieved using the IR range sensor can be represented by a map called D, where D(u,v) shows the distance between the object responsible for the intensity reading I(u, v) and the sensor. Using the camera focal length, x and y coordinates can be projected from u and v scene coordinates and z = D(u, v) to develop a point cloud. The Kinect sensor, widely used in the consumer video gaming market, is cheap and widespread, and has software support from both Microsoft and Open source communities. The sensor is designed for indoor unstructured settings and can be easily mounted to an experimental enclosure. It includes software that allows the generation and tracking of human body features using a skeletal model. Such models have been a topic of research for some time, and extracting them from distance sensors like the Kinect has been described in a number of studies.",0
2,8,"The article discusses a flexible method to use the Kinect for Windows sensor to extract 3-D body information of a pigeon viewed within an experimental enclosure. The method is embodied in a program called BehaviorWatch, which uses a simple skeletal model to represent key body locations. The approach is capable of estimating pecking behavior and identifying ""treadle pressing"" or ""head bobbing."" The results of the approach were compared with a standard contact-switch-based approach and showed similar measurements for pecking. Additionally, feeding behavior can be detected with close timing when the signal is sent to provide a food reward.",0
2,9,"The evidence shows that mealtimes can be stressful for patients with Anorexia Nervosa. These patients often experience fear and anxiety when eating and gaining weight. They may feel psychologically and physically uncomfortable after meals, and may be preoccupied with thoughts of purging or guilt. To alleviate this distress, support from staff or family during mealtimes is important. In-patient staff typically facilitate supported mealtimes, but there is little research into effective interventions for reducing meal-related anxiety in a hospital setting.",0
2,10,"Participation in music therapy has been shown to enhance the overall life quality, interpersonal relationships, and social skills of individuals with mental illnesses. It enables patients to improve their self-determination and fosters collaboration with their caregivers by focusing on their strengths and resource-oriented approach. Research also supports the effectiveness of music therapy in mental health recovery and patient-led processes that promote empowerment and self-efficacy. Inpatient mental healthcare settings may provide little opportunity for self-determination, which makes music therapy an essential tool for promoting feelings of empowerment and equality.",0
2,11,"The use of music therapy has been found to provide positive effects on recovery from eating disorders. It can help with distraction from negative thoughts and feelings, boost motivation, encourage creative expression, and provide a sense of empowerment. Patient experiences have also shown increased self-confidence and engagement through participation in music therapy. Although there is limited research on the role of music therapy during meal times, a study aims to evaluate the potential benefits of post-meal music therapy among inpatients with AN.",0
2,12,"The research was conducted in a specialized inpatient eating disorder program consisting of five beds within a psychiatric unit. This program is mostly for adults with severe anorexia nervosa who have not been successful in outpatient treatment. The average age of patients admitted to the program is 22 years old, predominantly young women. The approach used is patient-centered and focuses on individualized treatment utilizing collaborative conceptualisation-based therapy. The treatment also includes a supported mealtime with post-meal distress tolerance and support provided by team members every lunchtime.",0
2,13,"The aim of the study was to assess the effectiveness of post-meal music therapy for inpatients with AN by gathering both quantitative and qualitative data. The study involved using a mixed method approach, where participants were asked to self-report on their experiences and their levels of distress during post-meal support. The authors chose to focus on the quantitative component of the study, which involved comparing the effectiveness of music therapy with standard treatment following mealtime. This design was viewed as a fitting way to evaluate an existing music therapy program and gather initial indicators of its effectiveness, while also testing the feasibility of conducting a larger-scale study.",0
2,14,"The researchers gathered quantitative data using a scale called Subjective Units of Distress (SUDS). The participants underwent the intervention twice a week, and their progress was recorded before and after each session. They continued with their usual ward program for the rest of the week. The project was approved by the Human Research Ethics Committee at Austin Health.",0
2,15,"Adults who were admitted to the eating disorders program at the Mental Health Clinical Service Unit of Austin Health were asked to take part in the study. The main researcher, Bibb, provided patients with a statement and consent form when they were admitted to the hospital. A total of 18 patients consented to participate in the study out of 32. Throughout the study, 89 intervention sessions and 84 control sessions were recorded.",0
2,16,"The researchers taught the participants how to use the Subjective Units of Distress Scale (SUDS), which is a tool used to measure how anxious or distressed someone is feeling. Participants rated their anxiety on a scale from 0 to 10, with 0 indicating a complete absence of anxiety and 10 indicating the highest level of distress ever experienced. A 'feelings thermometer' was used to visually represent these ratings.",0
2,17,"The study involved weekly music therapy group sessions lasting for an hour each, held after lunch. A qualified music therapist facilitated the sessions where participants were encouraged to sing, listen to and share music, and even compose songs together. The group aimed at providing a distraction and an opportunity for participants to practice coping skills using music. A humanistic approach was followed whereby participants collaborated instead of a directive approach used in cognitive behavioral therapy groups. The therapist maintained an attitude of unconditional positive regard, and members were encouraged to discuss song lyrics and eating disorder recovery-related topics.",0
2,18,"The control group received structured post-meal support therapy, which involved a one-hour group session after meals three times a week. The sessions focused on discussing feelings, achieving admission goals, and participating in group activities like games and art. Nursing and allied health staff took turns facilitating the therapy.",0
2,19,The data was analyzed using the statistical software SPSS. The pre and post scores were compared in both the intervention and control groups to determine the mean differences and standard deviation. An unpaired t-test was used to compare the differences between the music therapy and control interventions.,0
2,20,"The study included 18 patients, with the majority being females. Their ages varied from 20 to 58 years old, and the length of their hospital stay varied from 21 to 90 days. The participants attended a total of 173 sessions between the music therapy and control conditions. Results showed that the mean pre-test and post-test scores for the intervention group were 8 and 5.6 respectively, with a pre-post test difference of 2.4 integers and a standard deviation of 1.9 integers. The control group's mean pre-test and post-test scores were 8.1 and 7.1 respectively, with a pre-post test difference of 0.93 integers and a standard deviation of 1.7 integers. These results are summarized in Table 1.",0
2,21,"The study found a significant difference between the control and intervention conditions with an ANOVA score of f=28.5 and a p-value of <0.0001. The average anxiety scores were higher among all participants in the pre-test (mean of 8.1) compared to the post-test (mean of 6.3) across 173 occasions. Furthermore, there was a statistically significant difference (p=<0.0001) between pre-test and post-test scores for all 173 occasions combined.",0
2,22,"The study aimed to compare the levels of distress and anxiety in patients with AN before and after group music therapy was provided after meals, as opposed to standard post-meal support therapy. The results showed strongly positive outcomes, indicating that music therapy can be helpful for AN inpatient care. Both groups experienced decreased anxiety after the music therapy sessions compared to before, which supports previous research indicating that meal-related distress and anxiety is a major concern for AN patients. Similarly, participants in both conditions reported reduced anxiety after therapist-facilitated support after meals, which is consistent with previous studies.",0
2,23,"The current study found that group music therapy is more successful in reducing meal-related anxiety than standard post-meal support therapy in an inpatient setting for eating disorder patients with an average age of 22. This could be due to the engaging and non-threatening nature of music therapy, which may act as a cognitive distraction for patients, allowing time for digestion while the mind is occupied with something enjoyable.",0
2,24,"The condition known as AN involves avoiding and controlling emotions, which can lead to feeling emotionally numb. Music therapy can be used as a distress tolerance technique, allowing patients to experience emotions through music instead of discussion. In this case, the musical process itself is the therapy, which could have wider implications for using music therapy as an alternative coping technique for patients who struggle with distressing emotions.",0
2,25,"The use of music therapy in inpatient meal support programs has been found to significantly decrease anxiety in participants with eating disorders. This is important because, while it was previously known that support after mealtime was helpful, the interventions that were effective in reducing anxiety during this time were unclear. Incorporating music therapy into these programs can give patients an alternative technique to cope with distress that they can use after discharge. This study is the first to use music therapy post meal-time and offers support for further research in this area.",0
2,26,"The study has positive implications for using music therapy to reduce meal-related anxiety in patients with AN. Limitations of the study include the research design, which was quasi-experimental, and the fact that participants were not randomized. Additionally, participants were recruited from only one site, which may limit the generalizability of the results. To improve future research in this area, larger numbers of participants should be involved and randomization to control and intervention conditions should be included. Recruitment from different hospital sites would also be beneficial.",0
3,1,"The study investigated how attentional focus and perceived hole size affect radial putting error in experienced golfers. The golfers were randomly assigned to either the Hole task or Club task after completing a putt and were tested under no pressure, pressure phase, and no pressure posttest. The results showed that golfers differed in their response to pressure, with some showing significant changes in kinematic variables and heart rate (Choke group) while others showed no changes (Clutch group). The Choke group had increased putting error and decreased accuracy on the Hole task, while the Clutch group had no significant changes in any of the variables. These results support the attentional accentuation hypothesis of action-specific effects.",0
3,2,"Recent studies have shown that skills which involve interacting with objects to achieve a goal can affect a person's perception of that object. For instance, individuals who perform better at hitting a ball tend to judge the ball as larger than those who perform poorly. Similarly, studies have found similar effects in golf, football, dart throwing, archery, and aviation. These findings suggest that perception is influenced by an individual's ability to interact effectively with goal objects in the environment, rather than being solely based on the object's physical properties. This is consistent with Gibson's theory that perception directly specifies the relationship between a person and their environment, rather than simply being based on the object itself.",0
3,3,"Despite the fact that research has shown action-specific effects on perception, the specific mechanisms behind these effects are not well understood. There are alternative explanations, such as those based on experimental demands and memory effects, but the present study focuses on attentional accentuation as another possibility. This hypothesis suggests that when someone intends to act on an object and directs their attention to it, that object becomes more noticeable, which has been supported by previous research on golfers perceiving changes in the size of a golf hole.",0
3,4,"The theory is further supported by research that investigated action-specific perception in situations with high levels of anxiety, where participants threw darts at a target and assessed its size. Under low anxiety conditions, target size and throwing performance had a positive correlation, but this was not the case with high anxiety conditions, where attention was drawn away from the target, consistent with distraction theory and self-monitoring.",0
3,5,"The aim of this study was to explore how attention affects perception in relation to performing certain actions, building on research previously done on anxiety and performance outcomes. Earlier research failed to produce direct evidence that changes in action-specific perception were caused by shifts in attentional focus. However, investigations into how attention affects movement and performance have found links between successful performance, attentional focus, and movement kinematics under pressure conditions, such as in a study on baseball batters.",0
3,6,"The act of focusing on a skill in golf putting can lead to an increase in putting error and changes in putting kinematics. These changes can include an increase in club-ball impact velocity, a decrease in the time to peak speed, and changes in downswing amplitude and putting distance. These changes are typically observed in novice golfers. However, previous studies have not examined how these kinematic changes relate to the perceived size of the target object. Additionally, no previous studies have directly manipulated attentional focus and measured the effect on perceived size, despite the links between attentional focus and perceived size inferred through fixation patterns.",0
3,7,"The purpose of this study was to examine the relationship between perceived size, performance outcomes, attentional focus, and movement kinematics in a golf putting task. The researchers measured each of these variables while participants performed the putting task under different pressure conditions. The study used a combination of competitive and evaluative pressures to induce performance pressure. The researchers also used an attentional probe method to determine whether participants were focusing on the hole or the movement of their club-head. Time to peak speed was measured as the primary kinematic measure, as it has been shown to be related to skill level and influenced by pressure in golf.",0
3,8,"The research included 25 participants consisting of 17 males and 8 females, all of whom were right-handed experienced golfers from the University of Birmingham's School of Sport, Exercise & Rehabilitation Science program. The participants' average age, mean handicap, and competitive playing experience were 20.1 (with a standard error of 0.4), 7.3 (with a standard error of 0.6) strokes, and 6.2 (with a standard error of 0.8) years, respectively. The Science, Technology, Mathematics and Engineering Ethical Review Committee at the University of Birmingham granted ethical approval for the study.",0
3,9,"The experiment used a right-handed putter, Wilson Ultra golf balls, and an artificial putting mat of specific dimensions. The task given to participants was to putt towards a red circle on the mat and stop the ball as close to the center of the circle as possible. The putts were made from a set distance and the position of the putter head was tracked using a sensor.",0
3,10,"The researchers used a method similar to one used in a previous study to estimate how big the participants perceived the hole to be. They asked them to draw a life-sized circle on a computer screen using PowerPoint and positioned the screen at the same distance as the putting distance. They also presented auditory stimuli using speakers placed at the end of the putting surface, 10 cm away from the hole, which had been determined in pilot experiments.",0
3,11,The heart rate was measured to indicate the activity of the sympathetic nervous system using a heart rate receiver unit connected to a transmitter with electrodes placed on the lower mid thorax. The average heart rate was then calculated during different phases.,0
3,12,"The researchers conducted an experiment that consisted of four phases which were practice, pretest, pressure, and posttest. Each phase was completed within a 1.5-hour session, and participants had 10-minute breaks between each phase. During all the test phases, the participants were shown the final position of the ball on the green.",0
3,13,"In this stage, the participants were given 20 opportunities to putt the ball normally without any additional task. The purpose of this phase was to help them get comfortable with the sensor attached to the back of the club and familiarize them with the putting exercise. They didn't have to estimate the size of the hole during this phase. After every putt, the experimenter measured the distance between the center of the target and the ball's final position in centimeters.",0
3,14,The researchers used data from practice trials to determine the timing of participants' putting strokes. This information was later used to control one of the secondary tasks. The researchers determined the start and back stroke times for each putting stroke and calculated the mean values for each participant.,0
3,15,"The participants were first explained about the hole size estimation task in this phase and were given practice sessions five times without hitting the ball. Then, they were introduced to two secondary tasks, where auditory cues were presented in the form of pure tones with a frequency of 500Hz and duration of 150ms via one of the two speakers placed on either side of the hole. These two tasks were modelled after Beilock and Gray (2012) and were performed by the participants by detecting the tone during their backswing. The data from those trials were discarded where the tone was not presented in the appropriate interval, and the trial was re-run.",0
3,16,The participants were asked to decide if the tone they heard was coming from the left or right speaker or from the hole by making a forced choice. They had to say "Bleft" or "Bright" after they hit the putt.,0
3,17,"The club task involved participants making a decision regarding where the tone occurred during their backswing by saying ""Bstart"" or ""Bend"", indicating if it was near the start or end. This task was chosen because previous studies have shown that this phase of the putting stroke is particularly sensitive to attentional manipulations and golfers can perform well in this capacity.",0
3,18,"Participants were asked to complete 30 putts after finishing all the practice trials. For each putt, they hit the ball and saw where it landed, then estimated the hole size. After each attempt, they were given instructions on what secondary task response to provide by a researcher. The putts were broken down into 12 with the Hole Task prompt, 12 with the Club Task prompt, and 6 with no prompt. The order and speaker side for each task were randomized. There was no feedback given to participants during the experiment.",0
3,19,"The researchers wanted to ensure that the secondary task did not affect the estimate of hole size, so they had participants complete it after making the estimate. Some trials did not involve a secondary task to measure where participants were focusing their attention. The participants did not know which task they would have to perform, so there was no bias in their attentional focus. These tasks were selected to compare with previous research, and their interaction with the hole size estimation task is discussed later.",0
3,20,"The pressure phase was the same as the pretest phase, but the participants were given additional instructions to make them feel more competitive and evaluated. They were told these instructions before starting to putt, and they had to read a script explaining the changes.",0
3,21,"The next stage of the activity is a competition where the aim is still to putt the ball as close to the marker as possible, but you will lose 10 points for every putt that finishes more than 5 cm from the marker. The prize money of ?50, ?25, and ?10 is available for the top three places. Your position on the leaderboard will depend on the number of points you accumulate. The results will be sent to all participants via email and displayed on the school's notice board, so everyone will know how others performed. The speaker jokingly mentions that there is no pressure, but good luck.",0
3,22,"The method being used is the same as the one used in a previous study on how pressure affects golf performance, and it has shown to have notable effects.",0
3,23,"To evaluate the intensity of cognitive and somatic anxiety among participants, the Immediate Anxiety Measures Scale (IAMS) was used. The two-item questionnaire asked participants to rate their levels of cognitive anxiety and somatic anxiety on a 7-point scale ranging from not at all to extremely. The scale was completed at the conclusion of each phase of the experiment.",0
3,24,"The researchers performed a manipulation check in order to see if their pressure manipulation had the intended impact. They analyzed cognitive and somatic anxiety ratings, as well as heart rate data, using a one-way repeated measures ANOVA, with pretest, pressure, and posttest phases as the independent variable.",0
3,25,"The researchers analyzed four dependent variables which included the mean radial error, mean perceived hole size, percentage correct for the Hole secondary task, and percentage correct for the Club secondary task. Each variable was examined using a one-way repeated measures ANOVA with phase as the independent variable.",0
3,26,"The results of the experiment are presented through Figure 2, which displays the MRE for two groups during different phases. The data was analyzed using a 2x3 mixed ANOVA with group and phase as factors. The analysis showed significant main effects of the phase and the group x phase interaction. Post-hoc t tests indicated that MRE was significantly higher in the pressure phase for the Choke group, whereas other comparisons were not significant.",0
3,27,"Although it has been shown that the way a performer interacts with an object can affect how big it appears to them, the mechanism behind this has not been fully understood. One question that has not been answered is whether attention plays a role in these effects. Some previous studies suggest that attention may mediate the effects, but a direct link has yet to be established.",0
3,28,"The study aimed to investigate the phenomenon of choking under pressure in skilled motor performance by examining the relationship between perceived hole size, performance outcome, and attentional focus in a golf putting task. The secondary goal was to explore the connection between movement kinematics and perceived target size, which has not been thoroughly investigated in previous studies.",0
3,29,"The researchers found that adding pressure to some golfers resulted in significant changes in their putting technique. Specifically, 11 out of 25 golfers had a shorter time to peak speed (TTPS) and higher velocity. This typically occurs in novice golfers who have a more symmetrical putting stroke, while expert golfers have an asymmetrical stroke with a later TTPS.",0
3,30,"The benefit of using an asymmetric putting stroke with a longer time period of solid contact between the club-head and ball is that it results in a smoother roll across the green. In the present study, the golfers in the Choke group showed a decrease in this time period, indicating a regression in skill acquisition due to pressure. This idea is supported by the higher MRE in the pressure phase for the Choke group.",0
3,31,"The study found that golfers who experienced choking under pressure had a change in their putting style, and this change was linked to a shift of their focus towards executing the skill and away from external factors. The golfers also showed a decrease in accuracy for tasks related to the external environment and an increase in accuracy for tasks related to the internal execution of the skill. These findings support theories that suggest pressure causes golfers to focus inwardly, resulting in a control strategy similar to that of a less experienced golfer.",0
3,32,"The study had important design choices that could have affected the results and need to be studied further. One of the choices was allowing participants to see the final position of the ball after each putt, which could have influenced their judgment of the size of the hole. However, previous studies have shown that perceived target size remained stable even when performance outcome variability was directly manipulated. Further research is needed to examine whether the findings of this study hold true when performers are not given knowledge of results.",0
3,33,"The timing of the secondary task used to measure attentional focus during the putting stroke could not be used to directly assess attentional focus before the initiation of the putt. However, research suggests that attentional focus patterns are similar before, during, and after the stroke, and attentional shifts during the stroke can spill over into behavior before and after the movement.",0
3,34,The study contributes to our knowledge of how specific actions affect our perception. It shows that the amount of attention an object receives from an actor is directly linked to how big they perceive it to be. This supports the attentional accentuation hypothesis. The study also found that changes in putting kinematics were observed alongside changes in attentional focus and perceived size.,0
4,1,"The theory of Signal Detection assumes that likelihood ratios are used to make decisions in recognition memory, and previous research has shown that this assumption leads to the Mirror, Variance, and z-ROC Length Effects. A study of data from 36 studies validated these effects, but noted that bias can obscure the Mirror Effect. This paper examines how bias affects the regularities at a theoretical level and offers four ways to counter the obscuring. The theoretical analysis and experimental results show that the three regularities govern individual and group performance, and that Signal Detection Theory provides a simple explanation of recognition memory data.",0
4,2,"The authors of a previous study (Glanzer et al., 2009) showed that the ability to recognize things is in line with the standard Signal Detection Theory (Green & Swets, 1966/1974) by using likelihood ratios (LR). They demonstrated this through three different stages.",0
4,3,"The LR assumption is proven to result in three regularities - the Mirror Effect, Variance Effect, and the z-ROC Length Effect. The regularities are explained and examples are given to demonstrate how LR decisions lead to these patterns. Finally, a survey of recognition memory data proves that these regularities are widespread.",0
4,4,"In a 2009 paper, two topics were briefly discussed: how bias can obscure the Mirror Effect and how to counter it. The current study provides a more detailed analysis of these two topics. The authors demonstrate that the Mirror Effect, which is usually measured, is affected by bias. To counter the bias effect, they suggest four different strategies. The first is to use a more informative index of the Mirror Effect, the second is to cancel the bias with a pay-off arrangement, the third is to use a between-list design, and the fourth is to increase the difference in accuracy between the two experimental conditions (familiar vs. unfamiliar names).",0
4,5,"The objection to the survey in Glanzer et al. (2009) is that the data was collected from groups rather than individuals, which may not accurately represent the underlying processes. This issue of disagreement between group and individual data has been extensively discussed by Estes (1956) and Estes and Maddox (2005). However, the results presented in this study show that the three regularities hold true for individual performance.",0
4,6,"The recognition memory experiment involves showing participants a list of items to study and a test list which includes some items previously seen and some new ones. Participants then have to indicate if each item is old or new, or rate their confidence in their decision.",0
4,7,"The use of two different types of items or conditions in experiments can produce a difference in accuracy. These experiments demonstrate three patterns resulting from LR decisions: the Mirror Effect, Variance Effect, and z-ROC Length Effect.",0
4,8,"If there are two groups of objects in a recognition test that have different accuracy rates and the choices are made using LR, the S group will perform better in identifying old and new items correctly. The difference is often noticeable in a yes/no test where there is a similar ratio of hits and false alarms.",0
4,9,"The accuracy of recognition tests can be affected by two sets of items or conditions. When decision-making is based on likelihood ratios (LR), there is a novel general effect on the relative variances of the new and old distributions. The new distribution of the superior condition will have a larger variance than the weaker, lower accuracy condition. The same effect also applies to the old distributions. The effect is measured using the slope of the z-ROC of new and old items ratings. If decision-making is based on LR, the slope will be less than 1.0.",0
4,10,The length of z-ROC contracts varies based on accuracy when making decisions using LR. The z-ROC becomes shorter as the condition becomes more precise.,0
4,11,"The log likelihood ratio, Λ, will be used going forward because it makes equations simpler. Λ, which is a function of random variable X, is also a random variable with its own distribution, mean, and variance. The distribution of Λ is determined by the distribution of X and the function λ().",0
4,12,"The authors used linear regression to estimate linear fits and slopes for the computed examples of the models. There is no problem using linear regression in this context because the ROC curves represent theoretical distributions, and neither axis is subject to random error.",0
4,13,The article presents an example of a Normal Equal Variance Model to explain the regularities and their generation. They assume a recognition memory model based on normal equal variance distributions as the equations and the displays are simple. The article shows that the unequal variance normal model generates the same regularities as the equal variance case. The regularities also apply to recognition memory models based on binomial and exponential distributions. The article adds that converting LR to log LR doesn't change the effects discussed but helps to present simpler equations and plots.,0
4,14,"In this specific scenario, the variables SN and WN are both following a Normal distribution with a mean of 0 and a standard deviation of 1. Meanwhile, the variable WO follows a Normal distribution with a mean of 1 and a standard deviation of 1, and SO follows a Normal distribution with a mean of 1.75 and a standard deviation of 1. As for decision making, the model takes into account the likelihood ratio.",0
4,15,"Figures 2A and B show the model's theoretical level, while Figures 2C and D illustrate observable data based on the model. Figure 2A reveals the initial distribution of raw information for SN, WN, WO, and SO called ""strength,"" ""familiarity,"" or ""amount of marking."" SO is located to the right of WO, indicating greater precision. SN and WN are not separated because unstudied items may not vary in strength. The new distributions are not separated, and the LR transformation's effects are displayed clearly, indicating that when SO shifts above WO, SN will move in the opposite direction, below WN, on the LR decision axis.",0
4,16,"When someone makes a decision using LR, the densities shown in Fig. 2A are rearranged on a logarithmic scale in Fig. 2B. The likelihoods represented by these figures are random variables that follow a normal distribution, according to Glanzer et al.'s research. The three regularities are demonstrated in Figures 2B, C, and D.",0
4,17,"Figure 2B illustrates that by using a log likelihood decision axis, the distributions SN and WN become separated, which were previously in the same position in Fig. 2A. This separation causes the Mirror Effect to appear with the distributions ordered.",0
4,18,"Glanzer and colleagues (2009) discovered that the H/FA Mirror Index does not work well in situations where there are biases present. This means that the index may show that there is no Mirror Effect, even when the distributions are actually in mirror order. Despite this flaw, we discuss the H/FA Mirror Index extensively in this paper because it is commonly used.",0
4,19,Recognition memory tests can be affected by bias if the observer has misunderstood the likelihood of an item being old. The likelihood-ratio procedure can be used to describe how decisions are made based on past experience and the distribution of effects from stimuli. Overestimating the likelihood of certain alternatives can lead to bias in decision making. This was discussed by Wickens in 2002.,0
4,20,"The second component represents the benefits and drawbacks of different accurate and erroneous answers. If the cost of a false alarm goes up, then the person is expected to raise their threshold for making a decision and become more cautious in responding ""Yes.""",0
4,21,"The authors presented five experiments that demonstrate three LR regularities and the impact of bias. The first experiment explored the normality of word frequency as a strength variable, while the subsequent four experiments examined familiarity of names as a strength variable.",0
4,22,"The regularities were observed in all five experiments. However, the second experiment revealed that the H/FA Index may not accurately measure the Mirror Effect due to bias. Nevertheless, the Distance Mirror Index was still able to show the effect. To counter the bias effects on the H/FA Index, the third, fourth, and fifth experiments introduced three other methods.",0
4,23,"The experiment results are presented in four stages. Firstly, the pooled results of confidence ratings of all individuals are reported, which provides a general view of regularity results but does not allow standard statistical analysis. However, the measures derived from this stage correspond closely to those obtained from subsequent standard analyses. Secondly, the conventional analysis of the Mirror Effect is presented using the H/FA Index. Thirdly, the three LR regularities based on ROCs computed for each individual are reported, providing distributions of measures that can be statistically analyzed. Lastly, a more detailed analysis of each individual's performance is presented.",0
4,24,"The authors want to demonstrate three LR patterns in a straightforward example without any influence of bias. They are doing this by revisiting and analyzing data from a study that looked at the effects of word frequency on recognition. Specifically, they are comparing high frequency words (H) to low frequency words (L), where L is considered the stronger or more accurate condition, while H is considered the weaker or less accurate condition.",0
4,25,"The study involved 16 undergraduate participants who completed a task where they had to decide if 248 words were real or not. Then, they were given a test where they had to recognize 248 old words, half of which had high frequency and half had low frequency, and 248 new words. They had to rate their confidence in their recognition on an eight-level scale. More information about the methods and steps taken can be found in the initial research document.",0
4,26,"The results of the study, based on ratings from 16 participants, are presented in figure 4A and B, which show the z-ROCs. These graphs reveal certain patterns that were previously identified in a theoretical model (see Fig. 2C and D). The researchers also analyzed these z-ROCs using various measures, such as examining the distances between the underlying distributions and measuring the slopes of certain z-ROCs. These measures were obtained using a statistical program and were used to analyze the Mirror Effect, Variance Effect, and z-ROC Length Effect.",0
4,27,"The outcomes of the statistical assessments of the participants' answers are presented in three steps. Firstly, the typical analysis of the H/FA Index of the Mirror Effect, followed by the analysis of the three LR patterns. Lastly, an individual response analysis is conducted with regards to the three LR patterns.",0
4,28,"The common way of analyzing the Mirror Effect is by comparing the accuracy of two situations and checking the difference between them. This difference is required for the occurrence of this effect. It is also essential to compare the hit and FA rate for each situation. All the important measures are listed in Table 3, including bias measures.",0
4,29,"The question of whether regularities hold for individuals alone was previously mentioned. To address this, the presence of regularities in each individual's data was tabulated and displayed as ratios in the first row of Table 5. All 16 participants showed SN < WN (dnn negative), and all regularities were found to differ significantly from chance (.50) by a binomial test. These results fully support the analyses in Table 4.",0
4,30,"In the following section, the authors describe four studies that use familiarity of names as the variable instead of word frequency. The reason for using this variable is to provide additional evidence for the three regularities previously discussed. Additionally, using familiarity allows for the evaluation of an alternative explanation of the Mirror Effect. The four experiments all demonstrate the three LR regularities and illustrate how the bias effects that obscure the mirror effect as measured by the H/FA Index can be addressed.",0
4,32,"The study and test list for each participant were created using two main lists, one consisting of well-known individuals from the fields of acting, sports, and politics (F list) and the other consisting of names from a local phonebook (U list). The F list had a mean rating of 1.14, indicating high familiarity among the participants, while the U list had a mean rating of 4.83, suggesting low familiarity. Additional U names were used as practice and filler items to eliminate primacy and recency effects. List names were randomly selected and individually randomized for each participant.",0
4,33,"In the study and test, names were shown in capital letters at the center of the screen. For each name during the study, it was shown for 1250 ms and then there was a 750 ms blank screen before the next name. The test was then given with 120 ""F"" names and 120 ""U"" names, half of them being previously studied and the other half being new. The participant could take their own time to respond to each name during the test.",0
4,34,"The participants were given a list of names and asked to decide whether each name was old or new using a 6-point confidence rating scale. The confidence ratings ranged from very sure old to very sure new. The participants were able to see the scale on the monitor during the experiment. A practice session was conducted before the actual experiment, which consisted of a 6-item study list followed by a 12-item test list, containing both old and new items.",0
4,35,"The information of 38 college students is shared, except for one person whose responses were less than expected. All students had been using English as their language from the age of 10 or earlier, and they took part in the experiment as part of their class. This information is also relevant to the participants in Experiments 3, 4, and 5.",0
4,36,"The experiment results in Table 3, second row, indicate a significant difference in accuracy, suggesting the presence of the Mirror Effect. The bias indices for familiar and unfamiliar items also differ significantly, with participants exhibiting a strong conservative bias towards unfamiliar items and a slight liberal bias towards familiar names. This differential bias affects false alarm rates and the H/FA Mirror Index, which only shows a significant difference between HWO and HSO. However, the FAFN versus FAUN comparison is not significant, leading to the conclusion that there was a failure of the Mirror Effect if only the H/FA Index is considered.",0
4,37,"The results in Table 4's second row indicate that the Mirror Effect exists, shown by the significant dnn and doo Distance Index (entries 1 and 2). The mean distance between the two new distributions is negative, while the mean distance between the two old distributions is positive. The Distance Index confirms that the Mirror Effect is present, with the distributions ordered as FN < UN < UO < FO. The H/FA Index fails to show this pattern when there is differential bias, whereas the Distance Index reveals its presence.",0
4,38,The frequency of each regularity displayed by individual participants is shown in the second row of Table 5. All three regularities are present and verified as significant by a binomial test. These findings strongly support the analyses presented in Table 4. The number of participants used to compute the ratios varies due to inadequate data from two individuals who did not use enough confidence categories. This same denominator variation occurs in the subsequent experiments due to participants' responses not allowing for the calculation of specific z-ROCs.,0
4,39,"To summarize, we have shown that individuals exhibit three regularities in their performance, specifically in terms of their familiarity with names. Additionally, we have found that the conventional H/FA Index for the Mirror Effect is not effective when differential bias is present, and instead should be replaced with the Distance Index that utilizes dnn and doo. We delve into this topic further by detailing how to handle differential bias when using the H/FA Index.",0
4,40,"The previous experiment showed that participants were less likely to say ""yes"" to unfamiliar names than to familiar names, which made it difficult to observe the Mirror Effect when using the H/FA Index. To overcome this bias, the experimenters used differential payoffs to cancel out the observed bias and induce a counter-bias. The success of this experiment is important because any failure to observe the Mirror Effect is likely due to such biases. The relationship between bias and the Mirror Effect is that biases hide the effect, especially when using the H/FA Index. Another possible explanation is that the Mirror Effect simply doesn't exist with the materials used in Experiment 2.",0
4,41,"In order to determine which interpretation is accurate, we will conduct Experiment 2 again, but this time we will use a feedback system and pay-offs to eliminate any biases. If our original interpretation is correct, we should see the full Mirror Effect, even when accounting for the H/FA Index.",0
4,42,"The second experiment was conducted using the same materials, procedure, and participants as the first experiment, with an additional instruction given to the participants regarding the scoring system. They were informed that identifying old, unfamiliar names as ""old"" correctly would earn them +50 points, while incorrectly identifying them as ""new"" would result in a deduction of ?50 points. Any other correct responses would earn them +10, and any incorrect responses would earn them ?10. The total score would be given to the participants at the end of the test.",0
4,43,"The diagram in Figure 6 shows the z-ROCs for the group. There are three LR regularities that can be observed. In Figure 6A, the z-ROC for F is higher than U, with dF = 1.45 and dU = 0.77. The length of the F z-ROC is shorter than U, which is known as the zROC Length Effect. In Figure 6B, the old/old z-ROC is located above the main diagonal, while the new/new z-ROC is located below it. This is known as the Mirror Effect, with doo = 0.61 and dnn = -0.40. The slopes for both z-ROCs are less than 1.0, which is known as the Variance Effect.",0
4,45,"The sensitivity measures dF and dU have significantly different values, with a pattern observed in the regularities across the two conditions. The mean bias indices cF and cU do not show any difference, indicating that the mirror pattern is not disrupted. The H/FA data shows a mirror pattern, which is statistically evaluated and found to be significant. The experiment's introduction argument is supported by the results, indicating that the Mirror Effect was obscured due to differential bias in Experiment 2. However, removing this bias revealed the effect even when measured by the weaker H/FA index.",0
4,46,"Table 4 presents regularity measures based on the z-ROC. The Distance Mirror Index has two means, dnn and doo. The mean dnn is negative and the mean doo is positive, both significantly different from zero. The Variance Effect regularity is indicated by means of the new/new and old/old z-ROCs slopes, which are both significantly less than 1.0. The means for dnn and doo are 0.75 and 0.76, respectively.",0
4,47,"The lengths of the standard zROCs for F = 2.75 and U = 3.60 are not the same, according to the statistical test. The z-ROC Length Effect is still valid.",0
4,48,The third row of Table 5 shows the ratios of participants displaying the three regularities. A binomial test confirms that all regularities are significant. These results align with the statistical analyses presented in Table 4.,0
4,49,"The three experiments before showed the same patterns, but in Experiment 2, a significant difference in bias removed the Mirror Effect as measured by the H/FA Index. In Experiment 3, this bias issue was fixed through a pay-off system and the H/FA Mirror Effect returned. Another solution is to use a between-list experiment rather than within-list, meaning separating the two conditions into different study-test sequences.",0
4,50,"Hoshino conducted experiments to investigate the impact that separate test lists have on bias. Using Japanese kanji and a yes/no procedure, he attempted to replicate the word frequency Mirror Effect with the H/FA Mirror Index. The first two experiments did not show the desired effect, with a higher incidence of ""old"" response for H rather than L words. Hoshino believed that the lack of success was due to differential bias. In a third experiment, two separate test groups were used, with one group being subjected to the same conditions as the first two experiments. The second group showed similar results in line with Hoshino's initial findings, indicating that the H/FA Index was violated due to differential bias.",0
4,51,"The diagram in Figure 7 displays the z-ROCs group, which illustrates three LR regularities. The standard z-ROC (Fig. 7A) exhibits a z-ROC length effect, with length F = 2.12 and length U = 3.26, and has dF = 2.26 and dU = 1.02. The old/old z-ROC (Fig. 7B) is positioned above the main diagonal with doo = 1.16 and the new/new z-ROC lies below the main diagonal with dnn = -0.80, which is known as the mirror effect. The slopes of both z-ROCs are less than 1.0, with 0.54 and 0.75, respectively, known as the variance effect.",0
4,52,The first two sets of data in row 4 of Table 3 show differences in accuracy means. The bias indices in the next set of data do not differ significantly. The mixed-list experiment showed a bias difference that disappeared in the between-list paradigm. The H/FA Index demonstrated a clear Mirror Effect when the bias was eliminated.,0
4,53,The regularity measures for Table 4 are listed in the fourth row. The first two values represent the Distance Mirror Index and show a significant Mirror Effect with negative mean dnn and positive mean doo. The next two values are slopes of z-ROCs for new/new and old/old and show a significant Variance Effect with values less than 1.0. The next two values represent a significant length difference with mean length F being less than mean length U. The z-ROC Length Effect is also observed.,0
4,54,The fourth row of Table 5 displays the percentage of individual participants demonstrating each of the three regularities. A binomial test confirms that each regularity is noticeable and significant. This data complements the statistical analysis presented in Table 4.,0
4,55,"The bias effect of Experiment 2 will be tackled by enhancing the accuracy of familiar names over unfamiliar names. This will be achieved by reducing the number of familiar names in the study and test lists. Previous experiments that studied the composition of the list have shown that by decreasing the number of items from one sub-list, recognition accuracy for those items can be improved.",0
4,56,"Experiment 5 had the same setup as Experiment 2, but with a reduced number of familiar names in both the study and test lists. The study lists had 30 familiar and 60 unfamiliar names, while the test lists contained 30 familiar old, 30 familiar new, 60 unfamiliar old, and 60 unfamiliar new items. Apart from this change, everything else in the experiment, such as the construction of lists and participant characteristics, remained the same as Experiment 2.",0
4,57,"The z-ROCs group is illustrated in Figure 8, showing all three LR regularities once again. The standard z-ROC in Figure 8A has dF=2.18 and dU=0.83, indicating the z-ROC Length Effect with the length F=1.78 and U=3.55. Additionally, the Mirror Effect holds as the old/old z-ROC lies above the Main Diagonal with doo=1.61 and the new/new z-ROC lies below the main diagonal with dnn=-1.12. Furthermore, both z-ROC slopes are less than 1.0, at 0.41 and 0.55, respectively, indicating the Variance Effect.",0
4,58,"Row 5 of Table 4 presents the regularity means. The first two values indicate a significant Mirror Effect for the Distance Mirror Index with mean dnn < zero, t(40) = 14.93, SE = 0.09, and mean doo > zero, t(34) = 18.37, SE = 0.06. The next two entries, the slopes of the new/new and old/old z-ROCs, show a significant Variance Effect with both values less than 1.0. The mean length F is significantly different from mean length U, F(1, 42) = 76.47, MSE = 0.76, and this is supported by the z-ROC Length Effect.",0
4,59,"The accuracy of recognizing items increased when the number of familiar names was reduced. This increased the difference in accuracy between familiar and unfamiliar items and recovered the Mirror Effect. However, it also made responses to familiar names more liberal, which was unexpected. This double effect of experimental operations on both accuracy and bias may be related to the salience of familiar names, which generates relatively liberal responses. When the number of familiar names was reduced, their salience increased, leading to further liberal responses.",0
4,60,"The authors argue that the three regularities in SDT can be explained by its three basic concepts: sensitivity, bias, and LR decision axis. SDT can also account for situations when mirror regularity does not appear. Process models of recognition memory that use SDT and LR component do not contradict the general SDT model because they operate at different levels of theory.",0
4,61,"The data from a simple memory experiment can be explained without invoking LR decisions, by assuming that decisions are made based on unprocessed strength. However, for more complex experiments with two conditions, strength-based decisions no longer work and LR conversion must be included in the computations to observe regularities in the data.",0
4,62,"The Mirror Effect can be explained by making up additional assumptions to support strength decisions. Two ideas, Criterion Shift and Two-Process, have been proposed to explain this effect with their own set of assumptions.",0
4,63,"It has been proven through experiments that WN and SN are not fixed and can vary. In these experiments, participants had to choose between WN and SN items, resulting in null choices. The results showed that the two new distributions SN and WN are separated, and SN is less than WN. This was found in all five experiments discussed in the article, where dnn value was negative, indicating that the two new distributions have a separation, and SN is less than WN with distance -dnn.",0
4,64,"The Mirror Effect is often explained through the two-process explanation which is limited to the word frequency Mirror Effect. The explanation assumes that individuals use a familiarity/strength decision axis and that low frequency new words start out less familiar than high frequency new words. However, low frequency words are learned and recollected much more effectively than high frequency words, which results in the Mirror Effect inequality, HO < LO.",0
4,65,"The Mirror Effect is demonstrated in a standard condition and then disrupted with an operation like presenting stimuli more quickly. This causes a disruption in recollection, as seen through the H/FA Index. However, the two-process explanation only applies to the word-frequency mirror effect and not the name familiarity mirror effect shown in later experiments. Furthermore, this two-process explanation does not cover the Variance Effect and the Length Effect.",0
4,66,"The interpretation of mirror disruption caused by speeding varies depending on whether L words or H words are being processed. L words take longer to process than H words, and so speeding affects L words more than H words. This results in decreased accuracy for both types of words, but more so for L words, which in turn reduces the difference in accuracy between the two word types. This difference in accuracy is crucial for the H/FA Index in mirror effect studies. If the difference in accuracy is smaller, then the H/FA Index is less likely to show the mirror effect in two-factor mirror disruption studies. Glanzer et al. (2009) and Experiment 5 demonstrate this effect.",0
4,67,"SDT, using its LR decision axis, can explain the data supporting the two-process explanation without assuming any extra processes like familiarity and recollection. It is not limited to explaining the effects of word frequency, which is the case with the two-process explanation.",0
4,68,"Experiments 2, 3, 4, and 5 provide evidence against the two-process explanation and any other explanation that indicates a decision axis based on strength/familiarity. These explanations suggest that unfamiliar new names (UN) should have lower values than familiar new names (FN) on the decision axis, resulting in no mirror effect. However, SDT with its LR decision axis predicts the opposite order, with FN having lower values than UN, resulting in a full mirror effect.",0
4,69,"The Mirror Effect that is produced by familiarity is supported by five other studies on recognition. These studies have looked at different levels of familiarity of words, names, faces, and tunes. Although the familiarity variable is referred to by different names by the different investigators, it is clear that in each study, there was a difference in initial familiarity between the two sets of items used.",0
4,70,"Rouder and his colleagues have raised concerns about the legitimacy of claims linking the asymmetry of ROCs to the underlying distribution's variance. Their challenge stems from Mickes et al.'s (2007) study, which supported the relationship between slopes and variance in the unequal variance SDT model. Rouder et al. introduced z-ROCs from other models with other variances that matched Mickes et al.'s findings, but they concluded that no method exists to evaluate the relative variability of latent mnemonic strength distributions. However, Wixted and Mickes (2010) have contested this conclusion, and the controversy requires further research to resolve.",0
4,71,"The authors Pratte, Rouder, and Morey (2010) are worried about a different issue that may occur when interpreting ROC asymmetries, which happens when the z-ROC slopes are less than 1.0. They fear that this phenomenon may be a result of data averaging and thus not reflect a real pattern. However, after applying a hierarchical unequal-variance signal detection model, they found that the asymmetries are indeed a real occurrence and not a distortion caused by averaging data.",0
5,1,"The study of eye movement behavior has led to an interest in understanding its spatial and temporal aspects, resulting in the development of multiple new methods to compare scanpaths. In this article, the authors discuss various scanpath comparison measures that were designed to solve specific problems and require different data-processing techniques. The authors applied these methods to data from an experiment and compared their abilities to reveal similarities in scanpaths within and between individuals. The results are discussed in terms of the different aspects of scanpath behavior that each method quantifies, and the article ends with recommendations for choosing an appropriate scanpath comparison measure.",0
5,2,"The methods for comparing scanpaths are explained in this article, but for further information, readers should refer to the original sources. The Appendix contains additional mathematical information.",0
5,3,"The string-edit distance method is used to compare scanpaths by measuring the dissimilarity of character strings. This involves transforming one string into the other using a sequence of transformations, such as insertions, deletions, and substitutions, and counting the number of transformation steps between the two strings. A grid is overlaid on an image, and each cell in the grid is assigned a unique character for fixation sequences to be transformed into a sequence of characters. The dissimilarity of two scanpaths is then represented by the number of transformations required to convert the string corresponding to the first scanpath to the string corresponding to the second scanpath.",0
5,4,"The string-edit measure was previously used on a similar dataset in a study by Foulsham and Underwood (2008). This study found that the similarity between scanpaths generated by the same person looking at the same image was the highest. Foulsham et al. (2012) also found that similarity in shape was highest for the same person looking at the same image. The string-edit distance measure is most sensitive to similarities in shape and sequential information, so it is expected that string edit similarity scores would be high between scanpaths of the same person looking at the same image for a second time. These findings are consistent with the earlier results.",0
5,5,"The authors of a study proposed a way to compare eye movement patterns that improves upon the limitations of previous methods. They use a bioinformatics algorithm to align eye movement sequences and create a sequence of letters that retains fixation location, duration, and sequence information. This sequence is then compared using a substitution matrix that can incorporate semantic information and assign scores for matching letter pairs and gaps.",0
5,6,"ScanMatch is anticipated to perform effectively in exposing similarities in scan patterns within a participant, incorporating information on spatial, sequential, and duration factors. It is expected to particularly highlight the similarity among observers when they view the same image twice, as demonstrated in a study by Foulsham et al. in 2012.",0
5,7,Shepherd and her colleagues (2010) came up with methods to determine how similar two scanpaths are. The scanpaths are first adjusted to have uniform time intervals and are then matched to the shorter length. These methods are based on samples and do not need pre-processing of eye-tracking data using saccade and velocity thresholds to separate fixation-saccade sequences.,0
5,8,"The overlap between two scanpaths is measured using a similarity measure that captures temporal and spatial differences between fixation locations. However, this method does not consider fixation duration and instead relies on resampling to assess temporal similarity. Therefore, it preserves the order of fixations but not the differences in their durations. As a result, two scanpaths may have the same spatial positions but different fixation durations, leading to a lower similarity score. One of the drawbacks of this approach is the use of an arbitrary radius threshold, which is similar to other grid-based quantization methods like string-edit and ScanMatch.",0
5,9,"Fixation overlap is greatly affected by the variation in timing of two scanpaths, while the variation in position has a lesser impact since the radius is considered. This indicates that the performance of this measure is likely to be similar to that of the ScanMatch measure, which also considers spatial and temporal similarities between scanpaths.",0
5,10,"The measurement is highly sensitive to variations in time and space between the two scanpaths. This sensitivity is advantageous when timing is crucial, especially when the stimuli change over time. The correlation measurement is also sensitive to slight differences in fixation positions, without any spatial quantization of the fixations. This method uses a simple and easily understandable correlation analysis, making it more sensitive to position similarities compared to the fixation overlap method, while simultaneously considering sequential information. However, this strong spatial-temporal sensitivity may not be as reliable with noisy data as other methods that use a grid or radius.",0
5,11,"The study by Shepherd and colleagues in 2010 developed a measure called gaze-shift which measures the saccade times and amplitudes between two scanpaths. The measure uses the correlation between the first derivative of each scanpath and is computed similarly to the temporal correlation, but uses the derivative instead of position.",0
5,12,"The scanpaths are smoothed and their derivatives are computed using a Gaussian filter. The gaze shift depends on both the size and timing of saccades and reflects the similarity of scanpaths in terms of these features. This can help capture overall viewing strategies, as different subjects may have different patterns depending on their tendency to make large or small saccades in different areas of the visual field. The technique is useful for analyzing responses to dynamic stimuli like videos.",0
5,13,"The gaze-shift measure calculates how similar amplitudes are, and this may align with the MultiMatch measure that measures likeness in the length of eye movements. Nonetheless, studies have shown that likeness in length is only consistent within/between-image comparisons. It is uncertain whether the gaze-shift measure would have a similar outcome, as it quantifies temporal similarity alongside other sample-based measures.",0
5,14,"The linear distance method is advantageous because it doesn't require quantization like the string-edit method. It compares fixations based on their spatial similarity rather than order, but it may ignore sequential information. A modified version of Mannan et al.'s method enforces a one-to-one mapping between two scanpaths, but the original method averages out clusters of fixations. Linear distance compares fixation positions in two scanpaths regardless of order and has shown an advantage for within-participant similarity in previous studies.",0
5,15,"Recently, a method called MultiMatch was introduced by researchers Jarodzka, Holmqvist, and Nystr??m in 2010, and Dewhurst et al. and Foulsham et al. in 2012 for comparing scanpaths. MultiMatch involves five measures that capture the similarity between different aspects of scanpaths, including shape, direction, length, position, and duration. To calculate each MultiMatch measure, the scanpath is simplified by iteratively combining successive fixations within a certain distance or directional threshold. This simplification process helps to reduce the complexity of the scanpath while maintaining its spatial and temporal structure.",0
5,16,"The process starts with simplifying the scanpaths followed by an alignment based on their shape using dynamic programming. It optimizes the difference between the scanpaths, which reduces the effect of small variations and helps the algorithm find the best match. The similarity measures are then computed on these simplified and aligned scanpaths. The MultiMatch similarity computations are based on Dewhurst et al. (2012).",0
5,17,"Vector similarity is a way to compare two sequences of fixations and saccades. It works by calculating the difference between aligned saccade pairs, then normalizing that difference based on the screen size. This measure is useful because it doesn't rely on pre-defined quantization, which can be limiting. Instead, it looks at spatial differences in fixation positions. The resulting value indicates how similar the two sequences are in terms of their overall shape.",0
5,18,"The similarity between lengths is determined by calculating the difference between the size of the aligned saccade vectors, with respect to the diagonal of the screen, and averaging them over the scanpaths. This calculation only takes into account the size of the saccades, not their direction or duration.",0
5,19,"The direction similarity is calculated by finding the difference in angle between saccades that are aligned, with the output normalized by π and an average taken over scan paths. This measure only takes into account the direction of saccades, and not their amplitude or the location of any fixations.",0
5,20,Position similarity is determined by measuring the distance between fixations that are aligned and then normalizing the distance by the screen diagonal. This calculation takes into account both the distance and direction of saccades and is then averaged across scanpaths.,0
5,21,"The duration similarity measures the difference in fixation durations between aligned fixations and normalizes it by the maximum duration, then averages it over scanpaths. This measure is not affected by the position of the fixation or the distance of the saccade.",0
5,22,"The MultiMatch method has a major benefit of offering multiple measures to evaluate scanpath similarity, with each measure highlighting a unique aspect of the scanpath. However, since there are so many measures to choose from, it can be challenging to determine which measure or set of measures is most suitable for a specific situation. Additionally, since each scanpath is first simplified, it is unsure how strong each measure is against scanpath changes.",0
5,23,"Considering that the MultiMatch measures have been tested before with a dataset that is quite similar to the one used in this study, we anticipate that the previous findings will be reproduced. These previous results showed that when comparing within-participant versus between-participant data, saccade direction, fixation position, fixation duration, and shape similarity were significantly greater in the former case.",0
5,24,The authors created ways to analyze gaze patterns of one person using recurrence quantification analysis. These methods are briefly mentioned and further explained in the Appendix.,0
5,25,"The article discusses two fixation sequences, f and g, that are of equal length, with the longer sequence being truncated if they are of unequal length. Any two fixations, fi and gj, are considered to be cross-recurrent if their distance is below a certain threshold or if they match or are close together. The article goes on to introduce a few different measures that can be used to describe cross-recurrent patterns.",0
5,26,The cross-recurrence measure of two fixation sequences is a way of measuring how similar they are in terms of the percentage of matching fixations. This measure takes into account the spatial similarity of the two sequences and is not affected by the order in which fixations occur. Cross-recurrence is most closely aligned with measures of linear distance and position similarity.,0
5,27,The determinism measure is a way to determine how similar two scanpaths are based on the percentage of cross-recurrent points that form diagonal lines in a recurrence plot. This measure looks at the overlap of specific sequences of fixations and preserves their sequential information. It is unique in that it can show similarity between two scanpaths even if their overall shapes or fixation positions are quite different. This measure is useful because it can identify smaller sequences that may be shared between two scanpaths.,0
5,28,"Laminarity measures the frequency of fixations on a specific area that occur in both scanpaths. It is related to determinism and both measures high indicate clusters of fixations in a particular region. If the laminarity is high but the determinism is low, it means that the number of fixations on a specific area was different between the two sequences. Laminarity is a measure of fixation clustering in two sequences.",0
5,29,"In simple terms, the center of recurrence mass (CORM) measures the dominant lag time of cross-recurrences between fixations in two visual sequences. The CORM value is small when the same fixations in both sequences occur close in time while large CORM values indicate a significant lag between cross-recurrences. The positive or negative lag can indicate whether one sequence leads or follows the other, and the CORM value is used to determine this. The present work uses the absolute value of CORM, as there are no specific predictions about which sequence will lead or follow. Low CORM values are expected for within-image and within-participant comparisons when participants consistently lead or follow a similar scanpath closely on later viewings of the same image.",0
5,30,"The study aimed to compare the effectiveness of different scanpath measures in detecting similarities and differences within and between individuals when viewing natural scenes. Participants completed a task where they first viewed the scenes and then recognized them. The researchers predicted that scanpaths of the same person viewing the same image multiple times would be more similar compared to those of different people viewing different images. To test this prediction, the researchers used several scanpath comparison techniques and evaluated their ability to capture similarities between observers and images.",0
5,31,"The visual stimuli were displayed on a 19-inch monitor with a refresh rate of 60 Hz, filling the entire screen. Participants were seated 60 cm away from the monitor and their head was firmly placed in a chin rest. The viewing angle was approximately 32.7° × 25.7°. Eye movements were captured using the Eyelink 1000 eyetracker from SR-Research, and responses were given using a regular keyboard.",0
5,32,"The researchers chose 36 images from a dataset provided by Foulsham and Underwood in 2008. The resolution of the images was 1024 × 768 pixels and they contained pictures of buildings, interiors, and landscapes. Half of the images were shown during both encoding and recognition, while the other half were only shown during recognition to serve as new images. More details can be found in Foulsham & Underwood's paper.",0
5,33,The sample-based methods involve re-sampling signals at 60 Hz. Two fixations are considered overlapping if they are less than 3.5° visual angle apart for the overlap method. A temporal Gaussian filter with σ = 100 ms is applied for the gaze-shift measure. Fixations are discretized on an 8 × 6 grid for the string-edit distance measure. The substitution matrix is used for defining similarity in distance between grid locations for the ScanMatch measure. The MultiMatch measure combines fixations that are closer than 3.5° visual angle or successive saccades with a difference in direction of less than 45°. Two fixations are considered cross-recurrent if they are less than 1.9° visual angle apart for the recurrence-based measures. A minimum line length of 2 is used for the determinism and laminarity measures.,0
5,34,"Instead of simply comparing the effectiveness of different measures in detecting the main effects and interaction in the analysis of variance, the use of effect sizes was chosen. For instance, a high effect size for the main effect of image in the recurrence measure indicates its sensitivity towards this factor in assessing the similarity of scanpaths. Generalized eta squared (η2 G ) was utilized for the comparison, which is comparable across various within-participant and between-participant variables in repeated-measures designs. This allows for a direct comparison of the effects of participant and image, which cannot be done using partial eta squared (η2 p ). To assess effect size, similar guidelines were followed as that for η2 p , where an effect size of 0.02 is considered small, 0.13 medium, and 0.26 large.",0
5,35,"The article provides tables and figures that show the statistical results of measuring scanpath similarity. Table 2 presents the F-ratio and p-values for the main effects of participant, image, and participant-by-image interaction. Table 3 shows the mean scanpath similarity for each measure in the four conditions. The article then focuses on the η2 G values obtained for each term in the analysis of variance, which are shown in Figures 1-3. Figure 4 provides the means of significant participant-by-image interactions and the corresponding post-hoc comparisons are discussed in the paragraph below.",0
5,36,"The researchers conducted various types of comparisons on scanpaths created during an experiment. They used different measures to compare similarities in scanpaths across images and participants to understand the influence of individuals generating the scanpath and the stimulus on resulting similarities. Additionally, they compared methods used to compute scanpath similarity in general, and evaluated their performance based on the type of information they quantify. The study reviewed the contributions of each measure to understanding scanpath similarity in participant and image similarities.",0
5,37,"The results of our study support previous research that shows when the same person looks at the same image, they are more likely to have a similar scanpath. We found that the within-image and within-participant comparison had the highest similarity scores. It's worth noting that different comparison techniques reveal different aspects of scanpath similarity.",0
5,38,"The methods that were most effective in identifying unique scanning patterns within individuals were those that measured similarity in both shape and position, such as overlap, linear distance, ScanMatch, and recurrence. Interestingly, measures that also accounted for sequential order, like ScanMatch and determinism, were particularly useful in distinguishing between individuals. The determinism measure specifically revealed that some individuals have a tendency to repeat certain short scanpath sequences consistently, regardless of the image they are viewing. Overall, differences in scanning behavior can be observed in the shape and order of scanpaths.",0
5,39,"The image had a strong impact on the similarity of scanpaths, which was detected by most measures. The measures that assessed the shape, position, and sequential order of the scanpaths were particularly effective in distinguishing between images. Interestingly, measures with configurable grid or radius sizes performed well in detecting these effects. It would be worthwhile to investigate the impact of different radius/grid sizes on these results in future research.",0
5,40,"The study focused on the comparison of different measures computed using author-recommended or previously-used parameters. The size of the radius and granularity of the grid used in the measures could impact the results. As the radius size increases, the chance of similar spatially sensitive scanpath measures also increases. The Overlap method used a larger radius compared to recurrence-based measures, which could result in spurious similarity due to radius size. Future research could investigate the impact of multiple radius and grid sizes on scanpath quantification and comparison. A sensible radius size reflecting the size of the region of foveal or parafoveal vision is recommended based on previous studies.",0
5,41,The different methods used to compare scanpaths have varying requirements. Some methods require the scanpaths to be trimmed or resampled which may result in loss of data or the specifics of fixations and saccades. Simplification may be performed to increase processing speed but it is not necessary. Future research can investigate the effect of simplification on scanpath comparisons.,0
5,43,"The choice of scanpath measure depends on the research question, but there are some general recommendations. Scanpath comparison has improved over the years, with recent advancements such as ScanMatch and MultiMatch. Cross-recurrence measures like determinism offer new ways to understand eye movement behavior. These methods represent the current state-of-the-art in scanpath comparison, but there are still many techniques being developed.",0
5,44,"The methods discussed in this study are remarkable because they are accessible to anyone- they can be obtained by contacting the authors or found online for free. Certain measures, such as ScanMatch and MultiMatch, come with user-friendly interfaces and tutorials which make them easier to use. A list of URLs where these available methods can be found is given below.",0
5,45,"The researchers compared various scanpath comparison measures by applying them to one data set and evaluating their ability to reveal differences in scanning behavior across participants and images as well as the aspects of scanpaths that they quantify. The purpose of this analysis was to provide a framework for other researchers to determine which comparison technique is the most suitable for their application. The hope is that this overview and results will assist those interested in studying eye movement behavior, specifically the spatial and sequential aspects of it.",0
6,1,"The article examines various studies that looked at interventions for inappropriate sexual behavior in children and teenagers with developmental disabilities. The searches resulted in 12 studies that met the necessary criteria, and each one was summarized according to specific aspects. All 12 studies showcased a decrease in the target behavior as a result of the intervention. The most common intervention method utilized multi-component behavioral strategies. Finally, the article concludes by discussing potential clinical implications and future research suggestions.",0
6,2,"The exploration of sexuality, including masturbation, is a normal part of human sexual behavior during prepubescent years. Masturbation behavior can occur as early as in the womb and during childhood. Masturbation commonly occurs at four years old and during adolescence. The context in which the behavior occurs, cultural and familial norms, and developmental stages should be considered in defining normal or abnormal sexual behavior. Masturbation in a private setting and not excessive is considered normal. However, sustained or public masturbation may require intervention.",0
6,3,"Children with autism spectrum disorder (ASD) tend to exhibit inappropriate sexual behaviors, including public masturbation, fetishistic behavior, and inappropriate touching of others. There are several reasons for this behavior, including a lack of sex education for individuals with disabilities, the predisposition of those with ASD to engage in self-stimulatory behavior, and difficulties in acquiring social and behavioral skills. Children with ASD may have difficulty distinguishing between public and private settings and may struggle with understanding appropriate behaviors in social relationships. Attention from others in response to their inappropriate behaviors may also reinforce this behavior.",0
6,4,"The meaning of ISB is not unanimously agreed upon in the literature. However, based on existing research, ISB is defined as sexual behaviors that are excessive, obsessive, occur in public, violate others, are aggressive in nature, and/or imitate adult acts that are socially inappropriate.",0
6,5,"When people engage in inappropriate sexual behavior, it can have profound effects on their relationships with family and community. Parents of children with disabilities often express concern about their child's behavior and may seek advice on how to address it. However, there is limited research on the treatment of childhood masturbation and even less on ISB among children with developmental disabilities. As a result, there is little agreement among clinicians on the best approach for treating ISB, and the services available in this area are often limited.",0
6,6,"Mallants and Casteels (2008) reviewed literature on assessment and treatment strategies for childhood masturbation in typically developing children. They suggest starting with an assessment that considers the child's development, behavior, medical history, cultural background, and more. If the assessment reveals no underlying issues, the authors recommend educating parents and providing support rather than punishment for the child's behavior. Additionally, children should receive developmentally appropriate sex education to help them understand appropriate sexual behaviors.",0
6,7,"Besides the recommendations given by Tarnai in 2006, other studies indicate that treatment for Inappropriate Sexual Behavior (ISB) in people with disabilities should involve providing them with sex education that is tailored to their specific needs. Koller, for instance, suggests that sex education for those with Autism Spectrum Disorder (ASD) should be brief, repetitive, and explicit. This education should also include disciplines on appropriate sexual behavior, response to unacceptable behavior, and scheduling of personal time for sexual activity.",0
6,8,"Although it is beneficial to provide sex education for children who have disabilities, it is apparent that more research needs to be done to establish evidence-based practices. Schaafsma and colleagues(2013) investigated the creation of sex education programs for individuals with intellectual disabilities and found that the programs lacked clear objectives, did not have a solid theoretical foundation, had not undergone a proper evaluation, and were not developed by consulting relevant groups.",0
6,9,"Understanding the life course trajectory of ISB is crucial. It can significantly affect the development of relationships, social participation, and education settings in early childhood and prepubescence. If ISB persists in adulthood, it can also impact the formation of social and intimate relationships, home living, and community integration. Without appropriate treatment, children with ISB may be at risk of sexual abuse, which is a concern given the higher risk for sexual violence that children with disabilities face.",0
6,10,"The first and second authors searched electronic databases such as PsycINFO, ERIC, Education Research Complete, and PubMed in March 2014. They combined search terms such as Bmasturbation, Bsexual behavior, and Bgenital stimulation with Bautism, BASD, Bdisabilities, Bdevelopmental disabilities, and Bintellectual disabilities. The PubMed search produced the highest number of results, with 122 articles. They conducted ancestry searches of each article found and also searched Google Scholar using the same search terms but found no additional articles. All identified articles were examined to determine if they met criteria for inclusion in the review.",0
6,11,"The fourth author conducted an update on the literature search in May 2015, but no new articles were found. However, two papers (Early et al. 2012 and Mallika et al. 2013) were discovered, but were excluded later since they didn't meet the criteria for inclusion.",0
6,13,"The inclusion criteria were met by twelve articles while the rest were excluded for various reasons including not involving individuals with developmental disabilities, not looking into ISB treatments, or having participants above 18 years. The selected 12 studies were then evaluated and summarized according to different criteria such as participants, research design, dependent and independent variables, data collection, treatment integrity, results, and certainty level.",0
6,14,"The interpretation of results in this assessment is determined by whether the desired behavior occurs spontaneously or not, and whether the teaching circumstances are altered. This is based on Stokes and Baer's (1977) description.",0
6,15,"Treatment integrity refers to techniques used to ensure that the intervention is carried out as intended. These techniques include measuring inter-observer agreement, providing training to those implementing treatment, directly observing and recording target behaviors, using checklists to assess implementation fidelity, and administering social validity checklists. A summary of the information for each study included in the review is presented in Table 1.",0
6,16,The term 'conclusive evidence' is used to refer to studies that provide treatment outcomes that are almost certainly true. These studies have all the necessary methodological features of studies that provide a high level of evidence and also attempt to account for other variables that could affect the treatment results.,0
6,17,"The studies in this paper were evaluated based on their treatment effects, which were categorized as positive, negative, or mixed following the method outlined in the Mulloy et al. (2010) review. Positive effects were seen when all participants in within-subject studies had positive outcomes or when group studies showed significant differences between treatment and control groups. Mixed effects were recorded when some individuals benefited from treatment while others did not, or when positive outcomes were observed for some but not all measures. Negative effects were observed when no positive effects were seen in a within-group design, or when group differences were not statistically significant in studies using a between-groups design.",0
6,18,"The study found 18 articles that could potentially be included in the review. To make sure the database search was accurate, the first and second authors reviewed each article and agreed that only 12 of them met the criteria for the review. The other six articles were excluded because they didn't report on inappropriate sexual behavior treatment or didn't involve people with developmental disabilities.",0
6,19,"In total, 50 participants were involved in 12 different studies. One study had 30 participants, another had 10, and the remaining 10 studies only had one participant. Out of all the participants, there were only three females and 47 males, and their ages ranged between 5 and 16.",0
6,20,"Out of the total 50 participants in the research review, 12 were diagnosed with ASD while the rest of the participants were either described as having a level of intellectual disability or had a specific diagnosis such as Down syndrome, traumatic brain injury, or spastic hemiplegia with severe mental retardation.",0
6,21,"The IQ of participants was given in only five studies and the scores varied from severe intellectual disability to normal range for one individual. Since only a few studies provided this information, it is challenging to come to any conclusions about the potential links between IQ, ISB, and treatment response.",0
6,23,"The review found that six out of the 12 studies used a single-case experimental design, while two of them had a multiple baseline method. Additionally, two studies used an ABAB reversal design. The remaining studies had either a simple AB design or a case report format. Only one study used a between groups design.",0
6,24,"The two studies mentioned used aversive techniques to address inappropriate sexual behavior in individuals with disabilities. One study involved facial screening and negative feedback while the second study used lemon juice squirts as a punishment for public masturbation. After intervention, the participant in the facial screening study received a sex education program to help them learn appropriate ways to express their sexuality.",0
6,25,"Three studies utilized medication to treat inappropriate sexual behavior, specifically by prescribing mirtazapine, a type of antidepressant that may cause sexual dysfunction. Mirtazapine is commonly used in treating clinical depression among adults and the elderly, and has also been suggested to alleviate symptoms of ASD and other pervasive developmental disorders. Coskun et al. (2009) chose mirtazapine for its potential antilibidal effects.",0
6,26,"In 9 out of 12 studies, public masturbation was identified as a behavior that needed to be addressed through treatment. Some of these studies also included the public display of genitalia. Three studies also included inappropriate and uninvited sexual touching of another person as a target behavior. In two studies that provided group intervention, several target behaviors were identified, including uninvited and inappropriate sexual touching of another person, public self-stimulatory behavior, exhibitionist behavior, and the inappropriate and public use of sexual language. Target behaviors in another study included public masturbation, inappropriate touching of others, public disrobing, arousal resulting from specific body parts or inanimate objects, and observation of others disrobing or bathing.",0
6,29,"The study conducted by Coskun and Mukaddes (2008) was distinctive because the subject showed fetishistic tendencies towards individuals wearing blue jeans, which led them to try and rub their genitalia against said individuals.",0
6,30,"Polvinale and Lutzker in 1980 concentrated on three groups of conduct that they called (1) belligerent conduct (not sexual), (2) wrong interpersonal sexual conduct, and (3) private area self-stimulation. They did not give any additional meaning to these behaviors.",0
6,31,"The studies reviewed utilized a number of standardized measures to assess changes in behavior. For instance, Albertini et al. utilized the Child Autism Rating Scale and Schema of Appraisal of Emotional Development during the initial evaluation and six months after treatment. Coskun et al. used the Clinical Global Impressions-Severity and Clinical Global Impressions-Improvement scales to measure changes in ISB at both the beginning and end of their study.",0
6,32,"Treatment integrity data was not reported in six out of 12 studies in the analysis, and those studies were named. In six of the studies, inter-observer agreement data was collected, and some studies reported on the training procedures and data recording procedures. Only one study provided outcomes related to social validity.",0
6,34,"Two studies used aversive procedures to respond to ISB and reported a decrease from baseline recordings, indicating positive treatment effects. Cook et al. (1978) reported that ISB stopped occurring after treatment, while Barmann and Murray (1981) observed significant reductions in self-stimulatory behavior in various settings.",0
6,35,"The one study that used group therapy did not have consistent results in terms of effects of treatment. However, there was a significant reduction in sexual acting out behavior within the sexual intervention group compared to the behavioral intervention and control groups. In the study that used an individual cognitive-behavioral intervention, there was a decrease in masturbation behavior from 10-12 times per week to none after the final treatment session.",0
6,36,"The majority of the 12 studies had just a single participant, so not many statistical analyses could be performed. However, Butler and Fontenelle-III (1995) used ANOVA to compare pre-test and posttest scores among treatment groups, while Coskun et al. (2009) utilized Wilcoxon nonparametric t tests to evaluate the changes in CGI-S scores from baseline to post-treatment.",0
6,37,"Seven studies examined the maintenance of treatment effects, ranging from 2 weeks to 12 months post-treatment. In each study, the treatment effects were sustained after a period of no intervention. However, four studies did not report follow-up data.",0
6,38,"To summarize, out of the studies analyzed, 11 showed that the treatment had positive effects. Nonetheless, there's a chance that certain parts of the intervention used alone may not lead to favorable results. Additionally, the results should be considered while keeping in mind the limitations of the procedures used in these studies.",0
6,39,"The review found 12 studies published between 1977 and 2009 that looked at treatments for ISB in children and adolescents with developmental disabilities. These treatments included medicine and behavior-based interventions, which were reported to have positive outcomes in reducing or eliminating ISB. However, due to the limited number of studies and participants, the authors of the review cannot draw conclusive results about effective treatments for ISB.",0
6,40,"The research has several limitations that need further analysis. Most of the studies have suggestive levels of certainty, while only one reached a conclusive level. One of the primary causes of this is the experimental design used in the studies, which includes a single-case AB research design used in many studies examined in this review. Using an AB design and other limitations in the studies make it difficult to conclude that the positive treatment effects reported occurred as a result of intervention. Although implementing a reversal design for behaviors of this nature can be unethical, further research is necessary to determine the true effectiveness of the treatments.",0
6,42,"The study's design limitations and the small number of participants in each study could affect the validity of the findings and make it hard to apply the study results across different groups. While some studies used a multiple baseline design which strengthened the research, most studies only had one participant.",0
6,43,"The studies that used behavioral treatment also included time sample and frequency recordings to gather IOA data. Many studies, like Barmann et al. (1981), Cook et al. (1978), Foxx et al. (1986), Fyffe et al. (2004), Luiselli et al. (1977), and Polvinale and Lutzker (1980), used these methods, and as a result, they became highly certain and effective approaches to intervene with ISB.",0
6,44,"Despite a change in how society views the sexual behavior of people with developmental disabilities, treatment for ISB has not changed much between 1977 and 2009. Most treatments used during this time rely on applied behavior analysis, although there have been a few recent studies that have explored the use of medication as a treatment option. However, it is important to consider the potential drawbacks of relying solely on medication as a treatment without also teaching individuals how to manage their behavior over the long term.",0
6,45,"It is crucial to take into account the effect of learning to control impulsive and aggressive behavior not only in direct terms of clinical implications but also in terms of its effects on the home and the community for children and adolescents with developmental disabilities. The impact of such behavior can have consequences on social relationships with family, friends, and school inclusion, which hinders community access and engagement. Therefore, it is necessary to develop interventions that teach functional alternatives that can be applied in various settings and to different people.",0
6,46,The studies conducted had very few female participants and it's important to note that there may be gender differences in sexual behavior. There is little research on how ISB differs between males and females but it's suggested that social and cultural factors and anatomical differences may lead to bias in treating males more frequently than females. The lack of research in this area leads to difficulty in drawing conclusions about any gender differences in ISB expression and response to treatment. This raises questions about whether there are differences in rates and manifestation of ISB between males and females.,0
7,2,"Over time, there has been a change in perspective regarding sexual behavior displayed by those with disabilities. While it is no longer considered abnormal behavior, there are still some concerns with regards to the timing, appropriateness, and location of such behavior. However, there has been insufficient research done on treatments for individuals with developmental disabilities who display inappropriate sexual behavior. Conducting more thorough research can lead to better understandings and implementation of evidence-based treatments that can improve social and developmental outcomes for this population.",0
7,4,"It is crucially important to understand the significance of testing as a learning tool, especially with the increasing implementation of high-stakes testing in education. The impact of information learned during testing versus studying the material is particularly intriguing. While testing has its benefits, such as better retention of information, there are also negative consequences, such as impaired retrieval of other items from a set and decreasing performance over the course of a test list. This decrease in performance is referred to as output interference and can be attributed to the updating of existing memories or the addition of new traces to episodic memory during testing.",0
7,5,"The Annis et al. (2013) study showed that using semantic memory did not increase OI in an episodic task. However, this does not address whether OI occurs within a semantic task. While the two memory systems have different functions and structures, they rely on each other heavily. Episodic memory benefits from semantic information, and vice versa. Semantic knowledge starts as episodic but becomes more generalized over time. This creates a lasting, resistant semantic memory that is less prone to interference from episodic events.",0
7,6,The researchers used a Bayesian multiple linear regression developed by Kruschke (2011) and cross-checked it with a frequentist regression to analyze test performance. They chose this approach because it allowed them to determine the amount of evidence in favor or against a null effect. The researchers focused on the change in performance over test trials and examined whether there was a nonzero slope for performance change. They also investigated whether the slope of performance across trials changed from Test 1 to Test 2. The interpretation of the Bayesian model parameters was the same as that of a typical regression from the frequentist tradition.,0
7,7,"The 150 test trials for each participant were divided into ten blocks, consisting of fifteen trials each. The standardized performance data for each block, the block number, and whether it was Test 1 or Test 2 were entered into a regression model, along with the interaction between block number and test number.",0
7,9,"The Savage-Dickey method involves comparing the likelihood of observing a zero slope in the posterior distribution to that of the prior distribution. A Bayes Factor (B01) less than 1 indicates that a zero slope is more likely in the prior distribution and supports the null hypothesis. On the other hand, a BF greater than 1 supports the alternative hypothesis that the slope is nonzero. These analyses were conducted using the JAGS software and Brjags package in R.",0
7,10,"The results for Test 1 and Test 2 are presented in Fig. 2, and the data shows that performance on Test 1 is consistent throughout successive trials, while performance on Test 2 decreases with each trial. The profile plot in Fig. 2a illustrates the performance for a given test block of Test 1. The interaction term between the two tests indicated that Test 2 had a higher value (β = -.007, 95% HDI: -.013, -.0004) and there was strong evidence that Test 2 performance declined over the test block while Test 1 remained consistent. There was some support for a difference between the slopes of the two tests.",0
7,11,"The reason for the observed OI in Test 2 could be a combination of searching for knowledge and recent memory, with the latter being more influenced by OI. To test this theory, the accuracy of the Test 1 response was evaluated, and if it was correct, OI may not be observed. However, if the response was incorrect, participants may generate a correct Test 2 response on occasion by guessing or using successful semantic memory search. The use of episodic memory for Test 1 feedback to generate a correct Test 2 response is also possible, as Test 2 accuracy was significantly higher. Under these circumstances, OI should be observed.",0
7,12,"The results in Fig. 3a show that when participants correctly answered a question in Test 1, their performance on Test 2 remained consistent across test position. On the other hand, when they answered incorrectly on Test 1, their performance on Test 2 decreased greatly across test position, as shown in Fig. 3b. The Bayesian analysis confirmed these patterns, with a positive interaction term indicating a steeper slope for Test 2 when Test 1 was answered incorrectly. The slope for Test 2 when Test 1 was answered correctly was flat, with evidence for both zero and nonzero values. Therefore, the null hypothesis cannot be rejected or accepted in this case.",0
7,13,"The results obtained from Bayesian analysis were supported by a frequentist multiple regression on the data combined from all participants. Test Block and Test 1 accuracy were found to have a significant impact on performance, and the change in performance across Test Block for Test 2 was influenced by the correctness of Test 1 response. When Test 1 response was correct, the slope of change was lower than when it was incorrect.",0
7,14,"The way participants responded to a set of questions changed based on whether it was the first or second time they had answered the questions. During the first test, there was no pattern of output interference (OI) observed, meaning participants were likely relying on their semantic memory. During the second test, after receiving corrective feedback, there was a strong OI effect observed, particularly for questions that were answered incorrectly during the first test. This suggests that participants were relying on their episodic memory, which resulted in more OI.",0
7,15,"Based on the data, it seems that people rely on two types of memory- episodic and semantic- to answer questions correctly. Episodic memory may be more likely to be affected by testing conditions, while semantic memory is less vulnerable. Interestingly, trying to remember the context of how information was learned, as often recommended by textbooks, might actually be harmful for tests that measure knowledge. This is because focusing too much on context can cause interference from other information that is similar to the context being recalled.",0
7,16,"To put it simply, we discovered that OI does not affect continuous knowledge searches when using a group of common knowledge questions. However, OI remained strong when participants used corrective feedback given during Test 1, indicating that episodic information may have an impact on semantic memory. These results offer restrictions on the connection between episodic and semantic memory.",0
8,1,"The current issue of Psychological Studies is published to coincide with two significant events reflecting the progress and development of psychology as a field of study and research. Firstly, Calcutta University is commemorating the centenary of Psychology Department established in 1915. Secondly, this journal is celebrating the completion of 60 years of its publication. Both these occasions demonstrate the advancement and growth of psychology in India over the last century. The editor of this journal, who has completed 15 years, acknowledges the challenging and rewarding experience of editing this journal with consistent and collaborative effort by the scholars' community. Due to personal reasons, the editor finds it difficult to continue and therefore resigns from the post, expressing gratitude to NAOP officials and the community for the trust and support shown. The editorial, administrative and production team have contributed significantly towards journal publication.",0
8,2,"In recent years, there has been a significant growth in the field of psychology in various aspects such as theory development, research, and practical applications. Although subfields such as psychometric, clinical, and organizational psychology still receive a substantial amount of research attention, there is a small yet robust group of researchers who are changing their research agenda by embracing indigenous concepts and methods. This shift demonstrates a greater cultural awareness in their choice of research topics and problems.",0
8,4,"The current issue of Psychological Studies includes an interesting article on diversity and presentism in psychology by Adrian Brock, which is followed by comments from various scholars. The discussion aims to contextualize psychology in socio-historical and cultural settings, while other articles in the issue focus on issues in the Indian context. The overall goal is to promote cultural awareness in psychological discourse.",0
8,5,"When the writer reflects on their past time as an editor, their only regret is not being able to be more innovative with handling manuscripts. While they attempted to reduce publication lag, they believe there is potential for improvement in the process. The support from their colleagues has made the publication procedure easier, however. The writer is confident that the new editor, Professor Damodar Suar, will do a great job and continue to promote psychology. They welcome him and his team, wishing him success in his new role.",0
9,1,"The research suggests that while retrospective studies show crying can be beneficial for improving mood, laboratory studies consistently report negative effects on mood. The study aimed to explain this paradox by evaluating the mood of criers and non-criers after watching an emotional movie in a laboratory setting. It was found that criers experienced an initial negative mood increase, followed by a recovery that led to an improvement in mood compared to pre-film levels. This suggests that crying can lead to more long-term mood recovery.",0
9,2,"Humans are the only species that have the ability to cry emotional tears, which is a widely observed behavior across various cultures. Despite its prevalence, research on the functions of crying has been limited. Theories on the functions of crying can be categorized into two categories - the catharsis effect which emphasizes the personal benefits of crying, and the inter-individual functions of crying which focus on communicating one's helplessness and need for support. Both positions are not mutually exclusive, and crying may be considered as a coping behavior that serves several functions, from facilitating emotional recovery to persuading others to act on the situation.",0
9,3,"The discrepancies in findings about the effects of crying may be due to the methodology used in retrospective studies, where participants choose which crying episodes to describe. This may lead to a bias towards reporting crying experiences that support the idea that crying makes one feel better. Another issue is the lack of a precise definition of the time interval between crying and reported feelings. Participants are asked to report how they feel after crying, without specifying the time frame. However, it is possible that people experience a dip in their mood immediately after crying, followed by an improvement, but we currently have insufficient information to understand this process.",0
9,4,"The study aims to investigate the immediate and delayed effects of crying on mood in a controlled laboratory environment. To ensure the results are applicable to a wide group of people, stimuli that elicit tears for negative and positive emotions were used. The study predicts that negative mood would be more prominent in individuals who cry after potentially emotional films. The study also anticipates that individuals who cry would experience a greater improvement in mood compared to those who did not cry, in terms of both initial mood downturns and overall mood improvement. Finally, the researchers expect a relationship between the frequency of crying and changes in negative affect.",0
9,5,"The study began with 46 female and 26 male students, who were between the ages of 19 and 33, with an average age of 23.80 and a standard deviation of 3.19. All participants agreed to take part in the study and signed informed consent forms. However, six participants were removed from the study due to incomplete or missing data from equipment failure or incomplete questionnaires.",0
9,6,"The researchers used a shortened Emotional States Scale to measure negative affect (NA), which included 18 items rated on a five-point Likert scale. The items evaluated a range of emotions such as anxiety, sadness and anger, and the scale demonstrated good internal consistency.",0
9,7,"The participants were placed in a soundproof room with a monitor, speakers, and video camera. They completed a mood rating before being randomly assigned to watch one of two films. After watching the film, they filled out a questionnaire about their emotional response. They completed two more mood ratings and additional questionnaires before leaving the lab. They were instructed to complete a final mood rating after receiving an SMS message on their mobile phone, without any further instructions for behavior during the 60 minutes prior to this rating. The results were sent to the experimenter via text message.",0
9,8,"The study conducted several statistical tests, including independent samples t tests, Chi square tests, and Pearson correlation coefficients, to investigate the relationships between relevant variables and to identify any potential confounding variables that needed to be controlled for. To compare changes in negative affect (NA) between participants who cried and those who did not cry, a mixed ANOVA was conducted with time period, group, age, and gender as factors. The changes within groups and specific measurements were analyzed, and an additional ANOVA was conducted to validate the possibility that low mood in criers stimulated successful mood enhancing behaviors. Bonferroni post hoc tests were also used.",0
9,10,"The study found that there was a significant difference in mood changes over time and a significant interaction between time and group, indicating that the crying and noncrying groups had different patterns of mood changes. However, there was no significant difference between the two groups overall. This supports the hypothesis of different emotional responses to crying.",0
9,11,"The researchers conducted two separate ANOVAs to determine whether there was a significant change in mood in each of the two groups. They found that there was no significant change in the group of non-criers throughout the four measurements, but in the group of criers, there was a significant effect of time. Post-hoc comparisons showed that NA increased from T1 to T2 and decreased from T2 to T3 and T4, supporting their initial hypothesis. They also found a significant decrease in NA from T1 to T4 in the criers group, indicating overall mood improvement following crying. Finally, the predicted decreases in NA remained significant when NA change from T1 to T2 was included as a covariate in an additional ANOVA.",0
9,13,"The idea that crying brings relief is possibly due to the strong improvement in mood experienced by those who cry. The decrease in negative affect (NA) in these individuals may be attributed to the return to baseline levels after initial increases. This suggests that people may feel better after crying, despite an initial deterioration in mood. These findings support the hypothesis that crying has cathartic effects and are in line with previous research on the effects of emotion expression on mood and well-being. However, it remains unclear if the long-term mood-enhancing effects of crying are due to the same mechanisms.",0
9,14,"The decrease in negative affect (NA) at the final measurement reported by those who cried could be argued to be caused by the increased tension and nervousness that participants experienced at the beginning of the study. This is because they were in a new and unfamiliar situation. However, it is unclear why noncriers did not experience an improvement in mood at the final measurement. Furthermore, both groups had similar levels of NA at the beginning of the study.",0
9,15,"The researchers are uncertain whether the decrease in NA is due to a change in mood caused by crying or a shift in how the participants perceive their emotional state. This response shift is a known phenomenon among cancer patients who often report an improved quality of life after their diagnosis, but a retrospective comparison reveals a decreased quality of life. Future studies should consider this methodological issue by directly comparing participants' current mood state to their pre-film measurement and considering factors that influence memory of emotional events and mood regulation processes.",0
9,16,"The findings suggest that there is a straightforward explanation for why different studies on crying and mood show contradicting results. Although crying initially causes a drop in mood in laboratory settings, it eventually leads to an improvement in mood that exceeds the original level. This aligns with retrospective studies on the topic.",0
10,1,"The connection between incentive information and improved cognitive control may not only be due to temporary brain responses to potential rewards. There is evidence that information about rewards can influence cognitive processing and brain activity throughout the task, in a more consistent manner. Recent research has found that motivation-related state effects can impact cognitive function, demonstrated by increased sustained activations across blocks of trials with incentive information. This suggests that rewards can enhance cognitive control through both cue-related responses and sustained responses.",0
10,2,"According to research, offering rewards or incentives may not affect behavioral performance and brain activity in everyone. This is because individual differences in reward-related sensitivity can affect how people respond to both primary and secondary rewards. Various studies have found a link between personality traits related to reward drive and neural responses to rewards. For instance, some studies have found that people with higher scores on measures of behavior inhibition and approach are more likely to show greater neural responses to appetizing foods in certain regions of the brain, while those higher in extraversion tend to show greater neural responses to monetary rewards. Overall, understanding these individual differences in reward sensitivity may be important for predicting how people will respond to incentives and make decisions.",0
10,3,"Another personality trait that affects reward processing is anhedonia, which is the reduced ability to feel pleasure. Experiencing rewards as positive or pleasurable is crucial for individuals to approach their goals and maintain positive emotions. Individual differences in anhedonia are present in both clinical and nonclinical populations, and those who find rewards less pleasurable are less motivated to change their behavior to achieve them. People who report higher anhedonia levels may have less improvement in cognitive control, less modulation for incentive-related brain activity, or potentially both.",0
10,4,"The study aimed to replicate previous research on how rewards improve cognitive control and examined sustained and incentive cue-related effects on cognitive control using fMRI. The focus was on the DLPFC and striatum due to their previous involvement in the influence of rewards on cognitive control. The response conflict processing task was modified to fit a mixed state-item design, allowing for examinations of sustained context-dependent effects and transient reward-related cue effects. Participants performed in baseline conditions before additional reward blocks where they could win money on some trials. The study predicted that motivational states induced by reward contexts would produce greater sustained activity in the DLPFC than in nonincentive baseline blocks and that incentive cues would generate increased transient neural activity in both reward-related cortical and subcortical regions.",0
10,5,"The researchers had two goals for their study. First, they wanted to see if receiving rewards would improve cognitive control, and if so, how it would affect the brain's activity. Second, they wanted to test if the level of self-reported anhedonia (lack of pleasure or enjoyment) in individuals would have an impact on how rewards improved cognitive control and brain activity. They used two measures of trait anhedonia to assess this.",0
10,6,The individuals who took part in the study did not have any prior psychiatric or neurological conditions in themselves or their family history. They were recruited from the Conte Center for the Neuroscience of Mental Disorders at Washington University and agreed to participate by providing written consent. The ethics board at the university approved the study protocol. Participants were compensated with up to $20 as a reward for their performance and an additional $25 per hour for completing the experiment.,0
10,7,"The baseline blocks consisted of two runs with 18 trials per trial type, intermixed with congruent, incongruent, and neutral trials. BTASK and BDONE cues were presented at the start and end of each task block for 2 seconds, respectively. Each trial began with a BXX cue for 1 second, followed by a fixation period ranging from 2 to 6 seconds before the onset of stimuli. Participants responded to the target stimulus within 0.5 seconds, followed by visual feedback for 1 second. ITI ranged from 2 to 6 seconds.",0
10,8,"Participants completed four additional runs where they had the chance to win money for correct and fast responses. A reaction time threshold was determined individually for each person based on their second baseline run. During these runs, some trials were preceded by a reward cue indicating points could be earned, while others had no potential for reward. Participants received feedback on their point earnings and their accumulated points were converted into real money.",0
10,9,"The imaging data was analyzed and processed using software developed by Washington University called the FIDL analysis package. The first four images of each run were not used to allow for signal stabilization. The functional-imaging data preprocessing involved various steps: slice-dependent time shift correction, removal of the first four images of each run, elimination of odd/even slice intensity differences due to interpolated acquisition, realignment of data to compensate for rigid-body motion, image intensity normalization, registration of the 3-D structural volume to the atlas template in the Talairach coordinate system, coregistration of the fMRI volume to the structural image, transformation of fMRI data to voxel atlas space, and spatial smoothing. Head movement during scanning was assessed by using the output of the rigid-body rotation and translation algorithm, and if the standard deviation of the root-mean-square movement exceeded 20, the BOLD runs were not included in the analysis.",0
10,10,The researchers conducted multiple ANOVAs to assess response time and accuracy in different trial types and reward conditions. They then used post-hoc paired t-tests to further investigate significant interactions. The team calculated two behavioral indices to measure the effects of reward context and cue on response time. They used these indices to perform a Pearson correlation analysis to investigate the relationship between individual differences in anhedonia trait and how rewards impact cognitive tasks.,0
10,11,The researchers used different statistical methods to analyze the data. They looked at sustained estimates and cue-related activity separately. They focused on regions that showed interactions with time points and used post-hoc ANOVAs and ttests to further analyze these regions. They extracted mean percent signal change for each time point to visualize the pattern of activity. They focused on Time Point 4 for the statistical analyses because it corresponded to the initial peak in the hemodynamic response. They conducted post-hoc paired ttests to compare the three trial types and parse the significant effects.,0
10,12,"The researchers conducted two different ANOVAs to analyze the relationship between targets and rewards. The first ANOVA looked at target activation across trials with the potential to earn reward, while disregarding the trial type. A post-hoc analysis was conducted on any significant findings. The second ANOVA included trial type and compared target activation across trials with the potential to earn reward in the reward context. Factors such as Reward Context, Trial Type, and Time Point were taken into consideration in this analysis. This was an attempt to replicate prior research from Padmala and Pessoa (2011).",0
10,13,"The authors limited their examination to specific brain regions known to be involved in the processing of reward, such as the dorsolateral prefrontal cortex (DLPFC) and basal ganglia (BG). They used established anatomical markers to create masks of voxels within these regions and conducted voxel-by-voxel analysis within them. To ensure accurate results, statistical activation maps were corrected for multiple comparisons using combined p-value and cluster thresholds. The DLPFC mask included Brodmann's areas 9 and 46, while the BG mask combined several structures. Follow-up analyses were conducted by extracting BOLD response values and importing them for further correlation analysis.",0
10,14,"The study investigated if differences in anhedonia influenced both behavior and brain function when rewards were presented. They examined specific regions of the brain that showed sustained and transient effects as well as the relationship between individual differences in anhedonia and brain activation during reward and cue contexts. The researchers also looked at two specific measures of anhedonia and their correlation with brain-personality traits, which were corrected using small volume procedures.",0
10,15,"The ANOVA analysis showed that trial type had a significant impact on the error data, with more errors on incongruent trials than on congruent ones. However, there was no significant effect of reward on the error data and no interaction effect between reward and trial type. Therefore, further analyses were conducted on the RT data.",0
10,16,"The study found that individuals who reported more anhedonia (the inability to feel pleasure) on the Chapman scales had lower levels of activation in the lateral globus pallidus when presented with cues predicting rewards. On the other hand, those who reported higher levels of hedonic tone on the SHPS had greater activation in the same region when presented with similar cues. However, the correlation for hedonic tone did not pass the Bonferroni correction.",0
10,17,"The study found that certain regions in the brain showed different patterns of activation in response to reward-related tasks. Some regions in the DLPFC and BG showed reduced activation on RC trials compared to RCXT and BCXT trials. Other regions in the DLPFC showed greater activation on RC trials relative to BCXT trials. Subcortical regions showed no difference in activation among reward-related tasks at Time Point 4, but showed greater deactivation on RC trials at Time Point 7.",0
10,18,"The study found that the DLPFC and several subcortical regions, such as the lateral globus pallidus and caudate, showed increased activation in response to incentive cues compared to no-incentive cues. These findings are consistent with previous research that found an increase in activation in regions associated with cognitive control in response to incentive cues.",0
10,19,"The DLPFC is typically viewed as a fundamental element of cognitive control, but recent evidence suggests that it also encodes both reward-related and task-related value information. Moreover, research has shown that the DLPFC is strongly linked to essential regions that are involved in value representations, such as the orbitofrontal cortex and the anterior cingulate cortex. Additionally, the DLPFC sends projections to the BG, which includes the caudate nucleus and the globus pallidus, and these striatal regions send back projections to the thalamus, which in turn projects to the DLPFC, premotor and motor cortices. As a result, the increased activations observed in the DLPFC and striatum in response to incentive cues may show improved neural representations of reward value via top-down control of activations in this circuit.",0
10,20,"The study found that certain areas in the brain show sustained activity during reward contexts, which extends previous research suggesting that regions in a fronto-parietal network can exhibit sustained increase in response to reward information. The present study used a hypothesis-driven analysis approach that may have offered greater power to detect sustained effects in the prefrontal and striatal regions. The sustained activity observed in the BG may reflect its role in reward-based learning and goal-directed behavior. The increased activity in the dorsal striatum during reward contexts may represent increased effort to maintain reward-related information, which can facilitate preparatory responses throughout reward contexts.",0
10,21,"In this study, we discovered that individuals with greater anhedonia had lower neural activation in response to reward-predicting cues. However, there was no significant connection between anhedonia and sustained, context-dependent activation in reward contexts. These results suggest that anhedonia may affect how rewards impact brain activation and behavior in response to explicit reward cues, but it does not seem to influence more comprehensive incentive effects. Additionally, these findings suggest that anhedonia may affect goal-directed behavior by making it more challenging to pursue rewards due to a lack of positive experiences or expectations.",0
10,22,"The study provided insight into one possible neural mechanism that causes anhedonia, but there were some limitations. The study did not find any significant reductions in conflict effects, although there was a speeding in RT in relation to reward. The study focused on the DLPFC and basal ganglia, and the analysis did not show any significant regions displaying interaction effects. Future studies are required to understand how the difficulty level of tasks affects the engagement of the DLPFC in reward contexts. The study also found that self-reported anhedonia trait in healthy adults had transient neural activity during reward predictions linked to the lateral globus pallidus, but not with sustained DLPFC activity.",0
10,23,"The study had a limitation in that the fixed-order presentation of the conditions could have led to practice-related effects influencing the sustained context-dependent effect. However, previous empirical evidence, such as the findings from Chiew and Braver's study, suggests that this is unlikely. Chiew and Braver used a similar design with randomized incentive trials and found that practice effects disappeared after the first epoch, whereas incentive effects remained. Therefore, the differences between the reward conditions in this study are unlikely to be due to practice effects. Additionally, the interleaved RCXT and RC trials could not have been affected by practice effects.",0
10,24,"The current study was able to differentiate between prolonged and immediate effects of rewards. However, future research could use other methods to distinguish these effects further. The study design used did not show the impact of continued rewards in the ability to provide incentives for improved performance throughout a block of trials. Therefore, a future study could include conditions where participants are notified of a bonus at the end of a set of trials for an overall increase in performance, but without individualized trial reward cues. Using this manipulation would create a design that would display both a general, sustained effect of an incentive in comparison to the presence or absence of transient reward cues.",0
10,25,The funding for this research came from National Institute of Mental Health Grant Number R01-MH066031. The authors do not have any financial interests or potential conflicts of interest. The Cognitive Control and Psychopathology Laboratory members and study participants are appreciated for their contribution in making this study possible.,0
11,1,"The study followed 74 children with Pervasive Developmental Disorder-Not Otherwise Specified for 7 years. The researchers examined the rates and stability of comorbid psychiatric disorders using the Diagnostic Interview Schedule for Children: Parent version at ages 6-12 and then again at ages 12-20. They also looked at childhood factors that predicted the stability of these psychiatric disorders. The study found that the rate of comorbid psychiatric disorders decreased from childhood to adolescence, and that behaviors like stereotyped behaviors and reduced social interest predicted the stability of these disorders. The study suggests that clinical practice should consider re-evaluating psychiatric comorbidity since some individuals shifted in their comorbid diagnoses.",0
11,3,"The study participants were required to meet two inclusion criteria. Firstly, they should have met the research criteria for PDD-NOS in childhood, as outlined in previous studies. Secondly, their parents needed to have taken part in the Diagnostic Interview Schedule for Children: Parent version during their childhood and again seven years later during adolescence. The study involved 94 participants during childhood and 74 participants during adolescence. The average time between the two interviews was around 7 years and took place when the participants were 6-12 years old and 12-20 years old, respectively.",0
11,4,"74 individuals who had both parents participate in the study did not differ from those with only one parent participating in terms of their gender, age, nationality, socio-economic status, and number of DISC-IV diagnoses. However, those with both parents participating had higher IQ scores than those with only one parent participating.",0
11,5,"The DISC-IV-P is a tool used to assess psychiatric disorders in children and adolescents through a structured parent interview. Trained research assistants conducted interviews with parents via phone. The DISC-IV-P measures internalizing disorders (anxiety and mood disorders) and externalizing disorders (disruptive disorders) using internet software. The anxiety disorder module includes nine disorders, while the mood disorder module includes three. The disruptive behavior category is further divided into ADHD, oppositional defiant disorder, and CD.",0
11,6,"The study used a parental questionnaire called the CSBQ, which has 49 items scored on a three-point scale measuring characteristics typical of autism spectrum disorder. The questionnaire has six subscales and has been found to have good reliability and consistency. The study aimed to investigate whether the level and type of parent-rated ASD symptoms in childhood were associated with the stability of comorbidity.",0
11,7,The study used the Wechsler Intelligence Scale for Children-Revised (WISC-R) to investigate if IQ scores in childhood were linked to the stability of comorbidity. The WISC-R has a verbal scale (VIQ) and a performance scale (PIQ) to make up the total scale (TIQ). The Dutch version of the WISC-R has been proven to be reliable and valid.,0
11,8,"The researchers used a questionnaire given to parents to evaluate the use of mental health care and medication between two waves of the study. The questionnaire contained eight questions pertaining to mental health care and was scored with a 0 or 1 depending on whether it was used or not. If any of those items were scored as 1, the child was considered to have received mental health care. In addition, parents were asked about their child's use of psychotropic medication in the past two weeks, which was also scored with a 0 or 1.",0
11,9,"Firstly, the rates of having multiple psychiatric disorders at two different time points were calculated and tested for significance using statistical methods. Then, a table was created to examine if these disorders remained stable from childhood to adolescence, and whether they were specific to certain domains. The results were also presented graphically to better understand the patterns of stability and change.",0
11,10,"The study aimed to investigate whether factors such as gender, age, IQ, level and type of parent-rated ASD symptoms, intermediate mental health care and medication were related to the stability of psychiatric disorders. The research compared groups with persistent disorders, those who changed from disorder to no disorder, persistent absence of disorders and those who changed from no disorder to disorder. T-tests and Chi Square tests were used for continuous and categorical variables respectively. Nonparametric testing was used for smaller groups using Mann-Whitney U test and Binomial test.",0
11,11,"The diagram in Figure 1 displays the percentages of individuals who fall under different groups based on their psychiatric conditions in childhood and adolescence. Among those with comorbid psychiatric disorders in childhood, 63% still had the conditions in adolescence, while 37% no longer did. Similarly, half of those without psychiatric disorders in childhood continued to be free of such disorders in adolescence, but the other half developed at least one comorbid psychiatric disorder.",0
11,12,"To gain more clarity on the research findings, an additional test was conducted to determine potential predictors that are specific for persistent externalizing disorders as opposed to persistent internalizing disorders. The test showed that in both cases, only stereotyped behavior reported by parents was a significant factor that predicted the persistence of the same psychiatric comorbidities. This was evidenced by statistically significant results for both externalizing disorders (t(40) = -2.953, p = .005) and internalizing disorders (t(39) = -3.287, p = .002).",0
11,13,"The study compared the childhood traits of two groups known as ""persistent absence"" and ""absent to present"" in terms of factors linked to the stability of coexisting psychiatric disorders. However, no significant distinctions were identified in terms of age, gender, IQ, the degree or type of ASD symptoms, intermediate mental healthcare, or the use of psychotropic medication.",0
11,14,"The incidence of MDD rises slightly from childhood to adolescence, going from 8% to 11%. These values are consistent with what is known in the literature, although there have been reported higher rates (up to 16%) and lower rates (as low as 1%) in individuals with ASD. There is also an increase in depression from childhood to adolescence in the general population, indicating a comparable developmental process.",0
11,15,"The prevalence of ADHD comorbidity decreases as individuals with PDD-NOS transition from childhood to adolescence, although relatively high rates are still observed. The hyperactivity and combined types of ADHD decrease while the inattentive type increases in adolescence. This change aligns with the expected trajectory of ADHD development, with attentional demands in adolescence potentially amplifying previously unnoticed problems. Lower rates of ADHD comorbidity have been reported for individuals with ASD in other studies.",0
11,16,"The overall occurrence of multiple psychiatric disorders reported by parents decreases between childhood and adolescence. Differences in methodological approaches, including diagnosis and sampling, could explain variation in the frequency of comorbidities in various studies. Our own research shows that the conversion from one kind of comorbidity to another is limited. There is little indication of cross-domain transitions, and domain stability seems to be the most consistent pattern. However, our dataset has limitations.",0
11,17,"The study found that children with stable psychiatric comorbidity had higher levels of parent-reported stereotyped behavior and reduced contact and social interest. These behaviors were also predictive of the persistent presence of either internalizing or externalizing disorders. However, the study did not find any significant predictors for the persistent absence of comorbidity. The findings suggest that parent-reported stereotyped behaviors might be an indication for persistent comorbidity. Future research is needed to confirm these findings.",0
11,19,"The children in our research were diagnosed with PDD-NOS, but it is unclear how these results relate to individuals diagnosed with ASD according to DSM 5 standards. Additionally, our sample was part of a larger study on the phenotypic profiles of children with PDD, which discovered that around 30% of the sample had a profile more consistent with the DSM-5 diagnosis of Social (Pragmatic) Communication Disorder. As a result, readers should examine our conclusions in light of this context.",0
11,20,"The YSR self-report data was analyzed to gather information on how adolescents are dealing with their internalizing comorbidities. Surprisingly, the study found that parents reported higher rates of anxiety in their children compared to the self-reported rates. However, adolescent self-reports did show a higher rate of subclinical depressive symptoms. It's important to note that DISC-P and YSR data cannot be directly compared due to their differences, and more research is needed to fully understand the comorbidities in this group over time.",0
11,21,"The authors express their gratitude towards the children and parents who took part in the project. The Sophia Foundation for Scientific Research (SSWO; Grant 586, 2009) and the NutsOhra Foundation (Grant 0803-53) provided financial support for the research.",0
11,22,"CV collected data, analyzed it, interpreted the results, and wrote the manuscript. AL, ME, JE, AG, FV, and FCV contributed to the study design, data interpretation, and manuscript development. KG was involved in the study design, data analysis, result interpretation, manuscript development, and supervised the study. All authors read and gave approval to the final version of the manuscript.",0
11,23,"Kirstin Greaves-Lord contributed as the second author to the ADOS-2 manual in the Netherlands, which Yulius compensates her for. Frank Verhulst leads the division of Child and Adolescent Psychiatry at Erasmus MC, which distributes ASEBA materials and pays him for his efforts.",0
11,24,"The parents of the children involved in the study signed consent forms before wave 1, and both the children and their parents signed the forms before wave 2. The study was also approved by the local Medical Ethics Committee (MEC-2008-388).",0
12,1,"In two experiments, rats were exposed to the flavor of almond paired with either fructose or maltodextrin, and their preference for almond was tested. The rats were split into two groups, with half having prior exposure to almond and half having none. During the first experiment, hungry rats showed a greater preference for almond in the nonpreexposed group regardless of which sweetener was used, indicating latent inhibition. In the second experiment, rats that were not food-deprived showed no latent inhibition and had a greater preference for almond in the preexposed group. These results suggest that different types of learning control behavior depending on hunger levels, but do not support the idea that different types of reinforcers generate different types of learning.",0
12,2,"The previous experience with an event, which is used as the conditioned stimulus in classical conditioning, often slows down the acquisition of the conditioned response. This is known as latent inhibition effect and is seen in most conditioning techniques, except for the flavor-preference conditioning procedure. In this method, rats are given a choice between plain water and water with a flavor they have previously consumed with a positive substance. The rats tend to choose the flavored water more, suggesting conditioning has occurred. Exposure to the conditioned stimulus before training does not always produce the same effect, and there are varying results in the literature.",0
12,3,"The findings suggest that the preference for sucrose can be established through multiple mechanisms. Sucrose has both a sweet taste and nutritive consequences, making it capable of supporting preference conditioning. A non-nutritive substance like saccharin can still be effective in preference conditioning, while intragastric infusion of a nutrient can form a preference regardless of its taste properties. Sucrose supports both flavor-taste and flavor-nutrient learning.",0
12,4,"The interpretation of the results from Garcia-Burgos et al. (2013) could be tested by using separate procedures to examine flavor-nutrient and flavor-taste learning. The former is expected to show latent inhibition, while the latter is not. Previous experiments have provided some information, but they used unorthodox procedures. For instance, Weingarten and Kulikovsky (1989) reported results from a study that investigated rats' response to sham-feeding, suggesting that preexposure to a flavor restricts the learning of an association between the flavor and the postingestive consequences of feeding. However, in a study by Galef and Durlach (1993), no latent inhibition was found, and the enhanced flavor preference induced by this training was not prevented by preexposure to the flavor. In the experiments reported here, the researchers attempted to isolate flavor-taste and flavor-nutrient learning by using substances other than sucrose as the unconditioned stimuli and the standard preference-conditioning procedure.",0
12,5,"The effects of different USs may be more complex than described in the paragraph. Intragastric fructose can support preference learning to some extent, but not as strongly as sucrose. Flavor-nutrient learning can occur with fructose, as demonstrated by a taste reactivity test on rats. Comparing fructose with maltodextrin has been successful in addressing other issues in flavor-preference learning. Looking for latent inhibition in rats trained with either fructose or maltodextrin as the US can help determine if different mechanisms underlie the preferences established by these USs. Finding evidence of an effect with maltodextrin but not fructose would support the hypothesis that the mechanism engaged by fructose is not susceptible to latent inhibition.",0
12,6,"The researchers divided the rats into four separate groups. Two of these groups were familiarized with the taste of almonds while the rest were not. The rats were then given two different mixtures containing almond along with either fructose or maltodextrin. During the final test, all the rats were given two bottles, one holding the almond solution and the other holding water. To ensure that the rats drank the fluids provided, they were deprived of water during training but had access to food. However, prior to the test, all access to food was removed to ensure that the hunger of the rats did not affect any preference towards a specific solution.",0
12,7,"The University of Granada Ethics Committee approved all experimental procedures. The experiment began by removing water bottles 24 hours before and allowing the rats to adjust to a deprivation schedule for three days. Each day, rats were randomly assigned to either an almond or water group and given access to the corresponding liquid for 10 minutes, followed by 30 minutes of free water access twice a day. After the exposure phase, rats were divided into four groups based on their average almond or water consumption for the conditioning phase.",0
