index_article,index_paragraph,content,label
1,1,"Performance indicators are developed and used worldwide predominantly to highlight the performance of a biological, physical, chemical, environmental, economic or social system (Jakobsen, 2008). In particular, an environmental indicator according to the United Nations (1997) is “an information tool that summarises data on complex environmental issues to show overall status and trends of those issues”. ",1
1,2,"The use of environmental indicators is essential in order to ensure that daily port activities and operations are consistent with sustainable development. In order to evaluate environmental performance of port authorities and to track progress towards continuous improvement, relevant Environmental Performance Indicators (EPIs) may be utilised (Donnelly et al., 2007). In this way, port authorities can demonstrate compliance and continuous improvement through scientific evidence and quantifiable measures.",1
1,3,"The use of EPIs has been continuously encouraged by several port organisations around the world among their members. For instance, in Europe, the European Sea Ports Organisation (ESPO) expressed the importance of identifying EPIs and carrying out environmental monitoring in the ESPOEnvironmental Code of Practice 2003 (ESPO, 2003), and it is also presently in force in the ESPO Green Guide (ESPO, 2012). Other organisations, such as the International Association of Ports and Harbours (IAPH) or the Baltic Ports Organisation (BPO) also promote the use of indicators.",1
1,4,"The identification of performance indicators is strictly related with the environmental aspects of the port. According to ISO 14001 (2015), an environmental aspect is an element of an organisation’s activities, products and services that can interact with the environment. Examples of them are the water discharges, emissions to air, waste generation or noise emissions. Indicators are necessary to control the performance of these aspects, especially those that are significant. For example, in the case of emissions to air, associated indicators could be the concentration of sulphur oxides (SOx) or nitrogen oxides (NOx). Therefore, these two concepts are inter-related. In fact, in any EMS, once the aspects have been identified a set of indicators are required to measure their performance over the time and ensure continual improvement. ",1
1,5,"In order to assist ports in identifying their Significant Environmental Aspects (SEAs), a tool was developed in the framework of the PERSEUS research project (PERSEUS, 2012). It is called Tool for the identification and assessment of Environmental Aspects in Ports (TEAP) (Puig et al, 2015), and it is available online at www.eports.cat/teap. TEAP is connected to the tool presented in this paper, the Tool for the identification and implementation of Environmental Indicators in Ports (TEIP). The results of the aspects obtained in TEAP can be taken directly to TEIP for the compilation of indicators. However, if a port has already identified its own SEAs, it can go directly to TEIP. ",1
1,6,"TEIP tool has been carried out within the EU-funded project PORTOPIA: Port Observatory for Performance Indicator Analysis (2013 – 2017). It aims at developing a Service Cloud where European ports can administer their performance, based on selected performance indicators (PORTOPIA, 2014). In this way, port managers will be able to track the annual variations in the performance of their port and to compare with the average of the sector. ",1
1,7,"Indicators are increasingly being developed and used as management tools to address environmental issues (e.g. Belfiore, 2003). The use of indicators is strongly recommended due to several reasons: ",1
1,8,"As seen in the previous bullet points, indicators are very useful for assessing environmental information and solving environmental problems. However, they may also have some challenges and limitations. Examples of them are mainly related to the difficulty of some indicators to describe the state of the environment in just some parameters or the limited data availability. In addition, the sensitivity is another parameter to be considered, since some indicators may vary with short-term environmental changes. ",1
1,9,"However, even considering the foresaid limitations, indicators are key elements of an Environmental Management System (EMS) since they supply quantitative information that allow to verify whether the objective of continual improvement is achieved in an organization (Perotto et al., 2008). There are three main standards widely recognised and implemented among the sector to put in place an EMS: the International Organisation for Standardisation (ISO) 14001 (ISO, 2015), the Eco-Management and Audit Scheme (EMAS) Regulation (EC, 2009) and the Port Environmental Review System (PERS) (ESPO, 2011). The specific information and requirements that these three EMS standards request with regards to indicators were researched and are provided below. ",1
1,10,"According to the ISO 14001 standard, the organisation should establish and maintain a procedure to monitor and measure the key characteristics of its operations that can have a significant environmental impact and a procedure for periodically evaluate compliance with legal requirements (ISO, 2015). The way to do so is through indicators. ISO 14001 does not provide any specification in terms of examples of indicators or methodologies for their implementation. However, there is one concrete standard, ISO 14031 (ISO, 1999) on environmental performance evaluation and belonging to the ISO 14000 family, which provides examples of indicators to be implemented. ",1
1,11,"PERS protocol, the only one specific for ports, also gives importance to the identification of performance indicators, existing one specific clause on this issue. According to PERS (ESPO, 2011), the port should identify from five to ten EPIs relevant to the major environmental aspects and to the policy of the port in order to facilitate monitoring of the environmental performance. The standard provides around 20 examples of environmental indicators likely to be monitored in port areas. ",1
1,12,"It was observed that the three standards require the use of environmental indicators, including, some of them, examples of indicators that may be adopted by port authorities. However, any standard provides a method on how each port should select its indicators. For this reason, a research was conducted within the EU port sector on the existing methods for identifying indicators, and it is presented in the following section. ",1
1,13,This section researches on the already existing methods used for the identification of indicators in ports. The methods that have been found are presented below classified in two groups: the methods that have been developed focussed on the whole port sector; and the methods that are used in individual ports. ,1
1,14,"An example of a methodology proposed to obtain a system of indicators in the port sector was found. It is a method that was developed as a result of the research project INDAPORT (2002–2004), which aimed at establishing systems of indicators to implement a sustainable environmental port management (Peris-Mora et al., 2005). The research pathway included the identification of 21 port activities that were applicable to the case study of the Port of Valencia, which were submitted to environmental analysis. Each activity was described through a steps-diagram process, which allowed the identification of inputs and outputs environmental aspects affected by these activities – processes. A cross matrix of aspects and activities permitted the identification of the most relevant impacts from activities. Experts’ panel was used in order to find out which were the most significant impacts. Finally, as a result of the described methodology, 17 selected port system indicators were provided. Examples of indicators provided by the INDAPORT project were the ‘Total annual greenhouse gas (GHG) emissions’ or the ‘Total annual water consumption’.",1
1,15,"A research on the current methodologies used in ports to identify indicators was also carried out. The sample considered 51 EU ports, 39 non-European ports, 13 port operators and 17 marinas. Within the sample of the EU port authorities, the research demonstrated that a large number of ports publish the list of indicators that they use (37 out of 51); however, just a few explained the origin of these indicators (10 out of 51). In all these 10 cases, the sources of the indicators were standardised lists of indicators, such as the ones provided by the Global Reporting Initiative (GRI, 2013) or by the EMAS standard (EC, 2009). ",1
1,16,"In the non-EU port authorities, the results were less encouraging. Although 26 ports published the list of indicators, only one port provided the source (GRI guidelines) and the resulting indicators. With regards to port operators, 38.5% of them provided the list of indicators and 30.8% the source, being this the list of recommended indicators by GRI and EMAS. In terms of marinas, there was a higher percentage (47%) of ports that published both the indicators and the source, being the EMAS standard (EC, 2009) the source of all marinas. ",1
1,17,"In any case, neither in EU ports nor in non-EU ports, any example was found having a methodology for identifying indicators. ",1
1,18,"In the previous sections of this paper, the benefits and importance for identifying environmental indicators have been detailed. Several reasons have been provided which demonstrate that they are key elements of the whole environmental management of a port. As mentioned before, ISO 14001, EMAS and PERS specifications determine that indicators should be used to assess the environmental performance. However, since each organisation has its own characteristics and distinctive features, the standards do not establish a common methodology for their identification and assessment. Some examples of EPIs are provided by the standards, although the final decision relies on each individual port, in accordance with their significant aspects. ",1
1,19,"In the research of the existing methodologies in the sector, only one procedure was found explaining how to create a system of indicators. In addition, the research demonstrated that this procedure is currently no longer used by ports. The research on individual ports made evidence that a wide range of ports use EPIs, but just a few explained the reason for using that set of indicators. ",1
1,20,"In addition, the European Port Industry Sustainability Report 2016 revealed that 66% of the respondent ports have identified environmental indicators to monitor trends in environmental performance (ESPO, 2016). Nevertheless, when ports were asked to name the environmental indicators used, the responses provided almost 100 different indicators. This wide range of indicators means that although ports are becoming increasingly aware of the benefits of using environmental indicators, there is not a common approach as to which indicators adopt. If ports are not using a procedure to identify indicators, it may well be that the selected indicators are not the most appropriate. ",1
1,21,"These reasons have contributed to identify the need for the creation of a common method that assists ports in identifying indicators in a more reliable manner. As mentioned before, even if each port is different, having a standard methodology that can provide specific results for each port is desirable to mutual advantage of sector and individual ports. As a consequence, an interactive tool has been created aiming at proving a set of performance indicators especially selected for the port user and which is based on the Significant Environmental Aspects (SEAs) of the port, as well as other port characteristics. The method has been developed specifically for the port sector and it is valid and publicly available for any port authority, including sea ports and inland ports. The development of the tool is explained in the following section. ",1
1,22,"An extensive research was carried out in order to identify and compile a very broad inventory of EPIs that are being used and reported in the industrial sector, with especial emphasis to the port sector. A vast list of references was researched and each single new indicator that was identified was considered for the study, gathering a total number of 1279 indicators. However, after analysing all of them, a final inventory of 648 indicators was obtained, excluding repetitions. It may be considered as the largest compilation of environmental indicators for the port sector that is known. Eleven different sources of information were used (including the outcomes of research projects or the results of the ESPO Environmental Questionnaire), obtaining in each one the number of EPIs provided in table 1, listed in descending order. ",1
1,23,"The inventory of 648 environmental indicators was classified under nine categories of indicators. On one hand, it was seen that most of the indicators could fit in the seven categories of environmental aspects that were previously defined in the development of the TEAP tool (Puig et al, 2015). These categories of environmental aspects were identified after a deep research on the existing environmental aspects in ports. The research included ports’ websites, ports’ environmental or annual reports, and EMS reports (involving mostly PERS and EMAS Declarations) of port authorities and terminal operators. On the other hand, it was seen that there were two types of indicators that did not fit to any of those seven categories. For this reason, two more groups were created: the environmental management and the port development indicators. As a result of that, all the indicators were classified accordingly to the nine established categories, as shown in table 2. ",1
1,24,"Since a large number of indicators were obtained, almost 650 different EPIs, it was found necessary to filter this large set to a shorter list, more suitable to be potentially applied in port areas. In order to carry out this filtering process in a methodological way, each indicator was assessed through a set of criteria. Then, the indicators that complied with more criteria were selected and the ones that obtained a poor performance were rejected. ",1
1,25,"From this 11 sources, a set of 84 different names of criteria used to assess performance indicators was obtained. By analysing them, it was found that although some of them were written differently, the concept and the meaning was the same or, at least, similar. For this reason, the criteria that had the same purpose were grouped under the same name. This process allowed the reduction from the 84 criteria identified in the sources until the final number of 11 criteria. These criteria were applied in two phases, since the criteria of the first filter were considered to be more generic and applicable to all indicators, and the criteria of the second filter were considered to be more specific. In this case, a previous research on the indicators’ characteristics was needed. Table 3 shows the criteria applied in the first and second filter. ",1
1,26,"The filtering process consisted of three steps: i) the first filter, ii) a regrouping of the indicators and iii) the second filter of the indicators. ",1
1,27,"The first filter consisted of analysing the complete broad list of indicators that were compiled. The evaluation of the indicators against the five criteria was carried out by three researchers, with the objective of applying the filter in a contrasted way. These researchers were coordinated by a supervisor, who ensured that they had the same understanding of the criteria and punctuation. Several internal meetings were held during the filtering process with this purpose. ",1
1,28,"As shown in the example of table 4, if the indicator met a criterion, it was coloured with a green dot and if it did not comply, with a red dot. It was considered that an indicator was accepted by an evaluator when the result of the division between the accomplished criteria (green dot) and the total number of evaluated criteria was higher than 0.5. In other words, since in this first filter all the five criteria were applied, the indicators that met three or more criteria were accepted. A green tick () indicates that the evaluator accepted this indicator, and a red cross () that the indicator did not pass the first filter. All those indicators that were selected by at least two of the three evaluators were accepted. If there was only one green tick or any of them, then it was rejected. ",1
2,1,"It is well known that several reports on the common educational problems of nuclear chemistry have been prepared by certain groups of experts from time to time. According to very important statements in these reports, nuclear chemistry and related courses generally do not take sufficient importance in undergraduate chemistry curricula and it was generally proposed that nuclear chemistry and related courses should be introduced into undergraduate chemistry curricula at universities worldwide. Starting from these statements, an ideal program in an undergraduate chemistry curriculum was proposed to be introduced into the undergraduate chemistry program at the Department of Chemistry, Ege University, in Izmir, Turkey during the regular updating of the chemistry curriculum. Thus, it has been believed that this Department of Chemistry has recently gained an ideal teaching program in the field of nuclear chemistry and its applications in scientific, industrial, and medical sectors. In this contribution, the details of this program will be discussed.",1
2,2,"It is well known that reports on the common educational problems of nuclear chemistry have been prepared and distributed worldwide either as hard copy or in electronic copy form by certain groups of experts from time to time. In this context, two important reports have been prepared in recent years. The first one was published by the International Atomic Energy Agency (IAEA) at the end of 2002 with the title “Assessment of the teaching and applications in radiochemistry” following an experts meeting which was held between 10–14 June 2002, in Antalya, Turkey.1 The second one was prepared and electronically distributed by the Presidential office of the International Nuclear Chemistry Society (INCS) with a title “Round table discussion panel report” following the 1st International Nuclear Chemistry Congress which was held between 22–29 May 2005 in Kusadasi, Turkey.2 These and other similar reports obviously indicate a basic statement on the global teaching problems of nuclear chemistry in undergraduate chemistry curricula which are applied by departments of chemistry at different universities worldwide in both developed and developing countries. Especially, according to the round table discussion panel outcome report of the INCS, the most important statements which were briefly outlined are given below:",1
2,3,"The academic chemistry curricula should include courses covering basic nuclear chemistry knowledge and the principles of its scientific and industrial, especially medical, application techniques.",1
2,4,"In most countries including industrialized and developing countries the chemistry curricula offered at undergraduate levels do not take sufficient consideration of the basic courses and laboratory studies on nuclear chemistry in their undergraduate programs and as an unavoidable reflection, graduate level students do not show enough interest to research areas requiring a basic knowledge of nuclear chemistry and its applications; this has resulted in a significant drastic decline in availability of the number of qualified professionals in the nuclear chemistry field in the recent decades.",1
2,5,"If the sad situation as outlined above in chemistry curricula continues, it will also not be possible to find qualified teaching stuff including professors to teach the required courses in universities worldwide in the near future. For this reason, the decline should be reversed as soon as possible by revising existing curricula to include basic nuclear chemistry courses and laboratory studies in undergraduate chemistry programs.",1
2,6,"Starting from the very important statements given above, it was proposed that a nuclear chemistry teaching program in an undergraduate chemistry curriculum introduced into the undergraduate chemistry program at the Department of Chemistry, Ege University, in Izmir, Turkey during the regular updating of the chemistry curriculum. Thus, it may be believed that this Department of Chemistry has recently gained an ideal teaching program in the field of nuclear chemistry and its applications in scientific, industrial, and medical sectors. The basic courses which were introduced into the chemistry curriculum are given below:",1
2,7,This course is also an elective course and is given in the 2nd semester of the 3rd year to be 2 hours per week. This is for students who have a detailed knowledge of Nuclear Chemistry and have laboratory experience and still wish to obtain more detailed information on other specific topics of Nuclear Chemistry. A sufficient number of students have also chosen this course.,1
2,8,"A similar program on nuclear chemistry is obviously recommended to be introduced into all chemistry curricula applied in different universities worldwide. Thus, the motivation of students for the field of nuclear chemistry will consequently result in the increase of interest of the young generation in all branches of nuclear sciences and technology worldwide in the future.",1
3,1,"It is extremely appropriate that the International Year of Chemistry, which was celebrated throughout 2011, comes right in the middle of what the United Nations declared as the “Decade of Education for Sustainable Development”.1 An incredibly complex set of interconnected challenges, sustainability encompasses issues as diverse as water quality, climate change, renewable energy, personal and national security, food production and safety, combating diseases with new diagnostics and drugs, new materials, and more efficient chemical manufacturing. Over the past few years, I have followed discussions of the grand challenges in chemistry and have been struck by how many of these challenges are directly connected to sustainability.",1
3,2,"There is another dimension to the incorporation of sustainability into chemistry education. The ACS Guidelines and Evaluation Procedures for Bachelor’s Degree Programs6 states that, as part of developing student skills in ethics, “[S]tudents should conduct themselves responsibly and be aware of the role of chemistry in contemporary societal and global issues.” That awareness of chemistry’s role in contemporary issues is reflected in another ACS document that has been around for many years, The Chemical Professional’s Code of Conduct.7 Within that code of conduct are statements regarding the responsibility of chemical professionals to the public and to the environment",1
3,3,Chemical professionals have a responsibility to serve the public interest and safety and to further advance the knowledge of science.,1
3,4,Chemical professionals should strive to understand and anticipate the environmental consequences of their work. They have a responsibility to minimize pollution and to protect the environment.,1
3,5,"These statements connect very easily to a model of professional education developed by William M. Sullivan,8 who described three apprenticeships that make up the education of any professional",1
3,6,"Sustainability, more so than any other context I can identify, has the potential to serve as an effective framework for engaging students simultaneously in more than one of these apprenticeships and thereby connecting undergraduate chemistry education to The Chemical Professional’sCodeof Conduct.",1
3,7,"An apprenticeship that “teaches the skills and traits, along with the ethical comportment, social roles, and responsibilities, that mark the professional ... the novice is introduced to the meaning of an integrated practice of all dimensions of the profession, grounded in the profession’s fundamental purpose.”",1
3,8,"While I know that many chemistry educators have desired to incorporate a global issue like sustainability into their courses, one of the great obstacles for a number of years has been a lack of resources that can easily be used. Very few chemistry teachers I have methigh school or collegehave the time to go digging through the primary literature to find examples and ideas of how sustainability could be incorporated as an intriguing question or problem to drive the learning of chemical concepts. Fortunately, more curricular resources linking chemistry to sustainability are now available. This Journal, for example, publishes environmentally focused articles and supports educators in celebrating Earth Day on April 22. Recycling is the theme of Chemists Celebrate Earth Day in 2012. National curricular reform projects like the NSF-funded Science Education for New Civic Engagements and Responsibilities9 have made available information on model courses through their Web sites. ACS launched in August 2011 a sustainability gateway within the ACS Web site10 that provides a convenient way for members to explore sustainability related resources; one of the major sections of the Web site is focused on education.",1
3,9,"The importance of sustainability to chemistry and chemistry education is clear, the connections are real and significant, and more resources are available now than any time before. The challenge is for each of us as chemistry educators to find ways to bring that connection and context into our courses.",1
4,1,"“Chemistry versus Ecology” – this report title has not been chosen by chance. An average human and even sometimes a scientist is sure that Chemistry and Ecology are opposite to each other. But is it true indeed? To answer this deep question, first of all, the detailed definitions are to be given.",1
4,2,"What is Chemistry? It is the science about chemical reactions, but also about the composition, structure and chemical properties of the substance. The aphorism given above proves chemistry to be a fundamentally important science, which studies the matter surrounding us. However, along with the very significant progressive constituent (new technologies and methods) chemistry has a strong negative impact that is manifested through the destruction of the environment by pollution. In addition, the fight between Chemistry and Ecology is considered inevitable, because any chemical substance, when its maximum admissible concentration is reached, can become a matter of serious environmental concern. In this case, a question appears: how this problem is to be faced?",1
4,3,"Ecology is the main scientific area dealing with the problem mentioned above. Everyone knows that it is ecology that detects and warns about the environmental problems. But what does Ecology mean? The definition is the following: ecology is a science, which studies the influence of living organisms to each other and their natural environment (by Ernst Haeckel). Ecology emerged as a distinct discipline at the turn of the 20th century; the relationship between a living organism and its environment had been explained in 1843 by German chemist Justus von Liebig, taking as an example the relations “plant-soil”. However, the notion “ecology” is much older, originating from the era of ancient thinkers. The first “ecologist” has been considered Aristotle or perhaps his student, Theophrastus (the latter has described the interrelationships between animals and their environment as early as in the 4th century B.C.).",1
4,4,"Nowadays, when practically all the scientific fields overlap with each other, many interdisciplinary areas of ecology appeared. It should be noted that the current difficult ecological situation caused the appearance of the following areas: geographical ecology, physics of the environment, mathematical ecology, genetic ecology, spiritual ecology and many others. Why do so many sciences contact with ecology? Probably because ecology examines the most important phenomenon - the interaction between living organisms and the environment they live in, this notion meaning to an even greater extent healthy lifestyle, a form of friendly relations, a process of purification, the actions, which are opposite to pollution. As soon as these problems can have different impacts, the more complex approach is needed.",1
4,5,"Coming back to the topic of the apparent opposition of chemical and ecological studies, the attention should be focused on the sciences which appeared on their border.",1
4,6,"Ecological chemistry is developing quite intensively in recent years at the scientific and educational level. The worldwide known Universities and even colleges had set up the departments to educate the young experts in Ecological Chemistry. Many institutions in the USA, Canada, Germany, Sweden, Norway, Poland, Russia, Kazakhstan, Ukraine, Belarus, China, South Africa and many other countries are based on chemical knowledge as the main scientific priority in solving countries’ environmental problems.",1
4,7,"A prodigious scientific activity in ecological chemistry has starter about three decades ago. Then, in the 80s of the past century, on the border between chemistry and ecology a new direction called ecological chemistry has emerged. It came to reveal the chemical aspect of environment interaction with living organisms. The ecological chemistry has found supporters and promoters in different countries. This fact led us to organize in 1985 the First International Seminar on ecological chemistry in Chisinau. In 1992, the Department of Industrial and Ecological Chemistry has been set up at the Faculty of Chemistry and Chemical Technology of Moldova State University, being the first one in Moldova specialized in ecological chemistry and environmental protection, which began to prepare doctoral students in the Environmental Protection and Rational Use of Natural Resources areas.",1
4,8,"The first textbook on ecological chemistry was edited in 1994 and subsequently translated in three languages. In 1991, the Research Centre of Applied and Ecological Chemistry (RCAEC) was established, comprising four scientific laboratories. The research performed at the department, at the RCAEC’s laboratories, was dealing with the chemistry and technology of industrial processes and treatment of water and wastes and was crowned with important elaborations.",1
4,9,"The 20th anniversary of the department’s formation is marked this year. During its growth and development, the department staff has been making the Chemistry students think “ecologically”. Actually, among the brightest realizations of the department is the significant number of students and publications. More than 20 monographs and manuals, 11 didactic materials for theoretical courses, 15 handbooks for laboratory works and approximately 500 scientific articles in the field of ecological chemistry and environmental protection were published; 130 patents for inventions were obtained. The titles of the main scientific monographs are highly suggestive, regarding the complexity and actuality of the problems discussed. They are the following: “Environmental redox-processes” (2001), “Ecological Audit”(2002), “Combustion technologies and reducing the air emissions” (2002), “Natural waters’ pollution and self-purification processes” (2002), “Environmental issues in power engineering” (2003), “Ecologically pure wine industry” (2004), “The hydrochemistry of small rivers” (2004), “Environmental economy” (2005), “Wastes management” (2006), “The fundamentals of winery wastes treatment” (2007), “Ecological chemistry of nitrates, nitrites and N-nitrosamines” (2009), “ENOXIL – an ecological preparation for plant protection” (2010), “Secondary wine products” (2011).",1
4,10,"Only the professional staff is working at the department (28 persons), including academician - 1, professors - 6, associate professors - 8, superior lecturers - 8, assistant lecturers - 5. The number of students is the following: license students (courses I, II, III) – 234, master students – 69, doctoral students – 8. 120 foreign students graduated from the department during the period of its activity as well. It should be mentioned that in 2008-2009 academic year the specialty entitled Ecological chemistry and environmental protection (master and doctorate studies) at the Department of Industrial and Ecological Chemistry of the State University of Moldova has been introduced.",1
4,11,"Thus, the department had played an important role in the development of ecological chemistry and environmental protection in the Republic of Moldova and reached a very honorable position in this scientific area.",1
4,12,"The educational aspect of Ecological Chemistry in Moldova is represented not only by the State University of Moldova (SUM), but also by the University of the Academy of Sciences of Moldova, “A. Russo” State University, Bălţi and Tiraspol State University, where not only the special courses are delivered, but the research laboratories and entire research centers work as well.",1
4,13,"Nevertheless, the fundamental research in the ecological chemistry area is carried out mainly in two major institutions – the Research Center Applied and Ecological Chemistry of SUM and the Institute of Chemistry of ASM.",1
4,14,"A bright example of Ecological Chemistry promoting is the state program entitled “Water Quality Management and Research”, where the chemistry and ecological condition of water sources have been studied under the several research projects.",1
4,15,"Starting with the fundamental research in this direction, we will pass to the project entitled “SELF PURIFICATION OF SURFACE WATER” supervised by dr. Viorica Gladchi that deals with the Catalytic redox processes in natural water.",1
4,16,The reducers are among the participants in the redox process in water: autochthonous substances - resulted from metabolism and decomposition of hydrobionts; allochthonous substances - substances that penetrate the aquatic environment together with atmospheric precipitates or wastewater. Copper and iron are metals having the great importance for redox transformations and can be found in water in catalytic concentrations.,1
4,17,"The transformations of nitrogen compounds were studied by Prof. Maria Gonta under the project “NITRATES, NITRITES AND NITROSOAMINES”. The scheme of oxidation and reduction of nitrites and nitrosoamines in water, food and living organisms was elaborated. The mechanism of nitrites reduction in the presence of various antioxidants, that caused the decrease in oncology maladies at people of different age was proposed. This research was carried out in cooperation with the Nebraska Cancer Center (dr. Irina Stepanov, USA).",1
4,18,"Under the project “PSEUDO JAHN-TELLER INSTABILITY OF HIGH- SYMMETRY PROTONATED WATER CLUSTERS” leaded by m.c. Ion Geru, the new experimental data on the different energy of H2n+1On + systems decay, and those referring to the spatial dimensions of non-homogenates in the water hydrogen bonds’ network were obtained. This fundamental research has a prospective application, especially in water purification from heavy metals. The brightest result of this project is that the 65th water anomaly has been found – it consists in the diffusion indices increase in the case of Ca2+ ions concentration increase.",1
4,19,"Even if this is not the first priority area of ecological research in Moldova, some research have been carried out in this field. For example, the theoretical study, carried out by dr. Natalia Gorincioi „RADICAL REACTIONS IN THE ATMOSPHERE”, had to examine the diversity of hydroxyl radical reactions in the atmosphere, the legitimacies of photochemical smog and PAN compounds formation, both of them being severe irritants to eyes, and having phytotoxic effect. The presence of the strongly reduced carbon (CH4) in a strong high-energy oxidant (stratosphere: O3, O2, hν) has been determined; consequently, methane at high altitudes increases the concentrations of hydroxyl and water radicals. The ways of PAN (peroxyacetylnitrates) decomposition were also studied (reverse process, photolysis, thermal degradation, reaction with OH-radicals).",1
4,20,"The wastes include all the objects or substances which the holder discards, intends to discard, or is legally obliged to discard, i.e. all the unwanted or useless material. Wastes may be classified according to their origin, their properties, how hazardous they are, and how they may be sorted, recovered or treated.",1
5,1,"It is fair to say that in the current climate, the concept of click chemistry (CC)perhaps requires no introduction. Most organic chemists are familiar with the term, but for many, the original meaning and philosophy have been misplaced. When the topic of click chemistry is discussed, some immediately think of the CuI-catalysed Huisgen cycloaddition as a synthetic ideal, others might consider polymer synthesis, whilst others may think of enzyme-catalysed templated reactions. Therefore, it seems pertinent to begin by reiterating the original definitions as originally laid down by the orchestrators of the concept, namely Sharpless, Finn, and Kolb.[1] It is worth remembering that the impetus behind defining the philosophy was the bleak reality that the estimated number of ’reasonable’ drug candidates—those with fewer than 30 non-hydrogen atoms; with mass < 500 Da composed of only H, C, N, O, P, S, F, Cl and Br; and that are likely to be stable at ambient temperature in the presence of water and oxygen—is on the order of 1062 molecules. Faced with this fact, it might seem clear that synthetic propositions aimed at drug discovery should be aimed at molecules that are easy to make. ",1
5,2,"The question heading this section was originally posed by Barry Sharpless himself at a recent conference in Berlin.[2] The answer, perhaps, is not much. Whilst CC was originally pitched as a concept to assist medicinal chemists in overcoming combinational chemistry issues, many of the publications exemplifying CC are those from materials science. The eagerness of this community to adopt CC strategies for the synthesis of polymers, dendrimers, etc., seems to reflect the attitude of ’why bother making things overcomplicated?’ Essentially a restatement of CC, the attitude is exemplified by numerous publications wherein the high-yielding reliability of the CuI-catalysed Huisgen reaction is used largely to overcome problems of low reactivity on polymer or dendrimeric scaffolds. Alongside are the medicinal chemists who choose to adopt the CC strategy, of which a brief account lies herein. Some are continuing in combinational chemistry applications, whilst others are using CC in the realisation of novel ideas which, before reliable and thermodynamically driven click reactions became available, were ill-advised. This review is intended to highlight both aspects of the union of CC and medicinal chemistry. However, this is by no means a comprehensive account of CC, and we direct the reader to related and complementary reviews in the field of CC.",1
5,3,"A final point before uncovering the medicinal applications is to address the issue of CC versus the CuI-catalysed Huisgen reaction. It is important to remember that CC was originated before the evolution of the CuI catalyst modification of the Huisgen cycloaddition, and that there are other examples of reactions that meet the CC criteria, including mainly olefinbased reactions. However, the CuI Huisgen reaction is currently the ’cream of the crop’, and this is correspondingly reflected in the literature to the extent that this reaction is sometimes interpreted as CC in its entirety.",1
5,4,"One of the original aims of CC was to provide an alternative to solid-phase synthesis, the popularity of which was accounted by Sharpless et al. as being derived from the allowance of “reactions that fall short of ’click’ status to be employed as click reactions”.[1] High yields and simple purification are available by using high excesses of reagents and washings as opposed to conventional chromatography. The CC alternative was intended to allow large-scale solution-phase library synthesis using reliable chemical processes. Numerous groups were drawn to this alternative, and some examples of successful library synthesis are given herein. Kolb and Sharpless[4] highlight the work by researchers at Lexicon Pharmaceuticals who effected a solution-phase library synthesis using numerous CC reactions to afford 200 000 individual compounds of acceptable purity on the 25–50-mg scale. Synthesis was initiated with noncommercial building blocks synthesised on a large scale. These starting materials included epoxides and aziridines ready for click nucleophilic ring opening to give 1,2-difuntionalised compounds. Imidoesters gave five-membered aromatic heterocycles from base-catalysed 1,3-dipolar cycloaddition with b-ketoesters, whilst 3-aminoazetidines gave nonaromatic heterocyclic libraries. ",1
5,5,More recently Xie and Seto[5] synthesised a library of protein tyrosine phosphatase (PTP)inhibitors. Their approach started with the short synthesis of the a-ketoester azide compound 2 shown in Scheme 1.,1
5,6,"In many CC library syntheses, it is fair to say that the ratelimiting steps are those preceding the final click reactions, that is, building-block synthesis. Since the widespread use of the CuI-catalysed Huisgen reaction, there have been notable advances in methodologies for the synthesis of azides. Often perceived as problematic, recent synthetic developments in azide synthesis have often been coupled with CC to give one-pot processes that circumvent the isolation of the azide building block intermediate. Examples include the use of TfN3 as a diazo transfer reagent by Wittmann and co-workers,[6] the use of microwave irradiation to effect the synthesis of 1,2,3-triazoles via a three-component reaction reported by Van der Eycken and co-workers,[7] and also our own work using aprotic diazotisation and TMSN3 to generate aromatic azides and the resultant ’click’ cycloaddition products from the corresponding aniline derivatives.[8] These in situ protocols may offer some relief to the so-called ’azido-phobia’, experienced by some!",1
5,7,"The aforementioned examples demonstrate the application of CC to decorate complex natural product frameworks with unnatural function, thus acting as an extremely powerful ligation tool. Some of the ’click’ analogues generated from these products are shown in Figure 4. Sun, Wang, and co-workers[14] synthesised a handful of bisdaunorubicins with linkers of varying length by using the CuI-catalysed Huisgen reaction between complementary alkyne- or azide-functionalised daunorubicins, or bisacetylene- or bisazide-functionalised linkers (phenyl and PEG)to generate compounds such as 13 (Figure 5), which display differential anticancer properties towards leukaemia K562 cells, depending on the linker length and flexibility between the two intercalators.",1
5,8,"Others, not giving up on solid-phase combinatorial synthesis altogether, saw the CC approach to library synthesis in a slightly different light. The reliable chemistry has been used in the development of triazole-containing linkers[16] and as a traditional solid-phase reaction. Recent examples include the work of Gmeiner and co-workers,[17] who employed pyrrole-2-carbaldehyde functionalised at the N-indole atom with a propargylic handle, which ’clicked’ onto an azide-functionalised resin with complete loading. The aldehyde handle was then used to synthesise a focused library of compounds, some of which displayed high binding affinities to dopamine D3 and D4 receptors (Scheme 3). The same research group had previously reported the use of the Huisgen reaction in the design of both the linker and the functionalisation of solid-phase-bound alkynes to generate a library of N-benzyltriazole carboxamides, some of which had nanomolar affinities towards G-proteincoupled receptors.",1
5,9,"Yao and co-workers synthesised a library of bidentate inhibitors of protein tyrosine phosphatases.[20] Previous studies had indicated that peripheral binding to a second site could increase the potency and selectivity of compounds. Using this knowledge the group selected a known core binding moiety, synthesised a handful of alkyne-substituted variants of this core group (Figure 6), and then coupled them with a number of aryl azides to generate the final compounds. The library screen identified a specific PTP1B inhibitor with moderate inhibition similar to Abbott’s original basis molecule. The same group also synthesised a library of matrix metalloprotease (MMP)inhibitors using an identical strategy, this time combining eight alkyne zinc binding succinyl hydroxamates with 12 azide fragments to give a library of 96 compounds,[21] some of which displayed good potency and moderate selectivity for MMP-7 over other metalloproteases.",1
5,10,"In their aforementioned convergent library synthesis, Yao and co-workers were able to screen their compounds for testing directly from the reaction mixture without the need for further purification.[20] Wong and co-workers have described two examples in which they successfully used the CuI-catalysed Huisgen reaction in library synthesis and followed this by screening the compounds in situ. In their realisation of inhibitors of human a-1,3-fucosyltransferases (Fuc-Ts), with little structural data available, they first identified the importance of the binding energy derived from the guanosine diphosphate (GDP)moiety of the GDP-fucose cofactor, and then synthesised a GDP core decorated with alkyne functionality (compound 15, Figure 7).[23] This core was then treated with a library of 85 azide molecules in individual wells of a microtiter plate under CuI catalysis conditions. The GDP triazole compounds were screened for inhibitory effects against Fuc-T directly in the plates. The best performing compound 16 showed inhibition that was an 800-fold improvement over the original alkyne GDP fragment (62 nm versus 47 mm). As a tribute to this technique, 16 is the first nanomolar inhibitor of Fuc-Ts. The same research group also used the in situ screening technique in the discovery of HIV-1 protease inhibitors.",1
5,11,"Irreversible/kinetic target-guided synthesis (under which the banner of in situ CC falls)effectively offers the same overall outcome, in that an enzyme selects its favourite inhibitors from a potential library. In the irreversible approach, however, the library is not synthesised by DCC; here the enzyme selects its favourite inhibitor by synthesising it itself. This approach to in vitro combinatorial chemistry has been previously attempted by different groups, employing different connecting reactions and strategies. Benkovic, Boger, and co-workers have described the tight binding of a reactive inhibitor to the enzyme active site after an enzyme-templated epoxide opening reaction with a nucleophilic site on the substrate.",1
5,12,"The use of CC for irreversible target-guided synthesis was pioneered by Sharpless et al. Despite the extremely slow rate of the Huisgen reaction at room temperature, Mock et al. had previously demonstrated that sequestration of azide and alkyne fragments inside a cucurbituril template dramatically increased the rate of cycloaddition.[27] It should also be noted that an enzyme target stabilises the transition state of a targetaccelerated reaction; a product-like transition state is necessary if the accelerated products are to be successful inhibitors. Therefore, cycloaddition reactions in which the transition state does indeed reflect the structure of the product are ideal. A strategy based on the Huisgen reaction involving both azide and alkyne building blocks would elude the use of reacting species that are nucleophilic and electrophilic and consequently prone to undesired reactions with biological molecules. Encouraged by these facts, Sharpless and co-workers set about a proof-of-principle experiment involving the use of acetylcholinesterase (AChE)as their ’reaction vessel’ (Figure 8 . )[28] This enzyme was chosen because of the availability of established inhibitors, it is known to bind both the active centre and a peripheral site, and the fact that inhibitors that span both the active centre and the peripheral site show tighter binding than the individual fragments.",1
5,13,"A technical advance in the in situ approach has been the incorporation of the existing in situ bCAII library designed by Sharpless et al. into a microfluidic chip device, an accomplishment achieved by Kolb, Tseng and co-workers.[30] The microfluidic chip device greatly decreases the quantities of reagents required, and operates at reaction volumes of approximately 4 mL. In this particular application, this means that much smaller quantities of enzyme are required. The microfluidic chip is capable of carrying out 32 reactions in parallel. It was shown that when identical azide fragments from the original study were mixed with the acetylene anchor with an incubation time of 40 h, the microfluidic chip gave a very similar outcome to the original study. Thus the advantages of the in situ approach to lead discovery can be coupled with the use of a microfluidic chip, incorporating the advantages of low reagent consumption, precise control over reaction conditions, faster reaction kinetics, and cost efficiency to make the process potentially even more efficient.",1
5,14,"The majority of this review has been concerned with displaying the work achieved based on the original intention of CC, that is to assist the medicinal chemist. However, we now focus our attention away from big libraries and high-throughput screens of combinatorial chemistry and take a brief look at the effect that CC has had on other aspects of medicinal chemistry. Not discussed herein, but well covered elsewhere, a CC approach with the CuI-catalysed Huisgen reaction has proven very useful in the conjugation of biomolecules to one another, for example in the synthesis of glycoconjugates and appending molecules to other proteins and DNA templates.",1
5,15,"We have discussed numerous arenas in which CC is emerging as an extremely useful tool for the medicinal chemist. In the chemistry discussed in the final section of this review, natural product funtionalisation and bioisosteric replacement of functionality in natural products and drug targets unlocks a wealth of potential applications in drug discovery.",1
5,16,"This review examines how the application of CC has evolved since its original conception, and as new applications continue to appear, we can assume that this trend towards increasing diversity of application will continue. With the discovery of new reactions that meet ’click’ status, the horizons will be expanded even further.",1
6,1,"Molecular cages with large internal voids are best synthesized by assembly of multiple building blocks under thermodynamic control. To connect the building blocks, metal–ligand interactions are commonly employed.[1] The resulting coordination cages have found numerous applications. For example, they can be used as nanoreactors for chemical transformations, as delivery agents for anticancer compounds, or for the stabilization of highly reactive guest molecules.",1
6,2,"The assembly of purely organic cages can be achieved using dynamic covalent chemistry.[2–6] Along these lines, imine condensations have been most widely used to date,[3] but the syntheses of cages based on boronic ester condensations,[4] thiol–disulfide exchange reactions,[5] or olefin metathesis[6] have also been described. Metallasupramolecular chemistry has been successfully merged with dynamic covalent chemistry by performing imine condensations in the first coordination sphere of metal ions.[7] This approach has proven extremely robust due to the resulting mutual stabilization of both the metal complex and the imine bond.[8] Fascinating recent results include the stabilization of molecular P4 within a coordination cage,[9] and the synthesis of a Borromean ring and a Solomon knot.",1
6,3,"Our group is interested in synthesizing complex molecular architectures by combining metallasupramolecular chemistry with dynamic covalent chemistry in an orthogonal fashion. Recently, we described a first success in this direction: a 52membered macrocycle was obtained by the concomitant formation of reversible imine, boronate ester, and rheniumnitrogen bonds.[11,12] Herein, we describe how the polycondensation of triamines with metallamacrocyclic building blocks, containing pendent aldehyde groups, has enabled the facile synthesis of several new nanoscopic cages.",1
6,4,"The high percentage of solvent-accessible volume in crystalline 4a prompted us to investigate whether a material with permanent porosity could be generated.[3a] N2 sorption measurements were performed at 77 K with a sample of crude amorphous 4a, and also with a sample of an X-ray-quality crystalline product, after prolonged drying in vacuum. The calculated Brunauer–Emmett–Teller surface areas were 30 and 15 m2 g1 for the amorphous and dried crystalline products, respectively, which indicates that larger voids between the cages are no longer present, presumably because of a structural collapse during the drying process. This conclusion is further supported by the poor match between the powder X-ray diffraction pattern of dried crystalline 4a with that calculated from the single-crystal diffraction data (Supporting Information, Figure S2).",1
6,5,"In conclusion, the work described herein provides evidence that remarkably large and complex structures can be obtained by combining metal–ligand bond-forming reactions with imine condensations in an orthogonal fashion (that is, the imine bond is not formed in the coordination sphere of the metal). The approach to connect metallamacrocycles by dynamic covalent chemistry complements existing strategies for the bottom-up assembly of molecular nanostructures, and it should be applicable to a variety of other structures.",1
6,6,"Diffusion of Et2O vapors into solutions of 4a and 4b in CHCl3/MeOH (95:5) resulted in the growth of large, wellshaped single crystals, which despite appearances diffracted X-rays rather poorly. A satisfactory data set was nonetheless obtained for a crystal of 4a[17] whose the structure was solved in I2/a, an alternative setting of the monoclinic space group C2/c. The solid-state structure of 4a is shown in Figure 1. The complex displays approximate tetrahedral symmetry (T), which is in line with the simple NMR spectra observed in solution. The trinuclear metallamacrocycles occupy the four vertices, whilst the triphenylmethane units span each of the four faces. Notably, within a given molecule, all four metallamacrocycles have identical relative configuration with respect to rotation about the pseudo threefold axes that connects each vertex with its opposing face (Figure 1 a). The crystal as a whole is, however, racemic and thus contains an equal number of opposite stereoisomers.",1
7,1,"The Royal Swedish Academy of Science has awarded several Nobel Prizes in Chemistry to scientists making groundbreaking contributions to theoretical and computational chemistry over the years. Linus Pauling was awarded a Nobel Prize in 1954 for his research into the nature of the chemical bond. In 1966, the Academy awarded Robert S. Mulliken a Nobel Prize for fundamental work concerning chemical bonds and the electronic structure of molecules determined by the molecular-orbital method. In 1981, the Nobel Prize in Chemistry was shared by Kenichi Fukui and Roald Hoffmann for their theories concerning the course of chemical reactions. Rudolph A. Marcus received the 1992 Nobel Prize for his contributions to the theory of electron-transfer (ET) reactions in chemical systems. The last Nobel Prize for work in theoretical and computational chemistry was awarded in 1998 and divided equally between Walter Kohn, for his development of density functional theory (DFT), and John A. Pople, for his development of computational methods in quantum chemistry.",1
7,2,"The Academy has decided to award the 2013 Nobel Prize in Chemistry to Martin Karplus, Michael Levitt, and Arieh Warshel for the development of multiscale models for complex chemical systems. No doubt, the new Nobel laureates might well borrow Newton’sstatement:“If I have seen further, it is by standing on the shoulders of giants”.",1
7,3,"While in the so-called molecular dynamics (MD) approach one estimates the time-averaged property, the Monte Carlo (MC) technique yields the corresponding ensemble-averaged values. It can be shown that, under the so-called ergodic hypothesis, namely, that every accessible point in configuration space can be reached in a finite number of MC steps from any other point, both averages should be equivalent and represent the observed value of the property considered.",1
7,4,"Simulations, particularly the MC technique, partly emerged from wartime scientific research at some of the US DOE National Laboratories, where the calculations of nuclear cross sections were crucial in the development of thermonuclear weapons. The very first calculations were published in the 1950s.",1
7,5,"The problem is very much like that dealt with more than two centuries ago by Laplace in his celebrated Mécanique Céleste; the main difference is that, in the present case, electromagnetic forces, which are relevant at the microscopic level, replace gravitational forces that govern the macroscopic (celestial) world.",1
7,6,"In multiscale modeling, multiple models at different scales are employed simultaneously to describe a given system. To perform simulations of chemical reactions involving large (complex) biological molecules, the small reactive areas (usually tens of atoms) can be treated at higher (computationally more expensive) theoretical levels (quantum mechanics (QM)) while the chemically “inert” regions (thousands of atoms) are described at the less sophisticated classical molecular mechanics (MM; classical techniques with no wave functions) level (much less computationally demanding), which employs empirically (or semiempirically) parametrized force fields. The resulting multiscale modeling is called the hybrid QM/MM approach.",1
7,7,"The introduction of the QM/MM model to tackle MD simulations in biomolecules was made by Warshel and Levitt in a seminal paper in 1976 on theoretical studies of enzymatic reactions [5]. The whole enzyme–substrate complex was considered, but, although the energy and charge distribution of the atoms directly involved in the reaction were treated quantum mechanically, the rest of atoms, including the surrounding solvent, were represented by classical forces. The same authors also implemented Shneior Lifson’s consistent force field (CFF) in a computer code that was the seed of some of the more popular programs in today’s computational biology, namely, Chemistry at HARvard Molecular Mechanics, developed by the Karplus group (CHARMM), Assisted Model Building with Energy Refinement (AMBER), developed by the Kollman group, and GROningen MOlecular Simulation (GROMOS), developed by the van Gunsteren group.",1
7,8,Figure 1 illustrates the QM/MM approach for the case of the complex (2665 atoms) formed by the interaction of the MMP-2 metalloenzyme (ribbon model) with a peptide substrate (balland-stick model). The structure was taken from a snapshot of an MD simulation using QM/MM multiscale modeling. The QM region (100 atoms) consists of the catalytically active MMP-2 residues and the peptide linkage. The MM region includes 1700 water molecules. The inset in Fig. 1 shows charge density embedding in the QM region obtained by DFT.,1
7,9,"Equation (3) is a combined Coulomb and Lennard-Jones potential, in which qi are atomic charges, Aij and Bij are fitting parameters, and rij are interatomic distances.",1
7,10,"Although the parameters used to define every term in Eq. (2) usually have an empirical or even semiempirical origin, parametrizations based on first-principles (QM) calculations have also been very popular. A good example is provided by the so-called Matsuoka–Clementi–Yoshimine (MCY) potential for water–water interactions (Vwater term in Eq. (2)) developed in the 1970s [6] at the IBM Research Laboratories in San Jose (California).",1
7,11,"In 1985, Car and Parrinello proposed an alternative approach called ab initio (first principles) MD, in which Newton’s equations (Eq. (1)) are solved for nuclei dynamics while the Schrödinger equation, within the DFT formalism, is used to describe the electronic motion [7].TheabinitioMDtechnique is a multiscale modeling technique in which interatomic forces are computed on the fly by using DFT, while the nuclei propagate by obeying classical mechanics. Despite its high efficiency [8], it represents a much more computer-timeconsuming approach than the QM/MM methods.",1
7,12,"As early as 1969, Levitt published articles showing the huge utility of CFF to provide invaluable information on systems of biological interest. In one of those contributions, the first energy minimization of an entire protein structure (myoglobin and lysozyme) was presented [9]. The authors developed a refinement procedure to improve structural information from X-ray diffraction measurements. A second breakthrough consisted of the sequence analysis of tRNA [10]. Levitt used CFF to refine the Cartesian coordinates and proposed a model for tRNA that was energetically stable and stereochemically plausible. Thus, research into computational biology was underway.",1
7,13,"Later, Warshel made the transition from energy minimization calculations towards molecular simulations by publishing, in 1976, the first MD simulation study on the dynamics of a biological process: the vision process [11]. A detailed model for the sequence of events in the first step of the vision process, which starts with the absorption of light by the protonated Schiff base of retinal chromophore bound to the active site of the protein rhodopsin, was provided by the MD simulation. The structure of rhodopsin was not yet available, and a simplistic model was adopted for the protein–chromophore phase. Even so, the main experimental observations were reproduced and explained how the protein made the photoisomerization process unique.",1
7,14,"In the 1980s, Warshel published the first microscopic simulation of ET reactions in condensed phases [13], as well as the first simulation of an enzymatic reaction [14]. ET reactions represent fundamental processes in photochemistry, for which MD results helped to elucidate the single step versus stepwise mechanistic alternatives in bacterial photosynthesis. Regarding enzyme catalysis, MD simulations contributed toward understanding the role played by the enzyme in lowering the energy barrier associated with the transition structure (TS), thus controlling the reaction rate. The MD calculations render the dynamic information required to rationalize why enzymeTS binding is energetically more favorable than that of enzyme–substrate binding.",1
7,15,"Also, throughout the 1980s, the so-called simulated annealing methods, commonly employed for X-ray structure refinement [15] and nuclear magnetic resonance (NMR) spectroscopic structure determination [16], were investigated. The interpretations of the relaxation rates (T1 and T2) and nuclear Overhauser enhancement (NOE) measurements, in terms of MD calculations, are particularly relevant.",1
7,16,"The present state-of-the-art, massive parallel computers, coupled with available powerful parallel software, make it possible to open up the MD simulation world to very exciting research fields in which more and more complex biological processes can be dealt with in real time. Indeed, continued progress in computational technology (software and hardware) allows one to look forward, with rational optimism, to the applications of MD techniques to the cellular scale in the near future.",1
7,17,"It is clear that properly processing the data libraries available, in which all the parameters and properties arising from computer simulations are recorded together with the corresponding mechanistic information on a wide variety of chemical, biophysical, or biochemical processes, through the tools provided by bioinformatics should be most useful to stimulate further progress in bioanalytical chemistry.",1
8,1,"Fred Basolo [1] (figure 1), Charles E. and Emma H. Morrison Professor Emeritus of Inorganic and Analytical Chemistry at Northwestern University and 1983 President of the American Chemical Society, died at the age of 87 on February 27, 2007 of congestive heart failure in Skokie, Illinois. He was preceded in death by his wife Mary and is survived by three daughters, a son, and eleven grandchildren.",1
8,2,"Fred made monumental contributions to inorganic chemistry, chemical education, coordination chemistry, inorganic reaction kinetics and mechanisms, and service to science and society. After his mentor John C. Bailar, Jr. [2] died, Fred assumed the position of dean of American coordination chemistry. He summarized his life and career in an autobiography [3] and an annotated collection of his most significant papers [4].",1
8,3,"Most of the miners were immigrants from the Piedmont region of northern Italy and spoke the ‘‘Piemontese’’ peasant dialect. Until Fred began to attend school, he understood but spoke little English. Conditions in the home were primitive—no central heating or plumbing. Fred’s experiences watching his mother in the family kitchen made cooking Italian dishes one of his favorite hobbies. His concern for students, colleagues, family, and everyone with whom he came into contact also may be traced to his roots in Coello.",1
8,4,"When Fred was about ten, The Great Depression began. Because he was too young to work, he attended elementary school in Coello and the Christopher Community High School. His first contact with chemistry was in high school, where his teacher told the class she hated the subject, knew little about it, and they were going to be largely on their own.",1
8,5,"Aided by a welfare program for college students, Fred enrolled at Southern Illinois Normal School (now Southern Illinois University). He became a chemistry major and earned his B.Ed. degree in 1940. The only person from Coello going to college, today he is still Coello’s only Ph.D. His parents expected him to become a high school teacher. However, Chemistry Department chairman James Neckers advised him to go to graduate school.",1
8,6,"A teaching assistantship enabled Fred to enter the University of Illinois. He chose as his mentor John C. Bailar (1904–1991), the father of American coordination chemistry, ‘‘a professor knowledgeable in organic chemistry doing work in inorganic chemistry which, to me, seemed a win-win situation’’ [3, p. 14]. He thought that Bailar ‘‘seemed to be a caring person, with a good understanding of people and their needs’’ [3, p. 14], qualities for which Fred later became legendary. Bailar became his second role model after his parents. As Bailar’s most eminent doctoral student, Fred continued Bailar’s work with his own students, and after Bailar’s death in 1991 he inherited his position as the ‘‘grand old man of coordination chemistry in the United States.’’",1
8,7,"Since Bailar worked with octahedral cobalt(III) complexes, he wished to extend this research to planar platinum(II) and octahedral platinum(IV) coordination compounds. For his dissertation, Fred synthesized optically active cis[PtCl2{NH2CH2CH2NH2}2]Cl2 and studied the stereochemical changes occurring during its ligand substitution reactions. His second publication on this subject [6], describing this research, aroused little interest until more than two decades later, when Barnett Rosenberg discovered the anti-tumor activity of the related complex, cis-[PtCl2(NH3)2] (cisplatin), now one of the most widely used anti-cancer drugs [7].",1
8,8,"Bailar advised Fred to complete his research in three years so he would not be drafted and need to return to Illinois to receive his degree. Fred received his M.S. degree in 1942 and his Ph.D. degree in 1943. He worked for three years on governmental classified research at Rohm & Haas Co. in Bridesburg, a Philadelphia suburb.",1
8,9,"In 1946 Fred became Instructor of Chemistry at Northwestern University. On June 14, 1947 Fred married Mary Nutely in Longmeadow, Illinois, the beginning of an extremely long and happy marriage that resulted in three daughters and a son, all of whom became educators. At NU Basolo rose through the ranks—Instructor (1946–50), Assistant Professor (1950–55), Associate Professor (1955–58), Professor (1958–79), and Charles E. and Emma H. Morrison Professor of Chemistry (1980–90). He served as Chairman of the Chemistry Department from 1969 to 1972.",1
8,10,"A Guggenheim fellowship allowed the Basolos to spend a sabbatical year (1954–55) in Copenhagen, where Fred worked in the laboratory of Jannik Bjerrum [8], whose dissertation popularized the term ligand [9]. The Basolos visited other European countries, including Italy, where they visited Fred’s relatives. A passionate lifelong golfer, Fred played at the Royal and Ancient Golf Course in St. Andrews, Scotland, where the game originated.",1
8,11,"During the summer of 1955 Fred and Mary attended the 3rd International Conference on Coordination Chemistry (3 ICCC) at Amsterdam. Fred heard the plenary lecture by Walter Hieber of the Technische Universita ̈ tM ̈ unchen, the ‘‘father of metal carbonyl chemistry,’’ and asked him about the mechanisms involved in the synthesis and reactions of these compounds. Hieber replied, ‘‘We do chemistry in my laboratory, not the philosophy of chemistry’’ [3, p. 101]. Fred realized this was a neglected field that he and his students could study.",1
8,12,"While browsing in the Rohm and Haas library Fred had become interested in studies of the kinetics and mechanisms of substitution reactions on carbon carried out by organic chemists. It now occurred to him that such studies could be made on inorganic coordination compounds such as those of cobalt(III) and platinum(II), with which he was already familiar. Lacking expertise in kinetics and mechanisms, he was fortunate in that fellow Instructor and physical organic chemist Ralph G. Pearson was carrying out such studies with carbon compounds. After persistent efforts Fred succeeded in convincing Ralph to collaborate on similar studies on coordination compounds, although no NU graduate students were interested in inorganic chemistry. Their first joint paper appeared in 1952 [16].",1
8,13,"Fred and Ralph’s studies of ligand substitution reactions of octahedral cobalt(III) complexes, acid hydrolysis or aquation of cobalt(III) and chromium(III) metal-ammine complexes, base hydrolysis of metal-ammine complexes, linkage isomers, ligand substitution reactions of Pt(II) square planar complexes, synthetic oxygen carriers, and organometallic chemistry, including the indenyl kinetic effect are true chemical classics [18]. Fred also made forays into the field of biological inorganic chemistry.",1
8,14,"Like John Bailar, his mentor, Fred educated several generations of chemists (58 doctorates, 66 postdoctoral fellows, and numerous bachelor’s and master’s degree candidates). About one-third of his students, inspired by his love of teaching, entered academia. The list of his former students is a virtual ‘‘Who’s Who’’ of inorganic chemistry and chemical education. Like Bailar’s, Fred’s success as a research supervisor and teacher owed as much to his enduring human qualities as to his considerable chemical knowledge. In 1992 he received the ACS George C. Pimentel Award in Chemical Education, and in 2001 he was awarded the Priestley Medal, the ACS’s highest honor [20]. He was also the recipient of numerous awards, medals, and honorary degrees.",1
8,15,"Fred was very active in the Gordon Research Conferences, International Conferences on Coordination Chemistry (ICCC) (figure 2), ACS Petroleum Research Fund Advisory Board, and North Atlantic Treaty Organization (NATO). He was elected to the National Academy of Sciences (1979), and he considered one of his most important NAS activities his participation in the book, Opportunities in Chemistry— the ‘‘Pimentel Report’’ [21]. In spite of his numerous professional activities and more than 380 scientific publications, he served as editor of journals or volumes [22] and wrote letters of recommendation, award nominations, or forewords to books or monographs.",1
8,16,"As President, Fred tried to correct some of his longtime concerns. In his attempts to combat chemophobia he agreed to discuss environmental problems with newspaper reporters, radio talk show hosts, and television anchor persons but only if he was given equal time to present the beneficial aspects of chemicals. He also made these views known to congressmen and congressional committees. Not all of Fred’s presidential efforts bore fruit.",1
8,17,"Fred traveled to 40 foreign countries, meeting with colleagues and encountering unusual foods and customs. His zest for life and remembrance of the humble circumstances of his childhood made him take great delight in each new experience during these trips. He considered Italy a second home, where he lectured in his ‘‘bad, but amusing Italian’’ [3, p. 156], and traveled there ‘‘more times than I can recall’’ [3, p. 153]. In 1981 he was elected an honorary member of the Societa` Chimica Italiana, and he received honorary doctorates from the Universita` di Torino (1987), the Universita` di Padova (1991), and the Universita` di Palermo (1997) as well as three Italian medals. In 1987 he was elected, one of only ten foreign members, five of whom were Nobel laureates, to the Accademia Nazionale dei Lincei, founded in 1603 as the world’s oldest scientific society.",1
8,18,"Unfortunately, in 1991 Mary had an emergency quadruple heart bypass and began to suffer from Alzheimer’s disease. One morning, while driving her to the day-care center, Fred fell asleep at the wheel because of a combination of some new medications and tiredness, and the car hit a tree. Mary died of her injuries on February 5, 1997. Five surgeries on Fred’s back damaged the nerves from his brain to his legs, and he was unable to walk without two canes. He used a motorized scooter to get around in the NU Chemistry Building (figure 5). In spite of pain and shortness of breath, he came to his office in the morning, had lunch with his faculty colleagues, and left in the early afternoon.",1
9,1,"Green analytical chemistry (GAC) is an increas­ ingly popular area of research in chemical ana­ lysis that may well redefine accepted truths. A search of the ISI Web of Science database yields more than a hundred hits on the keywords ‘green analytical’. An even more remarkable trend is the appearance of two reviews [1,2] and three books [3–5] on the subject in recent years. Bioanalysis as a subdiscipline of analytical chemistry cannot ignore this trend.",1
9,2,"Analytical chemistry deals with qualitative and quantitative information about the nature and presence of elements and molecules in the environment. Typically, the information is obtained from sample solutions. It follows that ‘greening’ information processing means reduc­ ing the volume, mass, size and so forth, of the media used for communicating the information. Therefore, the application of the principles of green chemistry to analytical chemistry is both valid and important [6]. Namieśnik was the first scientist to demonstrate that these principles could be used to delineate the main features of this new discipline.",1
9,3,"Taking only the consumption of harmful sol­ vents into account, most spectrometric methods are nominally green, since little or no solvent is required for sample preparation. However, instruments consume considerable energy and the principles of green engineering must be taken into account. Anastas and Zimmerman state that “Green engineering [in analytical chemistry] is the development and commercial­ ization of industrial processes [analytical instru­ mentation] that are economically feasible and reduce the risk to human health and the environ­ ment” [8]. However, the size of the carbon foot­ print required to produce an instrument is often completely overlooked in greening instrumental analysis. This makes miniaturization a crucial factor in greening instrumental methods, and contemporary bioanalytical instruments are now able to process miniscule amounts of sample.",1
9,4,"Both parts of the analytical process – sample preparation (solvent consumption) and mea­ surement (instrumentation/data processing) – represent a channel that conveys informa­ tion about the environment. The principles of green chemistry can therefore be condensed into a single principle with regard to analytical chemistry: to enhance green analytical chem­ sitry, information transmitting media needs to be minimized.",1
9,5,"Initial efforts to make HPLC greener have been thoroughly documented in recent reviews [2,11–14]. One way to reduce the consumption of solvents in HPLC is to minimize the column dimensions and to use smaller particles for packing. Second, it is possible to use elevated column temperatures instead of organic sol­ vents to tune the separation power. Third, safer alternative organic modifiers than ACN can be used in reversed­phase HPLC. Supercritical fluid chromatography (SFC), which uses carbon dioxide as a mobile phase, should also be men­ tioned. Although SFC is usually regarded as a technique only for nonpolar compounds, it has also been used for cationic, anionic and chiral compounds, as well as for proteins and drugs. Recycling solvents is an essential procedure in the laboratory, but often requires large amounts of energy.",1
9,6,"There are ambiguities in the greening of chromatography. The entire analytical process should be considered when evaluating the green­ ness of a particular form of chromatography. The energy aspects of green chromatography have mostly been ignored. A remarkable excep­ tion is the work of Van der Vorst et al., who estimated that preparative SFC requires about 34% more resources in total than preparative HPLC [15]. These findings could have far­reach­ ing consequences for other green chromato­ graphic techniques, such as elevated­tempera­ ture HPLC. Therefore, the actual greenness of elevated­temperature chromatography remains unproven until a thorough life­cycle analysis has been conducted.",1
9,7,"Separation science in general, and CE in particular, have been influenced by a form of miniaturization known as microfluidics. The volumes of fluid involved in microfluidics are on the order of nanoliters and picoliters. However, world­to­chip interfacing is a problem that jeopardizes the greenness of microfluidic devices. The trouble results from the fact that samples and reagents are typically transferred in quantities of microliters to milliliters (or even liters), but microfluidic devices deal only with nanoliters or picoliters of samples/reagents because reaction chambers and channels typi­ cally have dimensions on the order of microns. Microfluidics must integrate all components of the system on the same platform to ensure portability and minimum energy consumption. Supporting instruments such as pumps, valves and mixers, must also be miniaturized in order to achieve an integrated system.",1
9,8,"One way to miniaturize or even eliminate supporting instruments from a microfluidic device is to replace complex elements in analyz­ ers with passive components that operate with­ out external power. This can be accomplished by manipulating fluids by means of gravity, air pressure or simple manual actions. The driver for developing such simple (and possibly dispos­ able) devices is the need for simple point­of­care tests in developing countries for use in medical diagnostics. On the other hand, noninstrumen­ tal analytical devices can also be used in devel­ oped countries where, although most medi­ cal diagnostics are performed in centralized, well­equipped hospital laboratories, home tests have a place as well. Such applications include glucose and pregnancy testing, and detection by first responders to natural or man­made bio­emergencies (bioterrorism).",1
9,9,"Finally, a researcher who is developing GAC methods can take advantage of existing tech­ nology (which, from the standpoint of green philosophy, has already made its footprint on the earth’s ecosystem) for the quantitation of analytes. Some recent bioanalytical applications deserve mention in this regard. Xiang and Lu demonstrated the use of commercially available personal glucose meters for portable quantifica­ tion of DNA [20]. The use of a ubiquitous device, the personal glucose meter, provides portable quantitative DNA detection that is low cost, simple to operate, gives reliable quantitative results and, most importantly, is widely accessi­ ble to the public. In another example, Zhu et al. demonstrates the integration of cytometry and fluorescent microscopy on a cell phone using a purpose­designed, lightweight and cost­effective optofluidic attachment [21]. Jokerst et al. devel­ oped a paper­based analytical device for colori­ metric detection of select foodborne pathogens using a Xerox scanner",1
9,10,"Another question is whether green analytical chemistry makes sense at all. Would greening analytical chemistry have a significant impact on the earth’s environment (compared with the impact of the chemical industry, for example?).",1
9,11,"And finally, is green analytical chemistry genuinely green or are we merely transport­ ing waste away from our own locale? One can envision conflicting scenarios in which green chromatography is environmentally acceptable and economically attractive in laboratories and institutions but not sufficiently benign for the environment and society as a whole. We need to question where the assay chemicals originate and how they are produced. The same question needs to be asked about the analytical instru­ mentation. How will the laboratory eventually dispose of the product? These questions neces­ sitate a life­cycle analysis of the components of analytical methods (solvents, chemicals, energy, instruments and consumables).",1
9,12,"In summary, analytical chemistry is an information science that need not consume more resources than are necessary to support the analysis. The greening of analytical chem­ istry via miniaturization is possible in principle, and the development of greener instrumenta­ tion depends primarily on the creativity of the analyst. One way to reduce energy consumption is to miniaturize the entire analytical process. Yet, one cannot overlook the possibility that even if analytical laboratory practices are locally benign, global green analytical chemistry might be regarded with suspicion.",1
10,1,"Since their initial appearance in the scientific literature, the terms ""green"" and ""sustainable"" have been increasingly used and are nowadays ubiquitously present in the terminology of several research areas. The seminal origin of what is considered “green chemistry” today might be ascribed to the launch of the Responsible Care® initiative by the American Chemistry Council (ACC) [1] and to the Brundtland report [2]. The concept was then further refined and completed with the Pollution Prevention Act (approved by the American Congress [3]) and the definition of the Anastas and Warner’s 12 principles of green chemistry [4,5]. Very generally, green chemistry may be considered as the scientific and economical context in which academia, industry and government are attempting to converge their efforts for the development of a sustainable civilization.",1
10,2,"It is obvious that the chemical yield represents just one of the many features that a process must possess to be considered efficient. It is of extreme importance nowadays to consider not only the safety of a chemical procedure, but also the proper selection of solvents, starting materials, and technologies used to generate and control reactive intermediates. In addition, the need for minimizing toxic waste and the respective disposal cost highlights how crucial it is to consider the recovery and reuse of the materials needed for a synthetic process. It is also very important to promote the use of biomass-derived chemicals that feature an intrinsically lower CO2 consumption.",1
10,3,"Another key aspect of green chemistry, closely related to the chemical efficiency and efficiency of a protocol, is the technology behind the process. In fact, energy and time optimization are important factors. Increasing interest is being directed towards the development of innovative mixing and heating technologies that, individually or in combination, may furnish an innovative solution for controlling the safety and the reactivity of a chemical process and may facilitate the recovery and reuse of the materials used, which contribute to minimizing the energy consumption and increasing the overall efficiency of a process. Flow chemistry, microwave or ultrasonic irradiation, and mechano-chemistry are just a few representative examples of research platforms being independently developed, but all offer innovative tools for realizing chemically and environmentally efficient processes.",1
10,4,"Representative examples of these directions have been the subject of other excellent Thematic Series in the Beilstein Journal of Organic Chemistry, including “Strategies in asymmetric catalysis” by Tehshik P. Yoon [6], “Organometallic chemistry” by Bernd F. Straub and Lutz H. Gade [7], “C–H functionalization/activation in organic synthesis” by Richmond Sarpong [8], “Bifunctional catalysis” by Darren J. Dixon [9], “Sustainable catalysis” by Nicholas J. Turner [10], and “Organic synthesis using photoredox catalysis” by Axel G. Griesbeck [11], proving that green chemistry and sustainability can be approached from many different perspectives.",1
10,5,"The breadth of chemical and technological innovations makes the definition of novel metrics for the evaluation of the quality of a new process in the field of green chemistry necessary. A key aspect of green chemistry is in fact the comparison of the different strategies available by considering as many experimental aspects as possible. Of course the most important feature to be evaluated is the correct measure of the waste generated, which is derived from both the synthetic strategy and the technology used. The fundamental role of green metrics is to evaluate the modern classification of chemical transformations in relation to the potential or actual pollution produced. In some cases, such as calculating the waste associated with the mass of the material used, this is easily evaluated.",1
10,6,"However, it may be more difficult to compare energy, time, labor costs, and other variables of a process. Certainly, innovation is the most important goal of green chemistry, but it is also the most difficult feature to measure and evaluate. Novel chemistry and innovative technologies are needed for the development of future, sustainable, chemical production. To reach this goal, both fundamental research, as well as the ability to translate the innovation into real world applications, should be combined.",1
10,7,"Organic chemistry, with its kaleidoscope of interests and applications, offers the arena where countless opportunities exist to effectively contribute to the development of green chemistry. Journals dedicated to the field of organic chemistry, such as the Beilstein Journal of Organic Chemistry, represent an ideal medium for disseminating scientific efforts in this context. This Thematic Series, “Green chemistry”, collects original research and review articles, where an obviously limited but highly exemplificative portion of the broad field of green chemistry is described.",1
11,1,"Heteroatom chemistry has supported organic chemistry by providing synthetic methodologies for C–C bond formation. The Wittig reaction and hydroboration are representative examples that were developed by Wittig and Brown, respectively, who received the Nobel Prize in chemistry in 1987. Since then, many reactions utilizing characteristics of heteroatoms have been developed. Heteroatom chemistry has gradually shifted to organic element chemistry treating mainly chemical properties such as bonding modes, structural features, etc. based on the characteristics of the heteroatom or main group element. Here, I wish to overview such heteroatom chemistry through reports on symposiums and research funds related to heteroatom chemistry in Japan, the Asian contribution to conferences from the 1st to 9th International Conferences on Heteroatom Chemistry (ICHAC) in oral and poster presentations, chemistry of compounds bearing low- and high-coordination main group elements, the contribution of our group to heteroatom chemistry, and future heteroatom chemistry.",1
11,2,"In 1974, the Symposium on Organometallic Chemistry (21st to present) started as a symposium related to heteroatom chemistry. This symposium originally came from the Symposium on Organosilicon Chemistry, which Watase started as a chair of the Organosilicon Chemistry Division of the Kinki Chemistry Society in 1954, and which was later joined by Kumada, Sakurai, and Ando. In the last year, the 58th symposium was held in Nagoya. Recently, the number of chemists who attend both symposiums has been increasing.",1
11,3,"Heteroatom chemistry has been financially supported by research funds, namely, Grants-in-Aid for Scientific Research on Priority Areas by Akiba (1989–1992), Tamao (1997–2000), Tatsumi (2002–2005), and Miyaura (2006–2009) and a Grant-in-Aid for Scientific Research on Innovative Areas by Akasaka (2008–2012). These are big projects, which more than 100 researchers have joined for research based on a common theme, and many heteroatom chemists have benefitted from these funds.",1
11,4,"Here, Asia includes Turkey, Israel, Jordan, Iran, Iraq, Saudi Arabia, Oman, Pakistan, India, Bangladesh, Thailand, Malaysia, Mongolia, China, Taiwan, Hong Kong, Korea, Japan, Australia, and New Zealand, which are Asian countries that have contributed to oral and/or poster presentations more than once.",1
11,5,"Oral presentations include plenary lectures, invited or session lectures, and general oral presentations. Figure 1 shows the contribution from Asia, America, Europe, and Africa to oral presentations, and their contribution to poster presentations is shown in Fig. 2. Numbers in Figs. 1 and 2 show the Japanese contribution in Asia. For oral presentations, except for the 5th and 6th conferences, which were held in Canada and Poland, respectively, the Asian contribution was comparable to or higher compared with others. The contribution from Japan to oral presentations was always the highest in Asia, except for the 7th conference, where that from China was the highest.",1
11,6,"On the one hand, for poster presentations, the contribution from America is quite low and the contribution from Asia is much more than that from Europe, except for the 3rd and 6th conferences (Italy and Poland, respectively). Contribution from Japan to poster presentations was also the highest in Asia in all conferences, except for the 2nd, 4th, and 6th conferences, where the highest contribution was from India, Korea, and China, respectively. It can be concluded that contribution from Asia is high in most ICHAC conferences or reasonable for some cases considering the places outside Asia. Contribution from Japan in Asia can be concluded similarly.",1
11,7,"As double bond compounds between heavier group 14 elements, disilene 7 [7] and its heavier element analogues, digermene 8 [8], distannene 9 [9], and diplumbene 10 [10], were synthesized (Scheme 3). Tetramesityldisilene (7) was synthesized by West et al. as the first Si–Si doubly bonded compound. It is interesting to point out that bulkier substituents must be introduced on going from the third to the sixth row.",1
11,8,"The year 1981 was a memorable year, when the double bond rule that compounds with a double bond between heavier elements below the third row do not exist, was violated by successful syntheses of stable disilene 7 [7] by West et al. in the United States and diphosphene 11 [11], by Yoshifuji and Inamoto et al. in Japan (Schemes 3 and 4).",1
11,9,"The disilene was stabilized by introduction of mesityl group as a steric protection group, the much bulkier 2,4,6-tri-tert-butylphenyl group was needed for the diphosphene, because four steric protecting groups can be introduced to the disilene, while only two groups are available for the diphosphene. The heaviest element analogues of these series, namely, diplumbene 10 [10] and dibismuthene 12 [12], were successfully synthesized by Weidenbruch et al. and Tokitoh and Okazaki et al., respectively, although much bulkier groups than mesityl and 2,4,6-tri-tert-butylphenyl groups were necessary as shown in Schemes 3 and 4. Structural features of these series are as follows: the compounds in the heavier group 14 series have trans-bent structures, while the heavier group 15 series have planar structures, however, the carbon-pnictogen-pnictogen angles are much smaller than 120º, which are considered as different phenomena originating from the difficulty of hybridization between s- and p-orbitals in heavier elements in sharp contrast with each second-row element.",1
11,10,"Thiobenzaldehyde 13 [13] and selenobenzaldehyde 14 [14] were reported relatively early by Okazaki et al. by taking advantage of kinetic stabilization by the 2,4,6-tri-tert-butylphenyl group. Telluroketone 15, which is stable in solution, was also obtained by the same group [15]. For other heavy ketones, silanethione 16 [16], germanethione 17 [17], germaneselone 18 [18], germanetellone 19 [19], and even stannaneselone 20 [20] were synthesized by Tokitoh and Okazaki et al. using combinations of Tbt and Tip groups or Tbt and Dipt groups or Bbt and Tipt as steric protecting groups. Recently, Tokitoh et al. reported stannanetellone 21 [21] stabilized by Bbt and Tipt groups (Scheme 5).",1
11,11,"Very recently, Tamao and Matsuo et al. succeeded in synthesizing the first stable germanone 22 by taking advantage of effective steric protection of the Eind group originally developed by their group (Scheme 6) [22]. This has a trigonal planar structure around the germanium atom.",1
11,12,"Heavier analogues of acetylene have been synthesized. In 2004, Sekiguchi et al. and Wiberg et al. independently reported the first Si–Si triple bond compounds [26,27]. Sekiguchi’s compound 24 was synthesized as an emerald green crystal by reduction of the corresponding tetrabromodisilane with potassium graphite (Scheme 8) [26]. The X-ray analysis showed that it has a trans-bent structure, which is completely different from acetylene. The bond length is shorter than a double bond length, indicating a real Si–Si triple bond.",1
11,13,"Very recently, an aryl-substituted digermylyne was synthesized by Tokitoh et al. and shown to have a Ge–Ge triple bond [28]. For this type of compound, the situation changes completely on going farther down in the periodic table. Power et al. succeeded in synthesizing a lead analogue 25 of acetylene (Scheme 9) and showed that the Pb–Pb bond is not a triple bond at all, but a single bond and concluded that this compound should be recognized as a bis-plumbylene [29].",1
11,14,"Among them, heavy metallocyclopentadienides were the first to be synthesized. Silanole dianions [33] were synthesized as the first example, and then germanium analogues were also synthesized [34]. Disilagerma and trisila versions were also reported by Sekiguchi et al. [35,36]. Very recently, Saito et al. succeeded in synthesizing heavier analogues, stannole dianion [37], and plumbole dianion 26 (Scheme 10) and concluded that even plumbole dianion 26 has aromaticity from the fact that there is no bond alternation between the endocyclic C–C bonds and that it has a negative nucleus-independent chemical shift (NICS) value [38].",1
11,15,"Aromatic cation species were also synthesized. Sekiguchi et al. succeeded in obtaining the trisilacyclopropenium cation 27 (Scheme 10), which is a trisila analogue of the aromatic cyclopropenium cation, as a salt with tetrakis(4-tert-butyl-2,3,5,6-tetrafluorophenyl)borate [39]. The X-ray analysis showed that this is a completely free silycenium cation without interaction with a counter anion.",1
11,16,"After the attempted synthesis of a silabenzene by Märkel et al. [40], Tokitoh and Okazaki et al. opened the chemistry of neutral aromatic compounds containing heavier group 14 elements. As the first example, 2-silanaphthalene 28 (Scheme 10) was synthesized by taking advantage of kinetic stabilization by the Tbt group [41]. Its aromaticity was confirmed by a planar structure without bond alternation, a negative NICS value similar to that of naphthalene, etc. This chemistry has been continued by Tokitoh et al. and now tin analogue 29 (Scheme 9) has been successfully synthesized [42]. In 2007, Sekiguchi et al. reported the synthesis and characterization of 1,2-disilabenzenes 30 (Scheme 10) by (2 + 2 + 2)-cycloaddition of disilyne 24 with 2 molar equiv of phenylacetylene [43]. Very recently, Tokitoh et al. reported 1,2-disilabenzenes containing aromatic Bbt groups at the 1,2-positions [44].",1
11,17,"First, high-coordination carbon and boron compounds, which were expected to be difficult to synthesize, are described. The pentacoordinated carbon species 31 [45], pentacoordinated boron compound 32 [46], and hexacoordinated carbon species 33 [47] were synthesized and characterized by Yamamoto and Akiba et al. (Scheme 11). Their structures were determined by X-ray analysis, and bond paths were observed between the central atom and oxygen atoms by Atoms in Molecule calculations.",1
11,18,"Among many high-coordination silicon compounds reported previously, four species 34–37 by Japanese contributors are shown in Scheme 12 [48–51]. Sakurai and Kira et al. reported the first silylsilicate 34 with tetracoordinated silicon and anionic pentacoordinated silicon [48] and neutral hexacoordinated compound 35 [49]. Tamao et al. reported the first pentacoordinated fluorine-bridged compound 36 [50]. 5-Carbasilatrane 37 is one of our contributions to high-coordination silicon chemistry, which is a water-coordinated neutral silane. Interestingly, a dimeric structure in the solid state can be recognized as a frozen intermediate of the hydrolysis in a triaryloxysilane [51].",1
11,19,"Very recently, Sato, Furukawa, and Nabeshima et al. succeeded in synthesizing all carbon persulfurane 41 [57] by taking advantage of the high reactivity of the sulfurane dication, which was originally synthesized from the corresponding sulfurane (Scheme 14). The structure of 41 was determined by X-ray analysis to be octahedral.",1
11,20,"Among our contributions to main group element chemistry, three topics, namely, chemistry of fourmembered ring compounds containing high-coordination main group elements, photocontrol of the coordination number of a main group element utilizing photoisomerization of an azobenzene unit, and the “Asura” bond compound are described.",1
11,21,"To photocontrol of the coordination number of main group elements, we thought to introduce a main group element to the 2-position of azobenzene, which is well known as a chromophore and has an azo group available for coordination. If so, the coordination number can be controlled by photoirradiation, because the coordination of the nitrogen is broken or rebuilt by photoisomerization. If one can control the coordination number, one can also control the reactivity by irradiation. Initially, silicon compounds are described. We synthesized 2-trifluorosilylazobenzene (45), which was shown to have a pentacoordinated silicon both in solution and in the solid state by variable-temperature NMR and X-ray crystallographic analysis [69].",1
12,1,"Chemistry teaching has traditionally been weakly connected to everyday life, technology, society, and history and philosophy of science. This article highlights knowledge areas and perspectives needed by the humanistic (and critical−reflexive) chemistry teacher. Different humanistic approaches in chemistry teaching, from simple contextualization to socioscientific orientations to multifaceted problematization, are discussed. The latter is crucial for “critical chemistry teaching”, which includes both problematized content knowledge in chemistry and problematized knowledge about chemistry and chemistry education (about the nature of chemistry, its role in society, and the way it is communicated inside and outside the classroom). We illustrate how various facets of chemistry knowledge for teaching can be used to characterize different levels of complexity in the integration of the human element into chemistry education.",1
12,2,"Traditional approaches to chemistry education at all grade levels tend to be content-focused, with a strong emphasis on student understanding of disciplinary concepts and ideas.1 In general, there is too little consideration of science, technology, society, and environment (STSE) issues in which chemistry knowledge and practices play a central role. As suggested by Van Berkel and collaborators, “student activities in mainstream school chemistry [...] do not put emphasis in the curriculum on personal, socio-scientific and ethical questions that are relevant to students’ lives and society”",1
12,3,"The preparation of chemically literate citizens and responsible chemical scientists and professionals demands more than a solid understanding of fundamental chemistry principles. Driver et al.3 defined “scientific literacy” as knowledge about (a) scientific concepts and models, (b) scientific processes, and (c) societal contexts in which science is of relevance. Chemistry education has traditionally focused on facet (a) in this list, failing to engage students in activities and discussions that foster learning about how chemistry ideas may be used to address, reflect, or make decisions about relevant personal, societal, or environmental problems.4 Unfortunately, as expressed by Talanquer, “chemistry teachers seem to hold a monofaceted and unproblematic view of the subject matter” (p 832)5 that limits their ability to approach the teaching of chemistry in more meaningful and relevant ways.",1
12,4,"Hodson characterized citizen’s desirable knowledge about science as “developing an understanding of the nature and methods of science, an appreciation of its history and development, and an awareness of the often complex interactions among science, technology, society and environment” (p 23).6 In this article, we explore ideas that may help us approach chemistry education in ways that are better aligned with such an ambitious learning goal. We seek to discuss and integrate multiple ideas5,7,8 that can support multifaceted approaches to chemistry teaching. We call such integrated approaches humanistic chemistry teaching, which we see as in line with humanistic perspectives in science education as discussed and described by Aikenhead.",1
12,5,"The different levels of complexity in the analysis of the human element represented in Figure 2 are related to different orientations or strands of STSE education. Recently, Pedretti and Nazir23 proposed to arrange these various STSE perspectives in different categories, from Application/Designoriented (focusing on problem solving; related to Level 1 in Figure 2) to Historical-andLogical Reasoning-oriented (focusing on (a) understanding historical embeddedness of disciplinary chemistry or (b) decision making about complex issues through consideration of empirical evidence; corresponding to Level 2 in Figure 2) to Sociocultural-, Value centered-, and Socioecojustice-oriented (focusing on (a) understanding how sociocultural issues influence, and have influenced, scientific ideas and practices or (b) ideologically informed decision making and action; corresponding to Level 3 in Figure 2).",1
12,6,"Recently, Hodson has argued for four levels of sophistication of issues-based science education:24 (i) appreciating the societal impact of scientific and technological change (related to Level 1 in Figure 2), (ii) recognizing that decisions about science and technological development are taking in pursuit of particular interests (related to our Level 2), (iii) developing one’s own views and value positions, and (iv) preparing for and taking actions on socioscientific and environmental issues (the latter two are related to our Level 3).",1
12,7,"According to Gilbert, the function of using contexts in chemical education is that students “...be able to provide meaning to the learning of chemistry; they should experience their learning as relevant to some aspect of their lives and be able to construct coherent ‘mental maps’ of the subject” (p 960).25 Gilbert described four models of context and claims that there may be a steady progression from Model 1 to Model 4. In Model 1, which best corresponds to Level 1 in Figure 2, applications are solely used to illustrate the significance of disciplinary concepts. In Model 2, contexts are not conceived as static constructs to which chemical knowledge is applied, but rather they actively affect the meaning attributed to the concepts. Model 3 is characterized by the active involvement of the learner in giving meaning to the content in relevant contexts. Models 2 and 3 can be placed at the Sociochemistry level in Figure 2. Finally, in Model 4, the social dimension of context becomes essential as students actively engage in critical reflection (Level 3 in Figure 2).",1
12,8,The different levels of complexity in the analysis of the human element in Sjöström’s tetrahedron (see Figure 2) can be characterized by paying attention to different facets of chemistry knowledge for teaching as described in the following paragraphs.,1
12,9,"The triangular base of the tetrahedron in Figure 2 encapsulates approaches to teaching and learning of chemistry that are mostly focused on the development of fundamental disciplinary knowledge. According to Eilks et al., most traditional chemical teaching programs belong to this level as they “do not include technical applications of chemistry, societal issues, or personal related ideas” (p 20).1 As indicated by Aikenhead,9 science teachers tend to favor abstract “pure science”, and thus, it is not surprising that decontextualized chemistry courses are still predominant in many countries around the world. At this low level of complexity in the humanistic dimension, contextual, philosophical, and historical facets of chemistry knowledge and practices are not considered, and the essential questions (e.g., how chemical bonds form?), big ideas (e.g., matter is atomic), and crosscutting concepts (e.g., chemical bonding) guiding chemistry curricula are centered on the learning of core theoretical concepts and basic experimental techniques.",1
12,10,"In general, existing approaches at the Pure Chemistry level tend to emphasize the manipulation of symbols and formulas (i.e., emphasis on “visualizations” for the facet of knowledge types5), with a focus on compositional and structural aspects of chemical systems (conceptual dimension), which are mostly described and analyzed at the molecular level (dimensional scale). The wide scope of these types of programs often leads students to rely on rule-based and case-based reasoning (modes of reasoning) when confronting chemistry questions and problems. However, these shortcomings are not inherent to the Pure Chemistry approach and several educational initiatives have been directed at improving chemistry education within this perspective. Many of these reform efforts emphasize the need to engage students in model-based reasoning,26 helping them build and connect explanations at multiple levels of representation.",1
12,11,"At this Applied Chemistry level, essential questions guiding instruction may refer to relevant social and environmental issues (e.g., how greenhouse gases work?) and big ideas may be more contextualized (e.g., many energy sources commonly used by humans are forms of chemical energy). Crosscutting concepts can include overarching themes of importance to modern societies (e.g., human health). Nevertheless, the underlying chemistry concepts, ideas, and practices remain unproblematized and are often addressed in a partial and unreflective manner. For example, in a thematic chemistry video about energy and climate analyzed by Christensson and Sjöström,22 no mention is made about problems related to energy requirements of modern societies. Although the current search for new energy sources is discussed, no analysis is presented of how net emissions of carbon dioxide from fossil fuel consumption contribute to the enhanced greenhouse effect.",1
12,12,"In general, the introduction of applications at the Applied Chemistry level tends to focus instruction on the analysis and discussion of actual “experiences” in the real world, which often decreases the emphasis on the mere interpretation and manipulation of chemical visualizations of the systems of interests (knowledge types), and helps teachers and students build connections between macroscopic and submicroscopic (mesoscopic, multiparticle, supramolecular) levels of representation (dimensional scales). Furthermore, the focus on relevant contexts of application often brings the energy dimension to the forefront, improving the balance between energy and composition/structure considerations (conceptual dimensions). Unfortunately, a larger focus on relevant applications of chemistry knowledge and practices does not necessarily translate into an increased emphasis on model-based reasoning over rule-based or case-based reasoning (modes of reasoning).",1
12,13,"Within the sociohistorical strand, disciplinary chemistry is seen as a human endeavor and efforts are directed at understanding the historical development of chemistry knowledge. As Eilks et al. state, “chemistry curricula oriented on the history of science (HOS) try to make explicit that chemical facts and theories have a genesis [...] Learning about the historical genesis of fundamental theories of chemistry can help students learning about the nature of chemistry” (p 21).1 Chemistry ideas and practices are seen as cultural products developed by chemists working in particular contexts and subject to change in the light of new evidence. The use of this historical approach to chemical education has been discussed by Wandersee and Griffard.32 In particular, these authors describe an instructional technique called Interactive Historical Vignettes in which a nature-of-science incident in the life and work of one or several chosen chemists is dramatized. In a recent analysis of lesson plans where a historical approach is used to teach the nature of science (NOS), Tolvanen et al. concluded that to “increase the coherence and clarity of learning objectives and instruction, each lesson plan should focus on the limited amount of specific NOS issues instead of several overtly general NOS aspects”.",1
12,14,"The other strand in Sociochemistry, labeled as socioscientific, emphasizes science-based decision-making concerning chemistry applications in modern societies. As described by Eilks et al., “socio-scientific issues, e.g. the use of bio-fuels, are not only dealt with concerning their scientific and technological background, but also ethical and societal values of their use and consequences to society are reflected” (p 5).1 Practices and products of chemistry in society are highlighted, and their benefits, costs, and risks are emphasized. Many of the educational initiatives within this strand can be seen as examples of Education for Sustainable Development (ESD) as discussed by Burmeister et al. in a recent perspective paper;34 they are driven by democracy and sustainability issues,7,35−37 and are concerned with benefit−cost−risks relations. Examples of the application of this perspective, thus, include analyses and discussions of the social, economical, and environmental costs and benefits of chemical activities and their products. For example life-cycle analysis (LCA) has recently been shown to be of potential use in ESD-driven chemistry education.",1
12,15,"At the socioscientific level, essential questions guiding instruction refer to relevant societal and environmental issues (e.g., How can we evaluate the quality of the water we drink?). Big ideas guiding the curriculum link disciplinary knowledge and practices to their costs and benefits for modern societies. For example, students should be expected to realize that the “capacity of chemistry to change the material world has had significant consequences, both positive and negative, on the relationship between chemistry and society” (p 85).39 Crosscutting concepts are selected from a socioscientific point of view, looking to focus the introduction and discussion of chemical knowledge on the analysis of its personal and social relevance. One of such crosscutting concepts could be sustainable development. Vilches and Gil-Pé rez37 have stated that sustainability issues are practically absent from high school and university chemistry curricula across the world. They thus argue for chemistry education that focuses on the search for possible solutions for a sustainable future.",1
12,16,"A socioscientific educational approach is expected to be proactive, focusing not only on building models to explain chemical phenomena but also on discussing how to use chemical models and ideas to prevent problems and find solutions. Students are expected to integrate different knowledge types (experiences, models, visualizations) at various scales (from macro to submicro), as they engage in practical activity to address relevant issues. As learners give meaning to the content while solving authentic problems, they are asked to consider various conceptual dimensions of analysis, from composition/structure to energy to time issues. Concrete examples of this integrative and contextualized perspective have been developed and discussed by Marks and Eilks40 and by Bulte and collaborators.41,42 These latter authors have designed a variety of contextualized educational units built around structure−property relationships as a crosscutting concept. Recent educational efforts in the area of green chemistry also fall within this humanistic level.43,44 In this case, the work focuses on producing, using, and disposing of chemicals in order to reduce their environmental impact.",1
12,17,"Due to the technoscientific nature of chemistry,8 the teaching of our discipline creates rich opportunities for analyzing, discussing, and reflecting on the complex interactions between chemistry, technology, society, and environment, from integrated sociological, historical, and philosophical points of view.7 The top level in the tetrahedron in Figure 2, thus, includes sociocritical reflection about the role of chemistry in society, as well as critical-philosophical reflection about chemistry knowledge production and application. Both content knowledge in chemistry and knowledge about chemistry and chemistry education (about the nature of chemistry, its role in society, and the way it is communicated inside and outside the classroom) are thus problematized. Critical chemistry teaching emphasizes uncertainties in knowledge generation and application, and engages students in critical reflection about the nature of chemistry and of chemistry knowledge. A critical chemistry teacher enables students “to express, in a personal voice, judgments, interpretations, and arguments which are ‘free yet disciplined’” (p 768).",1
12,18,"Critical-Ref lexive Chemistry demands additional problematization of chemical ideas, models, and practices from a philosophical point of view. It requires analysis and discussion of, for example, which chemical ideas should be taken as central and why, how the selection and use of chemical models depends on the goals and context of application,49 and what practices are central to the chemical enterprise.8,50 This approach invites us to critically analyze the different ways of knowing and generating arguments and explanations in the discipline, weighing their pros and cons.51 It also leads us to critically reflect on how knowledge is represented and communicated, considering different dimensional scales and conceptual dimensions.8 One could argue that content analyses such as that of Johnstone,16,17 which made explicit different levels of representation used in the discipline, historical analyses such as that of Jensen,52 which integrated dimensional scales and conceptual dimensions of chemistry knowledge, pedagogical reflections such as that of Talanquer20 or Taber,21 which problematized the interpretation of the chemistry triplet, and pedagogical models such as that of Sevian and Talanquer,50 which highlighted critical aspects of chemical thinking, are intellectual exercises that support the implementation of Critical-Ref lexive Chemistry perspectives",1
12,19,"Our analysis also highlights the wide scope of the understandings in and about chemistry and chemistry education that teachers and instructors need to develop to successfully design and implement chemistry education that incorporates humanistic perspectives. As suggested by Thomas, “Developing critical thinking in learners requires learning by the teachers, not only to support the learners, but to become ‘critical teachers’” (p 257).57 These critical teachers need to reflect on the nature of chemistry knowledge and practices from sociocritical and critical-philosophical perspectives, looking to build meaningful inferences for pedagogical practice. Such reflection requires knowledge about the history, and philosophy of chemistry, as well as critical understanding of the political, ethical, and environmental contexts in which chemistry knowledge is developed and applied. It also demands pedagogical content knowledge that integrates the understanding of chemistry with the understanding of contexts.",1
12,20,"Van Berkel et al. states that “the initiation into normal chemistry should be largely replaced by an education in or through fluid, critical and creative chemistry, together with an education in or about the relations between chemistry, technology, and society” (p 47;2 emphasis added). From this perspective, chemistry educators should aspire to move their courses up in the tetrahedron in Figure 2, opening spaces for students’ empowerment and transformation by engaging in multifaceted problematization, looking to understand uncertainties in chemistry knowledge, reflecting on the benefits, costs, and risks of chemistry and its applications, and engaging in critical-democratic action for sustainability. It is, in Hodson’s words, about “assisting students in building a sense of identity as thoughtful, critical and active citizens”",1
13,1,"Active participation of Ph.D. students at international congresses is an important part of the educational program since it allows students to measure, compare, and discuss their scientific results at an international level. In 2008, the PFC made financial contributions to 19 PhD students to participate at the 2nd EUCHEMS conference (Torino, Sept 2008). For 2009, rather than focus on a single event, the PFC has set up the ‘SCNAT Chemistry Travel Award’ which is advertised in CHIMIA,[1] and on the PFC website",1
13,2,"The first ‘Young Faculty Meeting’ was organized at the University of Bern on 28 November 2008 by Karl Gademann (EPFL), Michele Cascella (University of Bern) and the author of this article. The event brought together over twenty professors and group leaders aged under 40 from all Swiss chemistry departments. The morning session focused on short presentations of research projects and in the afternoon session the topics ‘funding opportunities’, ‘work/ life balance’, ‘the cultural heritage of chemistry’ as well as ‘group organization and recruiting’ were discussed.[2] Given the success of this event, it will be repeated this year, albeit in a different format. The organizers in 2009 are Andreas Zumbühl (University of Geneva) and Hermann Wegner (University of Basel) together with PFC. The date is 17 June 2009, again in Bern",1
13,3,"In 2009, the «Platform Chemistry» starts its program ‘Chemical Landmarks’ (‘Historische Stätten der Chemie’, ‘Monuments historiques de la Chimie’). Key scientific and technological discoveries in chemistry have enriched our culture and have strongly contributed to prosperity in Switzerland. The PFC has launched a call for identification of the sites of these discoveries. A commemorative plate and a ceremony with press conference will recall these events and the inventors in order to preserve their memory and share the essence and consequence of these discoveries with the wider public. Details on this program can be found on our webpage (www. chemistry.scnat.ch/chemical_landmarks) or in CHIMIA.",1
13,4,The General Assembly of the United Nations has proclaimed 2011 as the International Year of Chemistry (IYC) and 2009 is the year when preparations for this event start. The «Platform Chemistry» and the Swiss Chemical Society will coordinate the Swiss activities for the IYC 2011. It will be an excellent occasion to bring into the public the benefit our science brings to society.,1
13,5,"More detailed information about the activities of the PFC may be found at www.chemistry.scnat.ch. Questions, comments and offers of active participation are welcome. Please contact the President or the Chief Science Officer of the Platform directly.",1
13,6,"Several of you may have come across announcements relating to the «SCNAT Platform Chemistry»; and with this short article we would like to introduce our institution in a more detailed way. The «Platform Chemistry» (PFC) is one of the six platforms of the Swiss Academy of Sciences (SCNAT), which itself is part of the alliance of the Swiss academies (Fig. 1). The Swiss Academy of Sciences has been committed to the establishment and development of the sciences since 1815. Today, this network brings together over 35’000 scientists from all over Switzerland. SCNAT makes use of expert knowledge and promotes the dialogue between science and society. In order to meet these goals the academy clearly defines local, thematic, disciplinary and interdisciplinary domains. To target available knowledge and expertise, SCNAT has created platforms, which group one or several disciplines. The «Platform Chemistry» – as well as the other platforms – is directed by a board, which is appointed by the Executive Board of SCNAT. The office of the PFC is headed by a Chief Science Officer, who is responsible for project management and for all administrative matters (Fig. 2).",1
13,7,"The PFC represents, via its member associations (Swiss Chemical Society (SCS), Swiss Society for Food and Environmental Chemistry (SSFEC)) some 3,000 scientists and experts. With their active support, the platform aims to further the dialog with society, the media, business and politics. The PFC focuses mainly on the promotion of chemistry at all educational levels.",1
13,8,"Besides making science – and especially chemistry – more attractive to students at all educational levels, it is crucial to increase the number of first-year students in this domain.",1
13,9,"The PFC sees its role in coordinating efforts in this area. It has set up a database of the various public relation activities of the institutes and departments of chemistry at all universities, Swiss Federal Institutes of Technology and Universities of Applied Sciences. It provides a ready overview of PR activities for future students, students and teachers at the different pre-university levels as well as the public; and contributes the efforts to coordinate these activities.",1
14,1,"The purpose of this research was to examine the relationships between conceptions of learning and approaches to learning in chemistry. Two questionnaires, conceptions of learning chemistry (COLC) and approaches to learning chemistry (ALC), were developed to identify 369 college chemistry-major students’ (220 males and 149 females) conceptions of and approaches to learning chemistry. First, it was found that students in higher grade levels (juniors and seniors) tended to express more agreement with higher-level COLC, such as learning chemistry by transforming, than those in lower grades (freshmen and sophomores). The regression analyses, in general, revealed that the students who expressed lower-level COLC, such as learning chemistry by memorizing and preparing for tests, tended to use surface approaches to learning chemistry, whereas those students possessing higher-level COLC, that is, learning chemistry by transforming, tended to use deep approaches to learning chemistry. However, inconsistent with theoretical perspectives, this study revealed that learning chemistry by memorizing could positively predict a deep motive for learning chemistry, while learning chemistry by transforming was associated with a surface motive for learning chemistry. The special features of learning chemistry which might account for these relationships are discussed.",1
14,2,"In recent years, research interest in conceptions of learning has increased, prompting education and psychology researchers to explore students’ conceptions of and approaches to learning. Previous studies have also revealed that students’ conceptions of learning are related to their approaches to learning, which then influence their learning outcomes",1
14,3,"Tsai (2004) has suggested that students’ conceptions of learning should be viewed as academic epistemic beliefs in school, as they are related to students’ beliefs about the nature of school knowledge and learning in class.",1
14,4,"Furthermore, Tsai’s (2004) study revealed that students’ learning outcomes and academic performance may be affected by numerous factors, and two of these factors, students’ conceptions of learning and approaches to learning, are considered to be particularly important. Thus, in this study, we argue that for chemistry educators, it is important to investigate students’ conceptions of learning and approaches to learning, particularly in chemistry. The purpose of the present research was therefore to identify Taiwanese college students’ conceptions of and approaches to learning chemistry through a quantitative methodology. The relationships between the conceptions and approaches were also investigated. This study also aimed to examine the grade differences in students’ conceptions of and approaches to learning chemistry.",1
14,5,"As previously mentioned, conceptions of learning refer to learners’ beliefs about or interpretations of learning and learning experience in school. The first research on conceptions of learning may have been undertaken by Sa  ̈ljo  ̈ (1979). By interviewing 90 college students about their learning experiences and their conceptualizations of learning, he distinguished five different categories of conceptions of learning: (1) increase of knowledge, (2) memorizing, (3) acquisition of facts or principles, (4) abstraction of meaning, and (5) interpretive process aimed at understanding reality. These conceptions are in a hierarchical order. Many studies subsequently followed that of Sa  ̈ljo ̈ to investigate conceptions of learning. For example, Marton et al. (1993) in Sweden identified a sixth category, ‘‘changing as a person,’’ and argued that these six categories could represent most people’s conceptions of learning. In the UK, Marshall et al. (1999) studied engineering background university students’ conceptions of general learning.",1
14,6,"According to Chiou et al. (2012), to gain a deeper understanding of how students learn in various scientific domains, future research should move forward to explore conceptions of learning in more specific domains. Chemistry is one of the important domains in science. Hence, in this study, we intended to investigate college students’ conceptions of learning chemistry (COLC).",1
14,7,"Approaches to learning have been defined as the ways in which learners process their academic tasks and influence their learning outcomes. In general, two modes of approaches to learning are predominant in the educational literature: a deep approach and a surface approach (e.g., Marton and Sa  ̈ljo  ̈, 1997; Trigwell et al., 1999; Chin and Brown, 2000; Cano, 2005). Generally, students who adopt a deep approach to learning aim at achieving a better personal understanding of new ideas and information, and are more likely to value the pedagogical intentions underlying the learning task. In contrast, students using a surface approach usually focus on the completion of their most obvious task requirements, and often distort the intent of the task in order to achieve their extrinsic goals (Bliuc et al., 2011).",1
14,8,"According to Yang and Tsai (2010), approaches to learning have been extensively investigated in various domains and for different academic tasks. For example, approaches to problem solving in engineering (Marshall et al., 1999), approaches to learning pharmacy (Smith et al., 2010), approaches to learning through discussion (Ellis et al., 2008), and approaches to learning mathematics (Cano and Berben, 2009) have all been studied. Specifically in science, research has been undertaken on approaches to learning biology by Chiou et al. (2012).",1
14,9,"The essence of the deep and surface approaches to learning varies widely across different domains (Ramsden, 1992). For example, in mathematics, the surface approaches to learning may refer to the processes of repeatedly calculating and following an algorithm, while in biology, they may refer to the processes of matching the name of a specific species with its distinct features. Although some researchers in the field of science education have started to tackle this issue (e.g.,Leeet al., 2008; Liang and Tsai, 2010), most of them have concentrated only on students’ approaches to learning in a broad content domain, such as science. Given the nature of different domains in the field of science, such as physics, chemistry and biology (Tsai, 2006), there would be merit in exploring students’ approaches to learning in the different scientific domains.",1
14,10,"Research has also extended to the exploration of the role of grade differences in students’ conceptions of and approaches to learning. Some studies have examined whether they differ across grade levels. For example, Sadler-Smith (1996) found that more mature students, that is, older students, indicated a deeper approach than younger students. Similarly, Zeegers’ (2001) finding supported that more experienced students tended to use deep strategies to process their learning tasks in science. However, an opposite result that students at higher grade levels (juniors and seniors) are more likely to use surface approaches rather than deep approaches has also been revealed by Kember (2000). The present research also attempted to investigate the role of grade level in students’ conceptions of and approaches to learning chemistry. In this study, undergraduate juniors and seniors were viewed as higher grade, and freshmen and sophomores were regarded as lower grade, the same categorization adopted by Lin et al.",1
14,11,"Since the 1980s, the research interest in relationships between students’ conceptions of learning and their approaches has been shared by many educational researchers. In van Rossum and Schenk’s (1984) study, they first used an open-ended questionnaire to investigate 69 undergraduate psychology students’ conceptions of learning; first they asked them to read an article, and then they asked them to report on how they approached the reading task. They indicated that the students’ lower-level conceptions of learning were closely linked to their surface approaches to learning. They found that students’ learning outcomes of relatively high quality must be especially associated with their deep approaches to learning. There are similar findings in other research (e.g., Dart et al., 2000; Edmunds and Richardson, 2009) that students holding more sophisticated, higher-level, conceptions of learning such as learning as applying, understanding and seeing in a new way, tend to employ deep approaches such as deep motive and deep strategies to learn.",1
14,12,Kember et al. (2004) claimed that students might perform differently in each learning domain. Students may use deep approaches to learning science but use surface approaches to learning in other domains. Tsai (2004) also suggested that conceptions of learning are domain specific.,1
14,13,"Therefore, it has become an important issue for science educators to investigate the interplay between students’ conceptions of learning science and their approaches to learning science (e.g., Chin and Brown, 2000; Tsai, 2004; Tsai and Kuo, 2008). However, few studies have addressed this interplay, particularly in the specific area of learning chemistry.",1
14,14,"This research, by using a stepwise regression model, was conducted to explore the relationships between college chemistrymajor students’ conceptions of learning chemistry and their approaches to learning chemistry.",1
14,15,"While some existing questionnaires have been established to investigate students’ conceptions of learning and approaches to learning (e.g., Biggs et al., 2001; Lee et al., 2008; Chiou et al., 2012; Chiu, 2012), there have been almost no specifically designed questionnaires to measure college chemistry-major students’ COLC and ALC. Therefore, in this research, the first step was to validate two instruments modified from previous studies (Lee et al., 2008; Liang et al., 2010) to assess college chemistry-major students’ COLC and ALC. This research then tested whether grade difference existed in the students’ COLC and in their ALC. Through the correlation analysis and stepwise regression method, this study then examined the relationship between the students’ COLC and ALC.",1
14,16,"The participants in this research included 369 college students in Taiwan, of which 220 were males and 149 were females. They were from 6 different universities in Taiwan.",1
14,17,"All of the students were chemistry-related majors and had taken a series of chemistry-related courses before participating in this study. Their ages ranged from 18 to 25, with an average age of 20.2; 152 were lower grade (freshman and sophomore) students (41.2%), and 217 were higher grade ( junior and senior) students (58.8%).",1
14,18,"To investigate the students’ COLC, the researchers in this study developed a survey which was a modification of the questionnaire used by Lee et al. (2008) and Liang and Tsai (2010).",1
14,19,"To develop the questionnaire about conceptions of learning chemistry, two experts in science education and chemistry examined the content of all the questionnaire items, providing expert validity for the survey. Following the procedure above, the questionnaire was slightly modified.",1
14,20,"Before carrying out the factor analysis of the COLC and the ALC questionnaires, KMO statistics were undertaken to determine the suitability of the factor analyses. All the variables in the overall KMO value must be greater than 0.50, and a value close to 1 means that the correlation patterns are quite compact, and so can give reliable factors as a result of the factor analysis (Field, 2000). In addition, a non-normal distribution can be determined by the skewness and kurtosis values of each questionnaire item. Kline (1998) suggested that skewness absolute values of less than 3 and kurtosis values less than 10 should be regarded as normal states. Furthermore, Noar (2003) also suggested that the skewness absolute values should not be greater than 1 and the kurtosis absolute values should not be greater than 2.",1
14,21,"As shown in Table 1, the KMO values are 0.95 and 0.92 for the COLC and the ALC questionnaire respectively, and the skewness and kurtosis values for each item of both questionnaires are also shown to fall within acceptable ranges, indicating a normal distribution. This means that these two questionnaire items are quite suitable for further factor analysis",1
14,22,"Table 3 shows the exploratory factor analysis results for the ALC questionnaire. According to the previous study (Lee et al., 2008), an oblimin rotation was performed because the factors of the ALS appeared to be correlated. This study also utilized the principal component analysis and the oblimin rotation method to determine thefactorsoftheALCquestionnaireitems.TheALCusedafactor loading greater than 0.4 for retaining the items. Thus, 18 items were kept in the final version of the ALC (the full list of items is in Appendix 2). The Cronbach’s alpha coefficients for the four factors were 0.90, 0.88, 0.92 and 0.74, which indicates a satisfactory level of internal consistency. In addition, the total variance explained in the ALCis70.62%.Table3alsoshowsthefactormeansandthe standard deviations of the ALC. As shown in Table 3, the ‘‘Surface Strategy’’factorwasscoredhighlybystudents(anaverageof4.15 per item).",1
14,23,"There are statistically significant positive correlations between ‘‘Memorizing,’’ and ‘‘Transforming’’ of the COLC and two factors of the ALC, ‘‘Deep Motive’’ (r = 0.26 and 0.58, p o 0.001), and ‘‘Deep Strategy’’ (r = 0.23 and 0.80, p o 0.001), and negative correlation was identified between ‘‘Testing’’ and two deep approach factors (r = 0.30 and 0.24, p o 0.001 for ‘‘Deep Motive’’ and ‘‘Deep Strategy’’ respectively).",1
14,24,"This positive relationship between the lower-level COLC, ‘‘Memorizing’’ and the deep approaches deserves more discussion, as it contradicts a common result regarding the negative relationship between lower-level conceptions of learning and deep strategies of learning (e.g., Zeegers, 2001; Lee et al., 2008; Chiou et al.,2012).Chemicalrepresentations,suchasformulae, symbols, equations, and structures, are widely seen in professional journals and routinely used to describe and explain chemical reactions and phenomena in textbooks (Black and Deci, 2000). Because of this feature of chemistry, no matter how much experience students accumulate or how they meaningfully process the chemistry learning tasks, they still have to use a certain degree of memorization to learn chemistry.",1
14,25,"Moreover, positive associations were found between ‘‘Memorizing,’’ and ‘‘Transforming’’ of the COLC and the factor of the ALC, ‘‘Surface Motive’’ (r = 0.37 and 0.78, p o 0.001). The correlation between ‘‘Memorizing,’’ ‘‘Testing,’’ and ‘‘Calculating and Practicing,’’ of the COLC and the ALC factor, ‘‘Surface Strategy,’’ are statistically positive, with coefficients ranging from 0.31 to 0.44 (p o 0.001).",1
14,26,This study also found some grade differences in undergraduate students’ COLC and ALC by t-test. These differences imply learning progress from novice to expert.,1
14,27,"According to the results, for the surface approaches to learning chemistry, first, ‘‘Memorizing’’ is a main factor to predict surface approaches. Second, another COLC, ‘‘Testing,’’ was also a positive predictor of ‘‘Surface Strategy’’ of learning chemistry. These conclusions are also in line with the aforementioned past research on learning science (e.g., Lee et al., 2008; Tsai and Kuo, 2008; Chiou et al., 2012).",1
14,28,"However, it was surprising to find that the higher-level conceptions of learning chemistry, ‘‘Transforming,’’ could be a positive predictor of ‘‘Surface Motive’’; that is, as the students who have the higher-level COLC tend to adopt the surface motive to learn chemistry, they might study chemistry just to fulfill a course requirement and want to have great performance so as to get ideal jobs in the future.",1
14,29,"To sum up, the regression results suggest that these college chemistry-major students’ COLC play an important role in their ALC. In general, students who held lower-level COLC, such as ‘‘Memorizing’’ and ‘‘Testing,’’ tended to use surface approaches to learn chemistry; however, their surface motive can also be positively predicted by the higher-level COLC, ‘‘Transforming.’’",1
15,1,"Chemistry core ideas as statements that summarize the most essential knowledge in chemistry1 have attracted much attention in science education research in the past few decades. Researchers have systematically explicated the connotation of chemistry core ideas in theory2,3 and organized chemistry curriculums around them in practice.4,5 For example, the Framework for K-12 Science Education6 and the associated Next Generation Science Standards7 organize science content around three strands: disciplinary core ideas, crosscutting concepts, and science (and engineering) practices. A similar approach is found in the Chinese Chemistry Curriculum Standards,8,9 which puts forward explicit requirements on chemistry core ideas in the Curriculum Content section.",1
15,2,"The importance of chemistry core ideas for learning10,11 and the authority of science education standards for teaching suggest that an analysis of chemistry core ideas in science education standards is of great significance. In 2014, Talanquer and Sevian reported a critical comparative analysis of chemistry core ideas between the National Science Education Standards (NSES) on the one hand, and the Framework for K-12 Science Education (FSE) and Next Generation Science Standards (NGSS) on the other.12 How are chemistry core ideas presented in the Chinese Chemistry Curriculum Standards (CCCS)? What are the similarities and differences of chemistry core ideas in science education standards between China and the United States? These questions are both theoretically and practically important as science education is becoming more global as the result of economic globalization.",1
15,3,"In general, chemistry is depicted as a prototypical science that studies the properties, composition, and structure of substances; how substance structure and composition change; and the associated change in energy.13 Meanwhile, chemistry is also a technoscience categorized and highlighted by various philosophers and historians recently.14−16 Chemical scientists are interested in not only explaining and predicting properties of chemical substances, but also transforming them and creating new chemical entities with potential applications.1 On the basis of this view on the nature of chemistry, we determined the analytical content and established an analytical framework for this study.",1
15,4,"The nature of chemistry tells us that “substances” and “processes” are two central themes of chemistry. Therefore, chemistry core ideas about substances and processes included in the CCCS and the NGSS are chosen for analysis. In our analytical framework, disciplinary core ideas that define the fundamental scientific understanding of important concepts, principles, and methods are the central conceptual knowledge to the discipline. Students who learn chemistry concepts during different schooling periods gain different levels of conceptual understanding, which inevitably affects students’ understanding and construction of chemistry core ideas.",1
15,5,"We analyzed chemistry core ideas about substances from dimensions of state of matter, chemical composition, property, structure, and composition−structure−property relationship and analyzed chemistry core ideas about processes from dimensions of change, energy and time. Also, macro level, molecular level, and subatomic levels18 were used to analyze the representation of chemistry core ideas. The selection of conceptual dimensions and conceptual levels is greatly influenced by the work of Claesgens et al.19 on the conceptual framework, and Jensen20 and Talanquer21 on the structure of chemistry knowledge.",1
15,6,"In China, chemistry is a separate science subject from biology and physics in school education and the CCCS is a separate standard accordingly. The CCCS is organized in terms of grade levels and topics. Specially, the CCCS is divided into three grade bands of junior high school chemistry, high school chemistry (compulsory), and high school chemistry (optional) corresponding to grades 7−9, grade 10, and grades 11−12, respectively. It should be noted that although the CCCS in grades 11−12 is optional, it does not mean that students in these grades have the right to give up chemistry learning completely. Instead, every student in these grades must take more than one level-one topic (module) to learn in order to meet the high school graduation requirements. This “compulsory in optional” form in grades 11−12 may be one of the most distinctive features in the CCCS.",1
15,7,"As shown in Table 1, the representation of chemistry core ideas about substances and processes in the CCCS is relatively rich and comprehensive on the whole. These chemistry core ideas are stated as behavioral goals and mainly include three types of chemistry concepts: (1) Theoretical Concepts (e.g., atomic structure, chemical bond, ionization, electrochemistry, chemical equilibrium); (2) Element and Compound Concepts (e.g., carbon, metals, acids and bases, organic compounds); and (3) Chemical Terminology and Calculation Concepts (e.g., chemical formula, calculation of the composition of matter and reaction heat). For conceptual levels, the representation of chemistry core ideas in the CCCS follows a learning progression from macroscopic level to molecular level to subatomic level as a whole. It suggests that the CCCS engages students in exploring the macroscopic properties and behaviors of different types of materials and substances to describe, explain, and predict the composition−structure−property relationships through analyzing their particulate and molecular models. This progression meets students’ cognitive development principles and is helpful to promote students’ chemistry learning.",1
15,8,"The system architecture of the NGSS7 is illustrated in Figure 2. We have chosen the Disciplinary Core Ideas section under the Performance Expectations as the source for chemistry core ideas, and the majority of chemistry core ideas about substances and processes can be found under its physical sciences category (marked in red in Figure 2). In particular, we recognize that the Performance Expectations section in the NGSS provides a set of learning expectations that integrate science and engineering practices, core disciplinary ideas and crosscutting concepts, which is one of the most distinctive elements compared to prior science standards. However, the Disciplinary Core Ideas section, at least in terms of the NGSS, is meant to help clarify the Performance Expectations and describe where it comes from.",1
15,9,"From Table 2, we can see that chemistry core ideas about substances and processes in the Disciplinary Core Ideas section in the NGSS mainly include theoretical concepts (e.g., atoms, molecules, molecular collisions, atomic rearrangements, bond energies), with element and compound concepts and chemical terminology and calculation concepts barely mentioned. It seems that the NGSS emphasizes and approaches more focus on modeling and argumentation. For conceptual levels, the representation of chemistry core ideas pays more attention to molecular level and subatomic level.",1
15,10,"The NGSS claims to be what all students should know and be able to do by the time they graduate from high school,7 and the CCCS aims at promoting students’ scientific literacy in order to prepare them to be informed citizens in the future.8,9 It can be seen that the educational purposes pursued by the NGSS and the CCCS are consistent. In the following sections, we report a comparative analysis in terms of content representation, statement forms, conceptual levels, and learning progressions of chemistry core ideas. To highlight the differences of chemistry core ideas between the two documents, a summary table is presented at the end of these sections.",1
15,11,"Chemical terminology concepts are important means and tools for communication,23 and chemical calculation concepts provide a fundamental prerequisite for quantitative research of chemistry.24,25 These concepts are also beneficial to understand the chemistry core ideas and should be emphasized in curriculum standards. Further analysis shows that there are several chemistry ideas and concepts relating to fundamental chemistry activities in the CCCS, such as hydrocarbon and its derivative, addition polymerization and polycondensation reactions, synthetic polymers. This practical, socially relevant face of chemistry is barely visible in the NGSS.12 As noted above, chemistry has also been characterized as a technoscience,1 so more attention should be paid to the transformative and productive nature of chemistry.",1
15,12,"While the Disciplinary Core Ideas section in the NGSS places relatively much emphasis on theoretical concepts, it should be specifically indicated that the clarification statement and assessment boundary in the Performance Expectations section in the NGSS contain a few specific chemical substances (e.g., ammonia, methanol, carbon dioxide, synthetic material) and processes (e.g., mixing zinc with hydrogen chloride, combustion reactions),7 which, to some extent, compensates for some missing concepts discussed above.",1
15,13,"Although the representation of chemistry core ideas seems relatively rich and strict in the CCCS, the NGSS when compared with the CCCS focuses more on some other chemistry concepts, especially concepts about processes (e.g., molecular collisions, rearrangement of atoms, attraction and repulsion between electronic charges, nuclear processes). These theoretical concepts emphasize molecular level and subatomic level and focus on exploring materials and substances from the perspective of their particulate nature, which implies that the NGSS places more emphasis on modeling, argumentation, logical thinking, and imagination in chemistry learning.",1
15,14,"From our perspective, each of the statement forms of chemistry core ideas in the two documents above has its own merits and inadequacies. Although the action verb included in the CCCS defines the fundamental requirement of chemistry core idea and provides a certain basis for teaching and evaluation, we must realize that some action verbs (e.g., know, understand) are cognitive and their corresponding behaviors are implicit. Therefore, it is difficult for most teachers and students to distinguish them, which may mislead teachers and students to pay more attention to the action verbs themselves instead of understanding the meanings of chemistry core ideas. Meanwhile, it is surprising that the CCCS only presents the names of some chemistry core ideas, with the absence of their specific meanings. Teachers with different experiences and abilities will, therefore, hold various understandings for chemistry core ideas, which can consequently influence students to understand and construct them. By contrast, the NGSS uses scientific languages to express the specific meanings of chemistry core ideas. These explicit statements highlight the interrelationships among concepts, which is helpful for teachers to gain the meanings of relevant concepts and their importance in chemistry easily.",1
15,15,"In the CCCS, chemistry core ideas about substances place more stress on the macro level in grades 7−9, which is in favor of facilitating chemistry learning for beginners and motivating their interest in chemistry. In all three grade bands, great emphasis is attached to macroscopic ideas about processes, and slightly less emphasis in the molecule level and subatomic level, especially for energy and time dimensions (see Table 1). However, chemistry core ideas in the NGSS focus mainly on the micro level, especially in grades 9−12. We can see from Table 2 that nearly all ideas about substances and processes are at the molecule level and subatomic level. The conceptual levels in the NGSS imply that micro domain of chemistry core ideas should be reinforced in higher grades. From the above comparison, we may make further inferences that the CCCS seems to include more aspects of descriptive chemistry while the NGSS seems to put more emphasis on models and modeling.",1
15,16," The comparative analysis we have presented above indicates that there are certain differences in the representation of chemistry core ideas included in science education standards between China and the United States. Exploring the reason for these differences is important because it will help us understand chemistry core ideas better and ponder over the goals of science education. In particular, we elaborate on three aspects below as the major influential factors in the representation of chemistry core ideas in the two documents under analysis.",1
15,17,"From our perspective, one main reason why there are differences in content representation of chemistry core ideas is the different research perspectives on science education. American education researchers study and understand chemistry curriculum in the overall context of science education which focuses on the learning of cross-cutting concepts31 and general concepts,6,7,32 emphasizes STEM education,33 and so on. Therefore, although chemistry is generally presented as a separate science course in high school, science education standards documents in American education classify science content knowledge into three major areas: physical sciences, life sciences, and earth and space sciences. In the NGSS, chemistry core ideas are mainly presented in the physical sciences, with slight references to the life sciences and earth sciences.7 The interdisciplinary nature of the U.S. chemistry curriculum standards is an important aspect to know for teachers who are not necessarily chemistry specialists and it can contextualize the chemistryan area that seems to be a deficit in the Chinese curriculum and in any other countries where chemistry curriculum standards are separate disciplinary curriculum standards.",1
15,18,"At present, Chinese curriculum still adopts the subject-based curriculum, and chemistry is a separate science discipline in school education. As noted above, the CCCS, as a separate disciplinary curriculum standards document, presents chemistry core ideas more systematically and highlights the characteristics of chemistry. However, for the same reason, it results in weak relationships between chemistry and other disciplines. It is our advice that Chinese chemistry teachers should pay more attention to the integration and connection among various concepts, consider the complementarity and mergence between chemistry and other disciplines, and guide students to learn and apply chemistry core ideas in the context of science, technology, and society.",1
15,19,"In the NGSS, the meanings of chemistry core ideas are presented explicitly, without action verbs included. It can be inferred that researchers in the U.S. view chemistry core ideas as the summary and distillation of central chemistry knowledge, which reflects the assumption of discipline ontology to some extent. The Chinese educators focus more on students’ understanding of chemistry concepts and specific knowledge from the perspective of student learning.17 Therefore, statements in the CCCS take the form of action verbs which provide the basic understanding requirements of chemistry core ideas for students. However, the meanings of some core ideas in the CCCS only present the name without their specific content. These general and vague statements call for more thorough research on the meaning of chemistry core ideas from the perspective of discipline ontology.",1
15,20,"We hold the opinion that respective emphasis on the nature of teaching process in school education of China and the Unites States results in different conceptual levels and learning progressions of chemistry core ideas between the two documents. School education in China has always been guided by epistemology, which underlines that teaching process is a special cognitive process during which school teaching should follow a sequence from the shallower to the deeper and attach great importance to students’ learning stage and development.34 Affected by this, the CCCS has followed a relatively coherent learning progression, with chemistry core ideas presented from the macroscopic level gradually into the microscopic level (see Table 1). However, it seems that chemistry core ideas included in the CCCS focus more on the macroscopic level, with less attention paid to explanation and modeling on the molecular and subatomic level when compared to the NGSS. Therefore, we may argue that the CCCS falls short of fully representing the nature of chemical knowledge and the power of chemical thinking, which demands more reflection and discussion among chemistry educators.",1
15,21,"The United States is a diverse country with various curriculum theories, such as subject-based curriculum theory, problem-based curriculum theory, student-centered curriculum theory35 and multicultural education.36 The collision and fusion of multiple theories affect the selection and presentation of curriculum. Table 2 implies that the influence of recent research results is not fully embodied in science education standards. It can be seen that the representation of chemistry core ideas in grades 9−12 in the NGSS is poor to some extent and there are many gaps in it with more focus on the molecular and subatomic characterizations. It does not deny that the ability of abstract thinking improves greatly with age. However, we question the focus mainly on the micro level in high school grades because research findings in science and chemical education show that students have serious difficulties in understanding and applying different assumptions of the atomic and molecular theories of matter.37,38 Some chemistry core ideas, especially ideas in the micro level, such as molecular collisions, atomic rearrangements, and bond energies, are difficult to understand even for high school seniors.",1
15,22,"We have analyzed and compared the representation of chemistry core ideas about substances and processes included in the CCCS and the NGSS. In general, the CCCS presents chemistry core ideas comprehensively and scientifically and has a good learning progression. However, we must acknowledge that many aspects of chemistry core ideas in the CCCS need to be improved. For the selection of teaching contents, more attention should be paid to the connection and integration between chemistry core ideas and other disciplinary ideas. For statement forms, specific meanings of chemistry core ideas are required to be presented explicitly and completely. For conceptual levels, when the macro levels are considered, the understanding of the micro level should also be reinforced at the same time. And for learning progressions, it is suggested that curriculum developers and teachers explore different levels of chemistry core ideas among different grades to improve the coherence of core ideas. Meanwhile, for the United States, chemistry core ideas included in the science education standards should emphasize more specific types of substances and chemical process, and more attention should be paid to the macro level of chemistry core ideas in order to achieve better learning progressions, which can certainly facilitate students’ chemistry learning.",1
15,23,"The differences in chemistry core ideas between the two documents reflect different perspectives on the goals of science education, the aims of chemistry, and expectations about quality teaching. We expect that our comparison and suggestions can inform chemical education and science education reforms not only for the U.S. and China, but also for other countries. And we also appeal for more focused attention and communication on the science education standards among different countries in order to prepare for scientifically literate future citizensour common goal.",1
16,1,"The current global escalation in resistance to antibiotics is a serious threat. Thus, it seems that the world is headed for a post-antibiotic era, in which common infections and minor injuries that have been treatable for decades could become fatal again. Ribosomes, the universal cellular machines that translate the genetic code into proteins, are paralyzed by many clinically useful antibiotics. Structures of ribosomes from genuine multi resistant pathogens, alongside those from eukaryotic parasites illuminated the antibiotics modes of action and highlighted issues associated with species specificity in susceptibility to antibiotics.These structures also showed that the ribosome’s catalytic site is located at its core within a universally conserved semi-symmetrical region. The high conservation of this region implies its existence irrespective of environmental conditions and indicates that it might represent a prebiotic RNA entity with catalytic capabilities. Hence, it could be the kernel around which life originated and evolved.",1
16,2,"Supramolecular chemistry is actively exploring systems undergoing self-organization, i.e. systems capable of spontaneously generating well-defined functional supramolecular architectures by self-assembly from their components, on the basis of the molecular information stored in the covalent framework of the components.",1
16,3,"Supramolecular chemistry is intrinsically a dynamic chemistry in view of the lability of the interactions connecting the molecular components of a supramolecular entity and the resulting ability of supramolecular species to exchange their components. The same holds for molecular chemistry when the molecular entity contains covalent bonds that may form and break reversibility, so as to allow a continuous change in constitution by reorganization and exchange of building blocks. These features define a Constitutional Dynamic Chemistry (CDC) covering both the molecular and supramolecular levels.",1
16,4,CDC takes advantage of dynamic diversity to allow variation and selection and operates on dynamic constitutional diversity in response to either internal or external factors to achieve adaptation.,1
16,5,"In particular, component selection on both the dynamic molecular and the supramolecular levels may be driven by the formation of an organized phase: - in 2D on a surface, - in soft matter (gel, liquid crystal), - as well as in 3D in a solid/crystal. Systems will be described and discussed that undergo such processes of self-organization-driven constitutional adaptation. They point to the emergence of an adaptive chemistry.",1
17,1,"This paper concerns Bildung-oriented chemistry education, based on a reflective and critical discourse of chemistry. It is contrasted with the dominant type of chemistry education, based on the mainstream discourse of chemistry. Bildung-oriented chemistry education includes not only content knowledge in chemistry, but also knowledge about chemistry, both about the nature of chemistry and about its role in society. In 2004 Mahaffy suggested a tetrahedron model based on Johnstone’s chemical triangle. The latter represents the formal aspects of chemistry teaching (macro, submicro, and symbolic) and the top of the tetrahedron represents a human element. In the present paper the following subdivision of the top is suggested (starting from the bottom): (1) applied chemistry, (2) socio-cultural context, and (3) critical-philosophic approach. The professional identity of the Bildung-oriented chemistry teacher differs from that of the chemist and is informed by research fields such as Philosophy of Chemistry, Science and Technology Studies, and Environmental Education. He/she takes a socio-critical approach to chemistry, emphasising both the benefits and risks of chemistry and its applications.",1
17,2,"Based on a risk society analysis (Beck 1992; Ekberg 2007), it is reasonable to argue for Bildung-oriented chemistry teaching, which in practice would mean including more ethical and socio-cultural perspectives in the teaching. This paper presents a model for content and perspectives in such chemistry teaching. The aim with Bildung-oriented chemistry teaching is to develop critical, deliberate and action-competent citizens or, in other words, ‘‘chemical literacy’’ (Shwartz et al. 2005). The latter can be seen as the contribution that chemistry makes to scientific literacy (Laugksch 2000; Roberts 2007; Holbrook and Rannikmae 2009).",1
17,3,"In a previous paper (Sjo ̈stro ̈m 2007) I problematised the mainstream discourse of chemistry and suggested a complementary discourse, aiming to replace the often too modernistic and reductionistic chemistry discourse with a more socio-critical and holistic one. Such a new discourse would emphasise the role of chemistry as a culture and within a cultural context. As shown in columns 1 and 2 in Table 1, I subdivide the mainstream discourse of chemistry into two levels: disciplinary and societal.",1
17,4,"This paper concerns chemical education based on the desirable reflective and critical discourse of chemistry (column 3 in Table 1), that is, Bildung-oriented chemical education, and how it differs from chemical education based on the mainstream discourse (columns 1 and 2 in Table 1). An extensive review of literature relevant for the area constitutes the basis for the theoretical and position-based approach in this paper.",1
17,5,"‘‘Bildung’’ is the German term for a key idea in the Continental educational tradition. In Swedish it is called ‘‘bildning’’ and in Danish and Norwegian ‘‘dannelse’’. However, there is no precise English translation of the concept (Va ́squez-Levy 2002), but it is sometimes translated as ‘‘liberal education’’ (Løvlie and Standish 2002), and is also closely related to the concept of ‘‘citizenship’’ (Elmose and Roth 2005). Va ́squez-Levy (2002, pp. 118–119) defines the concept of Bildung in the following way: ‘‘Bildung is the process of developing critical consciousness and of character-formation, self-discovery, knowledge in the form of contemplation or insight, an engagement with questions of truth, value and meaning.’’",1
17,6,"Because there is no precise English translation, the German term is used in the international (Anglo-American) educational literature. For example, the journal Educational Philosophy and Theory had a special issue on Bildung in 2003. In that issue Wimmer (2003, p. 185) wrote that ‘‘Bildung denotes whatever is not covered by the other central concepts of pedagogical theory such as socialisation, education, and instruction’’, but that it also stands for them all. It is, according to Wimmer, ‘‘the central critical concept of modern pedagogy’’. The concept is also occasionally used in the international environmental and science education research literature (see e.g.: Marks and Eilks 2009; Mogensen and Schnack 2010; Hofstein et al. 2011).",1
17,7,"In the discussion of Bildung-oriented chemistry education I will use Johnstone’s (1982) triangle describing the disciplinary content in chemistry education, and Mahaffy’s (2004) extension of the triangle adding human perspectives as a top of a tetrahedron. I suggest a subdivision of the tetrahedron’s top into three levels (starting from the bottom): (1) applied chemistry, (2) socio-cultural context, and (3) critical-philosophic approach. However, before the discussion of Bildung-oriented chemistry education I discuss and describe the common discourse in chemistry education.",1
17,8,"I use the term ‘‘discourse of chemistry’’ to refer to chemists’ philosophical and political worldviews and values (both explicit and implicit) (Sjo ̈stro ̈m 2007). The term can also describe a broad societal and historically based flow of ideas, which dominate the conceptions and practices of chemists (including many chemistry teachers) without their necessarily being aware of its influence. Often it is useful to describe chemists’ (including many chemistry teachers’ and chemistry textbook authors’) views of their science and the role of chemistry in society with labels such as positivism, objectivism, reductionism, rationalism, modernism, and sometimes even scientism. These labels will be commented on below, followed by a case and a discussion of the types of knowledge currently emphasised in most school chemistry courses.",1
17,9,"In a study of discourses in secondary school chemistry textbooks O ̈ stman (1996) used labels such as objectivism, atomism, and instrumental rationality to characterise the texts. One characteristic of the studied textbooks, he meant, is ‘‘the goal of making humankind the ruler of nature’’ (p. 49). According to Aikenhead (2006), ‘‘[m]ost high school science textbooks attempt to indoctrinate the reader into an ideology of positivistic realism endemic to the traditional science curriculum’’ (p. 55), and science ‘‘teachers tend to favor abstract decontextualized ‘pure science’’’ (p. 63). Van Aalsvoort (2004) has shown that logical positivism can explain many students’ experience of low relevance in chemistry teaching.",1
17,10,"Objectivism is the view that scientific facts are independent of the context in which they are observed. Most scientists see nature as objective and real. In contrast, post-modernists view scientific facts as constructed, relative and context-dependent (Good and Shymansky 2001). Christensen (2009, p. 208) points out that although ‘‘[s]cience is traditionally presented as value-free knowledge [...,] scientists routinely make assumptions and value judgements about uncertainties that are black-boxed into their research.’’ Norris (1997) argues for an ‘‘epistemic distance’’, by which he means, for example, a balance between realism and relativism (see further below).",1
17,11,"Another characteristic of the common discourse of chemistry is that ‘‘[c]hemistry, by its culture, has been almost blindly reductionist’’ Whitesides (2004, p. 3634). According to Early (2004, p. 144), contemporary chemistry conveys an atomistic and mechanistic worldview: ‘‘[M]echanics (in its classical, quantum, and statistical versions) can rationalize all sorts of interesting things—even aspects of biology. The take-home message [... is] that submicroscopic components of things are what is ultimately important’’. On receiving the implicit message that the parts are more important than the whole, many students ignore chemistry ‘‘and turn their attention to matters likely to have more importance for their lives’’.",1
17,12,"Rationalism is a view that considers scientific knowledge and methods to be free of values. According to Schummer (1997), the rationalistic view taken by many chemists makes dialogue with the public difficult: ‘‘[T]he main barrier of ecological dialogue between chemists and the public is the exclusive claim for rationality as part of the professional ethics of chemists.’’ A rationalistic view is often connected to the opinion that it would be good if scientific experts were given increased political influence.",1
17,13,In connection with the International Year of Chemistry in 2011 many different applications of chemistry in society were highlighted. In February the theme of the month in Sweden was fashion.,1
17,14,"Similarly, in a college textbook about chemistry in everyday life (Jakobsson 2003, p. 197), TeflonÒ—a polyethen polymer where all hydrogen atoms have been replaced with fluorine atoms—is described as ‘‘an excellent material for pans’’ (my translation). GoreTexÒ and TeflonÒ both contain chemicals belonging to a group of chemicals called perfluorinated compounds (PFCs).",1
17,15,"I would claim that many chemistry teachers and chemists have a nonchalant attitude towards the public’s fear of chemicals. They think that the public is ‘‘chemophobic’’. The following typical statement is taken from an abstract to an oral presentation held at the 18th International Conference on Chemical Education: ‘‘[P]eople blames ‘chemicals’ for causing some issues such as water quality, air pollution, and herbicides, etc. Although life is made of chemicals and human life cannot sustain [...] itself without chemicals, most of [the] public are unaware of the importance of chemicals and chemistry’’ (Do and Jin 2004). As illustrated in this quotation, chemistry teachers often take an uncritical view of the role of chemistry in society.",1
17,16,"Students are often uncertain about the aims of chemistry. This is partly due to philosophical difficulties in describing the aims of chemistry (Schummer 1999), and partly due to the fact that several different types of knowledge are emphasised within each teaching unit (Van Berkel et al. 2009). Schummer (1999) points out that ‘‘all received concepts to distinguish between science and technology fail, if we try to apply them to chemistry’’. Furthermore he writes: ‘‘From the point of view of philosophy of science, it is extremely difficult to understand what chemistry is all about.’’",1
17,17,"These are: Correct Explanations; Solid Foundation; Structure of Science; Self as Explainer; Scientific Skill Development; Everyday Coping; and Science, Technology and Decisions. Van Berkel et al. (2009, pp. 34–35) stress that it is problematic when several of the emphases appear in the same teaching units: ‘‘A mixing of emphases leads to confusing messages in chemistry lessons about what should be learned and why [...] Making clear and consistent decisions on the curriculum emphasis of units is necessary in order to escape from the existing confusion’’. They argue that when the message about what is to be learned is unclear, curriculum designers, teachers and students tend to fall back on the dominant form of chemistry education, which emphasises the Solid Foundation.",1
17,18,"It is interesting to pay attention to what is emphasised currently in chemistry teaching. Therefore I below refer to three recently published empirical studies about chemistry teaching in (upper-)secondary schools in Sweden. Maria Kouns (2010) has recently done an extensive empirical study in which she observed 31 chemistry lessons in an uppersecondary school science class. The chemistry teacher was described as ‘‘very experienced’’ and was appreciated by the students. In addition to the many observed lessons, the empirical material included several interviews with both the chemistry teacher and the students and four questionnaires answered by the students.",1
18,1,"The transformation of molecules through sequential reactions is a central feature of metabolism, defining the flow of matter through a living organism.[1] These reactions are organized into pathways that can be unidirectional, cyclic, or branched, and that are interconnected at shared intermediates, forming the interlinked, highly complex networks of transformations that define an organisms metabolome.[2] Understanding how to manipulate dynamic structural interconversions through the application of external stimuli could not only shed light upon the basic principles that underpin many biological processes, but also be beneficial to the design and construction of biomimetic molecular machines.",1
18,2,"Many signals have been shown to be capable of altering the constitution of dynamic systems, switching one structure to another. They include light,[4] pH value,[5] chemical templates,[6] temperature,[7] solvent,[8] and a change in concentration.[9] The use of subcomponent self-assembly[10] to construct complex metal–organic architectures[11] provides pathways for these structures to dynamically reassemble by taking advantage of enthalpic or entropic driving forces.[2,12] Herein, we examine how a system of diverse self-assembled cadmium(II) complexes responds to a variety of chemical signals to produce an array of multinuclear architectures.",1
18,3,"Cage 3 encapsulates a volume of 196 3,[16] 60 3 larger than its FeII analogue constructed by using aniline.[12a] In the crystal structure, one acetonitrile molecule was found within the cavity with two others in van der Waals contact with the faces of the tetrahedron. In solution 3 was observed by NMR spectroscopy to bind triflate ions, with an association constant of 43 m1. Despite its cryptate structure, the affinity of 3 for triflate is approximately 103 times weaker than that of the analogous noncryptate cage constructed from FeII ions and anilines, but similar to what was observed for an iron(II) cage assembled from A and aliphatic amines.",1
18,4,"Although we were not successful in numerous attempts to observe the parent ion of hexagonal prism 4 in ESI–MSsimilarly highly-charged species that are held together by relatively weak coordinative interactions are reported to be difficult to successfully observe[21]—its formulation is confirmed by elemental analysis, and its complex NMR spectra in solution are consistent with the solid-state structure.",1
19,1,"Chemistry is a difficult subject for many students, both at the secondary school level and at the college level for nonchemistry majors. Students face the challenge of assembling a mental model of atomic scale conditions and relating it to macroscopic phenomena. One piece of developing this construct is being able to imagine atoms and molecules and how they interact. The advent of computers has allowed chemists to create programs that aid in visualizing how atoms are arranged and predicting how they affect each other. However, these tools, which are so useful in research and education at the upper levels, are seldom used to present concepts at the secondary level1 and in introductory chemistry courses for nonmajors at the college level.2 Much of what has been reported is focused on second-year and beyond college chemistry classes.3−7 Very few studies have been reported discussing the use of research-grade computational chemical software as a learning aid for students in introductory college level courses.8−11 Fewer still attempt to use these tools to introduce important chemical principles to students at the high school level or to nonscience majors. Still, some resources aimed at high school level are available.",1
19,2,"I kept several collective goals in mind while developing each of the activities. First, the activity had to directly address common student misconceptions about the topic. To this end, I chose misconceptions described in the recently revised ChemSource SourceBook,18,19 as well as some from my own experience. These are listed in Table 1. Second, the text for the student-centered part of the activity had to be accessible to students with relatively little background in chemistry and who may still be developing literacy skills. I took care to avoid relying on knowledge of any but the most basic chemical terms and to define and explain new vocabulary. Below is a sample paragraph from the introduction to the Atomic Orbitals activity showing the style of writing.",1
19,3,"Another principle used in the design of the activities was to divide the activities into relatively short segments where the students alternate between reading to acquire knowledge and an exercise applying that knowledge. This helps the students stay engaged and also promotes learning.20 A fourth consideration was that each of the activities was designed to be used independently, although both activities assume at least some experience from the Getting Started activity. Therefore, once some or all of the Getting Started activity is completed, the other activities may be used in any order. Finally, each activity includes an instructor guide indicating what student background is expected, the major chemical concepts addressed, the objectives of the activity, typical results, and the time that the activity is expected to take.",1
19,4,"Although these activities use Gaussian 09 with GaussView for the graphical interface, the concepts underlying them could be adapted for use with other software, such as WebMO.21 Using sophisticated software engaged students more than they might have been with an animation or simpler simulation and gave them the impetus to work through the inevitable challenges that arose. See the section on the pilot programs below for more details.",1
19,5,"In addition to the collective design goals, both of the activities were designed with individual goals. The Getting Started activity is broken into several parts to introduce students to the software. After a general introduction, there are sections explaining how to use GaussView to build, rotate, move, and measure molecules, and finally a section describing in a general sense what Gaussian can do and how to start calculations with GaussView. Each of these sections includes a stepwise procedure demonstrating the process involved. This activity also includes a worksheet with a parallel structure for the students to complete while they read through the activity. It focuses attention on various aspects of each section, sometimes asking students to restate the most important information and other times asking them to think a bit beyond what they have just read. The Getting Started activity need not be completed in its entirety prior to using the other activities. For example, the section on measuring molecules is not necessary for completing the Atomic Orbitals activity.",1
19,6,"The Shapes of Molecules activity introduces students to the general terminology necessary for understanding why molecules have particular shapes and also to the five common molecular shapes: linear, bent, triangular planar, triangular pyramidal, and tetrahedral. Because these activities are designed for beginning levels, I chose to limit the shapes to those that students are most likely to see again in other science courses. The emphasis in this activity is to develop the skill of being able to predict an ideal three-dimensional geometry from a Lewis structure using the number of lone pairs and atoms bonded to a central atom. The activity does not address deviations from ideal geometries due to the nature of its intended audience. The first part of the activity presents vocabulary essential to the activity. In the second part, students are asked to draw Lewis structures and then build and measure several different molecules and identify their shapes using the software.",1
19,7,"A common misconception students have is “The number of electron pairs surrounding a central atom is equivalent to the molecular geometry of the resultant molecule.”19 In other words, students often take the short cut of simply counting the pairs of electrons, and using the result to assign the molecular geometry. For example, both CH4 and H2O have four pairs of electrons around the central atom, so a student may assign tetrahedral geometry to both molecules although water is a bent molecule. The module addresses this by having the students separately count the number of atoms and lone pairs attached to the central atom and then sum them. The students explicitly identify patterns in how bonding and lone pairs relate to different geometries.",1
19,8,"There are three sets of molecules included in the activity, which can be used on an individual basis to differentiate instruction. The first set has only neutral singly bonded structures that obey the octet rule and illustrate four of the five shapes. Triangular planar structures are omitted since there are no such structures that satisfy the other criteria for this set. The second set includes structures with multiple bonds and provides several examples of planar-triangular structures as well as a linear molecule with more than two atoms (CO2). The final set includes structures with multiple bonds, incomplete octets, and nonzero charges. Each set of molecules is presented on a separate page to simplify making combinations of the sets.",1
19,9,"Since students starting out in chemistry sometimes differ vastly in their ability to draw correct Lewis structures, the activity includes versions of the worksheets with the Lewis structures already filled in. These may be used at the instructor’s discretion to eliminate the requirement that students be able to create Lewis structures on their own. However, students will still need to be able to interpret them. In the data analysis section, students look for patterns among the three-dimensional shapes and Lewis structures to uncover the relationships between the two molecular representations.",1
19,10,"The Supporting Information contains the activity, a teacher’s guide, and worksheets for the Shapes of Molecules activity. There are four versions of the worksheets provided: one with all columns blank, one with only the Lewis structures filled in, one with Lewis structures and the number of atoms and lone pairs on a central atom filled in, and one with all the columns filled in except for the column containing a sketch of the molecules.",1
19,11,"The Atomic Orbitals activity explains the difference between orbits and orbitals and then looks at the structure of an orbital and its relationship to waves. Finally, the students look at a variety of atomic orbitals (s, p, d, and f) to discover the relationships between orbital size and energy level, orbital type and number of orbitals in a subshell, and orbital type and shape. Care is taken to limit the amount of vocabulary students need to know to understand the basic concepts. This activity has an accompanying worksheet for students to work on while they go through the activity, which includes short answer questions directly addressing the common student misconceptions listed in Table 1. The answers for these questions can be found in the accompanying text. Other questions ask students to sketch general shapes and sizes of orbitals, which helps students form nonlinguistic representations that aid in understanding.20 Using Gaussian for this part of the activity gives realistic sizes and shapes of orbitals. The Supporting Information provides the Atomic Orbitals activity, teacher’s guide, and worksheet.",1
19,12,The pilot studies were run using eight desktop personal computers in a high school library that functions as a computer lab. The computers had configurations typical of those found in many high schools today. Copies of these activities are available as Supporting Information for this article.,1
19,13,"The participants in this pilot were 11th and 12th grade students, 24 in an honors-type section of high school chemistry and 71 in three midlevel sections of college preparatory high school chemistry. Groups of three students worked on the activity for three 48 min sessions, the first two sessions were separated by a week, with the last session 2 days after the second. In each group, one student was selected to be the “driver”, the person who operates the computer and mouse. The software was used during the first two sessions, while the final session was reserved to allow students to discuss and work together on the analysis portion of the activity. Prior to beginning the Shapes of Molecules activity, the students had completed several parts of the Getting Started activity: building simple molecules, rotating and moving molecules, and measuring molecules.",1
19,14,"Students were very engaged while working with the software. Approximately 90% of the students in each section were consistently engaged during both sessions. Because Gaussian and GaussView are research-quality software, it is presumed that the users will have significant chemistry experience and, therefore, substantially developed chemical intuition when building molecules. Although these students had relatively little exposure to chemistry in the past and were still learning the patterns inherent in chemistry, they were able to use the software to good effect. Students were willing to try different ideas until they found the structures that matched their Lewis structures, rather than simply trying once and giving up.",1
19,15,"These results show improvement over my previous classes when ball and spring molecular models were used, although there was no control group in this pilot study to confirm this. In previous classes, approximately 65% of upper-level students and 40% of midlevel students were able to identify the correct molecular shape when given a Lewis structure. Also in prior classes, roughly 75% of upper level students and 60% of midlevel students would be able to correctly answer questions similar to the seven used in all the assessments. The results intimate a narrowing of the gap in performance between upper-level and midlevel students.",1
19,16,"The results of this pilot study indicate that it was successful in helping students understand the vocabulary and ideas necessary for determining molecular shape. Further, the students’ understanding was stable over a three week time span. The somewhat less successful outcome on the application questions of the longer term post-test suggests that an additional session, where students practice using findings from this activity, would be beneficial.",1
19,17,"The second pilot study also consisted of three parts: a pretest, the Atomic Orbitals activity, an immediate post-test, and then a final longer term post-test. All seven questions on both of the first two assessments were identical. On the final post-test, the questions were rewritten to focus on the application of the concepts, in order to minimize students simply repeating memorized answers from previous assessments. The questions were designed to directly address many of the learning objectives given in Table 1 as directly as possible and were all open-ended. Two of the learning objectives were not assessed during this pilot study. First, the objective concerning the improvements in the quantum mechanical model over the Bohr model was inadvertently omitted. Second, the objective about how orbitals overlap in three-dimensional space was omitted, since I was not able to formulate a question in such a way that students could understand what I was asking for, without also giving the answer as part of the question. A description of each question is given in Table 4. The questions can be found in the Supporting Information.",1
19,18,"At the high school level, much of the chemistry-related material made available to students using computers is limited to animations and simulations. Young, inexperienced students sometimes view these activities as toys or games and treat them casually. Using research-quality software, as these activities do, gives students the sense that their learning is being taken seriously and encourages them to take it seriously as well. The results of these pilot studies support this notion, since they indicate that students were engaged, achieved most of the learning objectives, and retained that achievement for some time. Thus, using research-quality software can be an effective means of learning even for students with very little chemistry background.",1
19,19,"These activities are designed, in both content and literacy level, to meet the needs of beginning general chemistry students at the high school and introductory college level. The activities may also be used with students in upper-level chemistry courses by increasing the difficulty of the questions and variety of the molecules.22 Using research-grade software engages students, showing them that the instructor sets high expectations for learning and is confident that students can meet those standards.",1
19,20,"Complete copies of the three activities, including student handouts, instructor guides, and typical answers to the activity questions; a complete copy of a fourth, unevaluated activity on periodic trends; all questions used in the assessments; scheme file for GaussView. The documents in the Supporting Information are reprinted with the permission of Gaussian, Inc",1
20,1,"This paper describes two case studies where problem-based learning (PBL) was introduced into two transportation courses in the civil engineering degree in University College Dublin (UCD). The transportation courses are taken in the penultimate and final year of the degree course when students are expected to become more able to direct their own learning and are preparing for the transition from passive learners to active researchers. Indeed, it is an objective of the university’s learning strategy that the education process produces graduates who are capable of independent learning (University College Dublin 2008).",1
20,2,"In the next section, there is a very brief description of PBL and its use in engineering programmes. The paper then goes on to describe the case studies. There were two courses in which PBL was implemented in UCD civil engineering. Finally, the paper discusses the successes and failures of this implementation process.",1
20,3,"PBL is a widely used approach to learning that allows students to take ownership of their own learning. Students work in small groups to define problems and then to deliver solutions to those problems. In PBL studies, students are presented with some form of problem or situation at the start of the learning process. They then work together to define that problem and to define their learning issues. Once the problem has been presented to the students, the critical inputs (in the form of lectures, tutorials, question and answer sessions) may then follow (Barrett 2005). With PBL teaching, the focus is on the student or the learner and on how they can think critically",1
20,4,"PBL approaches to learning have been used with some success in engineering courses in many countries.Young and Holgate (1994) describe the use of PBL in civil engineering drawing classes, while Said et al. (2005) describe how PBL has been used in Malaysia with electrical engineering students. PBL moves students to become more active in the learning process and is more studentcentred than other more traditional approaches to teaching (Kolmos 1996). Kolmos (1996) also suggests that using PBL develops the motivation to learn in students. The use of PBL for students, therefore, helps students learn to learn. It can also engender other important skills. Veldman et al. (2008) show that PBL helps students to improve the softer skills that engineers are so often criticised for lacking: cooperation skills; communication skills; teamwork skills. Johnson (1999) describes the use of PBL in engineering courses and states that the use of methods such as PBL and cooperative learning can be very refreshing for students and argues, like Veldman et al. (2008), that PBL methods can improve students’ other skills, such as writing skills and teamwork. There are difficulties associated with introducing PBL into courses. ",1
20,5,"Another difficulty lies in the fact that student evaluation in PBL courses may be more difficult and require more imaginative approaches to assessment (Acar 2004, McDonald 2005, Veldman et al. 2008). Work is done in groups and Acar (2004) suggests that group marking can be disadvantageous to some stronger students whose marks are pulled down by their team mates. Reeves and Laffey (1999) also mention that assessing PBL work is complicated. They argue that in PBL it can be hard to compare student performance and that embarking on a PBL course may mean facing considerable difficulties in assessment of that course.",1
20,6,"This section sets the context for the case studies. The civil engineering degree in University College Dublin is a 4-year programme. It is in the last 2 years of the programme that students start to really engage in civil engineering subjects. In the third and fourth years, students may take optional electives in transportation.",1
20,7,"In the fourth year, students start to look at modelling. One learning objective is that they can identify the advantages and disadvantages of different types of transport modelling and that they can apply critical thinking to assessing transport models. Fourth year students also study traffic engineering. The learning objectives are that they can identify how engineering can play a role in the safety of the road and to identify what factors can be changed by engineers to improve road safety and driver behaviour.",1
20,8,"PBL was used in both sections of the course. The objective of using PBL with the fourth year students was to enable them to make the transition from learning to research. These students are in their final year of university and will graduate to become engineers or may continue their academic career with further studies. In both situations, they need to be able to use the knowledge they have gained in lectures to solve problems and to research. Therefore, PBL was used with these students so that they could learn the skills necessary for problem solving and carrying out research.",1
20,9,"In both years, PBL was implemented in a similar way. The students have 3 hours of lectures per week. A series of tutorials were also set up for students to engage in PBL.",1
20,10,"In the third year, students were being introduced to PBL for the first time. The objective was to allow students to sample PBL and then this would prepare them for using PBL in their fourth year the following year. There were 35 students in this class.",1
20,11,"Transport policy is quite abstract and it is difficult for students to engage with this topic. In lectures, it is possible to outline to students different types of policies and to describe the theories or reasons for these policies but students must be able to critically analyse the policies and to be able to question their implementation. The best way to do this is to examine and research the implementation of the policies. Therefore, it was felt that using PBL to examine transport policy was an ideal solution.",1
20,12,"In lectures, students were introduced to different transport policies and given examples of how these policies were put in place. In week four, in a 2-hour tutorial, students were divided into groups of five and were presented with a newspaper headline regarding the potential introduction into Dublin of one of the more controversial of the policies that had been examined during lectures – privatisation and deregulation of the public transport network. This headline stated that the Minister for Transport was considering the introduction of privatisation and deregulation of bus networks in Dublin and was looking at international practice to see how this would work.",1
20,13,"In class, while students were introduced to the advantages and disadvantages of the relevant policies, they did not examine these disadvantages or advantages in any real way. It was hoped that in a PBL exercise students would research more deeply particular examples of the policies",1
20,14,Each group had to use the presented headline to define two questions related to the policy. Students had 1 hour in which to define these questions and each group had to present a page outlining their definition of the problem at the end of the session. Tutors were available in the room to facilitate the brainstorming sessions. The students could use some taught knowledge to tackle the problem but significant external research would be required as the topics had not been thoroughly covered within lectures.,1
20,15,"Having defined their problems, groups were then required to prepare several pieces of work, which would be assessed: an oral presentation of 10 minutes, where they discussed the outline of their problem and how they had defined it and where they answered the questions they had set for themselves; a more substantial written report; a poster that outlined the most pertinent parts of their presentations.",1
20,16,"The first two parts of the work (the oral and written presentations) were marked by the lecturer, while the final part (the poster) was assessed by the other groups. Groups were requested to return marks that reflected the ‘added value’ that they experienced from viewing these posters. These posters were a very important part of the students’ work. Groups were only allowed to prepare an A2 size poster and were limited in how much writing could be presented as these posters were meant to be visual representations of their problems and solutions. Therefore, students had to be innovative in how they presented the work on the posters. Students had 2 weeks in which the groups could work together to prepare and present their work.",1
20,17,"In the fourth year, students were able to engage in two problems. There were 50 students in this class. These problems were structured in the same way as the third year problem: students were presented with an outline or poorly defined problem at the start of a tutorial session. Then, in groups of five to seven students, they defined the problem and presented one page, outlining how they intended to tackle it over the course of the next 2 weeks. It had been hoped to have groups of only five students again. However, not everyone was present when groups were originally assigned and so some groups had to become larger.",1
20,18,"In the first problem, students were presented with a statement about the relative merits of different approaches to transport modelling, using terms and referring to theories not yet encountered by the students. In this case study, the learning objective was that students would encounter some of the complexities involved with transport modelling. In lectures, students had looked at transport modelling but had not actually compared models at this stage. To tackle the problem, extensive research into transport modelling was required, which had not taken place in class.",1
20,19,"As mentioned, students had not encountered the terms forgiving roads or self-explaining roads in the past and were expected to find out what these terms meant, to find out how a road can be defined in this way and how audits can be carried out to ensure that a road is self-explaining or forgiving. There are many different systems and tools used for auditing safety roads and it was hoped that the students would discover several of the methods used in different countries and would be able to present and debate the relative merits of different methodologies.",1
20,20,"There were several objectives to the third year and fourth year PBL exercises. It was hoped that students would engage with topics that are difficult to teach and would learn more about these topics. The students would gain the ability to research and to engage in independent study. Defining the problem would allow students to be more innovative in their thinking. In addition, the students were working in teams and would learn how to communicate and to organise teamwork. It is an objective of civil engineering in UCD that students are exposed to as much project work and teamwork as possible in order to allow students to learn how to work together in teams. In these third and fourth year courses, an introductory session explained the different roles involved with teamwork – such as chairperson, timekeeper and note taker. The chairperson was elected by the team and was charged with ensuring that every member of the team had an opportunity to speak and to ensure that the discussion remained relevant. The note keeper was also chosen by the team and ensured that all decisions were noted and that the final problem or question as defined by the team was written down and agreed upon by all team members.",1
20,21,"The most important skill it was hoped the students would acquire was the ability to direct their own learning and to engage in independent learning. Students were given very little guidance in how to define the problems and in how to carry out the research. At this stage, these students need to make the transition from passive note takers and learners to independent researchers and active learners.",1
20,22,"The objective of using PBL on these courses, as has been stated, was to encourage students to become more active learners and to take charge of their own learning. Therefore, to assess the success or otherwise of the implementation of PBL into these courses, it is necessary to ask the following question: ‘Did students make the transition from passive note takers to active, independent learners?’.",1
20,23,"In both classes, students engaged well with the PBL courses and groups presented innovative and unusual approaches to the problems that they were given. The third year class were looking at issues relating to transport policy. Students were very mature in their approach to these problems and there was significant evidence of students carrying out independent research and reading outside of the lecture course and reading materials for the course. Several groups made real efforts to look at more unusual examples where privatisation and/or deregulation of public transport had taken place. It had been hoped in this problem that students would be able to make mature decisions about the relative merits of privatisation and/or deregulation and at the end of the presentations they were asked to give their opinions on privatisation and deregulation. The opinions given varied, with some being in favour and some against these policies but all were able to back up their position with what they had learned.",1
21,1,"Analysis of many civil engineering phenomena is a complex problem due to the participation of a large number of factors involved. Traditional methods usually suffer from a lack of physical understanding. Furthermore, the simplifying assumptions that are usually made in the development of the traditional methods may, in some cases, lead to very large errors. The purpose of this paper is to present a new method, based on evolutionary polynomial regression (EPR) for capturing nonlinear interaction between various parameters of civil engineering systems.",1
21,2,"EPR is a data-driven method based on evolutionary computing, aimed to search for polynomial structures representing a system. In this technique, a combination of the genetic algorithm and the least-squares method is used to find feasible structures and the appropriate constants for those structures.",1
21,3,"Capabilities of the EPR methodology are illustrated by application to two complex practical civil engineering problems including evaluation of uplift capacity of suction caissons and shear strength of reinforced concrete deep beams. The results show that the proposed EPR model provides a significant improvement over the existing models. The EPR models generate a transparent and structured representation of the system. For design purposes, the EPR models, presented in this study, are simple to use and provide results that are more accurate than the existing methods.",1
21,4,"In this paper, a new evolutionary data mining approach is presented for the analysis of complex civil engineering problems. The new approach overcomes the shortcomings of the traditional and artificial neural network-based methods presented in the literature for the analysis of civil engineering systems. EPR provides a viable tool to find a structured representation of the system, which allows the user to gain additional information on how the system performs.",1
21,5,"Many civil engineering problems lack a precise analytical theory or model for their solutions. This is usually because of an inadequate understanding of the phenomena involved and the factors affecting them, as well as a limited quantity and poor quality of information available. In order to cope with the complexity of civil engineering problems, traditional forms of engineering design solutions have been widely developed.",1
21,6,"The information has been usually collected, synthesized and presented in the form of design charts, tables or empirical formulae.",1
21,7,"In recent years, by pervasive developments in computational software and hardware, several alternative computer-aided data classification approaches have been developed. The main idea is that a pattern recognition system (e.g. neural network or fuzzy logic) learns adaptively from experience and extracts various discriminants, each appropriate for its purpose. Although there are other general purpose data-driven techniques, artificial neural networks (ANNs) are the most widely used pattern recognition procedures that have been introduced to model complex civil engineering problems and capture nonlinear interactions between various parameters in a system.",1
21,8,"A neural network consists of a number of interconnected processing elements, commonly referred to as neurons. The neurons are arranged into two or more layers and interact with each other via weighted connections. The data are presented to the neural network using an input layer; and an output layer holds the response of the network to the input. The input-output relationship is captured by repeatedly presenting examples of the input-output datasets to the ANN and adjusting the model coefficients (i.e. connection weights) in an attempt to minimize an error function between the historical outputs and the outputs predicted by the model",1
21,9,"Although it has been shown by researchers that ANNs offer great advantages in the analysis of many civil engineering applications, they have their own drawbacks. One of the disadvantages of the ANN is that the optimum structure of the network (such as number of inputs, hidden layers, transfer functions, etc.) must be identified a priori, which is usually done through a time-consuming trial and error procedure. Furthermore, the main disadvantage of the neural network-based models is the large complexity of the network structure, as it represents the knowledge in terms of a weight matrix that is not accessible to the user.",1
21,10,"In this paper, a new approach is introduced to model civil engineering systems. This new technique is evolutionary polynomial regression (EPR) which uses evolutionary search to find polynomial expressions for a system. Previous applications of EPR have proved its effectiveness in the fields of environmental modelling (Giustolisi et al., 2007) and water system management (Savic et al., 2006). The capabilities of the EPR technique will be demonstrated here by application to two practical examples of civil engineering.",1
21,11,"GP and ANN are both very powerful nonlinear modelling techniques, but they have their own drawbacks. GP tends to search for mathematical expressions for F using an evolutionary approach, but the parameter values (vector u) are generated as non-adjustable constants, referred to as ephemeral random constants. Therefore, the constants do not necessarily represent optimal values as in numerical regression methods and good structures of F can be missed in the process. Furthermore, the number of terms in GP-based expressions can expand greatly and the evolutionary search within GP can be quite slow. Some of the disadvantages of ANN approach have been highlighted in the previous section.",1
21,12,"To avoid the problem of mathematical expressions growing rapidly in length with time associated with GP, in EPR, the evolutionary procedure is conducted in the way that it searches for the exponents of a polynomial function with a fixed maximum number of terms, rather than performing a general evolutionary search as used in normal GP. Furthermore, during one execution, it returns a number of expressions with increasing numbers of terms up to a limit set by the user, to allow the optimum number of terms to be selected.",1
21,13,The global search for the best form of equation (8) is performed by means of a standard GA over the values in the user-defined vector of exponents (i.e. EX). The GA operates based on Darwinian evolution that begins with random creation of an initial population of solutions.,1
21,14,Each parameter set in the population represents the individual’s chromosomes. Each individual is assigned a fitness based on how well it performs in its environment.,1
21,15,"Additionally, it is clear that the presence of one zero in EX assures the ability to exclude some of inputs and/or input combinations from the regression equation. The EPR process stops when the termination criterion, which can be either the maximum number of generations, the maximum number of terms in the target mathematical expression or a particular allowable error, is satisfied. A typical flow diagram for the EPR procedure is illustrated in Figure 1.",1
21,16,"In regression-based modelling, the “fitness” usually refers to a measure of how closely the regression expression fits the data points. However, it is widely accepted that the best modelling approach is also the simplest that fits the purpose of the application.",1
21,17,"Suction caissons are used as anchor foundations of large offshore structures. A suction caisson is designed to initially penetrate the seabed by its own weight. If it is required to penetrate to its full design depth, suction is usually applied by pumps in order to create an under pressure inside the caisson, relative to the water pressure outside. The schematic sketch of a typical suction caisson is presented in Figure 2.",1
21,18,"The inclined uplift capacity of suction caissons is a critical issue that needs to be evaluated reliably. During recent years, ANN has been used to predict the uplift capacity of suction caissons using experimental data (Rahman et al., 2001; Vijayalakshmi Pai, 2005). The ANN-based (black box) models have been able to successfully capture the input-output relationship for the given set of data but they do not provide a transparent relationship that can be used in engineering practice.",1
22,1,"Civil engineering is experiencing an increasing stakeholder emphasis on sustainable development (SD). As such, it is becoming ever more important that engineers share knowledge and information to cope with the complex integrated nature of SD. This article uses social network analysis (SNA) to explore SD knowledge and information sharing relationships. Three functional units within an international civil engineering consultancy were web surveyed to solicit population members’ SD contacts, achieving a 76.8% response rate. The data was analysed with the aim of understanding: intra-population and crossboundary connectivity; relationship effectiveness; and key players within the networks. This revealed three main findings. First, cross-functional relationships were commonplace, suggesting population members were seeking SD knowledge and information from other specialist areas. Second, population members were more likely to approach co-located peers for knowledge and information; they often exhibited fewer inter-office SD relationships e a common issue due to the inherent costs of developing and maintaining long-distance relationships. ",1
22,2,"Social networks play a fundamental role in how we share knowledge and disseminate information (Wang et al., 2006). Although modern communication technology, such as Web 2.0, is increasingly embraced in both public and private domains, there is still a plethora of research that indicates that people use personal networks to solicit knowledge and information before accessing other resources (e.g. the Internet, people outside of their immediate personal network). For knowledge-intensive organisations social networks are especially important as staff use personal relationships to find information and solve problems (Cross et al., 2001, 2002a).",1
22,3,"In this article we turn our attention to analysing sustainable development (SD) social networks within an international civil engineering consultancy. Civil engineers across the world are responsible for creating and maintaining environments that, to a large extent, govern how we live and behave (Shelbourn et al., 2006). However, it is widely understood that this sector has been slow to embrace SD, possibly due to civil engineering’s complex and fragmented nature (Myers, 2005). SD is increasingly recognised as an approach to “the fulfilment of human needs through simultaneous socioeconomic and technological progress and conservation of the earth’s natural systems” (Sage, 1999). This means developing SD systems is a complex process (Godfrey, 2006), shrouded in risk and uncertainty. Nevertheless, stakeholders are placing increasing emphasis on SD.",1
22,4,"To cope with this, individuals rely heavily on sharing interdisciplinary knowledge and information through personal networks to respond and adapt to shifting SD requirements and capabilities",1
22,5,"The aim of this article is to demonstrate how social network analysis (SNA) can aid in understanding knowledge and information sharing for SD. Whilst a large body of literature has applied SNA techniques, hitherto no SNA research in this context has been published. The work reported in this article forms part of a programme of research within an international civil engineering organisation. In a previous study the authors’ argued that the slow adoption of SD in the study organisation is in part caused by the poor intra-organisational sharing of SD knowledge. This concluded that three fundamental barriers were impeding effective SD knowledge sharing (KS) within the study organisation; these were: a lack of organisational slack (i.e. little or no available time to participate in KS activities); a silo mentality (i.e. little or no interaction with other business units); and poor information and communication technology (ICT) systems. The principal purpose of this research was to use SNA to verify whether the first two barriers, a lack of organisational slack and silo mentality, are preventing SD knowledge and information sharing within the study organisation. Four research questions underpinned this purpose as given in Table 1.",1
22,6,The structure of the article is as follows. It begins with a brief overview of social networks and SNA. The methodology and findings are then presented and discussed. Conclusions and implications of employing SNA for improved SD performance are outlined in the final section.,1
22,7,"Organisational social networks ideally connect a collection of individuals, directly or indirectly, across functional, geographic or organisational boundaries (McKeen and Smith, 2007) via a series of established relationships (Zack, 2002). These networks generally exhibit two principal purposes; to facilitate knowledge search and knowledge transfer (Mckeen and Smith, 2007). Knowledge search often comprises of a group of actors seeking a particular knowledge artefact. Actors initiate a search by using their existing knowledge of what is being sought to guide who they interact with. Organisational knowledge searching can occur within team networks (e.g. business units, project teams) or inter-subsidiary networks (i.e. seeking across functional boundaries) (Hansen et al., 2005). If the knowledge search is successful, identifying the sought or useful knowledge, it then needs to be transferred from the source to the recipient.",1
22,8,"SNA has been applied in various fields, including: sociology; anthropology; information systems; and organisational behaviour (Liebowitz, 2005). It is frequently used as a primary and systematic means of mapping and assessing an individual’s or group’s opportunities in terms of exposure to and control of knowledge and information (Haythornthwaite, 1996; Cross et al., 2001). Revealing a social network’s structure allows identification of opportunities for improvement; e.g. pockets of intellectual capital, the need to socialise actors or how organisational learning may be enhanced (Liebowitz, 2005; Chan and Liebowitz, 2006). However, SNA methods are yet to be applied in an SD context within the civil engineering domain, which is recognised for its slow uptake of SD practices (Boddy et al., 2007) and fragmented nature",1
22,9,"A plethora of factors contribute to the effectiveness of relationships. Investigating various relationship factors could produce dramatically diverse perspectives of a social network’s character and form. Cross and Parker (2004) outline a set of primary relationship factors that, for them, have proved useful in revealing network characteristics. Moreover, Cross et al. (2001) provide a reduced set of four factors that distinguish effective from ineffective relationships: knowing what another peer knows and thus when to elicit advice and support from them; being able to gain timely access to the peer; willingness of the peer to engage in problem solving rather than providing an overwhelming volume of information; and a degree of safety in the relationship that promoted learning and creativity.",1
22,10,"In SNA, social network data are commonly stored in a ‘relational’ data format (e.g. in an adjacency matrix) and are often visually represented as sociograms; two-dimensional diagrams where each actor is represented by a shape (e.g. a circle, a square) with lines connecting shapes where ties are present. A tie can be represented in a combination of ways. First, they can be either undirected (i.e. symmetrical) or directed (asymmetrical). Second, they can be binary (i.e. either present or not present) or valued (typically indicating the strength or ‘weight’ of a tie attribute, e.g. regularity of contact). The simplest data are undirected and binary; the most complicated data are directed and valued. It is noteworthy that directed and valued data can be dichotomised into undirected and binary data by specifying a cut-off bias or value. An example of how relational data are stored and represented is given in Fig. 1; this clearly shows how different interpretations can arise simply from the richness and format of the data. Dedicated SNA software, such as UCINET (Borgatti et al., 2002) and NetMiner (Cyram, 2010), efficiently manipulate such data structures, enabling users to visualise and mathematically analyse the relationships.",1
22,11,"Visualisation techniques play an important role in facilitating exploration of social network data (Moreno and Paton, 1953) and engaging with stakeholders. As such, different visual layouts and formats may generate different interpretations and discussions. This lack of consistency emphasises the degree of subjectivity when undertaking visual analysis (Butts, 2008). Graph theory overcomes this subjectivity by offering objective network measures by means of mathematical techniques.",1
22,12,"Social networks often exhibit ‘key player’ actors whose role is critical to the productivity of the entire network (Chan and Liebowitz, 2006). These roles are categorised, in one form or another, as: central connectors; boundary spanners; information brokers; and peripheral people. Table 2 provides a brief description of each of these roles. Identification of such actors is one of the primary uses of SNA (Zemljic and Hlebec, 2005), enabling organisations to recognise and work with these individuals to improve their effectiveness, thus improving the network’s productivity, whilst helping to retain those who make a substantial difference in the organisation (Cross and Prusak, 2002). It is important to note, however, that actors are likely to play different roles, at varying degrees of significance, in an array of networks.",1
22,13,"Over the past five years the organisation has developed a keen interest in SD. In 2007 two dedicated sustainability leaders were appointed to oversee SD activities within the organisation. One leader is responsible for internal SD operations (e.g. SD project assessment, office operation, and so on); the other is responsible for strategic development and interfacing with relevant external bodies. These dedicated individuals underpinned a Sustainability Task Force (STF) that consisted of SD representatives from each business unit. Meeting each month, STF members shared an understanding of sustainability within the organisation (e.g. initiatives, innovation, market conditions, and client requirements). The STF also acted as a platform for disseminating information and orchestrating programmes. In addition, the organisation’s intranet system hosted a sustainability ‘gateway’ resource tool which aimed to harness group-wide understanding, capabilities and experience in SD.",1
22,14,"Cross et al.’s (2001) four relationship factors relate to awareness, access, engagement and safety. They do not, however, refer to the frequency of communication between individuals, but this is more recently referenced by Cross and Parker (2004) as an important relationship factor for uncovering collaboration in a social network. As the authors’ seminal research within the organisation expressed an open communication culture towards SD and KS, it was decided thatCross et al. ’s (2001) safety factor would be substituted with frequency of communication. This, it was felt, would provide a richer insight into the organisational slack issue, for which this research in part aims to verify. In summary, the relationship factors measured to address RQ3 were: frequency of communication; awareness; access; and engagement.",1
22,15,"Social network data can be gathered in a variety of ways. The most common mode is survey, although there are examples of SNA research using interviews (cf. Hogan et al., 2007) or secondary data (e.g. email server data). Here we used an electronic web survey; an ideal and popular medium for conducting research (Couper, 2000; Faught et al., 2004; Van Selm and Jankowski, 2006). Web surveys have many benefits over conventional survey modes (e.g. speed of transmission, ease of analysis, respondent convenience, global reach, dynamic functionality) (Meese et al., 2010). However, they are also more susceptible to survey error, in particular nonresponse (Manfreda et al., 2008, cf.Meese et al., 2010 ). SNA studies are sensitive to missing data (Knoke and Yang, 2008) and require a high response rate, typically between 65% and 90% (Stork and Richards, 1992). As such, the researchers were proactive in reducing survey error by adopting the recommendations outlined by Meese et al. (2010); for example, a personalisation strategy was employed using Microsoft Outlook’s Mail Merge feature (Heerwegh, 2005), two rounds of follow-up ‘reminder’ emails were sent to nonrespondents at fortnightly intervals.",1
22,16,"The survey consisted of four sections. First, an introduction page provided a brief overview of the study, including a confidentiality statement and the research team’s contact details. Second, respondent information was gathered. Third, the respondent was presented with the main body of the survey; i.e. instructions on how to complete the SNA questions, a description of SD, and contact input boxes. The final section was a completion page to confirm that responses had been successfully submitted. A final survey pilot indicated the survey was likely to be completed in three to six minutes; research suggests that shorter, less time consuming surveys, such as this, deliver higher response rates",1
22,17,"Confidentiality protocols are vital when gathering, analysing and reporting social network data. Revealing these hidden structures can threaten or damage an individual’s position and roles within a network (Kadushin, 2005), even though the data may not be truly representative of the structure under scrutiny. Therefore, the research team was wholly responsible for the data’s secure handling, and only reporting findings that exempt actors’ identity.",1
22,18,"The survey was live for a total of four weeks. Responses were downloaded and imported into Microsoft Excel for manipulation. A series of VBA macros were used to: flag imprecise contact details for clarification (24.6% of names did not directly align with the personnel database); link respondents and contacts with the organisation’s personnel database; generate directed graph files that are recognised by UCINET (Borgatti et al., 2002), the software package used for analysis; and extract actors’ organisational grouping and location information from the personnel database.",1
22,19,"Specifying a boundary around the data to be collected and analysed is often a difficult task (Scott, 2000). An inadequate network boundary may include or exclude a relevant or irrelevant set of actors and, more importantly, the relationships between those actors and others within the population (Butts, 2008). As the research question was focused on knowledge and information sharing within functional business units, a ‘positional strategy’ was adopted; this is where formally defined memberships define the boundary of the population (Scott, 2000; Knoke and Yang, 2008). Three populations, referred to by the organisation as skill groups (SG), were studied. A SG is formed within the organisation’s hierarchical structure to serve a predetermined function. Each population, referred to as SG1, SG2 and SG3, was selected based on their information and knowledge sharing performance. Performance data were extracted from staff survey results in 2008, classifying SGs as: good (top 25%); average (middle 25%); or poor (bottom 25%). SG1 is involved in transportation infrastructure; SG2 provides business management solutions to internal and external clients; and SG3 is involved in power station design.",1
22,20,"Sociograms of the studied networks are shown in Fig. 3; graphs in the left column depict all actors (i.e. the whole network e all respondents and their contacts), whereas those in the right column depict only respective population actors (i.e. non-population contacts are excluded).",1
22,21,"Cut points were calculated to determine the fragility of the networks. SG1, SG2 and SG3 have 14 (16.5%), 47 (18.2%) and 23 (26.4%) cut points respectively within their networks. SG1 was least fragile in this sense as it was not reliant on non-population members for SD connectivity; SG3 had only one non-population cut point (which linked a single peripheral actor); whereas SG2 had four non-population cut points. These fragility measures were demonstrated by the degree of intra-population connectivity fragmentation created when non-population members were removed (Fig. 3: intra-population network).",1
22,22,"Fig. 4 shows the geodesic path lengths in each network; i.e. the number of links required from one actor to another. As shown, the majority (i.e. more than 80%) of actors could be reached in up to four links. However, there were a small number of actors that were difficult to reach; this is particularly true in SG2 with its longest shortest path being 12. In relation to this, Fig. 5 suggests how tightly connected local SD communities are within each network by presenting the size and number of weak cliques (Scott, 2000) in each population. Large numbers of small cohesive subgroups were present within each network. SG3 exhibited the largest clique consisting of seven actors; SG1 and SG30s largest clique contained six and five actors, respectively.",1
23,1,"There have been significant changes in undergraduate civil engineering curricula in the last two decades. Key issues for university curriculum committees are selection and transference of appropriate skills and attributes for students to succeed in the industry. Despite significant changes occurring in teaching theories, civil engineering education still relies heavily on deductive instruction. Case-based teaching is one of the most widespread forms of inductive learning and this paper describes the differences between two of the most familiar types: ‘case-histories’ and ‘case-studies’. These methods are presented using the Kansas City Hyatt Regency walkway collapse as an exemplar. The benefits of using this approach are improved retention of knowledge, better reasoning and analytical skills, development of higher-order skills, greater ability to identify relevant issues and recognize multiple perspectives, higher motivation and awareness of non-technical issues. Many of these outcomes are part of the expected attributes of civil engineers outlined by professional bodies.",1
23,2,"Over the last 20 years there have been significant changes in undergraduate civil engineering curricula in response to student, industry and societal needs, accrediting professional bodies and government organisations. In part this has been due to improvements in computational analysis and design in various fields, and greater recognition of the advantages of ‘soft skills’ to the engineering profession, but it has also been driven by research advocating more student-centred learning and teaching approaches (e.g., Entwistle 1988; Ramsden 1992; Biggs 1999; Fry et al. 1999). Hence a plethora of new and potentially contradictory educational theories are now entering our field, most of which have been developed in other disciplines.",1
23,3,"Key issues for university curriculum committees are the selection and transference of a definitive group of skills and attributes that they expect students to acquire before graduation, to best prepare them for a career in the industry. There has been much research and discussion within academia and industry on this subject (e.g., Williams 1988; Henshaw 1991; Harvey et al. 1997; Yorke 1999; Blum 2000; Mills and Treagust 2003).",1
23,4,"In the early 1990s, Professor Alan Davenport was intrigued by a debate that unfolded in his home between his daughter and a number of her peers. These students were enrolled in the Ivey Business School at the University of Western Ontario and they were discussing aspects of a ‘case study’ that formed part of their course. Fascinated by the process and the enthusiasm that he witnessed, Professor Davenport pursued the idea of teaching civil engineering using this methodology and this eventually led to the development of a full one-semester final year undergraduate course in ‘Case Studies in Civil Engineering’ at the University of Western Ontario. This course has been further developed over the last two decades and now forms a significant part of the preparation of students for their professional careers. The course is currently taught by the first author and a number of guest lecturers following the Harvard Business School case study method (e.g., McNair and Hersum 1954). The evolution of the course has spawned a large number of cases that have originated from Professor Davenport and other participants involved with the course. An overview of a selection of these pioneering civil engineering teaching cases is shown in Appendix A (Table A1).",1
23,5,"Other courses and case studies have also been developed elsewhere for the teaching of civil engineering (e.g., Bosela 1993; Rendon-Herrero, 1993a, 1993b; Baer 1996; Delatte 1997; Rens and Knott 1997; Pietroforte 1998; Carper 2000; Delatte 2000; Jennings and Mackinnon 2000; Rens et al. 2000; Delatte and Rens 2002) and a considerable database of case studies is now available for the teacher to utilize (see Appendix B). Whilst full courses such as that taught at the University of Western Ontario are still rare, dissemination of individual cases through other courses is becoming more common (Delatte and Rens 2002). Two distinct forms of case-based teaching method are employed in the majority of these courses: the classical Harvard Business School ‘case study’ and the ‘case history’. Both approaches can address the higher levels of Bloom’s revised taxonomy of learning domains (e.g., Bloom 1956; Anderson and Krathwohl 2001) and promote student-centred teaching that develops deeper and more meaningful engineering learning outcomes. ",1
23,6,"In contrast, inductive teaching assumes that knowledge can be based on the experiences and interactions of the student with different phenomena (Lahti 1978; Stahovich and Bal 2002). The instructor will initially illustrate a concept through a tangible example, rather than through generic instances. Students then attempt to make appropriate generalizations from observations (often quickly recognizing the need for relevant particulars, skills and concepts), with the support of the instructor. This provides a more experiential, guided form of discovery learning. Inductive teaching is therefore more learner-centered, challenging students to take more responsibility for their own learning, when compared to deductive teaching methods. There are a wide range of inductive teaching methodologies available, such as inquiry learning, problem-based learning, experiential learning, case-based teaching and discovery learning, and these are described in greater detail elsewhere (e.g., Kirschner et al. 2006).",1
23,7,"The effectiveness of inductive teaching methods has been investigated previously and has been found to encourage deep learning approaches (e.g., Coles 1985; Norman and Schmidt 1992; Ramsden 1992), enhance intellectual development (e.g., Felder and Brent 2004) and align with the findings of neurological and psychological studies (e.g., Bransford et al. 1999). In particular, workers in cognitive psychology have developed frameworks linking cognition, development and learning (e.g., Piaget 1972; Vygotsky 1977). They stress the importance that context and environment play for the learner, and argue that as humans we are already immersed in social and physical environments. These social interactions provide learners with established systems that can modify thought processes, present new values and introduce sets of obligations. Given the existence of strong professional engineering organizations and industries in many countries, this research suggests that we may benefit our teaching by further improvement of links between academia and industry, to provide the appropriate immersion and exposure within these engineering communities.",1
23,8,"Further development of the constructivist approach has involved collaborative learning and concepts of group work (Bruffee 1993). Collective construction of knowledge forms the basis of problem-based and case-based learning, where the instructor functions as the ‘master’ learner and resource, and group members function as a community to develop their own unique set of solutions to problems. One difficulty associated with constructivist approaches for instructors is that students are sometimes not compelled to develop suitable expertise prior to interacting with teaching sessions. However, they can still be encouraged to explore the presented problems and although they relate to them in a less intellectually robust manner, the aim of the learning outcomes will be the actual process of acquisition and retention of information. Therefore, learning ‘content’ for inductive methods is often a means to further knowledge, rather than an end in itself, and relates more to the development of unique and individual ways of understanding.",1
23,9,"The scheme of intellectual development created by Perry (1970) describes the sequence of approaches adopted by students during learning and their progression to more complex forms of thought as they develop with time. Four of the nine stages have been emphasized by Thompson (1999) as representing the most significant milestones: dualism, multiplism, contextual relativism and commitment to relativism. This progressive development involves learners altering the approach that they take to learning and content, from an acceptance of the certainty of knowledge and the influence of authorities (i.e., the instructor), to an acknowledgment of the uncertainty and contextual nature of knowledge, and recognition of their own analytical abilities. The use of this model in the context of engineering education has been discussed by various researchers (e.g., Culver and Hackos 1982; Pavelich and Moore 1996; Palmer and Marra 2004). Unfortunately, engineering students will often only reach the lower levels of the Perry scale (Wise et al. 2004), which is a reflection of the predominance of ‘dualistic’ forms of teaching in engineering (Wankat 2002). Baxter-Magolda (1992) extended the Perry model and defined four levels of intellectual development: absolute knowing, transitional knowing, independent knowing and contextual knowing. ",1
23,10,"In recent years, there has been a shift of pedagogical emphasis in engineering away from the laboratory and smallgroup sessions, to lecture-based and web-based education (Abdulwahed and Nagy 2009). This is thought to be due to a number of reasons, including larger class sizes, cost of maintenance and upgrading laboratories, and poor alignment of laboratory and lecture outcomes. However, recently there has been a rethink of this type of teaching (Feisel and Peterson 2002; Hofstein and Lunetta 2004) as the appeal of constructivist approaches has increased. The philosophical and research basis for this type of ‘experiential’ learning is encapsulated in the cyclical learning model of Kolb (1984), see Fig. 1. This model assumes that there is a sequence of learning activities that are involved in effective learning, where there is a cycle of experiencing, reflecting, thinking and acting. Learners belong to one of four types: divergers, assimilators, convergers and accommodators, being most comfortable with the activities in one quadrant of the learning cycle. This approach is useful because it enables understanding of different learning styles and simultaneously explains experiential learning. The model has been updated recently (e.g., Jarvis 1995), but still remains as an important model in learning theory. ",1
23,11,"Despite significant changes occurring in teaching and learning theories, civil engineering education still relies heavily on deductive instructional methodologies. Inductive approaches are commonly used in other fields and have considerable support in the literature. Case-based teaching is one of the most widespread forms of inductive learning and this paper has described the shared elements and differences for two of the most familiar types: ‘case-histories’ and ‘casestudies’, and presented these methods using the classic Kansas City Hyatt Regency walkway collapse as an exemplar. Preferred learning styles by students affect the efficiency of teaching and use of a combination of deductive and inductive methodologies may be the route to higher level and broader learning outcomes.",1
23,12,"Professor Alan Davenport pioneered the usage of the casestudy method in civil engineering education at the University of Western Ontario and this approach has been a great success over last 20 years. The course that he developed is often cited by undergraduate students as the most enjoyable and effective in their final year. Given the emphasis that is now placed upon critical thinking and problem-solving skills, it is surprising that this type of course is not more commonly used in civil engineering curricula across North America. The authors hope that this situation will change and that civil engineering educators will embrace this teaching approach in their efforts to educate and mentor the next generation of practicing civil engineers.",1
24,1,"This paper describes the use of project based learning to teach design skills to civil engineering students at University College Dublin (UCD). The paper first considers the development of problem based leaning (PBL) as a tool in higher education. The general issues to be considered in the design of the curriculum for an PBL module are reviewed. Consideration of the literature on the application of PBL in civil engineering suggests that because of the hierarchical nature of engineering education, PBL is best applied in a hybrid form known as Project Based Learning. A detailed description is given of how hybrid PBL was implemented in the final year of a civil engineering degree programme is then presented. In the final section, the results of an evaluation process designed to gain an insight into students’ perceptions of the PBL process are reviewed. The module which was developed at UCD provided an excellent mechanism for developing many skills including, problem-solving, innovation, group-working and presentation skills desired by graduate employers. It was clear that the students enjoyed the peer to peer teaching and increased interaction with staff and external experts which the problem solving nature of the module facilitated.",1
24,2,"Engineering education is in a state of flux with Universities facing requirements from industry to develop graduates with a wider skills base while at the same time a revolution in the availability of information is changing the way that students learn De Bono (1992) suggests that as global competition increases, the key to competitiveness is creativity, and companies must generate added value from their existing resources and assets. Baillie and Fitzgerald (2000) state that employers need transformative employees with the skills to analyse, critique and communicate innovative solutions within a team based work environment. In a recent report, the American National Science Board (2007) noted that one of the consequences of increased globalisation was that basic engineering skills are commodities which can readily be sourced in low-cost economies.",1
24,3,"Faced with these external drivers, a number of professional engineering and accreditation bodies have established task forces with a mandate to update and improve the curriculum of engineering programmes. One of the key recommendations the United States Accreditation Board for Engineering and Technology (ABET) guidelines (cited in Prados 1998) was that instruction in design, which included at least some of the following aspects; use of open-ended questions, formulation of design problems, and consideration of alternatives would lead to the development of more innovative engineers.",1
24,4,"Whilst PBL has proved to be very successful, particularly in medical education, the forms of PBL often practiced in engineering schools (such as Aalborg in Denmark and the National Technical University in Trondheim, Norway are often described as Project Based or Hybrid PBLMills and Treagust (2003) differentiate Project Based Learning (hybrid) and Problem Based Learning in the following ways",1
24,5,"Some of the major problems facing educators who wish to develop PBL courses include (i) the question of how to organise the students into groups, (ii) are good quality, experienced facilitators available?, (iii) is there physical space available outside of lecture theatres? and (iv) how to phrase the problems? Questions (i) to (iii) largely depend on the available resources and may in large part explain the diversity of PBL approaches adopted throughout the world. In general, engineering students are used to working in small (laboratory and tutorial) groups from the time they enter University and the group size appropriate to Project based learning (typically less than six students) is very familiar to them.",1
24,6,"The hybrid PBL or Project based approaches can be operated with a floating facilitator (or tutor) as the students are applying knowledge and creating links rather than creating knowledge and therefore need significantly less scaffolding or support. The question of physical space is an institutional issue. However, faculty members should be cognisant of the benefits in providing project rooms in new and refurbished facilities. Assuming that these obstacles can be overcome through resourcing, the perennial issue of the form of problems to be presented is the key to success of any PBL initiative.",1
24,7,"Federau (2006) describes the learning climate model which can be used to ensure the preparation of good problems. The two-axis model considers the assignment freedom, which is a measure of how open the question is. He describes the example of a bridge design exercise “design a bridge to span from A to B”, which if given to a first or second year student who has not studied engineering materials or bridge engineering, will represent a problem with a high degree of assignment freedom. In contrast, if a final year student is asked to “design a concrete bridge to span from A to B” a relatively low score on assignment freedom would result.",1
24,8,"The abscissa, Active Drive, is a measure of how motivated a student will be to acquire the knowledge required to solve the problem. Put simply, there is a significant pressure on the first or second year student discussed above to self-educate on the basics of bridge engineering, e.g. what spans are permissible for given engineering materials etc. thus resulting in a high value for active problem drive.",1
24,9,"Kolmos et al. (2009) present a PBL model which provides a holistic view of the elements which must be considered in a PBL curriculum. These include consideration of (i) the objectives and knowledge, (ii) types of problems, (iii) progression, size and duration, (iv) student learning, (v) academic staff facilitation, (vi) space and organisation, (vii) assessment and evaluation. The model forms a useful tool to consider the PBL module case studies in civil engineering which is taken by the students in the first semester of the 2 year Master of Engineering (ME) course in Civil Engineering at University College Dublin. This programme which is described by Gavin (2010) is open to students who have completed a 3 year BSc. in Civil Engineering (or equivalent). In semester one a series of 5 ECTS traditional lecture and tutorial based, core Civil Engineering Design courses (CED 1 to 3) are taken which build on the theoretical principles of Structural Engineering and Soil Mechanics developed during the BSc. programme and apply these to real design problems. A 10 credit PBL (Case Studies) is run in parallel with these modules. The UCD ME degree is structured over four semesters with students accumulating 30 credits in each semester. The PBL module thus represents 33% of the credits available in the semester one.",1
24,10,"Given the nature of the learning which is required (application rather than acquisition) the problems are well defined following the usual PBL definition. However, they contrast strongly with typical text book problems and are relatively open-ended. To encourage diversification and contribute to a real-world feel, the majority of problems are set by experts from industry and are based on current projects. The format is that a brief is issued to the class each Monday morning whereby they compile a scheme design and present their solutions to their peers, tutor and the external expert on Friday morning in a “question and answers” type, interruptible presentation format.",1
24,11,"Increasing problem complexity at the beginning of the semester is relatively simple. However, in practical terms, the use of outside experts (typically senior engineers from industry) sometimes involves rearranging the pre-determined schedule. Increasing problem complexity at the beginning of the semester is relatively simple.",1
24,12,The Civil Engineering department at UCD recently moved into a new building where the ground floor consists of a number of large project rooms (freely available for project work and study for each stage/year) surrounded by staff offices. The environment is therefore ideal for collaborative project work. The UCD campus is within 4 miles of the city’s capital and has a very good relationship with industry. We have access to a large resource of visiting engineers to act as tutors in our PBL initiatives.,1
25,1,"The twenty-first century presents a major challenge for civil engineering. The magnitude and future importance of some of the problems perceived by society are directly related to the field of the civil engineer, implying an inescapable burden of responsibility for a group whose technical soundness, rational approach and efficiency is highly valued and respected by the citizen. However, the substantial changes in society and in the way it perceives the problems that it considers important call for a thorough review of our structures, both professional and educational; so that our profession, with its undeniable historical prestige, may modernize certain approaches and attitudes in order to continue to be a reliable instrument in the service of society, giving priority from an ethical standpoint to its actions in pursuit of ‘‘the public good’’. It possesses important tools to facilitate this work (new technologies, the development of communications, the transmission of scientific thought.); but there is nevertheless a need for deep reflection on the very essence of civil engineering: what we want it to be in the future, and the ability and willingness to take the lead at a time when society needs disinterested messages, technically supported, reasonably presented and dispassionately transmitted.",1
25,2,"That society is subject to continuous evolution, and that in recent years this evolution has experienced historically unprecedented acceleration, is beyond dispute. However, in this process of change, there still remain some old-fashioned structures, both professional and educational, victims of ingrained inertia, that will require a decisive push if they are not to become hidebound organizations, enslaved to the past, with few signs of future effectiveness and efficiency. In this article we shall focus our attention on the specific field of civil engineering, essential in many aspects of city life and which, in the opinion of the authors, must accept a major transformation in its professional—and consequently educational—approaches, in order to be available to deal, with the reliability and effectiveness that it has shown in the past, with the new challenges, new attitudes and new implications called for by twenty-first century society.",1
25,3,"Any change that hopes to have a continuous effect in the future must be planned and instituted right from the preparatory stages of future professionals; in other words, teaching acquires, as it surely must, a position of prominence in the design and ‘‘training’’ of the attitudes and skills of the twenty-first century engineer. Problems may arise in the organization of plans and syllabuses with contents and new guidelines, as manifested by D. Lynch and J. Russell (2009); but the desired and desirable goals cannot be relegated or curtailed by the ‘‘administrative’’ or organizational problems that its implementation may involve. The comments of Dr. Morales Manceda may be particularly apposite, when he expresses the need to redirect university teaching, by including among the technical content subjects dealing with ethical aspects and humanistic disciplines: to teach not only the ‘‘how’’, but also the profound ethical sense which explains ‘‘the why and wherefore’’. For the ultimate goal to which technology should be directed is none other than the common good of man.",1
25,4,"This professional reassessment should go much deeper than simply a closer approach to new technologies or a redefinition of working procedures, or even joining forces with the engineers of newly emerging disciplines. Civil engineering must address a profound reflection on its attitude to society, its active and determined involvement in the major problems of concern to the twenty-first century citizen, its assumption of leadership and ultimately on their its approaches.",1
25,5,"In a world too often influenced by the immediacy of results, by economic performance, by political patronage and by a certain laxity of conscience, it is absolutely imperative that a profession so intimately linked to the ‘‘public interest’’ should be capable of leading social proposals and movements from a base of rigorous technical knowledge, of established ethical principles, and from a rational and independent approach.",1
25,6,"More than ever there is a need for a true social structure. As a condition sine qua non this requires independent organizations and intermediate groups (NGOs) to set themselves up as truly representative bodies, with real influence on the taking of decisions which affect what is understood as ‘‘the common good’’. From this point of view, professional associations, and specifically those which include civil engineers, should develop, and are morally bound to take, a responsible lead in designing processes to help to solve some of the problems that most concern today’s society.",1
25,7,"As Professor Valero Matas (2009) puts it: The intermediate bodies may be seen as one of the vital figures in complex societies, being an instrument for the rights and freedoms of individuals. Their nature leads them to solve the problems of society and the demands of private life, articulated as a tool for the critical action of public opinion and political will.",1
25,8,"The validity of the important role that civil engineering may play in the design of strategies on issues substantially affecting society depends on the development and strengthening of the structures that bring together individual engineers: the professional associations. This reinforcement of the genuine participation of professional associations has nothing to do with their obvious ‘‘corporatism’’. Indeed, corporatism occurs when groups are created, managed and oriented towards the achievement of specific objectives that are basically not concerned with the ‘‘social good’’: on the contrary, professional associations of civil engineers should be seeking optimum solutions in their fields of activity on the basis of dispassionate technical approaches, free of opportunism, with calm and pragmatic reflection; and they must do so with a real capacity to influence decision making.",1
25,9,"This will to take the lead, this assumption of responsibility, must permeate the whole field of civil engineering. This means that right from the start of the engineer’s academic training an effort must be made to instill in students the importance of the profession in solving vital problems in the daily life of the citizen, concern for the burning problems that threaten our way of life (sustainability, environmental impact, waste treatment); and all of this based on ethics and honorable behavior.",1
25,10,"The older an organization is and the greater its prestige, the more resistant it is to change. The proud history of civil engineering, the brilliance of a good number of its members, and the social prestige consolidated over the years as a result of work well done, may lead to a certain attitude of complacency, an ambiguous position of detachment and in extreme cases a progressive disconnection from the social field in which the activity of the engineer takes place.",1
25,11,"However, the social dynamic, the magnitude of some of the problems that threaten our living standards and seriously compromise the future of coming generations, the media’s generation and transmission of opinions that confuse and baffle the citizen, and ultimately the lack of independence and transparency of certain messages sent to society, call for much commitment from the civil engineer. It is no longer just a matter of designing or building, it is a matter of doing so with a much broader vision, a vision of the future, of sustainability, of respect for the natural environment, of responsibility to future generations.",1
25,12,"This increasing awareness necessarily implies a profound reorganization of civil engineering, a reorganization that affects both the teaching of engineering and engineering professionals, as well as the associations that bring them together. In our view it is not a question of ‘‘dismantling’’a structure; for despite its logical weaknesses, it holds a wealth of experience, a responsibility, a body of doctrine and a record tried and tested over its long history. These are in themselves the strong points of the profession, and define its profound values. It is therefore necessary to remodel civil engineering; cautiously, but also with the excitement of finding ourselves at a crossroads from which a new form of engineering should emerge, identifying and redefining the parameters of what the ‘‘public interest’’ will be in the twenty-first century.",1
25,13,"We possess very powerful tools: new technologies, the development of communications, the rapprochement of cultures and networks of knowledge can be of great help to the work of the new civil engineering. However, we need to make a profound reflection on the role of our profession in society, about our stance: determined, pragmatic, based on some of the priority issues of our society and that concern us directly in our practice; we need to resolve the question of our access to the communication media.",1
25,14,"It is clear that, generally speaking, the civil engineer is held in very positive esteem by society, although in some cases society is not fully aware of how much the engineer’s work influences their daily lives. Yet paradoxically society trusts the engineer, sometimes even to excess, so that when an accident occurs, the citizen’s faith feels somehow shaken: ‘‘that shouldn’t have happened’’, a bridge can’t collapse, a dam can’t burst, . This social pressure, which does not accept or understand what we might call ‘‘statistical failure’’, materially conditions the professional work of civil engineers, restricting their initiatives and giving them a heavy load of responsibility that is sometimes hard to bear. We thus come to a remarkable contradiction: a profession whose job is known only in very general terms nonetheless generates levels of expectations and certainty never demanded from other professional groups.",1
25,15,"There is a need, in the authors’ opinion, for a return to what one might call ‘‘classic values’’: prudence, perseverance, ethics , supplemented by unequivocal and effective attitudes to the momentous issues of our time: sustainability, respect for the environment, the independence of knowledge, and closer contact with society. Civil engineering, due to the involvement of its work in what is known as the ‘‘public interest’’, should take a much more active role than that which is purely limited to its technical side; it should lead in other fields that, influenced by its activity, are some of the main concerns and aspirations of the social environment.",1
25,16,There can be no doubt that training is the seed that will grow into the future professional development of the engineer; hence the enormous importance that teaching has in outlining the ideal profile that society needs to meet its expectations and to design ways of solving the most pressing problems of our century.,1
25,17,"The National Academy of Engineering (NAE) in the United States has published a list of what may be the main engineering challenges in the twenty-first century. This list, prepared by a team of experts from around the world, convened at the request of the National Science Foundation, can be grouped under four key headings for the success of humanity: sustainability, health, reducing vulnerability and the quality of life. There is no doubt of the enormous involvement that the work of the civil engineer has in these matters, and it is necessary for the academic environment where they develop their training instructs to arouse and stimulate the students’ concern about these issues; this will undoubtedly condition their future professional work and their vision of the world around them.",1
25,18,"Another key aspect is related to the design of the syllabus. On this issue, a variety of authors and scholars within the field seem to agree on the key points that should guide the learning system in the coming years; perhaps, thanks to the clarity of their approach, it is worth reproducing the appraisal of the situation made by Kindela ́n and Martı  ́n",1
25,19,"The rise of worldwide communication networks and information technologies has redefined the concept of education in all fields. In engineering, a new educational paradigm can be glimpsed where the development of generic skills is prioritized. Skills such as the ability to successfully communicate orally and in writing, to operate with a multidisciplinary perspective in decision-making and problem-solving, to work in teams, and to become involved in lifelong learning []. The relationship among communication, training and lifelong learning is a key point in the profile of the engineer in this century.",1
25,20,"It remains only to comment briefly on another basic question: once the overall objectives, basic concepts, attitudes and skills to be encouraged in the civil engineer in the coming decades have been established, how can we establish specific contents, as far as possible regulated, in university teaching? Trevelyan and Tilli (2007) place special emphasis on empirical methods; this may be so as regards technological knowledge, but we must also encourage in the engineer other attitudes which basically have profound ethical and humanistic roots.",1
25,21,"If engineers are viewed as mere technicians, then the relevance of nontechnical studies is called into question. Yet non-technical studies are means by which we hope to change engineers from technicians into true professionals. We must find ways to break this paralyzing cycle.",1
25,22,"Having said all this, we would not wish to conclude this discussion without emphasizing, if only briefly, the need to recuperate (for we believe that to some extent they have been lost or diluted) what might be called ‘‘classic values’’; and of all of these, basically the need to reinforce ethical values. Our famous thinker and writer Ortega y Gasset (2000) said, ‘‘To be an engineer it is not enough to be an engineer’’. We might add that engineering education should inculcate in students a profound conviction that engineering, to achieve its own objective, the objective that gives it full sense and meaning, must be carried out under certain conditions (effectiveness, efficiency, accuracy ). These conditions include morality, expressed in many ways (in decisions, procedures, motivations, prediction of consequences ). and should not only be a moral for life, but should also be considered, pondered, and subject to rational argument: in other words, ethics. In short, excellence in engineering is strictly speaking, although not exclusively, ethical.",1
26,1,"Much has been written about the skills that current engineers need and the desired attributes of the so-called twentyfirst century engineer. There is always debate around how much theoretical understanding a graduate engineer needs and how much practical application is required. This paper unpacks the requirements of twenty-first century engineers, from a UK perspective, and questions whether current civil engineering degrees are meeting such requirements. The requirements of existing professional bodies in the UK are critically reviewed. A key question is whether a post-modernist view of engineering should be adopted and the education aligned accordingly. A review of post-modernism, from a coastal engineering perspective, is presented and parallels are drawn with civil engineering. It is concluded that civil engineering degrees do adopt a post-modernist approach and are fit for the future based on current professional body requirements. It is further argued that to be even better prepared for the future, civil engineering educators and professional bodies should be cognisant of educational theories.",1
26,2,"Recent reports have brought to the fore the need for increased skills, together with an increase in quality and quantity of engineering graduates, in order for the UK economy to be able to compete with the best in the world (Leitch, 2006; RAE, 2007, 2010). The implications of a failure to act could mean that ‘ultimately the UK could slide into insignificance as an internationally competitive industrial nation’ (RAE, 2007). However, the Royal Academy of Engineering (RAE) states that between 1994 and 2004, while overall university admissions rose by 40%, students entering engineering degrees remained static at 24 500 each year. More recent University and Colleges Admissions Service (UCAS) data, covering the period from 2002 to 2007, shows the total volume of all university applicants has risen by 12.2%, while in the same period science, technology, engineering and mathematics (STEM) applicants from UK-domiciled students rose by only 3% (ETB, 2008). Compounding the shortage of engineers, the RAE reported that less than half of the engineering graduates entered the profession. It should be noted that the RAE is dealing with all disciplines of engineering.",1
26,3,"The focus of this paper is more about the quality of the graduates and whether higher education institutions are producing graduates with the necessary skills and attributes to contribute to the knowledge economy. To investigate this issue, the skills and attributes of future engineers are reviewed from the comprehensive report produced by the Royal Academy of Engineering (RAE, 2007). These skills and attributes are then compared and contrasted with the professional body requirements for civil engineering undergraduates. A definition of post-modernism is presented with the intention of exploring whether future engineers should be educated from a post-modernist viewpoint. An introduction to education theories is discussed and its relevance for future engineers presented.",1
26,4,"In June 2007 the RAE published the report Educating Engineers for the 21st Century (RAE, 2007). This report sought the views of senior personnel in engineering companies, both large and small, and of academic institutions. Academic responses were received from 48 universities, the Institutions of Civil Engineers, Structural Engineers and Mechanical Engineers, and the New Engineering Foundation.",1
26,5,"In summary it can be seen that future engineers require a range of skills and attributes. They need to be technically competent and to understand the fundamental engineering principles while possessing an awareness of how the engineering aspects interact with other aspects of a project, such as the business needs and the wider environment.",1
26,6,"So do the professional body requirements aspire to the same attributes and skills? For the purposes of the current paper, the professional bodies relating to civil engineering courses are reviewed. For civil engineering courses the Joint Board of Moderators (JBM) is seen as the professional body. Four civilengineering-related bodies together form the JBM: the Institution of Civil Engineers, the Institution of Structural Engineers, the Institution of Highways and Transportation and the Institute of Highway Engineers. On behalf of the four professional bodies, the JBM assesses and makes recommendations on accreditation.",1
26,7,"Similar thoughts have been aired from the USA. In his address to the National Academy of Engineering in 2005, Charles Vest spoke at length about educating engineers for 2020 and beyond. Vest feels that the details of curricular content are less important than making universities and engineering schools exciting places to be educated. He states that engineering courses should be creative and adventurous as well as demanding and rigorous. Closely aligned with the RAE report is Vest’s view that future engineers will need to be prepared to ‘conceive and direct projects of enormous complexity that require a highly integrative view of engineering systems’ (Vest, 2005).",1
26,8,"Vest’s views are very similar to the view of engineering businesses (RAE, 2007) that seek engineers with abilities and attributes in both their technical understanding and the understanding of the business world, requiring greater communication and people skills. However, it should be noted that the single most desirable attribute (for engineering graduates entering industry) is their ability to apply theoretical knowledge to real industrial problems. Other relevant attributes, in descending order of importance, are theoretical understanding, creativity and innovation, teamworking, technical breadth and business skills.",1
26,9,"To evaluate whether the output standards are being achieved they check students’ work, such as project reports and examination scripts, and they interview students.",1
26,10,"In addition to meeting the required output standards, civil engineering departments are required as part of the JBM guidelines to demonstrate close links with industry. One example is the JBM recommendation that civil engineering departments establish an industrial advisory board (IAB). Typically this involves members of academic staff meeting two or three times per year with practising civil engineers, and giving the industrial partners an opportunity to comment on and support the civil engineering programmes. For example at the University of Wolverhampton a member of the IAB is the head of transportation at Wolverhampton city council and he has been able to provide some traffic data, as well as suggestions for local design projects. There are guidelines on the JBM website for setting up an IAB provided by Professor Quentin Leiper who, for many years, has been involved with the University of Edinburgh and has greatly assisted with the IAB at the University of Wolverhampton. Tangible benefits at Wolverhampton have included site visits and guest lectures from industrial practitioners",1
26,11,"In its simplest form, ‘post-modern’ is defined in the Oxford encyclopedic dictionary as ‘denoting a movement reacting against modern tendencies’ (Hawkins and Allen, 1991). Further investigation shows that philosophers and artists have numerous definitions and interpretations for both post-modern and modern.",1
26,12,"A recent feature in The Structural Engineer by Dr Graham Owens addresses the concerns within the structural community about reducing levels of understanding of structural behaviour (Owens, 2011). Owens argues that there needs to be a reduction in the amount of time spent on traditional (manual) methods of analysis. He states that manual methods should only be retained if they can be shown to enhance students’ understanding of structural behaviour. He recognises that a twentyfirst century engineer does not need to have a detailed knowledge of the workings of an analysis programme, but needs to understand how such programmes are suitably applied in practice. Such an approach may be resisted by a modernist approach, but is more likely to be accepted by a post-modernist view. Owen also suggests that part of a syllabus should be dedicated to ‘the approximate nature of all engineering activities’. This includes the uncertainties of loads, environmental factors and risk assessments: and very much represents a post-modernist perspective.",1
26,13,"Kamphuis provides an interesting view of the journey of coastal engineering through the phases of modernity to postmodernity (Kamphuis, 2006). The comparisons with civil engineering are readily available and relevant in the discussion regarding future engineers.",1
26,14,"Kamphuis describes the post Second World War years as being the halcyon times for coastal engineering. At that time it was felt that anything was possible with enough effort, funding, time and research – the essence of modern thinking. Post Second World War, the driving force was national security leading to new ports and shoreline protection systems to prevent erosion and flooding. As the twentieth century progressed, it started to become clear that ever more sophisticated numerical and/or physical models had their limitations.",1
26,15,"Similarly, at the University of Wolverhampton students are taught the fundamental principles of Bishop’s rigorous method of slope stability analysis, but they do not spend hours on manual calculations. Instead they are encouraged to vary the input parameters and comment on the sensitivity of the outputs. The intention is that they appreciate the uncertainties and get a feel for how such uncertainties may influence the stability.",1
26,16,"It appears that the JBM and the RAE substantially agree on the attributes and skills required by industry from future graduate engineers. Most civil engineering departments pride themselves on their professional accreditation and, by default, if they are meeting the JBM requirements then they are meeting many of the desired attributes. The danger of course lies in becoming complacent and relying too much on the accreditation process as an event rather than an ongoing measure of what should be best and standard practice. But there are many examples of civil engineering departments working closely with industry; the RAE report Engineering Graduates for Industry (RAE, 2010) emphasises the importance of and highlights the benefits of closer links with industry. An exemplar is the Constructionarium developed by Imperial College and now run at the National Construction College in Norfolk. Students at the end of their second year can spend a 6-day intensive period gaining experience of a ‘real’ construction project. Groups of students take control of a construction site, in association with a consulting engineer and a contractor, and build a scaled-down engineering project. Many universities now have a large proportion of part-time students and Davies has reported on the benefits that these students bring to the less experienced full-time students",1
26,17,"While a post-modernist view, and subsequent approach, appears to be the way forward, any changes in relation to the education of future civil engineers should be discussed within the framework of educational theories. Neither the JBM nor the RAE explicitly refers to any educational theories. Even the detailed RAE 2010 report, which strongly recommends experience-led engineering, could be viewed as being quite onedimensional because, while it presents a solution, it does not take any cognisance of educational theories. The problem may well be that, while the intentions are good, the very nature of engineers is to seek a solution to a given problem: graduate engineers need to be better prepared for industry so a logical engineering solution is to have industry much more closely involved in their education. It sounds reasonable as an engineering solution, but fails to address the issues associated with how students learn.",1
27,1,"This paper presents an exploratory analysis to identify civil engineering challenges that can be addressed with further data sensing and analysis (DSA) research. An initial literature review was followed by a web-based survey to solicit expert opinions in each civil engineering subdiscipline to select challenges that can be addressed by civil engineering DSA research. A total of 10 challenges were identified and evidence of economic, environmental, and societal impacts of these challenges is presented through a review of the literature. The challenges presented in this paper are high building energy consumption, crude estimation of sea level, increased soil and coastal erosion, inadequate water quality, untapped and depleting groundwater, increasing traffic congestion, poor infrastructure resilience to disasters, poor and degrading infrastructure, need for better mining and coal ash waste disposal, and low construction site safety. The paper aims to assist the civil engineering research community in setting an agenda for data sensing and analysis research to address these challenges.",1
27,2,"Civil engineering plays an important role in the development and improvement of societies. Its endeavors are described as complex and diverse undertakings that tackle nonstandard challenges. Civil engineers plan, design, construct, and operate facilities that are essential to modern life, ranging from transit systems, to offshore structures, to water systems. Today’s world is undergoing vast changes that create unique challenges for civil engineers of every subdiscipline. These challenges and their manifestations in societies are often very complex in nature and require integrated approaches to solve.",1
27,3,"Research in the area of data sensing and analysis (DSA) can be used as a tool to partially alleviate the impacts of these challenges. DSA includes research in data sensing, preprocessing, analysis and fusion, intelligent searching and information retrieval, parallel and distributed computing, and knowledge management and discovery. This paper presents an exploratory analysis of civil engineering grand challenges that can be addressed and partially alleviated by DSA research. The initial work was reported by a task force assembled by the ASCE TCCIT (American Society of Civil Engineers Technical Council on Computing and Information Technology) DSA committee (Becerik-Gerber et al. 2011). In the DSA committee report, nine civil engineering challenges were identified by the task force. The challenges were introduced and their importance was highlighted. This paper reexamines the challenges presented in the DSA report and builds upon that earlier work. Expert opinions were solicited via a survey distributed online to validate the impact of potential DSA challenges. Ten challenges were shortlisted based on this validation and are presented in this paper. The grand nature of the 10 challenges is established through an extensive literature review that highlights the challenges’ economic, environmental, and societal impacts.",1
27,4,This paper is primarily a state of the art review. The objective of this research is to identify civil engineering grand challenges that the DSA research community could address in the next decade. The goal of this effort is to assist the DSA community in setting a research agenda that focus on addressing the identified critical challenges.,1
27,5,"Out of the 968 ASCE editorial board members, the survey was successfully delivered to around 850 potential respondents. Entries of respondents who have only provided their contact information but did not fill out the rest of the survey or who did not provide their contact information were not included in the analysis. Out of 154 survey entries received, representing approximately an 18% overall response rate, 110 survey responses were found to be complete in all respects. As detailed above, a respondent could provide input in more than one specialization area. These 110 respondents provided 124 valid responses for the seven sub disciplines. It must be reiterated that the survey results were used for validation purpose only. The grand nature of a challenge is established in this paper through the broader review of the economic, environmental, and societal impacts as reported in the relevant bodies of literature. Fig. 1 summarizes the 27 challenges in seven civil engineering subdisciplines. Fig. 1 uses standard box plots to show the distribution of responses on a 1 to 5 scale in each impact area corresponding to each challenge. The number on the right side of the plot is the median for that distribution. The shaded area represents the interquartile range, the thick vertical line represents the median, a circle indicates mild outliers, and a star is used to show extreme outliers.",1
27,6,"In an iterative process, the DSA task force conducted a review of journal articles and conference proceedings, as well as magazine and news articles to identify the major challenges faced by today’s civil engineering community. Through this review, the task force identified an initial list of 27 challenges covering seven civil engineering subdisciplines, including architectural engineering; coasts, oceans, ports and rivers; environment and water resources; transportation; structural engineering; geotechnical engineering; and construction engineering. For this paper, the authors evaluated these 27 challenges based on their impacts in three areas: economic, environmental, and societal. Economic impact of a challenge was ranked based on the effect of the challenge on the economic growth, and its associated direct and indirect costs. For example, economic impacts may include economic losses both from weather and climate-related disasters, cost of energy waste, or cost of vehicle repairs due to deteriorating road conditions. Environmental impact of a challenge was ranked based on the negative effects of the challenge on the environment, natural surroundings, and the ecosystem. For example, environmental impacts may include pollution, or global warming.",1
27,7,"In order to validate the selection of challenges by the DSA committee report, a sub list of challenges was created by selecting the challenges that have a median rating of more than 4 in two of the three impact areas. The median was preferred over the mean to shortlist the challenges as the individual responses on the Likerttype-item questions were treated as discrete ordinal and the response distributions are skewed. The sublist of challenges included a total of 16 challenges that were found to have high and very high impact in at least two out of three impact areas. These challenges are indicated by an asterisk (*) in Fig. 1.",1
27,8,The authors consolidated the challenges that are related by the virtue of their inherent characteristics or in the way DSA research would be applicable to the challenges,1
27,9,"Based on the survey, a challenge of the ASCE DSA report, namely, “low construction productivity” was deleted from the final list for this paper, and two new challenges were added: “need for better mining and coal ash waste disposal” and “water pollution and quality.” Accordingly, through these additions and consolidations, 10 challenges were included in this study for further investigation. The authors did not rank order the 10 selected challenges, nor do they endorse any particular approach to addressing them.",1
27,10,"The survey first asked respondents to indicate their area of expertise with an option of choosing more than one area if their area of expertise falls under multiple areas. Then the specific challenges in the respondent’s expertise areas were presented and the respondent was asked to evaluate the challenges’ impacts for the three areas: economic, environmental, and societal. A discrete five-point Likert visual rating scale was used: no impact, low impact, moderate impact, high impact, and very high impact (with 1 being no impact and 5 being very high impact).",1
27,11,"Coastal infrastructure is designed above the highest sea level and with necessary prevention against waves and tides. Better estimation of the sea level can help engineers reach a balance between coastal infrastructure safety and construction costs. Koch (2010) estimated the cost of erecting a single mile of new sea wall to defend against wave overtopping and flooding to exceed $35 million (in 2009 dollars) and the annual maintenance costs at a range between 5 and 10% of the construction cost (Koch 2010). When Hurricane Katrina hit the Gulf Coast in late August 2005, the incurred damages in the New Orleans area were estimated to be around $500 billion",1
27,12,"Another issue is the unstable sea level, especially the extreme sea level under natural disasters such as hurricanes and tsunamis. The last two decades have witnessed a series of natural disasters that have caused severe damage to the coastal area with great loss of life and money. There are multiple approaches to address these problems caused by the increasing and unstable sea level. Precise estimation of the sea level plays a fundamental role to set up a well-established prevention system.",1
27,13,"One indicator for measuring the societal impact of energy consumption is the percentage of expenditure spent on fuel. All members of the society should benefit from the use of energy. If people in a society cannot afford the energy they need, they suffer from negative societal (e.g., health) impacts. A household is defined as being in “fuel poverty” if it spends more than 10% of its total expenditure on fuel (Power 2006). 15.9 million U.S. households are in fuel poverty. Energy inefficiency of buildings has been identified as a main cause for fuel poverty (Power 2006). Improving building energy efficiency in the U.S. would, thus, reduce fuel poverty, and in turn, enhance the quality of life of Americans. Improving building energy efficiency would also reduce the nation’s dependence on foreign oil (U.S. DOE 2012). Reducing dependence on foreign oil will have beneficial economic and political implications.",1
27,14,"Sea level is expected to rise to dangerous levels because of the continuous emissions of greenhouse gases that cause global warming (Molina et al. 2009). In the U.S., many coastal cities and small island states are at risk of drowning under the rising sea level if temperatures continue to rise. An Organisation for Economic Co-operation and Development OECD survey revealed that around 2 million citizens in Miami and 1.5 million citizens in New YorkNewark were exposed to increasing sea level in 2007 (Nicholls et al. 2007). In the long term, Weiss et al. (2011) estimated that about 180 U.S. coastal cities would be affected by the increasing sea level by 2100. Among these cities, there are 20 municipalities with populations over 300,000 citizens and 160 municipalities with populations of about 50,000 citizens. More than 10% of the land area in Miami, New Orleans, Tampa, Florida, Virginia Beach, and Virginia will be covered under the sea (Weiss et al. 2011). In response to this challenge, a precise estimate of the increasing sea level at different stages is of critical importance for the society to take actions to prevent the corresponding consequences. With a better understanding of the long-term dynamic sea level, researchers can protect the affected population and properties in the coastal area.",1
27,15,"Over the last 200 years of U.S. farming, an estimated 108 hectares of farmlands have been abandoned due to soil erosion. Such a condition has imposed changes on the lifestyle of farmers, which in return affects the structure of the society (Pimentel et al. 1995). In addition, “erosion increases the amount of dust carried by wind, which not only acts as an abrasive and air pollutant but also carries about 20 human infectious disease organisms, including anthrax and tuberculosis” (Lang 2006). In coastal regions, economies are heavily dependent on marine-related activities, including marine transportation of goods, offshore energy drilling, resource extraction, fish cultivation, recreation, and tourism [U.S. Global Change Research Program (USGCRP) 2009] “Coastal areas are also home to species and habitats that provide many benefits to society and natural ecosystems” (USEPA 2012b). According to the USGCRP (2009), the annual yield of American fisheries is estimated at 5 million t, which contributes to about $1.4 billion to the U.S economy on an annual basis [U.S. Climate Change Science Program (CCSP) 2008b]. This sizable contribution is constantly at risk due to the increased rates of coastal erosion. Consequently, a better understanding of soil conditions, redistribution patterns, and associations with other natural parameters is necessary to develop efficient mitigation plans.",1
27,16,"Water is essential for life. Safe and clean supply of water is required by not only human beings but also by plants and animals. Water pollution refers to the presence or introduction of substances that have injurious and/or toxic effects. Naturally, introduction and presence of such toxic substances in water reduce the quality of water. The Clean Water Act of 1972 is the cornerstone federal law that governs the discharge of pollutants into waters of the United States and regulates quality of surface waters (USEPA 1972). In addition, the Safe Drinking Water Act of 1974 ensures the quality of Americans’ drinking water (USEPA 2012d). Despite these acts, 53% of assessed rivers and streams and 69% of assessed lakes remain unsafe for swimming, fishing, and other uses (USEPA 2012e). Several million pounds of toxins are released into U.S. waters each year impacting the environment and society, which creates a requirement for spending several million dollars.",1
28,1,"There is a long history of developments in civil engineering being tailored for and used by military engineers. This paper describes current UK research on protective structures and hardening of civil structures, its exploitation in current operations and future equipment and techniques. To deliver this research, an integrated team was created, with requirements definition and management being provided by military engineers and Ministry of Defence scientists. The  research was conducted by consultants in civil engineering, defence, security and infrastructure together with academic teams from civil engineering and physics departments in UK universities. Major drivers were cross-fertilisation and pull-through from civil engineering, innovation and exploitation into current military operations and for future equipment. Maintaining a balance between the demands from the priorities of current operations and the need to maintain fundamental work to underpin longer term thinking has been a key feature. The programme structure, processes and lessons learned are described, together with some example work strands and their successful use in practice.",1
28,2,"There is a long history of civil engineering developments being applied to military engineering. One  has to think no further than the use of concrete in military engineering (Hambly, 2014) to see the military impact of civil engineering knowledge.",1
28,3,"Military engineering in the UK is primarily the responsibility of the Corps of Royal Engineers. The corps has a role that can be simply put as enabling the military to ‘live, fight and move’. In this it is an enthusiastic adopter of technology. For example, it was an early adopter of balloons and manned flight and more recently of ground robots for explosive ordnance disposal.",1
28,4,This paper describes current force protection engineering research and its exploitation into practice in recent conflicts. In  doing so it offers an exemplar for moving civil engineering research into practice and of the cross-fertilisation of ideas between civil and military engineering.,1
28,5,The research is being conducted in a 3-year project that started in 2012. The basis of the programme is a set of requirements from the Ministry of Defence (MoD). These requirements are produced by serving military officers from a headquarters branch known as capability directorate combat support and MoD civilian scientists in the Defence Science and Technology Laboratory,1
28,6,Requirements look forward to 2020 and are expressed as far as possible in terms of the military capability needed rather than in terms of specific levels of engineering performance. Requirements are also driven by the needs and constraints of government defence and security policy and military concepts and doctrine.,1
28,7,"Based on the requirements, the Defence Science and Technology Laboratory ran a research competition that was won by an industry–academia team lead by QinetiQ. In  addition to the specific capability requirements, more general requirements relevant to a wider range of research programmes were identified, including a higher level of innovation, a higher level of exploitation of research into practice, a strong systems approach, a higher level of pull-through of knowledge from civil engineering systems and technology and a higher level of scientific rigour.",1
28,8,"The programme is contracted for, and managed over, a 3-year period with annual revisions based on progress and changes in requirements. A time-based view of the programme is impractical for this paper so Figure 1 shows the programme content and some of the associated performance drivers. In particular, it identifies the measures of performance – the key criteria used to judge system effectiveness. It  also identifies defence lines of development that are the wider issues that must be addressed in the acquisition of defence capability. The  first thing to note is that there is a split between work that addresses system solutions for specific capability needs and enabling work. The  enabling work is more generic and aims to provide methods and data that will underpin improved systems and solutions in the future.",1
28,9,"Combat effectiveness depends on many factors, including morale, leadership, training and equipment. The business of force protection engineering in this paper is primarily associated with equipment capability. The programme aims to move from military requirements through research activity and on to solutions to be used in military operations; that is, from research to practice. Several themes have been built in to the programme to facilitate this.",1
28,10,"The research programme began by reviewing existing softwarebased analysis tools, including those of international collaborators. It also used a process of formal requirements capture. In essence what was required was to bring together the various sets of data and design guidance already available into a rapid and easy-touse computer-based system that allowed options to be quickly developed and compared. Existing analysis programmes were focused on research and not the provision of guidance to in-theatre users.",1
28,11,"The programme was developed through a series of prototype builds, each of increasing functionality. Throughout the build, regular reviews were held with a user group and each prototype release was tested by them. Improvements of functionality and requirement changes were agreed and addressed in the next phase. The  current version of the tool, known as the ‘force protection engineering tool’, has been employed by those in the user group to support current operations and so the process of moving the research into practice has started. The tool employs a simple-to-use graphical user interface to create a model of a base and position people and infrastructure assets within it",1
28,12,"The tool contains databases of potential threat weapons and construction materials with their relevant characteristics. The tool contains standard camp layouts but gives the user the ability to create other layouts and to build simple framed structures. Calculations are based on interpolation from experimental data, algorithms developed from experimental data or solutions provided in the literature (US DoD, 2002). The  output from the model is an indication of likely injury numbers and severity. The output is displayed in simple colour-coded zones overlaid on the graphical model of the base.",1
28,13,Different force protection engineering measures are then built in to the base and their effect on injuries presented. These ‘what-ifs’ take minutes to produce and present a simple meaningful image of protection and resource requirements to commanders to enable decisions to be made.,1
28,14,"By its very nature combat is dynamic, riddled with uncertainties and conducted in wide-ranging and rapidly changing environments. People and equipment therefore need to be flexible, adaptable and versatile. Modularity of equipment has long been recognised by military engineers as a valuable attribute to achieve flexibility of use for equipment. One  needs to look no further than the ubiquitous Bailey bridge (Joiner, 2001) and its derivatives to see this demonstrated.",1
28,15,"With respect to force protection engineering, modularity has been studied both in terms of modular structural solutions and modular protection levels. This can allow the size, logistic constraints and protection level to be tailored to the phase and location of the operation. An  example from the research is a modular ‘sangar’. A sangar is a protected firing and observation position that can be ground-based or tower-mounted.",1
28,16,"The sangar was comprehensively tested and this included a full range of ballistic, fragment and blast effects. It  also included timed construction trials before and after blast and ballistic testing. Construction trials included those with troops, and user representatives attended the weapons effects trials. The lightweight frame is built from glass fibre reinforced plastic I sections with bolted joints. Walls are the primary protection scheme and are in three layers. The  maximum protection level is provided by an outer layer of overlapping steel armour plate panels, an inner layer of E-glass panels to catch spall and secondary fragments, and an intermediate gap that can be filled with sand or crushed stone. Ballistically protected glazing can be added as required. The  end result was a sangar design ready to be exploited in practice as and when required.",1
28,17,"Although the future emphasis of the military will be on contingency operations, recent operations have been, in military parlance, of an enduring nature. In such operations, soldiers can be based in a range of tactical bases of varying size from large main bases of several thousand occupants to forward operating bases of around a hundred soldiers. These tactical bases can be fixed in location for months and, as such, are attractive targets.",1
28,18,"The range of threats is large but of particular concern is indirect fire, principally rockets and mortars. These are readily available to ‘insurgency’ forces and have been widely used against UK forces. Work in the research programme has addressed defining the thickness of construction materials to protect against indirect fire weapons. This has included concrete slabs and gabions filled with sand or crushed rock.",1
28,19,"One outstanding problem of indirect fire that is being addressed is that of protection for gabion-type structures against residual kinetic energy effects. Protection from rocket blast and fragment threats has been well defined. However, it has been found that, post-detonation, the rocket’s motor remains in one piece and has sufficient kinetic energy to penetrate the protection. Although it is a local effect, it would be inefficient in materials and a burden on logistics to simply add the considerable extra thickness needed to defeat it. The  programme to address this issue started with a brainstorming meeting that included users and participants from academia and industry.",1
29,1,"The utilization of coal bottom ash in civil engineering is one of the most promising options to reduce, or possibly eliminate, the environmental and social problems related to the disposal of bottom ash. This study reviews the traditional and state-of-the-art utilization technologies of bottom ash in the field of civil engineering. It covers the production and characteristics of bottom ash, case studies of its conventional applications as a simple replacement of natural resources and advanced applications for special purposes, and environmental considerations for both raw bottom ash and its applications. This review is intended to stimulate and promote the effective recycling of coal bottom ash in the civil engineering field",1
29,2,"Thermal power generation is a major energy generation method in modern civilization the world over (IEA, 2009). Although biomass has recently gained attention as a promising substitute to conventional fuels, fossil fuels such as petroleum, coal, and natural gas remain the primary source for thermal power generation. In particular, due to its economical and technical advantages, thermal coal accounts for a higher proportion of power generation in many countries than the use of oil and gas combustion. However, with power generation using thermal Coal, Coal Combustion Products (CCPs) are produced during the process of electricity production (Feuerborn and Eck, 2010).",1
29,3,"CCPs are combustion residues including fly ash, bottom ash, Flue Gas Desulfurization (FGD) gypsum, and etc. Although some portions of CCPs are effectively recycled in developed countries, high percentages of CCPs are directly discarded in most power plants in developing countries, as the cost for disposal has been lower than the cost for utilization (Jang, 2010). However, the disposal of CCPs has recently become a more pressing issue due to several reasons.",1
29,4,"Second, the leachate from CCPs causes environmental contamination in the vicinity of landfills and ash ponds (Carpenter et al., 2007). Large scale death of fishes in the sea nearby a coalfiring power plant due to toxic leachate from an ash pond was reported in South Korea in 2009, and a large number of birds that ate these fishes also died (Han and Min, 2009). In response to these issues, many researchers have concentrated on methods to maximize utilization of CCPs in order to reduce their disposal and reclamation.",1
29,5,"In general, most studies and reviews on the utilization of CCPs have focused on fly ash. Fly ash accounts for almost 80% of the total CCP production and has suitable characteristics for application in various industry fields. In contrast, as bottom ash accounts for a minor portion of CCP production (less than 20%), fewer cases of its utilization have been reported, especially in developing countries where environmental issues tend to take a lower priority (Jang, 2010).",1
29,6,"Meanwhile, if bottom ash were applied such that these disadvantages became advantages, its utilization could be extended and its consumption increased. It potential advantages include its lower density and higher hydraulic conductivity than natural soils, and its higher strength relative to artificial lightweight aggregates. Recently, the availability of natural construction materials, including natural silt, clay, sand, and gravel, in advanced nations is decreasing due to social movements directed at environmental preservation. Bottom ash can be considered a low-cost and lowCO2 raw material, and thus its use would be in line with the trend toward conservation of natural resources.",1
29,7,"The present article reviews traditional and state-of-the-art utilization technology of coal bottom ash in the field of civil engineering. It covers the production and characteristics of bottom ash, case studies of its conventional applications as a simple replacement of natural resources and advanced applications for special purposes, and environmental considerations of both raw bottom ash and its applications. This review is intended at simulating and promoting the effective recycling of coal bottom ash in the civil engineering field, with the aim of mitigating environmental and social problems related to its disposal. It is noted that the term ‘bottom ash’ in this manuscript denotes coal bottom ash, which is different from Municipal Solid Waste Incineration (MSWI) bottom ash.",1
29,8,"Bottom ash in a dry condition is easier to recycle than that in a wet condition and hence recycling costs might be reduced (Oh, 2004; 2005). In addition, a new management system to transform bottom ash to fly ash by returning the dry bottom ash to the boiler combustion chamber was recently reported (Kochert et al., 2009). With this system, bottom ash removed from beneath the boiler is milled, conveyed back to the coal feeder, and then reintroduced into the furnace with coal (Kochert et al., 2009). Thus, most bottom ash could be converted into saleable fly ash and the cost for bottom ash disposal could be mitigated.",1
29,9,"Boiler slag is also produced in wet bottom boilers operated at very high temperatures of about 1600ºC (Moulton, 1973; Feuerborn and Eck, 2010). The ash in molten condition is drawn from the bottom of the boiler and flown into a water-filled hopper located below (EPA, 2010). When this ash contacts the quenching water in hopper, the molten ash is fractured and crystallized, and pellets are formed (Moulton, 1973). This coarse, angular, glassy material is called boiler slag (EPA, 2010b). In some countries, bottom ash and boiler slag are grouped together as bottom ash or bed ash (in Japan, also called as clinker ash) (Hinckley et al., 1980). The production of bottom ash including boiler slag generally accounts for 5 ~ 20% of total ash production (Manz, 1997), and varies according to the type and combustion efficiency of the boiler system as well as the type of coal source (Jang, 2010).",1
29,10,"In addition, other materials are also produced from thermal power plants as byproducts, including the following: 1) Flue Gas Desulfurization (FGD) gypsum derived from flue gas desulfurization (NETL, 2006); 2) Fluidized Bed Combustion (FBC) ash produced from boilers with a FBC system (Rao et al., 2007); 3) cinder ash (or air heater ash) that falls on the bottom of air heaters, and on ducts, before leaching to precipitators or baghouses (Jang, 2010); 4) cenospheres, which are lightweight, inert, hollow spheres mainly consisting of silica and alumina, filled with air or gases, floating on the water surface of ash slurry (Jang, 2010).",1
29,11,"The physical characteristics of bottom ash vary depending on the following factors: type and quality of coal source, pulverized fineness, and the operating conditions of the power plant (RMRC, 2008). In general, the particles of bottom ash have dark, angular shapes with porous textures, as shown in Fig. 2 (Kim and Lee, 2011). Many millimeter-sized craters and pores are shown on the surface of coarse bottom ash, while a few craters can be observed on the surface of fine bottom ash. Micrometer-sized pores develop on the surface of bottom ash (Fig. 3) (Kim and Lee, 2011). On the other hand, the porosity of bottom ash is about half that of quartz sand with a radius between 1.7 nm and 300 nm (Fig. 4) (Kim et al., 2011). This indicates that the nanostructure of bottom ash is denser than that of natural sands or gravels.",1
29,12,"The mechanical properties are affected by particle shapes, surface textures, and gradations, as listed in Table 1. Due to the rough surface texture, the angle of shearing resistance and California Bearing Ratio (CBR) of bottom ash are higher than those of normal aggregates (Ghazavi et al., 2008). The higher optimum moisture content, Los Angeles abrasion loss, and water permeability of bottom ash are attributed to its porous structure. However, the chemical soundness of bottom ash is at a similar level with that of normal aggregates.",1
29,13,"Various cases of bottom ash application can also be found outside of the civil engineering field. Another promising way to consume bulk bottom ash is through application in agriculture, such as agricultural soil amendment, where it acts as a nutrient source to plants and crops (Kowapradit et al., 2007), or as growth media in horticulture (Chen et al., 2005). Moreover, it is well known that bottom ash in a raw state or with some treatment can be used for ice and snow control of roadways (AACA, 2010). Bottom ash, especially boiler slag, has also been used as blasting grit and roofing granules (AACA, 2010). Fine bottom ash with similar particle sizes to clay and silt could be added to ceramics and porcelains to introduce unique colors and texture, which could not be obtained using clay and silt",1
29,14,"Utilization of CCPs as geotechnical fill is a common practice. In general, only bottom ash or mixtures of bottom ash with lowquality fly ash, sometimes FDG scrubber sludge, are used in construction fields as stabilized bases, granular bases, embankments, structural fills, backfills, and mine fills (Parker, 2002; Koehler, 2002). The physical behaviors, engineering properties, and gradations of particle size of bottom ash are similar to those of natural soils and thus it can be handled with similar processes and methods without adding complicated treatments or screening processes (Karim et al., 1997). Moreover, due to the excellent hydraulic conductivity of bottom ash as compared with fly ash, foundations containing bottom ash showed ‘free-drain characteristics’, which means that the ground is not easily swelled or shrunk by its moisture content and is non-susceptible to frost heave (RMRC, 2008). Due to a higher friction angle, the shear strength of bottom ash is within the same range as most natural soils (Lovell et al., 1991).",1
29,15,"Kumar and Stewart (2003) presented the results of a laboratory experiment on geotechnical engineering properties of dry bottom ash from Illinois, US, with various amounts of sodium bentonite. The unconfined compression strength and cohesion of bottom ash-bentonite mixtures increased almost linearly with an increase of bentonite content, while permeability was decreased (Kumar and Stewart, 2003). Moreover, Kumar and Vaddu (2004a) investigated the time dependent changes of strength and stiffness of bottom ash-bentonite mixtures, using the same type of bottom ash. While the physical characteristics of bottom ash are similar to those of natural soils, differences in its chemical characteristics results in variation of engineering properties of mixtures of bottom ash and admixtures with time",1
30,1,"In general terms, construction rehabilitation is not sufficiently studied worldwide in Civil Engineering Schools. In this article we propose an international guideline course for Rehabilitation of Constructions envisaged for Civil Engineering students at bachelor degree level. As we live in an increasingly globalized world, the course aims to prepare our students in the same basic concepts, so the course content and its focus can be common for all Civil Engineering programs worldwide. Nevertheless, the course should be considered as a general guideline, so that in each university, special attention should be paid to the topics that are most common due to the varying construction practices, preservation laws and regulations, and legal jurisdiction governing the scope of practice in construction rehabilitation, existing in the region/country in which the university is located. Moreover, in the authors’ opinion the guideline course should be focused on existing building types, both significant historic ones and those which make up the day-to-day rehabilitation market.",1
30,2,"To achieve this, the initial step of the methodology was the study and integration of the results obtained in a survey sent to lecturers in 89 universities in 30 countries around the world. Then, a preliminary grouping was done of topics which could be included in the course, pre-assigning a teaching time to each topic. Later, various renowned experts in the matter audited the tentative guideline course. Finally, based on their opinions and comments, we rewrote the definitive guideline course.",1
30,3,"The conservation of existing buildings is a fundamental principle in the cultural life of modern societies. In recent years, this topic has been the subject of extensive research, leading to development in the inspection, non-destructive testing, monitoring and structural analysis of constructions. However, the teaching of this topic has not received the same attention. The analysis of existing buildings creates challenges given the complexity of their geometry, the variability in the properties of traditional materials, the different construction techniques, the absence of knowledge about existing damage, and how certain actions affect buildings throughout their lifetime (Roca 2007). These challenges mean that existing buildings are subject to a number of difficulties in diagnosis and intervention, which in some cases limit the application of the regulatory requirements and existing guidelines in the general area of construction. Therefore, understanding, analysis and repair of buildings constitute one of the most important challenges for modern engineers",1
30,4,"The building rehabilitation and maintenance market is one of the most important economic sectors in construction, especially in the most developed societies. For instance, in Europe, in 2010, rehabilitation and maintenance was a major market, accounting for 28% of construction output with a value of 332∙106 € (FIEC 2010), and in the USA, this sector also accounts for an important fraction of the construction market. In addition, there are many other factors which indicate that the rehabilitation market has high growth potential in many countries: the growing social awareness that preservation and enjoyment of the building heritage has acquired, the favorable prospects offered in certain areas by the cultural sector as an engine for activity (Cultural Tourism), the progressive ageing of existing housing, etc. Moreover, the rehabilitation sector is a key topic in terms of sustainable urban growth: promoting lower energy consumption (in contrast with demolition and new work), consuming less material than new construction work, etc",1
30,5,"In construction rehabilitation there is wide variety of policies with extreme situations. Preservation laws and regulations vary significantly from one country to another, thus in some European countries the preservation laws are fairly rigid, while other countries do not directly consider rehabilitation policy. The same occurs in the legal jurisdiction for scope of practice in this area.",1
30,6,"To design a guideline course, first of all, we should ask ourselves some basic questions: When should a structure be rehabilitated? What procedure should be adopted during the inspection? Do students have previous knowledge about the behavior of traditional materials and about newly applied ones? What is more, we could add another question to all of these: Why? The civil engineer, at the design level (Dally et al. 2012), should be able to adopt an approach when answering these questions.",1
30,7,"On the other hand, we must pay attention to highlighted historic buildings, whose need for rehabilitation and maintenance is especially significant because their potential failure has important consequences (from technical, cultural and economical points of view). In this type of construction the provision of rehabilitation protocols to be adopted must be carefully considered. Nevertheless, there are existing buildings, which are not unique from the cultural point of view, but which must be rehabilitated, sometimes simply due to changes in functionality or habitability. Their lesser singularity does not preclude requiring similar exhaustive analysis. Besides, this day-to-day rehabilitation market contributes significantly to the economy of the construction sector. In the authors’ opinion, both types of buildings must be targeted by the educational proposal.",1
30,8,"All these circumstances result in the need for specific training of engineers dedicated to this area, including Civil Engineers. Lombillo et al. (2013) analyzed the current dedication worldwide to construction rehabilitation within the Faculties or Schools of Civil Engineering.",1
30,9,"As a result, and based on the previously mentioned research, we consider that the study of this course should be at least optional in Civil Engineering at the bachelor degree level due to the increasing demand for rehabilitation of existing buildings. For this reason and considering the varying practices in different countries, this article proposes an international guideline course in construction rehabilitation with the aim of collaborating, creating joint strategies for action and relationships among university colleagues.",1
30,10,"This article culminates in the selection of topics integrating all the information generated throughout the research. However, as a previous justification, in the following section, we introduce some of the topics considered important in order to complete the construction rehabilitation guideline course.",1
30,11,"Due to the previously mentioned challenges of analyzing existing buildings, we have to adopt a general methodology through consensus. As an example, Figure 1 illustrates a rational analysis procedure",1
30,12,"Within these phases, previous knowledge is fundamental in choosing the most suitable techniques and materials applicable in later stages of Design/Project and Work (Binda et al. 2009). Moreover, carrying out these preliminary studies will lead to a reduction both in overall costs of the intervention and in the working times (Lourenco et al. 2008), since these phases of previous study (phases 1-3) can limit the uncertainty in the intervention.",1
30,13,"Therefore, we should base the rehabilitation process on a precise preliminary investigation (Binda et al. 2008), in order to document the current state of the construction. So, we should approach the rehabilitation process from a multidisciplinary point of view, considering the previously mentioned complementary aspects including: the historical evolution of the buildings, geometry, cracking patterns, characteristics of the materials, construction technology, potential failure mechanisms, etc. (Penazzi et al. 2000). In this regard, collaboration is essential among architects, engineers, chemists, restorers, historians, archaeologists, etc. In this sense, Binda et al. (2000) suggest, in relation to studies carried out for the rehabilitation of the ""Torrazzo"" of Cremona (Italy): ""The multidisciplinary nature of the working method is the fundamental key to the successful development of the investigation"".",1
30,14,"At this point, we have sufficient motivation to ask the question: What construction types should we train Civil Engineers in? The following paragraphs give details about them. Most historical monuments are masonry buildings, as are many residential buildings, and there is also an extensive number of civil engineering structures, bridges, retaining walls and reinforcement in highways, etc. In Europe alone, according to the International Council on Monuments and Sites (ICOMOS), there are 500,000 registered monuments: 20% have structural problems, of which 40% may be categorized as masonry constructions/buildings, which implies 40,000 possible interventions on existing buildings, to which we could add a number of civil engineering structures (infrastructures, bridges, etc.) (Garmendia 2010). Therefore, the creation of a teaching module dealing with rehabilitation of masonry structures is necessary in Civil Engineering degrees.",1
30,15,"A large part of the world’s population lives or works in earthen buildings (Houben and Guillaud 1989). As a reference, as of March 2012, of the 563 cultural heritage sites that the World Heritage Committee has inscribed in its list, 96 (17%) are completely or partially built of earth (Unesco 2012). We can find earthen constructions practically all over the world, with a special importance in developing countries, where they still use other building materials limitedly and traditional construction is still common. In any case, earthen construction is more sensitive than its modern counterpart, as it is more vulnerable to external agents. These considerations highlight the need to take into account effective diagnostic techniques to help assess the state of conservation of earthen architecture, and adopt intervention methods in order to preserve these constructions.",1
30,16,"In the United States, an important part of the population lives in houses constructed almost entirely of wood, but only a small minority of students entering graduate programs in structural engineering and materials science choose to specialize in timber (Langenbach 2010). In Germany for example, only 14% of all single family houses and negligible numbers of other buildings are constructed of timber (Betz 2006). In large parts of China, timber used to be in common use for buildings. Today, wood construction has been almost entirely displaced by concrete, even in smaller settlements. Traditional constructions, either common buildings or historic and monuments, have used timber extensively for structures supporting floors and roof trusses.",1
30,17,"Finally, among other topics, there is a need to provide a minimal knowledge base in the seismic behavior of existing buildings in order to minimize the damaging effects of earthquakes in constructions.",1
30,18,"One of the challenges is to sufficiently unify the criteria of an optional course with great impact on society, training our students in the basics, with a proposal of a common course and focus in all the Civil Engineering degrees worldwide. Logically, we should consider the approach as a general guide, since each university should pay special attention to the topics that are most common in its constructive practices, taking into account the regional and national reality.",1
31,1,"The goal of the research reported in this paper is to design and systematically assess the effectiveness of a collaborative contextaware mobile augmented reality tool (CAM-ART) in construction and civil engineering curriculum. To achieve this goal, an augmented reality (AR)-based information delivery tool, CAM-ART, was implemented in classroom-scale experiments to enhance traditional lecture-based instruction and information delivery methods. In the research reported in this paper, the contents of an ordinary textbook were enhanced using computer-generated three-dimensional (3D) objects and other virtual multimedia (e.g., sound, video, and graphs), and delivered to students through an AR application running on their smartphones or tablet computers. The sample consisted of construction and civil engineering students, who were randomly assigned to Group A (control group) and Group B (test group). The designed learning tool was tested in a collaborative and interactive environment, preperformance and postperformance data was collected, and student perception of using the AR-based tool was elicited through a feedback questionnaire. Data analysis showed that CAM-ART had a measurable and positive impact on students’ learning both in short-term and long-term. ",1
31,2,"Despite previous research that points out the importance and value of technology in increasing the quality of learning, many higher education institutions are still investigating and experimenting technology advancements in relatively smaller scales and have much to learn about the turnover of educational technologies (Green and Gilbert 1995). Researchers have discussed that learning should occur in a blended environment where traditional classroom practices are combined with technological learning solutions (D’Souza et al. 2013). In contrast, the new generation of students is still being educated with old (and often outdated) teaching paradigms and methods (Beck and Wade 2006; Klopfer 2008; Prensky 2001) while they are growing up with information and communication technology (ICT) embedded in their daily lives. Compared to previous generations, the new technology savvy students handle digital information on a daily basis, are connected to others via mobile devices, work interactively, perform several tasks simultaneously, and play games in a more competitive and collaborative environment",1
31,3,"Researchers have suggested that instrumental aids are one of the effective ways of controlling human learning (Skinner 1954). A study conducted by Virginia Tech and University of Georgia on approximately 1,400 university instructors indicated that most of the instructors felt that classroom technologies had a positive influence on their teaching and students’ learning. Respondents noted that technology has helped them deliver quality information, present more complicated examples to students, and enhance the engagement and attention of students in classroom activities (Brill and Galloway 2007). In another study, academicians showed a positive attitude towards ICT since it helped improve students’ integration (Gülbahar 2008). Hence, providing a supplementary pedagogical tool in addition to teachers’ guidance would be an ideal solution to effective learning. One of the main questions that must be properly addressed when deploying a new technology in the classroom is that if students can potentially do the same activities using this new technology (e.g., smartphones or tablet devices) does this also translate into better and more engaging learning with longer lasting results? To this end, an important issue is to use technology in an effective and proper way.",1
31,4,"Therefore, the research reported in this paper was motivated by the idea of using mobile technologies in support of interactive learning, to enhance student engagement, and ultimately to transform traditional instructional techniques. The authors designed a context-aware mobile augmented reality tool (CAM-ART) and used it in an undergraduate construction and civil engineering course to assess its pedagogical potentials in engineering education. Within this context, an ordinary paper-based lesson was transformed into a mobilized lesson, a term defined by Norris and Soloway (2008). In doing so, the goal was to make a transition from a more content-centered and teacher-centered instruction to a systematic student-centered strategy that enables personalized and self-directed learning (Looi et al. 2009). The overarching goal of the research reported in this paper was to help students gain longerlasting visual and conceptual knowledge, and to obtain a better and more reliable understanding of how students perceive and interact with classroom technology. In the longer term, the research reported in this paper will seek opportunities to expand its application domain beyond construction and civil engineering and to other science, technology, engineering, and math (STEM) disciplines.",1
31,5,"Moreover, according to several learning theories, metacognition is also a critical factor in the learning process, which refers to the learner’s knowledge of how to improve their own learning. This goal is achieved when the learners know the best way they learn (awareness) and how they could control their learning (control) (Hacker et al. 1998). In the research reported in this paper, a presurvey test was taken from 166 undergraduate students to gain a better understanding of students’ awareness about their learning style (Vincent and Ross 2001) and obtain feedback about the potential of using technology and mobile devices as a learning tool in the classroom. Results showed that students perceive visual information and technologies as an effective learning aid that can supplement traditional text-reading methods. Although such visual aids could also be provided through the use of simple slide presentations, the authors hypothesized that motivation could not be properly stimulated by simply adding visual presentations to course materials. The previously mentioned learning theories combined with the critical role of motivation in learning was the underlying reason behind selecting and using mobile AR as an innovative approach to combine traditional and technology-based course delivery techniques into a single platform. ",1
31,6,"Several researchers have reviewed the literature on technology and learning and concluded that if properly used, it can have great potential to enhance student achievement and teacher learning. It has been discussed that across people and situations, interactive simulations are more dominant for cognitive gain outcomes (Dede 1998; Vye et al. 1998; Yoon et al. 2012). Given that technologies for creating and displaying virtual objects and virtual environments have become more accessible and easier to use, the authors were motivated to test the potential of such technologies in real classrooms and assess if students learn better by using their mobile devices to gain access to contextual visual information relevant to the course material. There are four types of virtual-real environments: (1) pure virtual reality (VR), (2) augmented virtuality (AV), (3) AR, and (4) reality (Milgram and Kishino 1994). In VR, the surrounding environment is completely digitalized. In AV, real objects are embedded into virtual ones. In AR visualization, 3D computergenerated objects and text are overlaid on top of the real world environment (Azuma 1997). Therefore, AR supplements reality rather than fully replacing it",1
31,7,"One of the reasons behind the increasing usage of AR in education and learning is that conducting hands-on experiments provides the opportunity for situated learning that is more likely to be applied to real world situations (Lave and Wenger 1991). AR can help combine the real world experience and the learning process, and thus create interactive and motivating learning experiences, which may result in more participation and group discussions even outside the classroom. As mentioned previously, in the research reported in this paper, a mobile context-aware AR tool called CAM-ART was designed and tested in an undergraduate course. Students were asked to use their handheld devices (i.e., smartphones or tablet computers) to receive context-aware virtual information about the materials presented in an ordinary course textbook, while working in groups in an interactive and collaborative setting. Through the use of mobile devices, the need for wearing bulky equipment such as AR head-mounted displays (HMDs) was also eliminated.",1
31,8,"Finally, in answering the survey questions, almost 80% of students responded that they were very confident about installing and using a mobile application on a smartphone or tablet device. Moreover, as stated in Table 2, almost half of the participants agreed that they were confident working in a group where each person could use their own mobile device. The results of this and other academic surveys (Dong et al. 2013; Felder and Silverman 1988) support the idea that using an interactive and collaborative pedagogical tool in engineering education can enhance the learning quality, increase students’ visual and practical knowledge, and help them match course concepts to real world problems. The rest of this paper contains a detailed description of the mobile AR learning system design, as well as the implemented assessment strategies, and results and discussion.",1
31,9,"Several researchers have listed key principles of a good educational system design, as follows: (1) interaction, (2) empowerment, (3) awareness, (4) flexibility, (5) accessibility, (6) immediacy, and (7) minimalism (Cuendet et al. 2013). To have the most effective design, these principles should be instantiated through a participatory design with the teacher and tested in the classroom. Therefore, the authors incorporated all these principles in CAM-ART to enhance the quality of their pedagogical system. In particular, using the context-aware mobile AR application to display additional visual information on top of the textbook pages coupled with the teacher’s knowledge of the subject matter provides empowerment (Item 2) and awareness (Item 3). Moreover, the ability to use the tool individually or in a collaborative group setting provides interaction (Item 1) and flexibility (Item 4) in the design, by allowing students and teachers to work together to cope with varying levels of knowledge within a group or between the groups. ",1
31,10,"In the AR platform used in the research reported in this paper, an AR experience based on augmented reality experience language (AREL) consists of a static part, AREL extensible markup language (XML) which defines all the content and links, and a dynamic part, AREL JavaScript, which defines the interactions and behaviors of individual objects or the entire scene. The AREL has been used in Junaio and runs on both Android and iOS operating systems. An AREL package consists of the following components: (1) static XML for content definition, (2) Javascript logic to define interactions, and (3) content (that includes 3D objects, images, movies, and other multimedia). Using these components, end-user and server communicate over a wireless internet (Wi-Fi or 3G-4G) and the developer exchanges data with the server over hypertext transfer protocol (HTTP).",1
31,11,"Next, as they move their handheld devices over the images of the book, 3D computer generated and other multimedia (e.g., videos, sounds, and images) appear on top of the textbook images (Fig. 3). For instance, as shown in Fig. 3(c), after the instructor described how a split spoon sampler is used to take samples from the ground and showed the image of the book to the students, students could use CAM-ART to watch a real video of how exactly the task takes place on the jobsite. Displaying detailed two-dimensional (2D) images over the images of each drill bit such as diamond drill, rotary bit, and cross-chopping bit, as well as 3D models of the hand-operated augers are among other examples used for this scenario. Students can also collaboratively work with their peers to discuss the delivered information. The ability to use multiple devices at the same time in a group enhances participation and encourages interaction between group members. It also enables teachers to form teams of students and easily implement the tool in the classroom by asking students to use their own mobile devices at no additional cost.",1
31,12,"Students (88% male and 12% female) were randomly divided into two groups (Groups A and B). Group A was used as the control group and asked to attend the first mystery lecture, and Group B was used as the test group and asked to attend the second mystery lecture. The two lectures were identical in terms of learning objectives and learning material, and differed in that only one allowed students to use CAM-ART. Students in both groups were not told ahead of time what to expect. This was essential to make sure that they came to class with minimum bias. However, as discussed previously, they were all given a presurvey questionnaire about 1 week prior to mystery lectures so that basic information (e.g., gender and program of study) as well as information about their level of familiarity with technical terms (e.g., VR and AR) and possession of certain tools (e.g., computers, tablets, and smartphones) could be collected. Each student was also assigned an identification (ID) number and the collected information was used to properly assign each student to either group. The topic of the lecture was selected to be construction site investigation.",1
31,13,"As previously stated, an important implementation issue in these experiments was to establish appropriate techniques and guidelines to effectively assess the benefits of the new tool, and analyze its impacts on the learning process. To achieve this, and considering different aspects and limitations of available assessment techniques, the authors selected and used nine different classroom assessment techniques (CATs) as introduced by Angelo and Cross (1988) to systematically evaluate if the new learning platform has real practical benefits when used in classroom settings. The nine selected CATs included (1) background knowledge probe, (2) memory matrix, (3) categorizing grid, (4) defining features matrix, (5) approximate analogies, (6) course-related self-confidence surveys, (7) punctuated lectures, (8) teacherdesigned feedback forms, and (9) group-work evaluations. Detailed descriptions of these CATs can be found in Angelo and Cross",1
32,1,"Monitoring of civil engineering structures and constructions requires techniques which can produce high precision and accuracy, reliable measurements and fast processing speed. The development of information and communication systems as well as of microprocessor controllers has enabled a creation of monitoring systems that can be used for tracking reliability of structures and constructions in civil engineering, with described key features. This paper describes in detail the architecture of the Civil Engineering Structures Reliability Monitoring (CERM) system. The system has been designed for the purposes of the Technical Mechanics and Theory of Constructions Department at the Faculty of Civil Engineering and Architecture, University of Nis. Unlike general commercial monitoring systems, the CERM system has been specially designed for the purpose of reliability monitoring, and its potential will be further exploited in this paper. It is based on usage of universal microprocessor controllers Integraf of series 10X, along with specially designed software package. This system provides real time acquisition of measurements for observed civil engineering structures and analysis of received values based on developed mathematical models.",1
32,2,"With the production of low cost sensors with solar charge and ability for wireless communication a new way is opened for designing systems and applications for monitor parameters of structures in many areas of science and particularly in civil engineering. Monitoring of structures and constructions in civil engineering is very important, especially from the aspect of structure stability and reliability. The stability of engineering structures can be changed over time due to functional deficiencies, changes of material and other properties, changes of load level during long time, or by human errors like negligence and improper maintenance. During design of engineering structures and constructions, the quantities important for their reliability and lifetime (load, material properties, geometry, environmental effects etc.) are calculated. Under the influence of various factors during structure’s lifetime, the actual values of quantities may differ from those used in design. In some cases these deviations can result in impaired function, shorter life, or even failure of the structure",1
32,3,"Reliability parameters of a structure can be measured in the design stage or during an operation stage. The factor of safety (FoS), as a measure of reliability of a particular design, can be calculated as a ratio of structural capacity (N) to actual applied load (L). The FoS, calculated in this way, is often referred to as a realized factor of safety. There are also the technical FoS, social FoS or design FoS. Having in mind, that variables N and L, depend on project parameters, one can introduce the technical FoS. If the social dimension of structure is taken into consideration, the social FoS can be introduced. And finally, we there can be a design FoS, as a constant value prescribed by the law, standard, specification, contract or custom to which a structure must conform or exceed. As we can see, the factor of safety should not be taken for granted. It can be a very complex measure, if we look at a different aspect of a structure. Beside the factor of safety, another factor that has influence on structure reliability is structural resistance. If we want to take into consideration dynamic influences on the structure construction we will refer to this factor as a structural resistance effect. In order to ensure structure safety in relation to functional impairment, technological constraints are used, such as maximum deflection angle, slope, vertical acceleration and others.",1
32,4,"Engineering structures in operation deteriorate gradually due to many effects of the load, environment or human negligence. An accurate prediction of deterioration processes and of the life-time is impossible especially for long-life structures [1]. However, there are certain methods that can be used in order to predict the effect of environmental and human factors on structures. In literature and in practice two methods are used for improvement of structure reliability during operational stage: computer-supported monitoring of load effects, and fuzzy methods for the evaluation of technical condition. Computer supported monitoring is used for simulation and for monitoring of stress parameters. The stability of construction and its parts, can be monitored using specially designed mathematical model. This model mostly incorporates the following structure parameters: deformations, stretching and structural resistance.",1
32,5,"The best solution for structures reliability monitoring would be a combination of the two approaches - a computer system capable of monitoring given structure parameters, simulation of human and environmental factors, prediction of structure behavior and giving recommendations for structure improvements during operational stage. Such computer systems can be applied for river water quality monitoring [5], plant production monitoring [6], or civil engineering structures monitoring",1
32,6,"In this paper we will present an architecture of a computer based system designed for Civil Engineering Structures Reliability Monitoring (CERM). The overall objective of CERM is to ensure the stability and reliability of observed structures trough precise measurements and risk assessment using prediction models and expert knowledge. The CERM system is designed to calculate structure parameters in real time, such as deformations, stretching and structural resistance. From calculated parameters, system can predict the behaviour of structure for the given period of time. The software package for CERM system, which is still under development, will be tested in laboratory conditions for measuring certain parameters on models with a goal of optimisation of dynamic influences and stability of structures and constructions. Along with monitoring of structure parameters, system is designed to analyze mathematical model of structure, which is a projection of constructional set and characteristic parts of structure itself, in order to establish a correlation between them. System can be used in the design phase of building, as well as during operation phase, since it can predict behaviour of building and simulate influence of dynamic parameters of environment. In this way it can help calculating the stability of design for the planned lifetime of structure.",1
32,7,"Architecture of the CERM system for monitoring reliability of structures and constructions in civil engineering is presented in Fig. 1. CERM has a clientserver architecture. Client is used for collection of structure parameters, using different types of sensors. Server is used for gathering measurements from clients and structure and reliability analysis using specialized software. Application software for CERM client and server, along with specially developed communication software makes a unique software package of CERM system for gathering, processing and data supervision on purpose of automatization and increase of structures reliability.",1
32,8,"It is composed of a universal regulator INTEGRAF 10X based on microcontroller Philips 80C552 [5]. INTEGRAF 10X (Fig. 2) as a compact universal regulator pro-vides acquisition, regulation, governing, automatization of processes and production systems, supervision and control. It is a high performance microcontroller suitable for instrumentation, industrial governing, automatization of industrial, waterworks or agricultural equipment. Integraf 10X has eight analog and eight digital inputs which are used for bringing two types of signals (analog and digital) from sensors or other measuring devices. Integraf 10X software is capable of processing and scaling received technical values of input signals using built in algorithms. On the basis of processed values, controller can administer outputs independently, without human intervention. Integraf 10X is in a real time connection with CERM clients. The connection can be established using GPRS modem, Ethernet cable, 485 communication interface or PLC.",1
32,9,"Communication infrastructure of CERM system is realized using different types of connections. Connection based on GPRS modem, solves the problem of communication between the central computer (server) and microprocessor regulators INTEGRAF 10X (clients) within any area covered with the local mobile network. In system where GPRS modems are used, it is necessary to enable data buffering as a mean of prevention of data loss in cases when there is a traffic blockage or an ability to ensure constant connection. This is why the client of the CERM system, has a buffering function, which ensures that data is secure in cases of technical errors. Although the usage of GPRS assures great flexibility of system in sense of eased expansion of network or excluding of some parts from the existing network, there are some disadvantages in using in comparison to cable connections. First one is the functional dependence of CERM system from the quality of mobile service which depends on the chosen local operator of digital GSM network. The response time is also longer using GPRS modems in comparison to wire connection. The load of the mobile network, often has a significant influence on the response time.",1
32,10,"Unreliability of the GSM service provider and the often traffic blockage could give negative reflection on the work reliability of CERM system. These disadvantages have caused the provision of three more types of connection in the CERM real-time system. We have given the client a possibility of using GPRS modems, Ethernet cable, RS 485 communication interfaces or PLC in order to connect to the server component of the system. The CERM system allows connection to several measuring points on one or more structures, and in that way creates a single information system for conjoint control of structures reliability",1
32,11,"CERM system can be applied for measuring reliability of different types of structures and constructions. Furthermore, it can serve as a central information system for conjoint control of structure reliability on different locations and of different types (Figure 4). In CERM system reliability is calculated on the basis of received and processed values of different structure parameters. Measured structure’s parameters can vary depending on structure type (e.g. bridge, roof construction, etc.). Common parameters of interest are mostly strain and temperature, since their changes during structure operation have the fastest effect on structure reliability. For measuring this parameters, resistant strain gauges and thermoelectrical sensors can be attached to Integraf 10X device. CERM system software will compare measured parameters in real time with the corresponding parameters from the structure’s design phase or from measurements’ database. If there is a mismatch in values, or if the measured parameters are beyond normal limits, system will suggest optimized constructive changes that should be done on structures, in order to bring the parameters within the limits which indicate structure’s safety. ",1
32,12,"For testing purposes mathematical models of bridge and roof constructions will be defined and entered in the software. For monitoring these two civil structures’ reliability, following parameters will be used: temperature, wind speed, frequency, strain, slope and deflection. Simulated input parameters’ values will be brought on Integraf 10X inputs, and forwarded to the server for testing structure reliability for defined mathematical models. If calculated reliability differs from nominal value, system will alert user. Special rules will be defined so that the system could provide user with reliability optimization steps, when there is deviation from the nominal value. Test results of reliability calculation and structure behavior prediction will be judged before CERM appliance for real structures reliability measurements.",1
32,13,"Within the last few years, evaluation and reduction of risk has become an important area of research in civil engineering. When structure properties differ from its nominal values reliability, safety and performance are at risk. In order to maintain structure reliability continuous monitoring of structure is necessary. This includes measuring important parameters of civil engineering structures and tracking changes in the construction or material. All this is necessary for an efficient and timely maintenance of structures. Nowadays, there are many methods for monitoring of structures’ reliability, but most efficient ones are computer based methods.",1
32,14,"In this paper we gave a brief overview of a computer based system for civil engineering structures reliability monitoring (CERM). System is designed to propose necessary steps in order to minimize deviation of characteristic values of measured parameters, which should be within the limits of pre-designed value.",1
33,1,The use of digital-models to communicate civil-engineering design continues to generate debate; this pilot-work reviews technology uptake towards data repurposing and assesses digital (versus traditional) design-preparation timelines and fees for infrastructure.,1
33,2,"Extending (building-information-modelling) literature, distribution-impact is investigated across: quality-management, technical-applications and contractual-liability. Project casestudy scenarios were developed and validated with resultant modelling-application timeline/fees examined, in conjunction with qualitative semi-structured interviews with eleven prominent stakeholder companies.",1
33,3,"Results generated to explore digital-model data-distribution/usage identify: an eight-percent time/efficiency improvement at the design-phase, and a noteworthy cost-saving of 0.7% overall. Fragmented opinion regarding modelling utilisation exists across supply-chains, with concerns over liability, quality-management and, the lack of Australian-Standard contractclause(s) dealing directly with digital-model document hierarchy/clarification/reuse.",1
33,4,"Representing a small-scale/snapshot industrial-study, findings suggest that (modeldistribution) must emphasise checking-procedures within quality-systems and, seek precedence clarification for dimensioned documentation. Similarly, training in specific fileformatting (digital-model-addenda) techniques, CAD-file/hard-copy continuity, and digitalvisualization software, can better regulate model dissemination/reuse. Time/cost savings through digital-model data-distribution in civil-engineering contracts are available to enhance provision of society’s infrastructure.",1
33,5,"This work extends knowledge of 3D-model distribution for roads/earthworks/drainage, and presents empirical evidence that (alongside appropriate consideration of general-conditionsof-contract and specific training to address revision-document continuity), industry may achieve tangible benefits from digital-model data as a means to communicate civilengineering design.",1
33,6,"Available methods of communicating engineering design documentation have grown from the use of hard-copy blueprints, evolving beyond computer-aided-designs, towards integrated digital-models. Despite increasingly commonplace digital-data-modelling software, hard-copy (signed-off) drawings are still favoured by many in industry as a principal means to disseminate engineering design and upkeep (Steel 2012). Whilst the contractual obligations and responsibilities related to traditional, hard-copy engineering-drawing dissemination are very well understood by practitioners, the same cannot be said of digital-model datadistribution. The civil-engineering industry remains somewhat unsure of the risks and/or benefits of using digital-model data to communicate design solutions, and uncertain of the potential to repurpose a civil-engineering model for use in asset-management activities. Many involved in the design and creation of infrastructure projects remain reticent about the extent to which modelling might improve both their design procedures, and post-construction assetmanagement (Steel 2012). Whilst subjective support exists for digital-model data-distribution in civil-engineering contracts, industry continues to seek information about the extent to which benefits do, in point of fact, balance the risks of uptake.",1
33,7,"Building information modelling/BIM-Infrastructure civil-engineering data-modelling produces (not software per-se but) digital-models that communicate construction/engineering design information (Li et-al 2009; Li et-al 2012). However, it is suggested here that respective user-disciplines differ in their understanding of the potential for model-repurposing over a built asset’s life-cycle (Hughes, 2000; Cai, 2006;). BIM-software, used for architectural/structural and mechanical and electrical activities somewhat lends itself to assist a building’s future retrospective refitting (retrofitting) during its operational and maintenance life-span (Azhar, 2011; Becerik 2012); civil-engineering modelling software on the other hand, which is applied primarily to earthworks, drainage infrastructure and transportationengineering is very much tied to site-establishment and a particular site environ. A need exists to build upon existing theory (Tran, 2011; Cheung 2012) and tie the subject matter into, not only design-stage application but also, asset-management.",1
33,8,"Arguably a key difference between BIM and earthworks/drainage-activities data-modelling is the level of opportunity for model reuse or repurposing, with civil-engineering infrastructure activities largely (re)survey-intensive. Substructure/sub-element establishment falling within the remit of asset-management requires civil-engineering digital-data-models might be argued as having only limited potential to assist facilities managers in retrofitting upgrades, when compared to design-model aspects that encompass architectural/structural superstructure and, mechanical and electrical fittings and fixtures.",1
33,9,"Analysis of the key issues relating to ‘civil’ (transportation, drainage and earthworks) datamodelling, can however be addressed by review of work pertaining to ‘BIM’; this is justified, not only by acceptance of an industry ‘truism’ that the generic label of BIM covers all construction but also, by the fact that both building jobs and civil-engineering projects require distribution of respective information to a range of inter-disciplinary parties.",1
33,10,"The following discussion outlines the main issues surrounding data-model data-distribution, namely: quality-management and drafting; liability and contracts; and, intellectual property and remuneration; all framed progressively as a reflection upon key variables. Analysis of these core variables allows the development of research objectives outlined in the ‘methodology section’ towards a main aim of assessing key benefits (extending work by Sas, 2008; Arayici, 2011) in digital-data-model distribution in civil-engineering contracts.",1
33,11,"A civil-engineering digital-model [and related BIM execution-plans and quality-assuranceprocedures put in-place instead of traditional/manual methods (Hartmann, 2012)] has potential to reduce hard-copy set-out point information, reduce road cross-section illustrations, and allow for smaller-scale simplification of longitudinal-sections’ drawings (Li,2009; Li, 2012). Thus quantity of information provided in drawing-form can be reduced, but only if it is known from the outset that: native format digital versions of design drawings and models used to produce them are to be provided universally to the principal and contractors/subcontractors; and, that the parties receiving the files are capable of using information in that format (in other words, are able to use software capable of reading all supplied data). If these two modelling antecedents are not met (or only partially met by deciding upon digital file dissemination at the post-contract stage), designers logically adopt a ‘default’ position, by ensuring that all (traditionally required) information is placed on their drawings (and accordingly ‘invoiced by timesheet’), irrespective of potential duplication or irrelevance. Discussion of ‘eastings’ and ‘northings’ below, is a case-in-point.",1
33,12,"A mine-expansion project of access roads, camp infrastructure and ancillary plant facilities will require a multitude of drawings. Just one of these drawings, a site-plan for an unsealed heavy-vehicle access-road, can be expected to require identification and siting of up to thirty (30) equating-elevation-level easting and northing set-out points (Donaldson, 2013). Since digital-model data-distribution reduces duplication and multiple-party verification, elimination of several dozen (unnecessary) set-out points for easting/northing/levels (across many design drawings to locate key features) can occur if modelling is adopted early. Indeed after the certificate of practical completion such points lose relevance.",1
33,13,"Set-out points on design drawings are time consuming both for designers to produce, and for recipients to process/re-digitise. In a worst-case (remote/unintegrated) scenario, surveyors receiving hard-copy of several hundred eastings, northings and levels might seek to recreate their own digital copy. The checking process (invariably carried out by a senior drafts-person opening a CAD file and/or modelling software file, checking each supplied coordinate with a corresponding digitised/re-digitised equivalent) is laborious. Whilst industry’s current extensive use of ‘disclaimers’ (detailed below) seek to dilute contractual obligations and responsibilities, surveyors’ still seek to check document-consistency such that, supplied design-data matches construction/as-built versions. Even with data provided ostensibly ‘for information only’, vigilance and checking for errors and mismatches between contracted hardcopy documents and digital-information is essential.",1
33,14,"Best-practice for civil-engineering set-out points is available; beyond laser-scanning products such as Trimble for producing a digital-model of existing infrastructure, need remains to provide integrated geometric design information to a construction team that extends traditional hard-copy set-out points, through a digital-model of strings rather than points. In other words, the surveyor ideally seeks to receive a reliable native-format digital-model that forms part of the contract-documents, without having to navigate ‘disclaimer-stamps’.",1
33,15,"Although availability of advanced equipment is increasingly common, the extent to which BIM balances the technology application with contractual-obligation/responsibility, is seldom clear-cut. Well-developed (revision) management procedures are important for BIM (Arensman, 2012) at the construction phase; however, theory can be somewhat at-odds with practice. To use a very basic example, a truism exists in industry that traditional hard-copy drawings are typically checked by senior staff prior to being issued as tender/contractdocuments. Data gathering interviews here identified that ‘digital-model data requires these same checks but largely, senior-staff are less comfortable checking three dimensional models than hard-copy’. A platitude might be that industry needs to address quality control (and liability), as design data moves down the supply-chain and, extends into an assets usable lifespan.",1
33,16,"At various project stages, requisite checks form part of quality systems that require to be made explicit within (standard) forms of contract. General conditions of contract (set-out in Australian Standards AS-4000 clause 8) that seek to define responsibility for ‘correct information’, as well as (AS-4000 clause 29) conditions related to the need to establish and adhere to a conforming quality system, currently make no explicit provision for digitalmodels. The lack of standard contract clauses defining risk allocation for model content is an issue (Foster 2008) as is, perceived liability (discussed below) of stakeholders.",1
33,17,"Unlike hard-copy drawings, design-models can be somewhat easily edited after distribution (Azhar, 2011; Kotwal, 2011); liability for model updates is an issue. For the party providing the model, there is concern that once the data leaves their control it may be modified deliberately, accidentally or as a result of software incompatibility (Florkowski, 2007). Regardless of the cause, modification is seen as a serious risk (McAdam 2010a; McAdam 2010b). Resultantly, many designers are resorting to the use of ‘disclaimers’ to accompany the digital-models that are distributed in editable format(s). The purpose of such a disclaimer is to indemnify the information supplier/source from claims that may arise as a result of the digital-model being edited erroneously and, to distance designers from liability",1
33,18,"Concerns over digital-model liability are also expressed by recipients. Nominated and domestic suppliers/subcontractors are similarly uncertain of the extent to which digitalmodels alone, are (contractually) binding; digital-models are still routinely checked against hard-copy for discrepancies and anecdotal evidence suggests that, if found, parties further down the supply-chain will simply correct minor errors in the model, and in some cases find it easier to recreate/remodel their own area of concern from scratch. Arensman (2012) found that whilst industry wants to rely solely upon digital-models, stakeholders remain wary of doing so.",1
33,19,"Liability concerns and disclaimer statements are further compounded by uncertainties regarding model intellectual-property, where a designer’s digital-model is ultimately determined by the propensity for reuse (and the relative cost of time and labour in its creation as well as the potential for lost revenue if used by others). IP rights are a concern for BIM, since an organisation’s own in-house innovative designs, disseminated for one job, may be open to (re)interpretation by others seeking to use similar innovations to secure both new and refurbishment projects independently. The value of a softcopy model extends beyond a particular project, since multidisciplinary models contain significant libraries of standard specification entities; digital-models have high usability if ‘repurposed’. Overall, the rights different parties are granted regarding the completed building model remains an ongoing issue, particularly since the collaborative nature (and specialist input that occurs) during the creation of integrated models, makes it hard to determine who owns the final package (Foster 2008; Larson 2008). Clarification of ‘patents’ within a design-model and a more explicit identification and ‘registration’ of individual innovation, may ensure that specific ‘patented design’ gains legal protection. ",1
33,20,"Project ‘procurement’ may provide a way forward, where a client purchases (or gives a donation towards) a submitted completed design-model; thus, winners are given the chance to bring the design to fruition and losers simply release the rights to the submitted model for suitable/appropriate remuneration. Indeed, as part of a bus-station redevelopment in Perth WA (within the Australian National Infrastructure Construction Schedule), a multi-stage tendering process sought initial expressions-of-interest for the design-&-construct project, which resulted in a subsequent invitation to supply, for suitable remuneration/donation (and implicit transfer of IP from the design/builder organisation to the client), a digital-model of the design proposal. This process allowed subsequent tenderer review and ultimately, the award of the contract (estimated at between Aus$100m-250m) to the winning consortium, and suitable compensation for the ‘losing’ supplied models (NICS, 2014). This type of procurement and remuneration for digital-models (and implicitly, respective IP) as part of the tendering process, invites further discussion of fee structures directly below.",1
33,21,"Calculations (and subsequent validations) were based on the assumption that the amount of hours estimated to complete a digital-model, in lieu of traditional media, includes model error-checks prior to issuing. It is also assumed that even if a digital-model is not stipulated explicitly in the contract, current practice in industry means that a (high) degree of digitalmodelling will still be carried out (in isolation, booked in timesheets and feature in progress reports) whether supplied ‘for-information-only’, or not at all. Similarly, preparation/calculations are also framed with an assumption (as mentioned by one respondent) ‘that industry currently spends more time on modelling and less time preparing (isolated) hardcopy (automated) drawings’; anecdotally (and subsequently verified by interviews), ‘many more hours are spent modelling than are booked with timesheets recorded against hard-copy drawing’.",1
34,1,"A civil engineer who lacks motivation, may perform poorly in making decisions, which may in turn negatively affect the performance of a construction project. This study extends knowledge about individual-level motivation among civil engineers and the relationship between the motivation of civil engineers and their demographics (i.e., age, marital status, education, work experience, type of company, project value). A questionnaire survey was administered to Turkish civil engineers in order to collect data on their personal demographics and their perceptions of the importance of different motivators. The case of Turkey is investigated because a large number of Turkish contractors are major players in international markets. This paper argues that there are statistically significant differences in the perception of some motivators by civil engineers based on their demographics and that different individuals need to be motivated by different motivators. The study demonstrates the existence of a relationship between demographics and motivators, an area that is mostly ignored in the motivation literature. Higher executives in the construction industry, who understand this relationship, may be able to motivate their engineers individually rather than using blanket motivators for all engineers.",1
34,2,"The motivation of employees has been a focus of debate that is of considerable interest to employers and researchers in different fields. Participants in the construction industry have acknowledged the importance of motivation as they have become aware of the advantages that motivated personnel could bring to their organizations. Highly-motivated personnel may enhance the performance of a construction project and deliver high-quality projects at lower cost over a shorter duration. This is consistent with the ultimate goal of construction projects (Oyedele 2010). Indeed, completing construction projects within budget, on schedule, and with good quality is important in the construction industry as it increases the likelihood of winning new contracts.",1
34,3,"It is commonly claimed that improving the performance of construction workers will increase the performance of a construction project (Uwakweh 2006). Therefore, researchers have paid great attention to the motivation of construction workers. However, little research has been carried out about the motivation of professionals (e.g., civil engineers, architects, etc.). Motivating professionals is as important as motivating construction workers in completing a construction project successfully. A civil engineer who lacks motivation, may perform poorly in making decisions, handling problems, and managing changes, which in turn can affect the project success (Pheng and Chuan 2006; Seiler et al. 2012). Stated another way, the success of a construction project highly depends on the decisions made by the professionals involved, who may occupy a variety of design and management positions.",1
34,4,"At this point, a question arises as to how to motivate professionals in the construction industry. Some studies have been conducted to identify the motivators of professionals in the construction industry. However, most of these studies ignore the fact that professionals are individuals with different characteristics (e.g., age, marital status, education, work experience) and that studies exist (e.g., Gaki et al. 2013; Kukanja 2013; Urosevic and Milijic 2012; Wong et al. 1999) revealing the importance of demographic variables on perceptions of motivation. Therefore, in this study, the factors that motivate civil engineers are studied, and the relationship between the motivation of civil engineers and their demographics is explored in the context of Turkey. The objectives of the study are (1) to collect and analyze data to understand what motivates civil engineers in Turkey; and (2) to explore the relationship between the motivators of Turkish civil engineers and their demographics.",1
34,5,"Understanding the relationship between civil engineers’ motivators and their demographics could be useful to the top management of construction companies. It is anticipated that, armed with such an understanding, higher executives should be able to motivate their staff more effectively if they are able to use a mix of different motivators for each individual civil engineer.",1
34,6,"Even though cultural examination is not the main focus of this study, the factors that influence the motivation of Turkish civil engineers can be understood better in the light of the local national culture. Hofstede’s(1980) study was chosen among a number of studies (e.g., Trompenaars 1993; Schwartz 1994) to provide information about the national culture of Turkey. Hofstede (1980) identified four dimensions (i.e., power distance, individualism, masculinity, uncertainty avoidance) to explore national culture in different countries. Hofstede’s(1980) model was used by many researchers",1
34,7,"Turkey scores high on the element of power distance, which is used to express the culture’s attitude towards inequalities among members of organizations within a country (Hofstede 1980). A high score shows that power is centralized and there is a hierarchy. In addition, Turkish employees expect to be told what to do and be closely controlled by their managers. Superiors consider subordinates to be a different type of people and vice versa. Having a high score on power distance also highlights the difficulty in obtaining cooperation from subordinates.",1
34,8,"Turkey’s score in individualism is low (Hofstede 1980). Individualism defines people’s self-image in terms of I or We.A low score for individualism shows that Turkey is a collectivistic society that attaches more importance to the We. Maintaining group harmony is important for group members. Therefore, open conflicts are avoided. Communication and feedback are indirectly conducted between the members of the group. Employees have an emotional dependence on their organization. The relationship between individuals has a moral base that has priority over task fulfillment.",1
34,9,"Hofstede (1980) used the masculinity dimension to see whether individuals define success by being the best in their field or enjoying what they do. Turkey scores low on masculinity, which means that spending time with family and friends is more important than work for Turks. Stated in another way, individuals work in order to live and not vice versa. In addition, a low score in masculinity means that conflicts are avoided in personal and professional life, and more importance is attached to reaching consensus.",1
34,10,"Hofstede (1980) also explored how society deals with ambiguous and unknown situations by defining an uncertainty avoidance dimension. Turkey received a high score on this dimension, which reveals a need for written rules and regulations. In addition, individuals use a large number of rituals to minimize anxiety and ease tension. Having a high score on uncertainty avoidance also reveals that individuals are greatly concerned about job security in life. Deviant individuals and innovative ideas are often seen as dangerous right up until they become commonplace",1
34,11,"In sum, the current literature makes use of different motivation theories to identify the motivators of engineers and architects. While these studies emphasize what motivates engineers and architects, most of them ignore the fact that engineers and architects are individuals with different personal characteristics. Oyedele’s (2013) study is the only study that considered individuals’ demographics in the context of motivation in the construction industry, but Oyedele’s(2013) study considered only two personal factors, namely the respondents’ work experience and the type of firm the respondent works for. In addition, the study focused only on factors that demotivate architects. The motivation of civil engineers in consulting/construction organizations has never been investigated relative to the respondents’ personal characteristics. This study was undertaken in response to the absence of such research. The main goal of this study is to examine the factors that motivate civil engineers according to their demographics (i.e., age, marital status, education, experience, type of company, maximum project value). A better understanding of the relationship between demographics and motivators should allow executives to motivate their civil engineers individually rather than by using blanket motivators for all engineers.",1
34,12,The main hypothesis of this study is that civil engineers’ motivators are affected by their personal demographics. The tasks that were performed in this study can be summarized as follows: (1) identifying the most-cited factors that motivate civil engineers by means of an extensive literature review; (2) designing a questionnaire based on the information obtained in the literature review and conducting a survey of civil engineers in Turkey to seek information about their personal characteristics and their perceptions of different motivators; and (3) performing statistical analysis on the collected data to verify whether a statistical relationship exists between Turkish civil engineers’ personal characteristics and different motivators.,1
34,13,"A short questionnaire was developed that consisted of a total of seven questions. The first section of the questionnaire consisted of six questions that recorded the personal characteristics of the respondents, including (1) age; (2) marital status; (3) education; (4) work experience; (5) type of company; and (6) the maximum project value. These personal characteristics were considered in studies that were conducted in the construction industry (Oyedele 2013) and other industries (Kukanja 2013; Amankwah et al. 2013; Linz 2004; Huddleston et al. 2002; Wong et al. 1999; Gaki et al. 2013; Urosevic and Milijic 2012) except for the maximum project value, which is also considered to be of importance for civil engineers.",1
34,14,"It is commonly advised that a Cronbach’s alpha coefficient of reliability should be calculated in order to determine the internal consistency of a questionnaire when using a Likert scale (Oyedele 2013). Also, Carfio and Perla (2008) and Jamieson (2004) suggest that Likert data should be analyzed with nonparametric tests. Therefore, the Mann-Whitney U test was performed using the IBM SPSS Version 21 program in this study.",1
34,15,"In order to confirm whether the motivators and their associated Likert scale are actually measuring the motivation of civil engineers, the Cronbach’s alpha coefficient is calculated. A Cronbach’s alpha coefficient value that is greater than 0.8 is suggested by George and Mallery (2003) to indicate good internal consistency. The overall Cronbach’s alpha coefficient for this study was found to be 0.855, which indicates good reliability and internal consistency. Cronbach’s alpha values if an item is deleted should also be examined for each item to see that all the criteria are contributing to this internal consistency. A Cronbach’s alpha value if an item is deleted that is higher than the overall Cronbach’s alpha coefficient means that if the criterion (i.e., motivator) is deleted, the overall Cronbach’s alpha coefficient value would be higher (Field 2005). As seen in Table 2, there is no need to exclude any of the motivators, because all Cronbach’s alpha values if an item was deleted are lower than the overall Cronbach’s alpha coefficient of 0.855.",1
34,16,"The null hypothesis is that there are no differences in the mean scores of the motivators as perceived by civil engineers in the two groups (e.g., more than 10 years work experience versus less than 10 years work experience). If the null hypothesis is rejected, it means that the difference between the mean scores of the motivators are statistically significant at α ¼ 0.05, indicated by an asterisk (*) next to the mean scores in Table 3.",1
34,17,"The age criterion is often used in motivation studies (Kukanja 2013; Amankwah et al. 2013; Linz 2004; Huddleston et al. 2002; Wong et al. 1999; Gaki et al. 2013; Urosevic and Milijic 2012). Table 3 shows that there a statistically significant difference exists in some motivators when viewed by civil engineers who are younger than 35 compared to those older than 35. Civil engineers who are younger than 35 attach more importance to the options “gaining knowledge, ability and confidence” and “opportunity for advancement and promotion.” These motivators are important for technical/ functional-anchored individuals such as civil engineers according to the career anchor categories identified by Schein (1990). This result makes sense because young civil engineers need more opportunity to gain knowledge, ability, and confidence due to their limited experience in the construction industry. They are commonly hired for lower positions in the organization’s hierarchy. Therefore, they need opportunities for promotion more than older engineers. This finding is supported by the results of the studies conducted by Wong et al. (1999) and Linz (2004). In both studies, it is stated that younger employees tend to attach more importance to motivators concerning opportunities for advancement and opportunities to develop their skills and abilities.",1
34,18,"It was found that single and married civil engineers are in general agreement in their perceptions of motivators except for “gaining knowledge, ability, and confidence” and “comfortable physical work environment.” Single civil engineers attach more importance to “gaining knowledge, ability, and confidence” and “comfortable physical work environment” motivators than the civil engineers who are married. It is likely that single engineers would spend more time at work in order to gain experience. It is understandable that they attach more importance to “gaining knowledge, ability, and confidence” and a “comfortable physical work environment.” This finding is consistent with the results of the study conducted by Wong et al. (1999), even though those respondents are employed in the hospitality industry in Hong Kong. On the other hand, Gaki et al. (2013) could not find a statistically significant difference in perception of motivators by single and married nurses in Greece. Despite the varied findings on the relationship between marital status and perception of motivators, the findings of this study suggest that marital status does have an impact on some motivators.",1
34,19,"When one considers the educational background of the respondents, Table 3 shows that there is a significant difference in the perceptions of three motivators, namely, “gaining knowledge, ability and confidence,”“impacting my subordinates positively,” and “working on projects of my choice.” Respondents who have a bachelor’s degree attach more importance to these motivators than respondents who have a higher degree. This finding is consistent with previous studies conducted by Gaki et al. (2013), Huddleston (2002), Kukanja (2013), and Wong et al (1999) that found the very same influence of the educational background on the employees’ perception of motivators.",1
34,20,"The results also suggest that the motivators “gaining knowledge, ability and confidence,”“rise in salary,”“impacting my subordinates positively,” and “opportunity for advancement and promotion” are perceived differently by the respondents who have less than 10 years of work experience compared to those respondents who have more than 10 years of work experience in the construction industry. The respondents with less than 10 years of work experience attach more importance to “gaining knowledge, ability and confidence,”“rise in salary,” and “opportunity for advancement and promotion,” which is consistent with the motivation of technical/functional-anchored individuals as per Schein’s(1990) career anchor categories. This finding makes sense because engineers who are at the beginning of their career would be much more interested in gaining knowledge, improving their abilities, and getting promoted. Wong et al. (1999) present a similar finding even though the study was conducted in Hong Kong hotels. On the other hand, the respondents, who have more than 10 years of work experience in the construction industry attach more importance to “impacting subordinates positively.” ",1
34,21,"The respondents, who worked on small (less than $50 million) and large (more than $50 million) projects, are in agreement in their perceptions of all motivators except for “job security.” It is clear that the civil engineers who have worked only on small projects feel less secure in their jobs, either because of a quicker cycle of layoffs in smaller projects and therefore short-lived employment, or because of a higher likelihood of staying out of work longer, or not having the qualifications for employment in larger projects. Nevertheless, in this study, it is observed that it can affect, at some extent, the perceptions of motivators by civil engineers. Higher executives should be aware that the civil engineers with a history of small projects in their past are more appreciative of motivators that ensure employment security. This criterion has not been considered in previous motivation studies.",1
34,22,"In order to explain the results of this study more clearly, two respondents who represent different demographics are selected randomly. The first respondent is a civil engineer who is younger than 35, single, has an advanced degree, has more than 10 years of work experience, works for a contractor, and has worked on at least one project of more than $50 million. The second respondent is a civil engineer who is older than 35, married, also also a higher degree, has less than 10 years of work experience, works for a consultant/ public owner, and has worked on smaller projects under $50 million. The two respondents represent two different individuals differing in all personal characteristics except for having a higher degree. When a Mann Whitney test is performed between these two civil engineers to test the differences in ranking priorities, it is observed that there is a statistically significant difference in the way those two individuals perceive motivators. The Mann-Whitney U statistic is significant at α ¼ 0.05, which proves that the importance attached by these two individuals to different motivators is quite different, resulting in a marked difference in the rankings. This finding suggests that different individuals need to be motivated by a different set of motivators.",1
35,1,"This study explores the challenges that civil engineering consulting firms face in their projects when they apply Systems Engineering (SE). It is also explained were these firms should focus when improving the use of SE. To conduct this study, the methodology of Eisenhardt (Building theories from case study research, Acad Manage Rev 14 [1989], 532–550) for building theory from case study research is used. The extent, to which SE is applied, is assessed in six civil engineering projects, using a newly developed framework containing an extensive list of questions about how and why SE was applied. Based on this assessment, it is shown that there are three major reasons why SE was not applied to the full extent. First, SE procedures and responsibilities were not always clearly established and communicated to team members. Second, team members were in a learning process and did not yet possess all the SE knowledge and skills required. Finally, there was a lack of a demanding client to enforce the use of SE. This paper also presents recommendations for improving the application of SE in projects, related to methods, skills, and the client. Further research should focus on different (kinds of) companies within the civil engineering industry.",1
35,2,"The International Council on Systems Engineering (INCOSE) defines SE as follows: “An interdisciplinary approach and means to enable the realization of successful systems. Systems Engineering considers both the business and the technical needs of all customers with the goal of providing a quality product that meets the user needs” [INCOSE, 2000]. Among others, SE means that the responsibilities of contractors transform from merely carrying out a predefined, structured assignment into solving an ill-defined, ill-structured, and complex problem in an early stage of the project. In keeping with that, the use of integrated contracts like DesignBuild, and Design-Build-Finance-Maintain increasingly becomes standard practice in the civil engineering industry.",1
35,3,"In the transition from traditional ways of working to an SE way of working, engineering consulting firms has an important role. On the one hand, these firms guide the implementation of SE in civil engineering and construction engineering projects. On the other hand, they have to apply SE themselves. In particular, those firms that have design departments, or project management departments. Several firms however, face challenges when applying SE in construction projects.",1
35,4,"In this research, we explore the challenges that engineering consulting firms face in civil engineering projects when applying SE. We explain why these challenges exist, and formulate recommendations to improve SE practices. This paper answers the following research question: To which extent do civil engineering consulting firms apply SE in construction projects, and where should they focus when trying to improve the use of SE? The answer to this research question provides the reader with detailed information on the application of SE within the engineering consulting firm in the civil engineering industry.",1
35,5,"The engineering consulting firm we studied is an international firm that provides consultancy, design, engineering, and management services in a broad range of market sectors related to the built and natural environment, including the civil engineering industry. Consulting services used by this firm are accredited the ISO 9001 quality management and the ISO 14001 environmental management standards. The firm has recognized the rise of SE for several years now, and since 2010, the firm has made the decision to implement and use SE in its business more prominently. The aim of SE within the case-firm is twofold: first, to professionalize and improve the working method of the firm in order to improve the quality of the services and products, and second, to limit failure costs by improving clarity, traceability, and demonstrability of the processes of the firm. To promote the use of SE in the firm, an in-company handbook on SE was developed.",1
35,6,"This research is carried out in the context of the civil engineering industry. This industry has certain characteristics that are important to describe because they influence the role consultancy firms have in projects and hence influence the way they can apply SE. First, the role of the engineering consultancy firm varies from project to project because in the construction industry, the client chooses the stage to involve the firm in a project. After carrying out (parts of) the assignment, the engineering consulting firm bears the project over to the client. The stage in which the firm is active has a large influence on the freedom that the firm gets when executing a certain assignment. After all, in case the firm should only produce the detailed design, many design choices have already been made earlier and the solution space is small.",1
35,7,"The second important characteristic of the civil engineering industry is that it is quite common to split a project into contractually separate segments. For example, it is common to engage one consulting firm for the concept phase, and another one for taking the design forward to completion [Farnham and Aslaksen, 2009]. This disjointedness causes problems with the application of SE because each firm may consider its own part as “the project” and loses sight of what constitutes success for the project as a whole. Consequently, the overview over the entire projects is mostly lost and so is the top–down approach of SE.",1
35,8,"The third characteristic of the civil engineering industry is that projects are one-off. This means that when the project has finished, the project organization will be dismantled and the involved companies go their own way again. Consequently, there is no continuity in the use of SE. It also means that for each new project, there are costs for setting up SE and these costs have to be amortized on that construction project.",1
35,9,"The importance of this study lies in the fact that, to our knowledge, never before the use of SE within a consulting engineering firm in the civil engineering industry has been studied in such level of detail. Most literature describes only certain parts of SE, for example, requirements engineering [Hull, Jackson, and Dick, 2010], requirements verification [Marchant, 2010], communication among team members and stakeholders [Piaszczyk, 2011], strategic decision making related to SE [Smartt and Ferreira, 2012], attribute substitution in SE [Smith and Terry Bahill, 2010], and traceability in SE [K  ̈ onigs et al., 2012]. Also, the effects of SE on construction safety [Saurin, Formoso, and Cambraia, 2008], and information flows in construction projects [Tribelsky and Sacks, 2010] have been studied. Moreover, most of these SE studies were conducted in other industries than the civil engineering industry.",1
35,10,"This paper is structured as follows: first the conceptual SE framework is described (Section 2). Based on the elements of this framework, the scoring method is developed and the research design of the in-depth case study is addressed (Section 3). Results, discussion, and conclusion are presented in, respectively, Sections 4, 5, and 6.",1
35,11,"Kossiakoff et al. [2011] state that “the function of SE is to guide the engineering of complex systems.” Figure 1 describes the different elements of the SE process based on the Systems Engineering Fundamentals of the Department of Defense [US Department of Defense, 2001] and key SE handbooks and guidelines available in the Civil Engineering industry in the Netherlands, where this research was carried out [ProRail et al., 2008]. In this process, nine elements form the main SE process (elements 1–9). The other three elements are: process input (element 10), process output (element 11), and a systems analysis and control element (element 12). The sections below describe the nine main elements, because these are the elements an engineering consulting firm encounters during the design process. These nine elements were used as a framework for analysis in our study. Each element was decomposed into several aspects that were more concrete. These aspects were further decomposed until we reached a level of concreteness that allowed for specific yes or no questions. Answers to these questions were based on interviews, documents analysis, and observations. This method is also proposed by Farnham and Aslaksen [2009]. ",1
35,12,"A case study research methodology was chosen to explore the challenges that engineering consulting firms face in their projects when they apply SE. A case study is relevant here because it enables to understand the dynamics within a reallife context, such as civil engineering projects [Eisenhardt, 1989; Yin, 2009]. Furthermore, Eisenhardt [1989] mentions a case study research provides the opportunity to iterate in between theory and data, therefore supporting both theory and practice. In this section, we explain the method we used in our research. It consists of three major stages: getting started, data collection, and data analysis.",1
35,13,"The first step was to define the research question, the context, and to establish the constructs. We defined the research question as: To which extent do engineering consulting firms apply SE in civil engineering projects, and where should they focus when trying to improve the use of SE?",1
35,14,"The context in our research was the civil engineering industry in the Netherlands. The situation in the Netherlands is relevant because the two main clients, Rijkswaterstaat and ProRail, prescribe the use of SE in all their projects [ProRail et al., 2008; Elliott et al., 2012]. Rijkswaterstaat is the executive body of the Dutch Ministry of Infrastructure and the Environment, and is responsible for the safe and smooth flow of traffic on roads and waterways in the Netherlands, including development and maintenance. The other main client, ProRail, maintains and controls the Dutch railway network and the transfer related facilities at railway stations. ProRail is financed by the Ministry of Infrastructure and the Environment. That both clients prescribe the use of SE for some years now has two advantages in this study. First, many cases in which SE was applied are available for our research. This means, we could select cases strategically. Second, SE is applied in the civil industry in the Netherlands for about several years now, so there is a lot of knowledge available. Nevertheless, SE is still new enough to be able to study the problems related to implementing the method in civil engineering projects.",1
35,15,"Important constructs in our research are “Systems Engineering,” which was operationalized by the SE process model discussed in Section 2. The other construct was “improvement.” By this, we mean a better application of the elements in the SE process model, and measured with a yes/noquestioning system explained later.",1
35,16,"All six cases were examined using the same protocol to enhance the reliability of the case study [Yin, 2009]. The protocol was built in two steps. First, an SE framework for analysis was composed. This framework contained an extensive list of questions to operationalize the extent of how SE was applied. These questions were based on the elements of SE (discussed in Section 2), and of such detail, that they could be answered by “yes” or “no.” For each “yes,” five points were allocated, for each “no,” there were no points allocated. For each answer that lies between yes and no, 2.5 points were allocated.",1
35,17,"The second step was the composition of a method to determine fulfillment of each SE element of the SE framework. Each element was appointed a score of up to a maximum score of 100%. This made the elements mutually comparable. An illustrative example of calculating the score for the RA is given in Table II. For readability purposes, we demonstrate the workings of the method based on four questions. In the original score method, more yes/no questions were asked about the application of the RA. A score of 0% means nothing of the framework was applied during the project. A score of 100% means everything of the framework was applied during the project. The score is a result of questions to be answered with “yes” or “no.” The score on each of the SE elements (in percent) is determined by summing the score of all questions and divide them by the maximum score that could be obtained on these questions. In the example in Table II, the four questions score 10 out of 20. This results in an application of 50% on this SE element.",1
35,18,"From the projects it follows that not establishing and capturing clear internal procedures and responsibilities regarding SE, in advance of project execution, is a major explanation why SE activities have not been applied to the full extent. In particular, regarding the lack of standard V&V forms and/or procedures.",1
35,19,"For example, in one project, it was not made clear at the beginning how to deal with design changes. This led to a situation in which new and adjusted requirements were not documented. This resulted in designs that did not meet the agreed-on requirements, and hence were difficult to verify. In four projects, requirements were structured in more detail by using an information software program. Such programs can support the management and control of changes, and facilitate the application of SE. Thus, although V&V procedures were not established beforehand, the use of software did facilitate V&V later in the project.",1
35,20,"A second major explanation why SE activities were not applied completely is that employees were in a learning process. They did not yet possess the SE knowledge and skills for performing SE activities to the full extent. One project clearly endorses this. In this project, it became apparent that a lack of change in work routines led to SE elements not being executed, or only implicitly. It appeared that employees found it difficult to cope with the new SE activities, and several mentioned that there was not enough training available, due to the time pressure of the project.",1
35,21,"In particular, employees are not familiar with applying the SE feedback elements (the requirements loop, the design loop, verification, and validation). Some anecdotes clarify this. For instance, in only one of the six projects, a verification plan was made because the project leader in that project saw verification as an important element of SE. Nevertheless, the verification plan did not clarify how to deal with the verification of every specific requirement. It appeared that in this project, the employees did not know how to compose the verification plan. This led to additional time being spent in the project team to figure out how to verify requirements.",1
35,22,"Another example that demonstrates that employees were in a learning process is that in the some of the cases, the employees from different disciplines made changes directly in the design. These design changes were not reported to the SE controller and were not documented. Consequently, nobody had a clear overview of design changes anymore. Rework and additional meetings were needed to regain control. This demonstrates that employees were not aware of the importance of documenting changes, which is considered crucial in SE.",1
35,23,"The core SE elements, being the RA, FA, and Synthesis, are better performed than the feedback elements between them. The reason is that the firm already executed the SE process, prior to the implementation of SE. When applying SE, the core elements only require better capturing and structuring of standard activities already performed for many years. The core elements are more or less normal activities for the employees of an engineering consulting firm, the intensive and highly structured SE feedback activities are not.",1
35,24,"A second recommendation for improvement is to enhance employees’ knowledge and skills of SE. In particular, training is required to apply the feedback elements of SE (verification, validation, and loops), as these elements are new to most of the employees, opposed to the core SE elements (RA, FA, design synthesis), which are more or less normal activities for an engineering consulting firm. In addition, the presence of employees with SE-experience in projects has a positive effect on applying SE through transfer of knowledge and experience to the other team members. Therefore, it is recommended to involve experienced SE employees more. In literature, the importance of SE education and training is acknowledged as well [Bonnema, Lutters-Weustink, and Van Houten, 2005; Bhasin et al., 2010; Godfrey, Crick, and Huang, 2014].",1
36,1,"Learning ability is one of the most distinctive characteristics that make humans social creatures. Numerous research has found that individuals learn in different ways, so every student has a different, individual learning style. The more instructors understand the learning differences of their students, the better their chances of success in civil engineering education. Therefore, determining the learning styles of civil engineering students is an important factor in their academic success. The research reported in this paper aims to explore the learning styles of civil engineering students in Turkey, and correlate their learning styles with success in construction management courses, gender, age, type of university, and year of engineering study. Data were collected using the Kolb Learning Style Inventory II, from civil engineering students in undergraduate programs at four different universities. The questionnaire was administered to students by direct contact, and 227 items of data were collected. At the end of the research reported in this paper, it was revealed that there is a correlation between learning styles and management success, age, year of civil engineering education, and type of university, but not gender.",1
36,2,"Learning is one of the most important abilities and an inseparable component of human beings. Each person is unique, with their own characteristics, abilities, preferences, and ways of thinking and acting that make them different from each other (Kuri and Truzzi 2002). Preferred ways of perception, organization, and retention of new information are distinctive and consistent for each learner (Chou and Wang 2000; Hsu 1999). The particular method of perceiving and processing information is denominated as a learning style (Carter et al. 2000). People have different learning styles that are reflected in different academic strengths, weaknesses, skills, and interests (Felder et al. 2002). Given the almost unlimited variety of job descriptions within engineering, it is safe to assume that students with every possible learning style have the potential to succeed as engineers (Felder et al. 2002).",1
36,3,"Numerous reports on the application of learning styles in engineering education found in the pertinent literature clearly show that the benefits of its implementation are significant. Some researchers describe how they have reformulated their disciplines in an effort to reach the whole spectrum of learning styles; others explain how they have achieved success using a variety of techniques and learning activities, such as group problem solving, projects, and exercises. Understanding learning style differences is thus an important step in designing balanced instruction that is effective for all students (Felder et al. 2002). Therefore, civil engineering syllabi and the programs of other disciplines should be prepared with consideration for the learning styles of students.",1
36,4,"The research reported in this paper aims to focus on learning in civil engineering education and construction management using Kolb’s learning styles, and explores the relationship between learning styles and students’ construction management success, gender, age, year of engineering study, and type of university. Within the scope of the research reported in this paper, survey forms were collected from civil engineering students at four different universities in Turkey. SPSS 18 software was used in the analysis of data; reliability analyses were made, percentage and frequency distributions were analyzed, and correlation analysis and ANOVA were examined. In addition, some proposals are brought forward.",1
36,5,"Learning can be defined as an internal process that is different for every individual. Nowadays, educational leaders recognize that the process of learning is critically important and the way individuals learn is key for educational improvement (Griggs 1985; Leutner and Plass 1998). An individual’s preferred method of receiving information in any learning environment is the learning style of that individual (Kraus et al. 2001). There are many studies on learning styles in the literature. The most frequently used learning style models are the Myers–Briggs-type indicator (MBTI), Hertmann brain dominance instrument (HBDI), Felder–Silverman learning style model, and Kolb’s learning style inventory (LSI; Felder 1996). Although all the styles classify different learning types in different ways, their aims and approaches are similar. In the research reported in this paper, LSI II was used, which is a revised version of Kolb’s learning styles inventory.",1
36,6,The concrete experience mode describes people who feel more than they think. Individuals in this mode tend to be very good at relating to others and they tend to be intuitive decision-makers. The reflective observation mode describes people who would rather watch and observe others than be active participants. Individuals in this mode tend to appreciate exposure to differing points of view. The abstract conceptualization mode describes people who think more than they feel. Such people tend to have a scientific approach to problem solving as opposed to a more artistic approach. The active experimentation mode describes individuals who take an active role in influencing others as well as situations. These individuals welcome practical applications rather than reflective understanding as well as actively participating rather than observing.,1
36,7,"Assimilators are learners who combine AC and RO. Assimilators are best at understanding a wide range of information and organizing it into a concise, logical form. They are more interested in abstract ideas and concepts than people. They value the logical soundness of a theory more than its practical value (Kolb and Kolb 2005).",1
36,8,"Accommodators are learners who combine the learning steps of CE and AE. Accommodating learners grasp their environments concretely through their feelings and utilize action to transform the information obtained. Accommodators learn primarily from hands-on experience. They prefer to act on feelings rather than on logical analysis. In solving problems, they rely more heavily on people for information than on their own technical analysis (Hsu 1999; Kolb and Kolb 2005).",1
36,9,"The learning style inventory test is in the form of 12 open-ended questions that have four alternative responses. Each question asks respondents to rank-order four sentence endings in a way that best describes their learning style. After answering all the questions, four scores are calculated according to the key of the test. These scores are clustered under four modes of the learning cycle, as follows: (1) concrete experience, (2) reflective observation, (3) abstract conceptualization, and (4) active experimentation; Kolb 1984). After this process, the four scores are placed on the cycle of learning graph (Fig. 2).",1
36,10,"In this situation, because of the industry’s close ties with business, civil engineering students are obliged to gain basic skills in areas such as law, management science, planning and coordinating skills, planning techniques, and team work, all of which are within the scope of construction management (Sears and Clough 1991; Gürer and Koç 1996). The success of the sector is heavily dependent on the quality of education of its employees. Similarly, the employees’ level of education has repercussions on the level of success that they will experience in their careers (Sertyeşilışık et al. 2012).",1
36,11,"Given that the construction sector continues to develop, there is an expectation among civil engineers that they will find a position in the management of a construction company. According to an observation of Russell and Yao (1996), “an engineer is hired for his or her technical skills, fired for poor people skills, and promoted for leadership and management skills.” Since the construction sector operates on a project basis, it requires different skills and qualities in comparison with other sectors (Warszawski 1984).",1
36,12,"Their level of knowledge in these areas undoubtedly affects the quality of construction and the costs involved in construction work. In this context, it is necessary for civil engineers who participate in construction projects to have sufficient grounding in management and the subunits of management, which are planning, organization, coordination, direction, and control. Therefore, as in other courses, teaching students of construction management according to their learning styles is important for their professional careers.",1
36,13,"Using a questionnaire, data were collected from civil engineering students at four different universities in Turkey to determine their learning styles. In this context, LSI II was used which was developed by Kolb consisting of 12 questions. During the research reported in this paper, 227 items off data were collected. Using the SPSS 18 software for analysis of obtained data, the reliability of the data was analyzed, and percentage frequency distributions, correlation analysis with Pearson’s coefficient, chi-square, ANOVA, and Tukey’s honestly significant difference (HSD) posthoc test were examined.",1
36,14,"The curriculum of the Departments of Civil Engineering of Çukurova University, Gaziantep University, Zirve University, and Hasan Kalyoncu University require the students to take construction management courses. The curriculums also offer managerial courses in construction including, law for engineers, project management, and so on.",1
36,15,"Construction management courses are fundamental in teaching the basic concepts of construction management, cost analysis and pricing methods, the bidding process, construction site organization, scheduling, occupational health and safety, and so on.",1
36,16,"In the sample group, there were 227 subjects whose ages ranged from 19–27. There were 120 (69.0%) 22–24 year old participants. The mean age was 22.26 and the SD was 4.059. There were 185 (81.5%) males and 42 (18.5%) females. Most of the participants (127, 55.9%) were educated at state universities. Most participants (95, 41.9%) were fourth-year students; however, sufficient participation was provided from students in all years (Table 1).",1
36,17,"Table 2 represents the distribution of civil engineering students’ construction management grades. In Turkey, the construction management course is usually found in the third or fourth year of the civil engineering syllabus. Therefore, the data of first-year and second-year students were not considered in this evaluation so this analysis was made with 134 items from the survey. According to Table 2 values, 67.9% of the participants had grades of 70 or higher in the construction management course.",1
37,1,"Automation of processes, in combination with quality assurance, is an important development in civil engineering. One of the critical components of quality assurance relates to geometry. In order to determine and control geometric elements, measurement and evaluation processes of engineering geodesy must be integrated with construction processes. The quality of products and processes is a complex, multi-faceted field and this complexity is considered here by a new model that describes quality on the basis of characteristics and parameters. The model that has been developed for engineering geodesy processes in civil engineering has been applied to describe the quality of the geometry of a building.",1
37,2,"Due to the increasing complexity of products and increased customer attention, quality issues are now strongly within the focus of many professional disciplines. This applies in fields such as machine construction, plant engineering, civil aviation, transportation and information technology, as well as in civil engineering and geodesy. While the methods and approaches to managing quality are often very different, they are often shaped by an underlying safety philosophy.",1
37,3,"The quality of products and processes, especially in civil engineering, is a complex and multi-faceted field. This complexity is considered in this paper by a new quality model that describes quality on the basis of characteristics that are substantiated by parameters. This model has been developed within the project ‘‘Optimization of E‰ciency and Quality Control of Engineering Geodesy Processes in Civil Engineering’’ (in German: E‰zienzoptimierung und Qualita ̈tssicherung ingenieurgeoda ̈tischer Prozesse im Bauwesen (EQuiP)) which is supported by the German Research Foundation (DFG).",1
37,4,"In contrast to most quality models which are only product-oriented, this quality model is both product- and process-oriented. This new two-level model has the following characteristics: accuracy; correctness; completeness; reliability; timeliness and specialized application-oriented parameters. In this paper the basics of the quality model are first explained and then the development of the model follows. The propagation of the quality parameters is also partly presented and the paper finshes with a worked example and some closing remarks.",1
37,5,"A quality model is a conceptual framework in which the abstract term of quality is gradually resolved into individual aspects such that the abstract term is substantiated. Using a quality model, the quality of a product or process should be completely describable and comparable. In engineering geodesy there exists no complete quality model that considers processes. To obtain a broad idea of how such a model would appear in theory and practice, it is necessary to examine allied disciplines such as civil engineering software development, data management and transport telematics. In the area of software quality a three tier model is used, consisting of characteristics, sub-characteristics and metrics (Boehm et al. 1978). The metrics may also be called parameters while sub-characteristics are essentially a middle layer between the parameters and the characteristics.",1
37,6,"Other well known quality models are the FURPS (Functionality, Usability, Reliability, Performance, Supportability) model in the area of software development (Kenett and Baker 1999) and the quality model provided in ISO 9126 Software Engineering – Product quality – Part 1: Quality model (ISO 2001). In the area of geographic data management, a three-tiered model consisting of quality elements, sub-elements and quality measures is also used (ISO 2002). Unlike the FURPS and ISO 9126 models, at the Institute of Engineering Geodesy (IIGS) models with two-tiers (characteristics and parameters) have been developed for transport telematics (Wiltschko 2004) and civil engineering (Schwieger et al. 2010). A detailed description of the latter model will follow elsewhere in this paper.",1
37,7,"In addition to the characteristics and parameters, a quality model should be complete according to the actual set of products or processes. All requirements should be represented by characteristics and parameters. Another desirable attribute of a quality model is its independence. The characteristics and parameters should not depend on each other and a parameter should not influence any other parameter. Furthermore the model should be applied to products as well as processes and this should be taken into account at both the parameter and characteristic levels. The parameters are quality measures which describe quality by means of parameter values. In Table 2 shows possible parameter types according to ISO/TS 19138 (ISO 2006).",1
37,8,"Taking into account the general structure of the quality model and possible parameter types, a complete quality model for engineering geodesy processes in civil engineering can now be developed.",1
37,9,"The process-related quality characteristics of expense, timeliness, process-correctness, resource and synchronization as well as their parameters are defined in relation to the construction plan and the contract. The first four characteristics refer to the total process and sub-processes, while the fifth characteristic of synchronization refers to the interaction among the sub-processes. It describes to which grade sub-processes that depend on each other, run in synchronization.",1
37,10,"The product-related quality characteristic of availability is defined as the overall quality characteristic that takes into account all other characteristics. The product-related quality characteristics of accuracy and product correctness, as well as the processrelated quality characteristic process of correctness, can be defined and measured by parameters using standards, generally recognized codes of practice and technical specifications written in the contract.",1
37,11,This quality model is application-related and fits the demands of small and medium enterprises. It does not consider the special needs of engineering geodesy. Moreover it does not show the possibility to consider parameters and to propagate them through processes. It is adapted to quality checks during the process of residential houses construction. These entire arguments mean that a more detailed quality model on the parameter level still has to be developed.,1
37,12,"The task of engineering geodesy is bringing the planned building geometry into reality. The geometry issues are very important for high rise buildings. So, one main focus regarding the quality of the geometry of a high rise building is engineering geodesy. To evaluate the quality of the geometry of a building, requirements first have to be defined. Quality characteristics and parameters can then be derived based on these requirements.",1
37,13,"One possibility for defining the requirements for the geometry of a building is to rely on standards such as the DIN standard 18202 (DIN 2005). Here, limit deviations for actual sizes are defined for geometric building components such as walls, foundations and floors. The size and shape of a building component and its location within a coordinate system are represented by nominal sizes in plans. The actual size is the real size of a building component. The relation between nominal side, actual size, actual deviation, limit deviation and tolerance is shown in Figure 3.",1
37,14,"Unlike the quality model for residential houses (Section 2.2), where the distinction between product and process quality is realized at the characteristic level (product- and process-orientated characteristics), here it is realized at the parameter level. The parameters ‘Adherence to the plan’. ‘Vulnerability to failures’ and ‘Time delay’ are exclusive processorientated parameters while the others are first and foremost product-oriented. In any case, a product parameter can also be derived to rate a process. This is the case if the product is the result of one sub-process only. A description of four key parameters is now presented in more detail.",1
37,15,"The quality parameters, described previously, are related to single products or processes. To describe the quality of several processes or finished products, an appropriate computational procedure to propagate the quality parameters through the process has to be described for each parameter. For two key parameters, standard deviation and tolerance correctness, the computational procedure is explained as follows.",1
37,16,"The standard deviation may be propagated through a process by the law of propagation of variances (propagation of errors) (Teunissen 2003) or by Monte Carlo Simulation (Binder 1979). The law of propagation of variances is a statistical method by which the impact of the measured values of various parameters on the final result is computed. The stochastic variables are dedicated to a distribution, usually the normal distribution.",1
37,17,"In this section an example is presented of an engineering geodesy process, integrated into the construction process including the resulting quality parameters. In the example, a stake out of the corner marks of a formwork with a total station on the foundations of a floor is shown (see Figure 5).",1
38,1,"Developing an expert system has been considered as complex and knowledge driven process. This study proposes a natureinspired metaheuristic regression system that can find appropriate solutions. The system uses a graphical user interface but does not require a mathematical program installation. The user-friendly interface was designed in the MATLAB graphical user interface design environment (GUIDE) and was implemented by MATLAB compiler. The stand-alone system is easy to use and has many functions, including evaluation, use of an opened data file, test set selection, hold-out, cross validation, and prediction to solve many civil engineering problems with simple manipulations on the system interface. Five benchmark functions were used to evaluate the effectiveness of the optimization module. The performance of the proposed regression system was then validated by comparing its solutions obtained for civil engineering problems with those obtained by empirical methods reported previously. Five actual data sets including energy-efficient buildings, construction material strength, concrete structure shear strength, bridge scour depth, and subbase soil modulus were used as case studies. The prediction accuracy was 8.24–91.76% better than those of previously reported models. ",1
38,2,"Artificial intelligence (AI) has been an active and dynamic field of research and development since 1956 (Cantu-Ortiz 2014). In the past decade, AI has been widely applied in civil engineering (CE) problems. Recently, AI has been used to model the complex behavior of many CE applications. Major AI methods include predictive modeling (supervised learning in machine learning, i.e., classification and regression problems), clustering and association, evolution, pattern matching, data visualization, and metarule guided mining (Liao et al. 2012).",1
38,3,"Specifically, prediction is the most popular data mining function, and AI has demonstrated superior predictive capability compared to conventional methods (Chou and Pham 2013; Mousavi et al. 2012; Platon et al. 2015). Many AI researchers have attempted to develop computer algorithms for performing data mining tasks (Ville 2001).",1
38,4,"In the AI field, support vector machine (SVM) is a well-known AI technique for analyzing a small sample of data based on the structural risk minimization principle in statistical learning theory. The objective of an SVM is to obtain the global optimum and to avoid the local optima. To achieve this task, nonlinear problems are linearly solved in a higher dimension comparing to its original dimensional feature space.",1
38,5,"This solution has been intensively studied because of its successful application in classification tasks, time series prediction (Quan et al. 2010), and especially on regression tasks (Paletal.2011). Support vector regression (SVR) is the most common use of SVMs in regression (Vapnik 1995). The SVR is typically used to solve nonlinear regression problems by constructing the input-output model and has proven highly effective in various prediction fields (Mohammadi et al. 2015; PengandLing2015; Suykens et al. 2002).",1
38,6,"The major drawback of SVR is its high computational burden because of the required constrained optimization programming (Wang and Hu 2005). One proposed solution is an algorithm called least squares SVR (LSSVR) (Suykens et al. 2002). LSSVR works with equality instead of inequality constraints and a sum of squared error cost function similar to the one used in a classical artificial neural network (ANN). It greatly simplifies the problem because its solution can be found by linearization, which increases the efficiency and simplicity of training the SVR.",1
38,7,"In recent years, the smart firefly algorithm–based LSSVR has proven effective in many civil engineering fields (Chou et al. 2015; Chou and Pham 2015). This approach integrates firefly algorithm (FA), chaos theory, adaptive inertia weight, Lévy flights, and LSSVR to construct a smart artificial firefly colony algorithmbased LSSVR model. This novel swarm intelligence model has superior computational efficiency and solution quality when used to solve forecasting problems in CE.",1
38,8,"Unfortunately, the complexity of implementing the AI techniques may hamper the potential extensive applications for civil engineers and construction managers. Trained practitioners are needed to apply the model with heavy manual operations. To be effective in realistic environments, reasoning systems must identify and implement effective actions. Although some AI techniques can be applied by using related software, those software programs may be expensive and difficult to learn. Additionally, most of them only include basic AI techniques without optimization feature.",1
38,9,"Therefore, the objective of this research is to develop a userfriendly interface by using the data analytics loop to solve the preceding problems with the proposed nature-inspired metaheuristic regression system. The system includes a smart firefly algorithm (SFA)–based least squares SVR (SFA-LSSVR) model. Furthermore, the SFA-LSSVR model integrated in the system was upgraded by improving the computing efficiency. The optimization approach used in the system was validated by using several classic benchmark functions. Besides, the optimized regression algorithm has shown excellent performance in various fields in the CE area (Chou et al. 2015; Chou and Pham 2015).",1
38,10,"In the system interface, the two main user functions are evaluation and prediction. The evaluation function gives the user four options for testing data (i.e., use opened data file: the opened data file is used for testing; select test set: another test set data is used for testing; hold-out: the opened data is divided to leaning data and test data; and cross validation: the opened data is divided via k-fold cross validation method). The system also includes the baseline least squares SVR without the smart firefly optimization algorithm. The performance of the proposed system is validated by performance comparisons with empirical methods and previous works via cross-validation algorithm and hypothesis testing. Experiments showed that the system can help solve many prediction issues in CE with high performance.",1
38,11,"The remainder of this paper is organized as described here. The following section introduces the study context by reviewing the related literature. The third section then elaborates all methodologies used to develop and implement the system and to validate its effectiveness. The fourth section describes development of the nature-inspired metaheuristic regression system in this study including system requirement and implementation, system architecture, and system interface design. The fifth section presents validation of system via benchmark functions and five case studies. Concluding remarks and research contributions are given in the final section.",1
38,12,The AI techniques are typically used to solve prediction and classification problems. The wide range of AI techniques and applications developed in recent years can often provide a competitive advantage when compared with other conventional approaches (Mousavi et al. 2012; Platon et al. 2015). Several AI techniques have been applied in energy management and construction engineering (Coelho and Mariani 2013; Mosa et al. 2013).,1
38,13,"Particularly, many nature-inspired metaheuristic optimization algorithms were developed in recent years. For instance, genetic algorithm (Goldberg 1989), particle swarm optimization (Kennedy and Eberhart 1995), differential evolution (Storn and Price 1997), artificial bee colony (Karaboga and Basturk 2007), teachinglearning-based optimization (Rao et al. 2011), and symbiotic organisms search (Cheng and Prayogo 2014) were introduced as novel approaches for efficiently solving optimization problems.",1
38,14,"Recently, SVR, a variation of support vector machine (SVM), has been widely used in forecasting and regression (Cherkassky and Ma 2004). Cheng et al. (2010) used a fast messy genetic algorithm to tune an SVR model for estimating the final cost of two construction projects. In a study by Li et al. (2009), an SVR for predicting the hourly cooling load of a building performed better than artificial neural network model. Moreover, Pal et al. (2011) proved that, for modeling pier scour, SVR was better than a four-empirical-relation model, a back propagation neural network model, and a generalized regression neural network model (Paletal.2011).",1
38,15,"An alternative method, least squares SVR (LSSVR), has also been used to minimize the sum of squared errors of training data sets while simultaneously minimizing the margin error (Van Gestel et al. 2001). Li et al. (2008) used LSSVR to forecast the weights of parts produced by injection molding (Li et al. 2008). Their study showed that, compared to the SVR and radial basis function neural network methods, the LSSVR is a very effective forecasting method.",1
38,16,"Although the SVR model has proven highly effective for solving prediction problems, the accuracy of the model depends on the parameters that are set in advance (Min and Lee 2005). Until now, however, no general rules have been established for determining suitable parameters (Cristianini and Shawe-Taylor 2000). Therefore, the determination of optimal parameters is a critical procedure in the SVR research fields.",1
38,17,"Many researchers have used optimization methods to identify the best SVR parameters. Their works show many advantages of these techniques (Gilan et al. 2012; Hong 2009; Yang et al. 2011). For example, Gilan et al. (2012) developed a hybrid SVR–particle swarm optimization model for predicting the compressive strength and rapid chloride penetration test results of concretes containing metakaolin (Gilan et al. 2012). In Li et al. (2013), the learningbased optimization is adopted to adjust the hyperparameters of a least squares support vector machine in order to build NOx emissions model of a 330-MW coal-fired boiler (Li et al. 2013).",1
38,18,"Recent research shows that the firefly algorithm (FA) is very efficient and can outperform other metaheuristic algorithms. The FA has proven better than other well-known algorithms such as PSO and GA (Pal et al. 2012). In a comparison of performance in feature selection, Banati and Bajaj (2011) showed that FA was faster and had better solution quality when compared with GAs, ant colony optimization, PSO, and bee colony algorithms. For solving civil engineering problems, the smart FA based least squares SVR model has superior computational efficiency and solution quality (Chou and Pham 2015).",1
38,19,"Although the many advantages of AI techniques are acknowledged, they are still difficult to implement effectively. For implementation in the real world, the expert system with a window or browser interface for the ease of use by practitioners is imperative (Leung 2009). Many user interfaces have been developed for the civil engineering domain.",1
38,20,"Zapata et al. (2013), for instance, proposed an interface to assist users (instructors, students, and professionals) in the search and selection of learning objects. Lin (2013) developed a web construction network–based interface management system sharing information and tracking efficiency. Senthilkumar et al. (2010) designed an interface management system to help users apply the dependency structure matrix method on large construction projects. For the proposed SFA-LSSVR, however, a user interface for regression prediction is still needed. Hence, this work intends to design a friendly use interface for this advanced method.",1
38,21,"The various methodologies used to develop the nature-inspired metaheuristic regression system are discussed in this section. These methodologies include the hybrid artificial intelligence model, the development tools that were used to design and implement the system, and performance evaluation methods for validation.",1
38,22,"The SVM developed by Vapnik (1995) has been widely used in classification and regression. The high learning capabilities of SVMs have been confirmed in many studies of the civil engineering field. The regression model of SVMs, i.e., SVR, is widely used to solve nonlinear regression problems when constructing the input/ output model.",1
39,1,"The cultivation of professional ability for undergraduate civil and construction engineering students is very important to help them meet the challenges that await them in the fast changing world. This paper presents a thorough study of practical training in the field of civil and construction engineering. Based upon an extensive literature review of the practical training curriculum worldwide, questionnaires were provided to contractors, educators and students in Taiwan to assess problems in traditional summer practical training courses for civil and construction engineering in Taiwan. At the outset of the study, it was thought that the lack of available jobs for students might be related solely to the economy but the findings indicated that the reasons were more complex ranging from concerns about liability for students working in construction sites to traditional cultural concerns about whether apprentices should be paid. The Delphi method was used to study the problems that were identified, relating to planning, execution, evaluation, and development of the existing practical training programs.",1
39,2,"One of the most important goals in engineering education is to cultivate professional ability Belcher 1995. Achieving this goal is a big challenge for engineering educators. Hence, civil and construction engineering education should include theoretical and professional knowledge, practical skill training, and macroscopic experience Hulse et al. 1985. Both theoretical and practical skills are, therefore, very important and should be included in curriculum planning.",1
39,3,"Practical training is a bridge between the student in the classroom and industry. By using the opportunity of practical training, students can realize and encounter first hand the problems of construction engineering. Students can combine the theory learned in universities with the experience gained through practical training Murphy et al. 1976. The gap between their undergraduate education and the practice of construction engineering can be shortened through the use of practical training Pitts et al. 1986. Practical training can streamline the training period of a new engineer who is interested in becoming a professional engineer. Therefore, the objective of this research is to investigate the mode and process of practical training for undergraduates in civil and construction engineering. The state-of-the-art of practical training programs Kaushik 1997; Pigg 1998; Farr et al. 1996; Koehn 2000 is reviewed in the first part of this paper. Questionnaires about practical training completed by contractors, educators, and students are then presented. The Delphi technique Linstone and Turoff 1975 is used to forecast outcomes. An improved practical training program based upon the findings is then proposed.",1
39,4,"A hypothesis is proposed in this study. The hypothesis is that the summer practical training is very important and necessary for civil and construction engineering undergraduates. In order to prove the hypothesis, questionnaires were developed and provided to contractors, educators and students based upon an extensive literature review of the practical training curriculum worldwide. The Delphi Technique was also used to prove the hypothesis. We tried to judge the appropriateness of the methodology. Major results are presented and discussed in this paper.",1
39,5,"In the first part of the paper, current summer training programs in civil and construction engineering education in Taiwan are reviewed. Questionnaires developed for the project are then presented. In the second part, the research procedure of the Delphi Technique and research results are discussed. A refined and improved summer practical training curriculum based upon the findings is proposed for civil and construction engineering education in Taiwan.",1
39,6,"In order to address the problems that exist in current summer training programs for civil and construction engineers, it was necessary first to identify and rank them through a series of practical questionnaires and to have input from all parties including contractors, educators and students, and professional groups. The questionnaires were developed based upon an extensive literature review of the current status of engineering education with practical training worldwide.",1
39,7,"In this study, two hundred first-class contractors from all parts of Taiwan were selected to answer the questionnaire. There were only twenty-five responses from contractors. The retrieval percentage is 12.5%. This may be due to the current depressed economy of our country and that contractors were not interested in the practical training of undergraduates because of lower levels of available construction work.",1
39,8,Department heads or professors in 25 departments of Construction or Civil Engineering were also invited to answer the questionnaire. There were 19 responses from the departments of construction or civil engineering from universities or institutes of technology. The retrieval percentage was 76%. It was seen that the heads or professors of departments of Civil Engineering were interested in the practical training.,1
39,9,Two sets of questionnaires were sent to students. The first questionnaire to seventy-five students was done before the summer practical training. The second questionnaire to sixty-nine students was done after the summer practical training.,1
39,10,"The opinions from heads and professors of departments of civil engineering are listed in Table 2. It is seen that although most of professors believe that practical training is necessary for students, only 5% of departments offered practical training programs. Practical training can help students understand how to apply the theory to practice. Practical training is helpful for students to find a job in the future. Practical training can increase students’ interest in civil engineering. However, Construction sites are dangerous. Departments of civil or construction engineering worried about the life safety of students.",1
39,11,"Table 1 lists the survey summary from contractors. It is seen that contractors agreed that practical training is required and students should have insurance. They also made very constructive suggestions. Constructors agreed that summer practical training is important and necessary. However, constructors worried about their profits. They did not have many extra resources for practical training during the economic crisis.",1
39,12,"The following questions about the implementation of practical training were discussed. The answers to the corresponding question are listed in Table 5. The main recommendation is that students should have injury insurance during the practical training and students should write reports on what they have learned. Buying insurance was not popular in Taiwan. From 1998, all automobile drivers were forced by government to buy accident insurance; then, all motorcycle drivers were forced to buy accident insurance from 1999. In order to protect students, Delphi group strongly suggests that students should have injury insurance during the practical training. Delphi group suggests that students should submit reports after training. Hence, school can realize the outcome of training.",1
39,13,The following questions about the developing problems of practical training were discussed. The answers to the corresponding question are listed in Table 7. It shows that an agreement that the summer practical training should be mandated within all the departments of construction engineering in our country is achieved. The practical training can help students understand how to apply theory to practical engineering. The Ministry of Education in Taiwan encourages all universities to demand students for practical training. The effects on practical training will become an index of academic accreditation. The Ministry of Education will provide much more financial support to those universities having good effects on practical training.,1
40,1,"Structure dynamic research is a hot field in civil engineering. It involves in many challenge topics, such as dynamic analysis and tests under earthquake, wind or other dynamic excitations. This paper introduces main dynamic researches in civil engineering in recent years, which will be classified into five aspects, especially for researches published in Science in China Series",1
40,2,"In recent years, civil engineering structures including high-rise building, long-span reticulated structure, bridge and dam develop very quickly with the fast development of economic. As known, strong earthquakes happen frequently in these years, such as Wenchuan earthquake in China and Haidi earthquake. Hurricane, tsunami etc. extreme disasters seem more and more with changes of climate of the earth. These disaster loads are the typical dynamic excitations for civil engineering structures. Many challenge topics on dynamic problems have been paid more attention by the world. The momentous research program in National Natural Science Fund is erected for these topics in China.",1
40,3,"Dynamic problems lie in civil engineering structures widely. Many issues including dynamic excitation field, numerical model, dynamic responses analysis, structural health monitoring, vibration resistance measures and vibration tests are still required to be explored actively by researchers.",1
40,4,"This study summarized key researches and pointed out the hot topics in this aspect. Li et al. [9] carried out study on fundamental modeling on benchmark structure for structural health monitoring. It was suggested that a more sophisticated 3-dimensional frame structure model should be adopted as the identification model, if intending to detect local member damages correctly. Xu et al. [10] studied the dynamic behavior and responses of multi-span bridges under the action of moving loads. Numerical results were presented with a focus on the dynamic impact of the coupling conditions between spans. It has been shown that the deflection on each span strongly depends upon its local coupling conditions, especially near the critical stiffness values. Xu et al. [11] proposed an integrated intelligent control strategy for building structures incorporated with magnetorheological dampers subjected to earthquake excitation. In this strategy, the time-delay problem was solved by a neural network and the control currents of magnetorheological dampers were determined quickly by a fuzzy controller.",1
41,1,"The need for civil engineers is growing rapidly. Highly complex, global problems require a diverse pool of engineers with a variety of skills, views, and leadership styles. Although the job market for civil engineers is predicted to grow substantially over the next decade, women currently comprise a small percentage of the civil engineering workforce and the percentage of women graduating from undergraduate civil engineering programs across the US has stagnated. In this paper, recent data are presented to provide a current, overall picture of the national presence of women in civil engineering. The data showed that, overall, ASCE membership is reflective of the national percentages of women in B.S. civil engineering (CE) programs and in CE practice. However, ASCE senior membership, including the rank of Fellow, has very few women and is not reflective of the percentage of women in the society. Recommendations are provided for the role of ASCE as a champion in the effort to increase the percentage and standing of women in ASCE and, thereby, in the CE profession.",1
41,2,"Civil engineers are needed to creatively solve problems associated with our crumbling and insufficient infrastructure, global climate change impacts, urbanization, natural resource depletion, and access to clean water.",1
41,3,"The Bureau of Labor Statistics (2012) reports that women account for only 9.7% of the CE workforce. Some progress has certainly been realized since the 1970s, when there were nearly zero women practicing CE; however, the lack of women in CE practice is still evident and far from satisfactory.",1
41,4,"In this paper, recent data are presented to provide a current, overall picture of the national presence of women in CE, as evidenced by the percentages in university programs, in CE practice, and in ASCE membership. ASCE is in an excellent position to take a proactive leadership position in championing the effort to increase the percentage and standing of women in ASCE and, thereby, in the CE profession.",1
41,5,"There are many reasons cited in the literature explaining why women have not populated engineering degrees or the engineering profession. To give a few examples, numerous authors have speculated that the engineering profession suffers from an image problem (Johnson et al. 1992; Hersh 2000; Isaacs 2001; May and Chubin 2003; Extraordinary Women Engineers Coalition 2005; Tietjen 2004; Widnall 2006; National Academy of Engineering 2008). Few precollege girls know what engineering is or what engineers do. According to Tietjen (2004), this problem can be at least partly attributed to the fact that everyone has interactions with doctors, dentists, and other professionals, but not typically with engineers. In addition, many television shows and movies are related to people working in legal, medical, and other professions. Engineers are rarely the topic of television shows and movies.",1
41,6,"In an attempt to provide a solution for the lack of gender and racial/ethnic diversity in the CE workforce, Hatch (2008) developed guidelines to create a more diverse workforce through understanding the importance of diversity and to create a climate in the workplace that is conducive to recruiting and retaining diversity. Hatch addresses the challenges of a diverse workforce, including communication, work/life balance, retirement, telecommuting, and religious needs, and the rewards of developing a “workplace for all.” Hatch’s work highlights and addresses the workplace issues identified in the study by Rayman and Stewart (1999) and those in a subsequent study, described in the following.",1
41,7,"The gap between women receiving degrees in engineering and the far smaller percentage of women in engineering practice has also been an area of concern. According to the US Bureau of Labor Statistics (2012) for 2010, women make up a small percentage of the engineering workforce. Table 1 provides the percentages of women in the CE discipline, along with several other engineering disciplines for comparison. Rayman and Stewart (1999) suggested that this gap indicates that the most serious problem may be the environment in the workplace. One possible area of concern is hiring practices. Rayman and Stewart postulate that companies may unconsciously determine the characteristics of an ideal candidate based on the pool of current employees in the company. They cited a study conducted by the National Society of Professional Engineers (NSPE), which found that CEOs and human resource professionals surveyed in small and midsized engineering firms believed that the primary barrier for women was the fact that they would leave the field prior to advancement for family responsibilities. However, statistics from the study showed that there was little difference between the number of years worked by males and females",1
41,8,"Based on a survey of 85 high school girls, the Extraordinary Women Engineers Coalition (2005) found that there is a disconnect between motivating factors for high school girls in selecting a career path and the message communicated by the engineering community. They found that high school girls emphasized the following factors: enjoying their work, having a good working environment, making a difference, earning a good income, and having flexibility. The message from the engineering community, on the other hand, indicates that engineering is challenging, is difficult but rewarding, and requires math and science to solve problems. None of these factors are motivators for the young women surveyed. This idea is echoed by Tietjen (2004), who theorized that women pursue professions in which they see value; if they do not know what engineers do, they cannot assess the value of their work. In addition, the engineering profession is sometimes viewed as the cause of environmental destruction, further hurting the image of engineering, particularly for women (Hersh 2000). The Extraordinary Women Engineers Project was developed in 2004 as a collaborative initiative between ASCE, American Association of Engineering Societies, and WGBH Educational Foundation.",1
41,9,"The need for improvements in the engineering workplace climate was also born out in a survey of 2,500 executive women currently working in science, engineering, and technology fields or who have worked in these fields at a management level (Servon and Visser 2011). This study sought to identify factors that discouraged women from participating in these fields. The authors found that the women in engineering fields (approximately 28% of the respondents) experienced sexual harassment (69%), were viewed as less capable (26%), perceived bias in performance evaluations (44%), and received unwanted attention due to their feminine appearance (32%). In addition, one third of the women reported feeling extremely isolated. Their recommendations based included: (1) adopting family friendly policies, (2) changing organizational culture, and (3) helping to promote the presence of women in higher positions to build a more supportive environment.",1
41,10,"In CE, the percentage of women in both universities and the profession increased significantly during the 1980s. In the early 1970s, the national percentage of women receiving degrees in CE began to rise from nearly zero to more than 1% of the total number of degrees. The percentage of women receiving B.S. degrees in the US in 1970 was 0.82%, and just four years later, in 1973, the percentage had doubled to 1.58% (Keith 1978). As an example of this rapid increase in women receiving B.S. degrees during and following this period, Fig. 1 shows the numbers of women granted B.S. degrees in CE at Penn State over the history of the department.",1
41,11,"The correlation between private schools and high percentages of women over all programs is not strong (correlation coefficient is approximately 0.31). However, some general characteristics of those schools that have 35% or more women can be determined and are summarized in Table 3.Fig.3 shows the distribution of the 28 schools with at least 35% women in the B.S. degree pool. The median graduating class size for those programs is 19.5, compared to the median class size of 43 for all programs. Thus, these are relatively small to moderately sized programs with between four and 72 graduates. Of the 28 schools, 22 (79%) are private and 86% are in or adjacent to urban areas. The prominence of Ph.D. programs within CE departments is an additional characteristic that differs between programs. More than half (16 out of 28, or 57%) of the programs also have Ph.D. programs in CE, all of which are at least 10% as large as the corresponding B.S. program in terms of degrees, ranging from 11 to 133% of the B.S. degrees. Six of those Ph.D. programs are at least 50% as large as the B.S. program in the same school. By comparison, nine of the 11 largest programs (in terms of B.S. degrees) have Ph.D. programs; however, they range from 4 to 14% of the number of B.S. graduates in the same year. ",1
41,12,"These characteristics may point to some considerations for university programs, companies, and professional societies in terms of getting women involved in challenging research and other CE problem solving, and in creating more intimate environments within otherwise large programs or companies.",1
41,13,"It shall be ASCE policy to encourage Section activity in the field of professional and paraprofessional job training, counseling and education for women; to work with other engineering organizations and with industry, private philanthropy and government, to increase the number of women graduates of engineering schools in the coming years; to support legal and moral requirements that discrimination in employment not be permitted and to urge all engineering employers and administrators to adopt affirmative action programs; and to invite women engineers to join ASCE and to participate as ASCE members and especially in policy-making positions in solving problems of exclusion as well as the general problems of the nation.",1
41,14,The committee determined that the same high standards should apply to both men and women so that female civil engineers could enjoy the same status and respect as their male counterparts (Keith 1978).,1
41,15,"The situation has certainly improved since 1976. There are now 16,265 female members in ASCE, including students. An examination of the membership in ASCE as of June 2012 highlighted some potential areas in need of improvement. Similar to the national data on the percentage of women graduating with civil and engineering B.S. degrees (20.5%), female student membership in ASCE currently comprises 19.5% of the total membership and the nonstudent population at ASCE is 9.4% women, compared with 9.7% in the national workforce data. However, the categories of nonstudent membership are highly skewed between men and women. In the category of Member, only 6.7% are women. The membership level of women is nearly equally divided between Associate Member and Member, in which 46% of the nonstudent women are Associate Members and 48% are Members. By contrast, the male nonstudent members are 19% Associate Members and 70% Members. The problem is worse at the Fellow grade. For this high level of achievement, only 1% of the current ASCE Fellows are women and 99% of the Fellows are men. Of all nonstudent ASCE members, 0.6% of the women are Fellows and 5.9% of the men are Fellows. ",1
41,16,"The need for civil engineers is growing rapidly. Not only does the profession need more qualified civil engineers, it needs a diverse pool of engineers to solve the vast array of highly complex, global problems that humanity faces now and in the future. With a mix of students, academics, and professionals from private industry and government agencies, ASCE is perfectly poised to champion the effort to increase diversity.",1
42,1,"The civil engineering capstone senior design course at Purdue University involves all seniors in their last semester before graduation and is titled “Civil Engineering Design Project.” The course catalog describes it as “Planning, design, and analysis of a civil project; an integrated and realistic group project involving as much as possible all major aspects of the civil engineering profession.” This highenrollment course (30–120 students per semester) has been team taught since the early 1960s and many approaches to teaching it have been utilized. Since 2001, the version of the course discussed in this paper has been taught in the spring semester with the student teams responding to a request for proposals (RFP) for local projects following the design-build method of project delivery. The proposals are submitted in two phases: (1) conceptual designs and alternatives analyses; and (2) design-build project proposal with approximately 30% complete design, total construction cost, and scheduling. The design-build proposal is the culminating activity in the course. Both phases have oral presentation components. Students are assigned to teams on the basis of factors that include overall grade point average, grades in key courses, work experience, computer software skills, and Meyers-Briggs typology. ",1
42,2,"The civil engineering capstone design course at Purdue University involves all seniors in their last semester before graduation and is titled “Civil Engineering Design Project.” The course catalog describes it as “Planning, design, and analysis of a civil project; an integrated and realistic group project involving as much as possible all major aspects of the civil engineering profession.” This highenrollment course (30–120 students per semester) has been team taught since the early 1960s, and there have been many approaches to teaching it. In its current form, the course carries three credits and has 50 min briefing sessions on Tuesday and Thursday mornings, followed by 2-h office sessions for the teams. All students enrolled in the course are required to attend all briefing sessions and the office hour sessions throughout the semester. Five teams share an office (classroom) that is staffed with an engineering manager.",1
42,3,"The engineering managers are typically civil engineering graduate student teaching assistants (TAs) but at times volunteer professionals from the community have filled that role. The course director (senior member of the faculty) is responsible for scheduling the content and speakers for each briefing session. Course instructional team members deliver several briefing sessions and act as consultants during the office sessions. In addition to the offices, the teams have access to a design lab with workstations, printers, plotters, and design reference materials; it is fully equipped with the modern software needed to execute the project.",1
42,4,"Since 2001, the course has been taught with the student teams responding to a request for proposals (RFP) for local projects following the design-build method of project delivery. The RFP is collectively prepared prior to the start of the course by the course director, instructors, teaching assistants, and typically the project owner. Drnevich (2005) provided a history and evolution of this course through 2004, which included a listing of people involved in developing it and of the projects completed. Students are assigned to teams based on many factors that contribute to a balanced team. Drnevich and Norris (2007) describe the process that makes use of an optimization model developed by Norris (2007) that is also used for forming MBA teams in the Krannert School of Management at Purdue. Team sizes for the civil engineering design project range from 5–8 students depending on overall course enrollments. There is a 15-team limit based on facilities and scheduling logistics.",1
42,5,"Once teams are defined, they are asked to develop an identity by generating logos, letterheads, drawing sheet title blocks, transmittal forms, and other relevant materials. No requirements are placed on the structure of the teams except that collaboration is required for the products to have continuity and consistency and be professional in both looks and substance.",1
42,6,"Starting in 2007, a module on project planning and management was introduced through a lecture and an assignment that requires each team to study the RFP and generate a written plan with a Gantt chart for meeting the requirements and deadlines of the RFP. After the teams complete the Phase 1 submissions and presentations in the second month of the semester, they are required to evaluate and revise their plans and Gantt charts as part of the Phase 2 submissions and presentations. This evaluation is aided by reviewing their time sheets. Detailed weekly time sheets, including individual and team hours, are submitted by each team. Project expenses, based on invoiced hours and associated billing rates, are used during the evaluation of the final deliverables.",1
42,7,"Individuals associated with the actual projects, including the owner and practitioners, are integrated into the course. In addition, recently retired local engineers commonly participate in the course as volunteers. For projects on the Purdue campus, a staff member of the office of the Purdue Architect typically presents an overall master plan for Purdue with emphasis on how the project for that semester fits into the plan. Additionally, the athletics director, the director of athletic facilities, and others such as the coaches for the sports facilities provide briefings and answer questions, when applicable. There is strong engagement from the design and construction group of the Purdue physical facilities. Engineers from local firms provide briefings on civil site development including utilities, LEED case studies, roadway and traffic ordinances, structural design, grading and drainage, construction estimating, bonding and finance, and methods of project delivery during a portion of the biweekly (Tuesday and Thursday) morning sessions.",1
42,8,"All calculations submitted are required to be independently checked and signed-off by another member of the team. Deadlines for submission are firm and realistic of professional practice conditions (e.g., 12:00 p.m. EST on mm/dd/yy in room G175 Civil Engineering). Late submittals are not accepted. (In the last 9 years, every team has met these deadlines.) All information including drawings, calculations, schedules, spreadsheets, etc., must be submitted electronically, typically in PDF, except for presentations submitted in Microsoft PowerPoint format. The teams also submit multiple hard copies of the proposal, including a set of drawings on 11 × 17 in: (280 × 432 mm) paper, and one copy of the design, cost, and scheduling calculations. Submission of multiple copies of the proposal allows for more efficient grading by the instructional team and also allows each member of the team to retain a copy of the completed product.",1
42,9,"Grading rubrics are collectively generated by the instructional team, and all deliverables are reviewed by at least three members of that instructional team. The rubrics associated with proposal deliverables include a detailed description of requirements related to elements such as formatting, grammar, and writing style. Comments are placed directly on the hard-copy products. After these reviews are completed, the instructional team then discusses the products of each team and comes to an agreement on an appropriate grade for every product. Although it is anticipated that individual members of a team address various components of the project based on their interests and/or background, all deliverables are considered to be group efforts. Accordingly, all members of a team receive a common grade. Adjustments are made to the written proposal grades for both phases, based on the peer evaluations discussed subsequently. Presentation grades are established on the basis of rubrics for both team and individual presentations. In addition to receiving grades on each deliverable, a comprehensive feedback report is developed for each of the two phases. Feedback is provided to all teams and is a collective summary of things done well and of things that need to be improved to bring the products up to professional quality.",1
42,10,"Peer evaluations, at an individual level, are conducted twice: once after Phase 1 submittals and presentations in the second month, and again after Phase 2 submittals and presentations at the end of the course. This anonymous process includes a self-assessment and individual assessment of team member performance. Group-earned grades are then adjusted for each member of the team based on the average peer evaluation. Thus, although grades are assigned for group deliverables, individual grades are adjusted based on peer evaluation. The peer evaluation process is discussed further by Drnevich and Norris (2007) and has been found to be very effective in promoting team work and early identification (and remediation) of team collaboration challenges or identifying issues in teams.",1
42,11,"Student assessment of the course is typically done twice during the semester, once after Phase 1 and once at the end of the course. They are in the form of web-based anonymous questionnaires. Additionally, the School of Civil Engineering conducts exit assessments and postgraduation assessments.",1
42,12,This paper describes the civil engineering capstone design course at Purdue University. It is taken by all senior civil engineering students in their last semester before graduation. The course is driven by RFPs and closely follows the types of activities done in the practice of civil engineering. The replication of realistic practice conditions is supported by involvement of engineering practitioners and professionals from the community.,1
42,13,"The authors gratefully acknowledge the many colleagues, practitioners, teaching assistants, and staff persons, all too numerous to mention, who have contributed to the success of this course over the years. Special recognition goes to the students who took the course and provided feedback to improve it.",1
43,1,"Recent natural events such as earthquakes in Japan and storm surge effects in New York have led to the growing interest in sustainable civil engineering. While sustainability topics, such as soil liquefaction and green building design, are typically included within civil engineering programs at the baccalaureate or graduate levels, topics in sustainability can be adapted for secondary school students as well. In addition, efforts to attract quality and diverse students into civil engineering have given rise to engineering camps aimed at secondary school students. This research focuses on the exploration of civil engineering sustainable module topics for secondary school students through the development of content as well as implementation of two case studies. Sustainability module topics are identified and instructional content (lesson objectives, key concepts, activities, experiments, and other pedagogical techniques) are proposed. Two modules are applied at the Bucknell Engineering Summer Camp program, targeting secondary school students. The module topics developed, as well as the case study results, can provide examples for how engineering educators throughout the country can introduce sustainable civil engineering as a way to encourage future civil engineering students.",1
43,2,"Recent natural events and global awareness have led to a rise in sustainability topics in the civil engineering curriculum. Events such as the earthquakes in New Zealand and Japan, storm surge effects in New York and New Orleans, along with the ongoing issue of global warming have inspired new developments in topics such as earthquake engineering, soil liquefaction, and green building. As new concepts in sustainability evolve and develop, specifically within undergraduate and graduate curricula, the opportunity arises to introduce secondary school (high school) students to these new developments as a way to attract and engage high quality, diverse students into civil engineering. While traditional civil engineering design topics have been used, adapting current and innovative topics using hands-on, real world, problem-based lessons, specifically for secondary school students, can increase awareness and interest in the field of civil engineering (Kevern 2011).",1
43,3,"Currently, Bucknell Univ. offers a 1-week summer engineering camp for secondary school students. The camp participants are introduced to engineering through a series of lessons and hands-on exercises taught by a wide range of engineering faculty. The camp provides the opportunity for new civil engineering modules to be developed, implemented, and evaluated by secondary school students each year.",1
43,4,"This research explores the ability to develop, implement, and evaluate sustainable module topics spanning all subdisciplines of civil engineering such as water conservation, environmental impact assessment, and sustainable construction. Development of these module topics can provide a foundation for how to integrate sustainability at the secondary school level in order to encourage and inspire future engineering students. In order to determine the applicability and effectiveness of teaching these topics, two case study modules have been developed in full (Introduction to Sustainability and Introduction to Earthquake and Liquefaction) and have been implemented in the camp. The results of the case studies as well as the list of sustainable module topics and instructional content can serve as the foundation for how engineering educators can integrate sustainability into secondary school education programs.",1
43,5,"Based on the knowledge that effective engineering modules using contemporary sustainability topics can be beneficial in attracting students to engineering (Al-Tamimi et al. 2011), sustainability modules were developed and assessed based on specific learning objectives. These learning objectives, described later in detail, serve as the basis for the organization and implementation of the module. Through the completion of the sustainability module, students should have knowledge of basic principles, perform experiment/ activities demonstrating their knowledge, and understand the context for real world implementation.",1
43,6,"Much has been written regarding successful pedagogical techniques; specifically, the benefits of active learning are generally well recognized and accepted (Felder et al. 2011). While precise definitions may vary, active learning is a technique by which students are engaged in the learning process by doing meaningful learning activities (Bonwell and Eison 1991). A review and analysis of the literature reveals considerable support for the core elements of active learning (Prince 2004). Active learning improves the recall of information with the accompanying benefits of student engagement such as clarifying student misconceptions and improving conception understanding. It is also clear from Prince’s analysis of the literature that collaboration enhances student retention, student attitudes, and academic achievement. With this in mind, sustainability modules developed in this study incorporate both active and collaborative learning processes as well as traditional instructional methods.",1
43,7,"This section includes a review of previous literature on the connection between sustainability and civil engineering as well as pedagogical techniques that can be used for secondary school instruction. In addition, a brief background on secondary school student engagement is provided, specifically focusing on engineering camp programs.",1
43,8,"Interest in sustainability continues to rise as local, national, and global events strive to bring insight to the issue of human impact on the natural environment (Litman 2006). Storm surge events along the East and Gulf Coasts of the U.S., rising sea levels, depletion of natural resources, and population growth are indicators that a sustainability movement, particularly with regards to reducing the anthropogenic influence, is needed. Since sustainability is often defined as “meeting the needs of the present without compromising future generations to meet their own needs” [World Commission on Environment and Development (WCED) 1987], secondary school students are the generation that will need to innovate, plan, and develop in ways that reduce negative impacts on the environment, society and economy.",1
43,9,"Sustainability is more than simply protecting the environment. Civil engineers of today, and especially the future, will have to design and build in a way that addresses all three pillars of sustainability, that is, the economy, environment, and society (ASCE 2012). This model, referred to as the triple bottom line of sustainability, suggests an equal balance of all three components by reducing environmental, economic, and social impacts. Therefore, engaging future engineers in this effort and attracting them to the field of civil engineering is vital, as they will be the next designers, contractors, and tradesmen.",1
43,10,"Much has been written regarding successful pedagogical techniques; specifically, the benefits of active learning are generally well recognized and accepted (Felder et al. 2011). While precise definitions may vary, active learning is a technique by which students are engaged in the learning process by doing meaningful learning activities (Bonwell and Eison 1991). A review and analysis of the literature reveals considerable support for the core elements of active learning (Prince 2004). Active learning improves the recall of information with the accompanying benefits of student engagement such as clarifying student misconceptions and improving conception understanding. It is also clear from Prince’s analysis of the literature that collaboration enhances student retention, student attitudes, and academic achievement. With this in mind, sustainability modules developed in this study incorporate both active and collaborative learning processes as well as traditional instructional methods.",1
43,11,"Studies have shown that summer education programs focused on engineering influence secondary school student interests in pursuing engineering degrees in higher education (Qiao et al. 2012). With the opportunity to introduce high school students to engineering concepts through real world design challenges, hands-on experiments, and team building projects, engineering camp programs can cultivate and inspire the next generation of engineers. Although data on the number of K-12 students exposed to engineering curricula is not well documented, studies have shown that there is an increased interest in the field as a result of exposure prior to college (Katehi et al. 2009). These programs are being implemented across the country and continue to attract interested students of all backgrounds, including women and minority students.",1
43,12,"Bucknell Univ. holds an annual 1-week intensive summer program focused on engineering education for high school students. Approximately 100 students per year participate in the program where they are taught by Bucknell Univ. faculty on topics spanning a diversity of engineering fields (mechanical, civil, chemical, electrical, biomedical, and computer science). Faculty members teach a topic based on their area of expertise for a typical 90-min module of approximately 25 students per lesson. The active learning techniques are incorporated into each module in order to maximize student learning and interest. The engineering camp provides the opportunity not only to introduce students to the field of engineering, but also to spark interest in the field of civil engineering through the use of sustainability modules.",1
43,13,"In order to determine the applicability of the sustainable module topics and instructional content, two of these topics (#1: Introduction to Sustainability and #2: Introduction to Earthquakes and Liquefaction) are fully developed and implemented as case studies at the Bucknell Univ. Summer Camp. The effectiveness and relevance of the instructional content for high school students is evaluated based on indirect assessment methods.",1
43,14,"In order to assess the applicability and relevance of sustainability modules to secondary school students, two case study modules were selected for full development and implementation at the Bucknell Univ. Engineering Summer Camp program. The two modules selected include Introduction to Sustainability (#1) and Introduction to Earthquakes and Liquefaction (#2). The modules are based on the structure of 90-min lessons of approximately 25 students. Both of these case studies are explored in-depth based on the process of developing the lesson materials (objectives, implementation techniques, and activities) as well as module evaluation.",1
43,15,"The following section describes the development and implementation of the Introduction to Sustainability module as it was applied to the Bucknell Engineering Summer Camp. The module was developed in 2011 and then implemented three times during the 2011, 2012, and 2013 camp programs (approximately 50 students per year participated in the module). The module was developed for the purpose of exposing sustainability concepts and activities to secondary school students interested in engineering. With rising issues related to anthropogenic impacts on the environment, pressure will be placed on future engineers to prepare, protect, and renew the natural and built environment.",1
43,16,"The module began with a warm-up activity that requires the students to work in teams of five students. The students were given a series of objects (wooden spoon, cloth bag, shoe, belt, plastic cup, and a dishtowel) so that each group had one object. The students were given 5 min to invent five appropriate uses for the object, other than its original use. For example, the plastic cup can be used as a flowerpot, or the cloth bag can be made into a pillow. Through the process of identifying other uses, the students have to be creative, which is the foundation for innovative, sustainable, systems-based thinking. The students reported their top three answers to the class and justified their thoughts.",1
43,17,"Step 2 focused on developing real world, hands-on, problembased activities that required the students to demonstrate critical thinking and communication skills. Activities such as calculating their ecological footprint as well as drawing concept maps of exemplary green design projects were developed and adapted for implementation within the 90-min time period as well as for a class size of about 25 students.",1
43,18,"The last portion of the module is devoted toward applying engineering design principles to address sustainability. Green design is discussed as one tool used to integrate sustainable techniques into engineering. The USGBC (United States Green Building Council) and its widely used Leadership in Energy and Environmental Design (LEED) rating system is discussed on a broad scale in terms of creating a standard for how engineers can begin to reduce environmental, economic and societal impacts (USGBC 2013). The purpose, as well as the process, for how projects become LEED certified is discussed in detail. Following the discussion, students were divided into six teams and information packets on exemplary projects, consisting of a project summary and related news articles from the Internet, were distributed. The projects selected for the case studies were the Exelon Building, Nationals Park Stadium, Chipotle Restaurant, Vista Dunes Development, Clearview Elementary, and Twinbrook Station. These six projects range in project type (e.g., new construction, neighborhood development, school, homes), as well as were identified as profile projects by the USGBC (2013).",1
43,19,"The students were given 30 min to read through the materials and identify the key design components that were used in the project and classify them as either economic, environmental, or societal benefits (or a combination). The students created Venn diagrams and organized the design components into these three components of the triple bottom line. The students then presented their findings to the class and shared background about why the project is exemplary.",1
43,20,"The following section describes the development and implementation of the Introduction to Earthquakes and Liquefaction module as the module was applied to the Bucknell Engineering Summer Camp. The module was first developed in 2011 and implemented three times during the 2011, 2012, and 2013 camp programs (same instructor all 3 years).",1
43,21,"Researchers at Bucknell Univ. are part of a team with researchers from Stanford Univ. and Arizona State Univ. investigating the post-liquefaction shear strength and structure of sands. It is hypothesized that the liquefaction and the resedimentation process results in a soil structure that is amenable to reliquefaction under subsequent earthquake events. In seeking funding from the National Science Foundation, the module was proposed to develop learning modules for two demographic groups. The work for the first group, secondary students, is included in this research. The second group, upper level undergraduates and graduate students, will be the subject of future research efforts. While the module is centered upon a small-scale shake table and liquefaction, several other instructional components of the module were developed and employed to illustrate the principles as described below.",1
43,22,"During this portion of the module, soil properties including density, porosity, and void ratio were discussed both in general and in how they relate to liquefaction during an earthquake. Also, students were introduced to the particulate nature of granular soil, which consequently made it easier for them to understand concepts of porosity and void ratio. Prior to the experiment, the students were asked to define porosity and void ratio. Some students could relate porosity to the volume of voids with respect to the total volume. The fluidized bed was used to demonstrate porosity and some students were able to correctly predict what would happen if air was blown from the bottom of the cylinder filled with dry sand. Students were also asked to identify the reason for the increase in volume once the sample was permeated upward with air. Students were then prompted to identify methods to density the soil. With the help of the instructor, methods such as blowing air in a different direction, creating a vacuum through the bottom of the cylinder, applying stress to the surface of the specimen, and shaking the soil specimen were identified. The question and answer sessions during the experiment stimulated discussions and helped students understand the concepts.",1
43,23,"After the fluidized bed experiment, the concept of effective stress was discussed. The students were able to understand the effect of pore pressure (water or air) on effective stress. The analogy of a person standing in a pool in different water depths was used and proved to be useful in students’ understanding the changes that occur in effective stress of a soil specimen in presence of water. Effort was also taken to ensure students recognized that the effective stress in a dry soil sample is equal to the total stress while the effective stress during liquefaction (where there are no intergranular stresses) is zero. Students also gained an understanding of why the soil became denser after liquefaction and why ponded water occurred on the top of the liquefied soil surface.",1
43,24,"As a final step during this phase of the module, students participated in a gauntlet experiment that helped them understand the movements of individual sand grains and performance of the miniature penetration test. This involved students simulating individual soil particles in a corridor in different arrangements (denser and looser) and asking a student to walk through their fellow students. The student then had to relate the resistance experienced by the student moving through the crowd to how the soil property of density related to liquefaction. The students enjoyed the experiment and were able to understand its purpose.",1
44,1,"This report carefully examined the scientific productivity of chemical engineering, civil engineering and mechanical engineering professionals in Taiwan in 2008 by analyzing the authorship for all journal papers listed in the ISI Web of Science from chemical engineering, mechanical engineering, and civil engineering related departments and institutes in Taiwan. The result from analysis of the authorship data still follows a general trend of scientific productivity studied for the three disciplines.",1
44,2,"Fronczak et al. (2007) recently analyzed the scientific productivity of more than three millions of authors listed in the INSPEC database in the period of 1969–2004. They also found that the power-law model, N(x)  xg, described well on their data retrieved from the INSPEC database. This power-law distribution function is also known as the Pareto distribution. As a result, they reported two exponents, g = 1.67  0.01 and g = 2.87  0.03, for those with publication numbers less than 20, and larger than 100, respectively. That is, two different power-law scaling regions with two different exponents exist for junior and senior scientists. Besides, the distribution could be also partly fit well with the lognormal distribution function, which could account for the papers written by the long-life scientists. Interestingly, Fronczak et al. (2007) concluded that the degree of the scientific productivity of researchers at different generations for a given seniority remains approximately the same.",1
44,3,"Cheng and Chen (2007) analyzed the scientific productivity of Year 2006 of chemical engineering professionals in Taiwan with information retrieved from the database of the ISI Web of Science. Cheng and Chen (2007) noted that the distribution between the number of authors from chemical engineering professionals with x publications, N(x), in Year 2006 could be fit well with N(x) = 1320x2.22. These authors revealed that the number of publication x and the number of faculty authors F(x) followed F(x)  257.5x1.64. The smaller exponent, 1.64, indicates that the correlation between the scientific productivity and the number of faculty authors behaves more like that for the junior scientists by Fronczak et al. (2007).",1
44,4,"This report examined the scientific productivity of chemical engineering, civil engineering and mechanical engineering professionals in Taiwan in 2008 by analyzing the authorship for all journal papers listed in the ISI Web of Science.",1
44,5,"The scientific productivity of the Year 2006 of chemical engineering, civil engineering, and mechanical engineering professionals in Taiwan was obtained by conducting a thorough search using the database, ISI Web of Science (Copyright@2009 The Thomson Corp. and http://isiwebofknowledge.com). The search criteria was set as ‘‘AD = (Taiwan AND (Chem Engn))’’ and ‘‘Pub Yr = 2008’’, ‘‘AD = (Taiwan AND (Mech Engn))’’ and ‘‘Pub Yr = 2008’’, and ‘‘AD = (Taiwan AND (Civil Engn))’’ and ‘‘Pub Yr = 2008’’. A subsequent careful examination on authorship information of all papers retrieved from the ISI Web of Science was performed labor-intensively in a way of paper by paper to guarantee all information found within our scope, i.e., all contributed with at least one domestic chemical engineering professional. For example, a paper that was authored by a nonchemical engineer of Taiwan and a chemical engineer affiliated with any institute located outside Taiwan will be excluded from our data.",1
44,6,"With a further analysis on the authorship of these identified articles 237, 433 and 163 corresponding authors from domestic chemical, civil or mechanical engineering institutes and 256, 253 and 144 from foreign corresponding authors.",1
44,7,"This work examined the papers published in 2008, cited in ISI Web of Science database, authored by chemical engineering, civil engineering, and mechanical engineering professionals in Taiwan. 802, 278 and 968 papers were authored with 237, 163 and 433 corresponding authors from domestic chemical, civil or mechanical engineering institutes. Half of publications were produced by a few leading domestic institutes. The number of corresponding authors who are anyone of the domestic chemical, civil or mechanical engineering institutes with x publications, C(x), could be fit well with a power-law function of x publications with the same exponent of 2.16  0.08.",1
45,1,"Over the last 30 years or so, human beings have been delegating the work of culture – the sorting, classifying and hierarchizing of people, places, objects and ideas increasingly to computational processes. Such a shift significantly alters how the category culture has long been practiced, experienced and understood, giving rise to what, following Alexander Galloway, I am calling ‘algorithmic culture’. The purpose of this essay is to trace some of the conceptual conditions out of which algorithmic culture has emerged and, in doing so, to offer a preliminary treatment on what it is. In the vein of Raymond Williams’ Keywords, I single out three terms whose bearing on the meaning of the word culture seems to have been unusually strong during the period in question: information, crowd and algorithm. My claim is that the offloading of cultural work onto computers, databases and other types of digital technologies has prompted a reshuffling of some of the words most closely associated with culture, giving rise to new senses of the term that may be experientially available but have yet to be well named, documented or recorded. This essay, though largely historical, concludes by connecting the dots critically to the present day. ",1
45,2,"Author Mark R Probst first brought the issue to widespread attention when, on Good Friday, he noticed that several gay romance books had lost their Amazon sales rankings, including his own novel, The Filly. Hoping the matter was a simple mistake, he wrote to Amazon customer service. The agent who emailed Probst explained that Amazon had a policy of filtering ‘adult’ material out of most product listings. Incensed, Probst (2009) posted an account of the incident on his blog in the wee hours of Easter Sunday morning, pointing out inconsistencies in the retailer’s policy. The story was subsequently picked up by major news outlets, who traced incidences of gay and lesbian titles disappearing from Amazon’s main product list back to February 2009 (Lavallee, 2009; see also Kellog, 2009; Rich, 2009).",1
45,3,"In a press release issued on Monday afternoon, a spokesperson for Amazon attributed the fiasco to ‘an embarrassing and ham-fisted cataloging error’. More than 57,000 books had been affected in all, including not only those with gay and lesbian themes but also titles appearing under the headings ‘Health, Mind, Body, Reproductive and Sexual Medicine, and Erotica’ (quoted in James, 2009a; see also Rich, 2009). An Amazon technician working in France reportedly altered the value of a single database attribute – ‘adult’ – from false to true. The change then spread globally throughout the retailer’s network of online product catalogs, de-listing any books that had been tagged with the corresponding metadata (James, 2009b). This was not homophobia, Amazon insisted, but a slip-up resulting from human error amplified by the affordances of a technical system.",1
45,4,"In the wake of the controversy, author and lesbian, gay, bisexual and transgender (LGBT) activist Larry Kramer observed: ‘We have to now keep a more diligent eye on Amazon and how they handle the world’s cultural heritage’ (quoted in Rich, 2009). Indeed, Amazon may have started as a retailer, but it has grown into an exemplar of the many ways human beings have been delegating the work of culture – the sorting, classifying and hierarchizing of people, places, objects and ideas – to data-intensive computational processes.1 Amazon’s back-end data infrastructure is so vast, in fact, that in 2006 it began selling excess capacity to clients under the name Amazon Web Services. It also collects sensitive data about how people read through its Kindle e-book devices – which is to say nothing of how it profiles and then markets products to customers based on their browsing and purchasing patterns (Striphas, 2010). What one sees in Amazon, and in its kin Google, Facebook, Twitter, Netflix and many others, is the enfolding of human thought, conduct, organization and expression into the logic of big data and large-scale computation, a move that alters how the category culture has long been practiced, experienced and understood. This is the phenomenon I am calling, following Alexander R Galloway (2006), ‘algorithmic culture’.",1
45,5,"While this essay combines elements of these approaches, it is inspired primarily by Raymond Williams’ (1983) work on keywords. This piece emphasizes moments of catachresis – instances of lexical ‘misuse’ that help concretize an alternative semantics for particular words and word clusters. These moments enable new or at least different ways of figuring reality through language, for example, in drawing what was long taken to be the conceptual sine qua non of qualitative human experience – culture – into the orbit of computational data processing (see, e.g. Kittler, 2006). It is a contention of this essay that the semantic dimensions of algorithmic culture (and also then of the related phenomena of big data, data mining and analytics, the themes of this special issue of European Journal of Cultural Studies) are at least as important as the technological ones, the latter, for perhaps obvious reasons, tending to command the spotlight. But as Williams (1983) noted, ‘some important social and historical processes occur within language’, giving rise to new existential territories that only later come to be populated by technical artifacts (p. 22; see also Striphas, 2014).",1
45,6,"Moreover, a keywords approach is useful in apprehending latencies of sense and meaning that persist, insist and subsist in contemporary usage as ‘traces without ... an inventory’ (Gramsci, 1971: 324; see also Seigworth, 2000: 237). Logging that inventory, as it were, allows one to not only situate algorithmic culture within a longer durée but also reflect on claims to objectivity and egalitarianism that are now made in its name. Beyond semantics, what is at stake in algorithmic culture is the gradual abandonment of culture’s publicness and thus the emergence of a new breed of elite culture purporting to be its opposite.",1
45,7,"Gary Hall (2002) opens the final section of Culture in Bits with the line, ‘what if Richard Hoggart had had email?’ (p. 126). This is tantamount to asking, ‘what would the work of cultural studies’ canonical figures look like were it composed today, a time of ubiquitous digital computational technologies?’ Imagine, say, Raymond Williams (1958) were writing Culture and Society having to confront the #AmazonFail episode. How might he make sense of the entwining of culture, which he posited as a ‘court of human appeal’ (Williams, 1958: viii), and computational decision-making (see also Hallinan and Striphas, 2014)?",1
45,8,"Spanning the years 1780–1950, Culture and Society is bookended by two major historical events, namely, the industrial revolution and the end of the Second World War. The latter helped precipitate another great transformation referred to variously as the computer revolution, the communications revolution, the cybernetics revolution and so on (Beniger, 1986: 4–5). Prescient as he was, it is doubtful Williams grasped the full significance of his endpoint. More likely, he chose 1950 because the date marked midcentury, the moment in which the symbolics of history and futurity mingle more or less freely. Still, one can see Williams (1958) grasping to understand new technological contexts in his reflections on communication appearing in the conclusion to Culture and Society (pp. 296, 300–304, 313–319). It was not until the publication of The Sociology of Culture, however, that Williams (1981) broached the relationship between culture, information and digital technologies – but then only in passing, in the work’s conclusion (pp. 231–232).3 He may not have been able to work out a fully revised theory of culture per se, but he managed to lay important groundwork for assessing how the semantic – and hence practical and experiential – coordinates of culture had shifted since 1950.",1
45,9,"When information enters the English language sometime around the 12th or 13th century CE, chiefly from Latin, the tension at the heart of the word is already becoming manifest. At this early stage, it operates in two main semantic registers: religion and law. The use that the OED claims is ‘now rare’ is the religious one, although it might be more apt to describe it as spiritual, even deific. Here, information denotes ‘the giving of form or essential character to something; the act of imbuing with a particular quality; animation’ (‘Information’, n., n.d.). This definition posits an irreducible connection between the shaping of something and the endowment with character, substance or life.",1
45,10,"The influence of early modern empiricism and idealism on the word information must not be underestimated. The definition to which I referred in passing, ‘knowledge communicated concerning some particular fact, subject, or event’, is indicative of the term’s encounter with these crosscurrents of early modern thought, for it posits information not as intrinsic quality or character but as extrinsic sense data. This bit of semantic drift is significant, underscoring how far the locus of information has shifted from pre-modern through early modern times and beyond. Although it continued to refer to a kind of existential work, divine or worldly, gradually, a more object-oriented definition sidelined this sense of the word.",1
45,11,"The etymology of the word crowd is, like that of information, a study in polarity reversal. It entered the English language around the 15th century CE as an adaptation of verbs extant in Dutch, German and Frisian denoting pressuring or pushing. The English verb form ‘to crowd’ preserves this early meaning of the word, although in some contexts the element of physical force may be figurative rather than literal. The OED mentions that crowd was ‘comparatively rare down to 1600’, which means its rise roughly coincides with early modernity (‘Crowd’, n.d.). The noun form of the word has often been used interchangeably with mass, mob, multitude and throng to refer to large gatherings of people, generally in public, especially in urban settings. Frequently, it denotes impedance, inefficiency and frustration, as in the expressions ‘fighting the crowds’ and ‘three’s a crowd’. It also conveys individual anonymity and engaged inaction, as in the phrase, ‘a crowd of onlookers’.6 For these reasons crowd has, until recently, harbored almost exclusively pejorative connotations.",1
45,12,"But Mackay does not only play to the conventional wisdom – he also plays upon it. Preceding his statement about ‘thinking in herds’ is a passing reference to an analogous concept: the ‘popular mind’ (Mackay, 2001 [1841]: x). Terminologically, it is a small difference, but semantically it is a bait-and-switch. The verb phrase ‘thinking in herds’ would seem to designate an active, living process, albeit one in which any individual contribution registers diffusely. The noun form ‘popular mind’ largely elides that process, positing some overarching thing referring to everyone in general and no one in particular. And in this way, crowd’s etymology closely parallels that of information, which follows the term’s divestiture from the human body, its transformation into an immaterial object and its dispersal into the world.",1
45,13,"Mysterious, ghostlike, the ‘invisible hand’ is essentially a deus ex machina of economic activity, and in this regard it is not too far removed from the spiritual sense of information mentioned earlier. In the 20th century, Friedrich A Hayek would make the link more explicit, helping to bolster the more affirmative view of crowds nascent in both Smith and Le Bon. The key work here is Hayek’s (2007 [1944]) Road to Serfdom, published in 1944, arguably the strong state’s high-water mark in both Europe and the United States. Hayek believed there ought to be some force to which was assigned the task of holding the state in check; for him, that force was the economic sphere. Hence, his desire to strip the state of the responsibility of economic planning and to leave the task of coordinating economic activities up to individual actors dispersed far and wide (Hayek, 2007 [1944]: 232). Instead of positing that coordination resulted from the arcane workings of an invisible hand, Hayek stressed the crucial role that information – his word – played in choreographing this intricate group dance, particularly through the price system (Hayek, 2007 [1944]: 95).",1
45,14,"It is this set of positive connotations that crystallizes into contemporary terms like ‘crowdsourcing’, ‘crowd wisdom’ and a host of cognates, all of which have entered popular usage over the last two decades or so: ‘hive mind’, ‘collective intelligence’, ‘smart mobs’, ‘group genius’ and more (see, for example, Howe, 2008; Jenkins, 2006; Kelly, 1995; Levy, 1999; Rheingold, 2002; Sawyer, 2007; Shirky, 2008; Surowiecki, 2004; Tapscott and Williams, 2006). The translation between then and now is hardly perfect, owing to the diverse traditions out of which this vision of crowds has emerged, which is to say nothing of the technological transformations that have occurred over the last century. Indeed, when Williams (1958) wrote about the ‘solidarity’ necessary to sustain a ‘common culture’ (pp. 332–338), could he have anticipated the degree to which, today, that solidarity would be forged computationally? And what then to make of the redemption of crowds, when proprietary computer platforms have become the major hubs for interaction online?",1
45,15,"In a word, information. The touchstones in this regard are two landmark papers, both written by engineers who worked at Bell Laboratories in the United States. The first, Ralph Hartley’s ‘Transmission of Information’, appeared in 1928. The second, Claude E Shannon’s ‘Mathematical Theory of Communication’, appeared in 1948. Hartley’s paper was noteworthy for many reasons, chiefly technical, but perhaps his most audacious move was to subsume communication under the rubric of information. He states, ‘In any given communication the sender mentally selects a particular symbol ... As the selections proceed more and more possible symbol sequences are eliminated, and we say that the information becomes more precise’ (Hartley, 1928: 536). Hartley thus conceived of communication as a procedural activity – a game of chance in which the stake was information, or the likelihood of achieving identity of message within and across a specific context of interaction. He was followed in his work by Shannon, who raised the stakes on Hartley’s theory.",1
45,16,"It is worth mentioning that Shannon was not just a talented electrical engineer, he was also a world-class cryptographer, having worked on several government-sponsored ‘secrecy’ projects at Bell Labs throughout the Second World War. During that time, he produced a lesser-known paper, originally classified, entitled ‘A Mathematical Theory of Cryptography’ (Shannon, 1945). Shannon operated, in other words, at the junction point of algorithms and algorisms. Or, as he described his work on communication and cryptography many years later, ‘they were so close together you couldn’t separate them’ (quoted in Kahn, 1967: 744; see also Gleick, 2011: 216–218). Indeed for Shannon, communication in the ordinary sense of the term was nothing other than a special, simpler case of cryptography, or of ciphering and deciphering. Both in his view consisted of signals and noise stuck in a dizzying, entropic dance, along with telling redundancies that, if exploited using the right mathematics, could mitigate much of the turmoil and thereby point the way toward order (Rheingold, 1985: 119). What Shannon was essentially proposing in his work, then, was the use of algorithms to attenuate algorisms.",1
46,1,Blood culture bottles are superior to conventional media for vitreous culture in clinically suspected infectious endophthalmitis. Vitreous culture using blood culture bottles should be recommended as the primary method for microbiological diagnosis. A combination of both methods further improves the positive culture yield.,1
46,2,"This study follows the tenets of Declaration of Helsinki and was approved by the Khon Kaen University Ethics Committee for Human Research (HE551093). All patients with the diagnosis of clinically suspected endophthalmitis at the KKU Eye Center, Khon Kaen University, from 2008 to 2014 were recruited for the study. Inclusion criteria were those who had best-corrected visual acuity of 6/15 or worse, clinical findings of endophthalmitis no longer than 3 weeks and history of prior intraocular injury or surgery no longer than 6 weeks. Exclusion criteria included those who had a history of uveitis or were using eyedrops, which might interfere with the culture results within 1 week.",1
46,3,"In all patients, undiluted vitreous specimens were obtained by aspiration through a 23-gauge needle at the start of a vitrectomy procedure. The vitreous specimens were inoculated in both BCB and conventional culture media (CCM). The BCB used were VersaTrekREDOX1 80 mL with Stir Bar (TREK Diagnostics, Cleveland, OH, USA), and the CCM were composed of blood agar, MacConkey agar, chocolate agar, Sabouraud dextrose agar and thioglycolate broth. Within 30 min, both BCB and CCM were sent to the Clinical Microbiology Laboratory where they were further inoculated, incubated and examined for growth. Any organisms were identified.",1
46,4,"The primary outcome was the numbers of positive culture yields in each media method. Positive culture yields in both BCB and CCM were compared and analysed. The secondary outcomes were types of infectious endophthalmitis and causative organisms. Statistical analysis was performed using SPSS for Windows version 16.0 (SPSS Inc., Chicago, IL, USA). The collected data were analysed using McNemar χ2-test and an odds ratio with 95% confidence intervals. The difference was considered significant when the P value was <0.05.",1
46,5,The vitreous specimens were processed for microbiological investigations. They were inoculated in both BCB and CCM. There were 151 eyes (49.5%) having positive cultures in either BCB or CCM or both methods.,1
46,6,"There were 136 eyes (90.1% of 151 eyes) having positive cultures in BCB, whereas 99 eyes (65.56% of 151 eyes) yielded positive cultures in CCM. These findings were different with a statistical significance (P < 0.00001). The BCB method yielded more positive cultures than the CCM method with an odds ratio 3.47 and 95% confidence interval 1.92, 6.63 (Table 1)",1
46,7,"Tan et al., however, did not show a superiority of BCB over CCM.19 They studied 85 vitreous specimens from 85 eyes and reported that BCB yielded 69% growth and CCM yielded 72% growth. This difference between the two methods was not statistically significant. They concluded that BCB were not superior to CCM and noted that a combination of both culture methods significantly increased the culture yield. The current report herein studied a larger series and confirms the results of the previous KKU report. BCB yielded more positive cultures than CCM with a statistically significant difference. It is also noted that a combination of both methods had better positive results compared with either BCB or CCM alone.",1
46,8,"The reasons why BCB are superior to CCM for the vitreous culture are not clear. It is postulated that purulent fluid exerts an inhibitory effect on the organisms. Dilution of this purulent fluid in a large volume of BCB may enhance the chances for recovery of the organisms. In addition, BCB are rich in nutrients suitable for growth of many organisms. It is time saving, as only one medium needs for inoculation. It needs only a small volume of vitreous specimen. Transportation to the laboratory is simpler because there is no need for immediate incubation. Therefore, this method is especially suitable for office settings and especially in hospitals where adequate microbiology laboratory facilities are not available.",1
46,9,"The strength of this study is that it is the largest series of patients reported. There is, however, a limitation. The yield for positive cultures was 49.5%, which is rather low when compared with the previous studies. This may be due to the retrospective nature of this study. Only the patients having vitreous culture by both methods were studied, and those having cultures with only one method were excluded, although cultures were positive. Some patients may receive antimicrobial treatment before vitreous cultures. Some microorganisms may therefore not be detected by currently available techniques. Furthermore, some patients may have endophthalmitis of a non-infectious cause.",1
46,10,"In conclusion, the BCB showed superiority over the conventional media in vitreous culture for infectious endophthalmitis. Vitreous culture using BCB should be recommended as the primary method for microbiological diagnosis. A combination of both culture methods further improves the positive yields.",1
46,11,"The authors wish to thank Dr. Kaewjai Thepsuthammarat, Clinical Epidemiology Unit, Faculty of Medicine, Khon Kaen University, for statistical analysis and Professor James A Will, University of Wisconsin, for assistance with the English language presentation of the manuscript.",1
47,1,"In this article Author considers notion “body culture” – its role and place in the theory and practise of the specific kind of human movement activity related to variously conceived sport and physical culture. He researches this issue from the historical and contemporary point of view. He presents large theories on body and culture of Norbert Elias, Frankfurt School, phenomenology, Michael Foucault and Pierre Bourdieu context of justification. He analyses expression body culture also in the light of philosophy, sociology, anthropology, ethnology, psychology, education, linguistic, theology, politics and democracy assumptions.",1
47,2,"We start with an introductory case. In the beginning of the 20th century, the people of the Mentawai islands off the west coast of Sumatra (Indonesia) entered for first time into contact with the Dutch colonial power, which dominated Indonesia in the early 20th century. Living in longhouses and clans along the rivers in the equatorial rainforest, the Mentawaians had kept to their (in colonial jargon) so-called ‘Stone-Age’ culture. The “mild savages”, as they were also called by Westerners, lived in an “original affluent society”, without villages, without chieftains, but rich in festivities and shamanic rituals. When the Mentawaians encountered colonial authorities, this isolation was broken and led to processes of cultural learning and astonishment.",1
47,3,"The story is about a misunderstanding. The Dutch had the idea to involve the Mentawaians, who were famous for their art of shooting, in a festivity in honour of the Dutch monarchy. By bodily activity there should be built a bridge between the cultures (in a similar way, it is often said today that sport expresses an elementary, objective and universal body language, which – being far from linguistic language – may serve as an ideal medium of understanding across borders and of bridging between peoples).",1
47,4,"In real life, however, the encounter developed in another way, and this is what the old Mentawaian remembered. The well-intentioned meeting began friendly with festive decoration and a meal. It turned into a ridiculous event as the Dutch cheered in a – for the indigenous guests incomprehensible way about the arrow hitting a coconut. And it ended with an insult when the Dutch officer distributed the sports rewards. The prices were given according to the principle of achievement, and this conflicted with the artificial balance between the clans, which was basic for Mentawaian social relations. To give somebody more and someone else less, according to their shooting results, neither corresponded to the egalitarian pattern of this stateless society nor to the complex relations between the different longhouse clans. Bow-and-arrow shooting as a Mentawaian art of hunting and bow-and-arrow shooting as a Western sport were two fundamentally different activities.",1
47,5,"The case casts light on the complexity of bodily activity, body language and body culture. And it tells us about how relevant body culture is for the understanding of society and cultural diversity.",1
47,6,"Furthermore it tells us about the interlacement between Western history of sport and nonWestern history. History is not only the genesis and change of the one mainstream we call ‘sport’ (a standard work on this perspective: Guttmann 2004). It is also the history of ‘non-sports’ in thousands of Asian, African, Indigenous American and Pacific cultures. Their particular ways (in German: Sonderwege) throw light on what has been the sonderweg of Western sports. Through body culture and in this case especially through the clash between body cultures – cultural diversity becomes visible.",1
47,7,"The attention of cultural and social studies to “the body” started in the 1970s in a nearexplosive process. Sociologists, historians, philosophers and anthropologists, scholars from sport studies and from medical studies suddenly met in talking about “the return of the body” or its “reappearance” (typical: Die Wiederkehr des Körpers, Kamper/Wulf 1982). The term “body culture” soon follow to express the new interest in the body .",1
47,8,"In trying to describe the history of this term and the related field of knowledge, however, one has to distinguish between three different lines of development: the line of ‘classical’ theories about the culture of the body, the history of the word “body culture” itself, and the recent profile of discourse as well as the changes in social practice, which produced or promoted the new attention. These three lines lead to different historical phases.",1
47,9,"When the attention to “the body” and to body culture had found its word, scholarly attention turned back to sociologists and philosophers who had earlier made studies in this field. These were since the 1920/30s – especially Norbert Elias, the Frankfurt School, and some phenomenologists. Michel Foucault and Pierre Bourdieu built bridges towards the new studies of body culture.",1
47,10,"Based on phenomenological traditions, the French philosopher Michel Foucault (1975) undertook deep studies in the configurations of knowledge during the Renaissance and the ‘classical age’ of Baroque in order to approach the post-1800 society of modern ‘development’ and panoptical control. His studies approached the body by analyzing the history of military discipline and the panopticon as a mechanism of control. The modern body moves in an “archipelago of prisons” and is subjected to what Foucault called the biopolitics of power. This approach became especially influential for sport studies in body, space, and architecture (Vertinsky/Bale 2004). But it also inspired critical studies in the disciplined body of gymnastic and sport (Vigarello 1978, Barreau/Morne 1984, Vertinsky/McKay 2004).",1
47,11,"While Foucault’s studies in bodily discipline focused on the top-down strategies of power, the French Sociologist Pierre Bourdieu directed his attention more towards bottom-up processes of social-bodily practice. He started by studying the Kabyl Berber people in Algeria, their houses and life practices, before entering into studies among different social classes in Paris and France. On this basis, Bourdieu (1966/67) developed the influential concept of habitus. Habitus is a sort of incorporated pattern, which became social practice through diverse forms of taste and distinction, through the display of the body – and through sports. Side by side with economic capital, the social habitus could be understood as a sort of “cultural capital”. Some of Bourdieu’s disciples, such as Jacques Defrance (1987), applied these concepts to the history of sports and gymnastics.",1
47,12,"Also in the works of other ‘fathers’ of modern social thinking, ‘the body’ was recently discovered as being at least an underground category – in Karl Marx’ reflections on the “basis” of human practice and social relations, in Max Weber’s analysis of the Protestant and capitalist “secular asceticism”, and in Marcel Mauss’ observation of “body techniques”.",1
47,13,"German Socialist workers’ sport gave a prominent place to the concept of Körperkultur, while Nazi sport gave priority to Leib and Leibesübungen and detested Körperkultur as being materialistic, decadent and Jewish. It was probably by way of the German Socialist “body culture”, that the concept entered into the theory and practice of Russian Socialists under the name of fiskultura. After the revolution of 1917, fiskultura became an alternative to bourgeois sport, uniting the revolutionary fractions of more aesthetically oriented Proletkult and more health oriented hygienists. Under the dominance of Stalinism, however, the contradictory terms were united under the formula “sport and body culture”. This continued in the Soviet bloc after 1945. Körperkultur was, thus, re-imported into the German Democratic Republic, where the official review of sport sciences bore the title Theorie und Praxis der Körperkultur, and the sports university in Leipzig was called “German High School of Body Culture” (DHfK).",1
47,14,"During all these transformations, the concept of body culture was generally used in the singular. Though at a closer view both historical change and cultural diversity became visible, one did not yet talk about body cultures in the plural.",1
47,15,"Among some European scholars, this was supplied by the term “body anthropology”, as in the framework of the French-Danish-German Institut International d’Anthropologie Corporelle (IIAC 1987 ff; Barreau/Morne 1984, Dietrich 2001 and 2002). The review Stadion, Journal of the History of Sport and Physical Education (Cologne 1975 ff) chose for its title the terms Sport und Körperkultur in German, and Sport et culture physique in French. Outside Europe, the Japanese sociologist Satoshi Shimizu established a Centre for the Study of Body Culture at the University of Tsukuba.",1
47,16,"As mentioned before, the concept of body culture has met with a new scholarly interest in the human body since the 1970s. This innovation happened as a cross-disciplinary process.",1
47,17,"In anthropology, the classical article of Clifford Geertz (1972) about Balinese cockfighting received worldwide attention, and during the 1970s, an anthropology of the body was drafted (Blacking 1977). Susan Brownell (1995) delivered important body-cultural studies of sport in China, and G. Whitney Azoy (2003) showed by analysis of the Afghan game of Buzkashi, how power and violence was embodied in the situation of playing.",1
47,18,"In ethnology, the Tübingen School in Germany around Hermann Bausinger contributed with studies among others about upright posture (Warneken 1990). Danish ethnologists launched the bodynear concept of life-form analysis (Højrup 1983), and the Swedish “cultural analysis” approached modernity as a transformation of bodily practice (Frykman/Löfgren 1979). The Birmingham school of the Centre for Contemporary Cultural Studies (CCCS, 1964-2002) obtained broad international attention with its studies of youth cultures, sport and rock music.",1
47,19,"Psychology had some problems extending its perspective from the bodiless soul or psyche towards the body. The German Communist psychiatrist Wilhelm Reich was the first, during the 1920/30s, to give the body a central place in therapeutic practice and in psychoanalytical theory, especially “body armour” and orgasm. He used this for a sort of body-political critique of Fascism. His work was rediscovered after 1968 and led to new forms of therapy, especially in California, at the Esalen Institute and in the new field of Somatics. In Finland and the UK, the body, its subjectivity and its culture was approached via narrative and autobiographic methods (Sparkes/Silvennionen 1999). David B. Morris (1991) presented an important study on the “culture of pain”.",1
47,20,"All this influenced the field of education. Under the heading of “body anthropology”, educationalists from France, Germany and Denmark cooperated (IIAC 1987 ff) and undertook case studies in traditional games as well as in “scenes” of new urban body cultures (Barreau/Jaouen 1998, Dietrich 2001 and 2002). “Movement culture” became a pedagogical keyword in German pedagogical thinking (Moegling 2001/2). The “non-sportive sport”, play and games, and diverse forms of Sport for All were regarded as an educational challenge for the sport-dominated culture of the body.",1
48,1,Bone marrow culture is considered superior to blood culture in evaluation of FUO. The aim of this study was to compare the usefulness of these two cultures.,1
48,2,"A one year prospective cross sectional study was conducted to find out the usefulness of bone marrow culture and blood culture in the diagnosis of FUO. Marrow aspirates in each case were sent for bacterial, myocbacterial and fungal culture. Simultaneously venous blood was sent for bacterial culture. The results of BMCs and BCs were compared.",1
48,3,"Total 57 cases of FUO were included in the study. Male female ratio was 1.22:1. Age range was five to 83 years (median 30). Duration of fever was 21 to 365 days. Bacterial growth was seen in nine cases (15.78%) of BMCs and in three cases (5.26%) of corresponding BCs. Fungal or myocbacterial growth was not seen. Salmonella typhi was the commonest organism isolated in BMCs (three cases) followed by Staphylococcus aureus (two cases), Escherichia coli, Non fermenting Gram negative bacilli, Enterococcus species and Salmonella paratyphi–A (one case each). Two cases of Salmonella typhi and one case of Salmonella paratyphi–A were isolated in BCs.",1
48,4,"BMCs are more useful than BCs in evaluation of patients with FUO, especially in cases of salmonella infection and are particularly important when the patient has already taken antibiotics. In immuno-competent patients presenting with FUO, BMCs for mycobacteria or fungi is unlikely to yield any growth.",1
48,5,"This was a one year prospective cross sectional study. All the cases of FUO referred to department of pathology of Manipal Teaching Hospital , were included in the study. FUO was defined by the criteria of Petersdorf and Beeson: temperature of 38.3oC (101oF) or above persisting or recurring during a period of two weeks and seven days investigation in hospital, or if three out patient visits fail to result in a diagnosis.6 Patients not fulfilling the above criteria were excluded from the study",1
48,6,"In all the cases clinical fi ndings were recorded and Patients were informed about the procedure . Venous blood is drawn for bacterial culture. Bone marrow aspirations were performed under local anesthesia from posterior superior iliac crest using Salah needle attached to 20 cc syringe, after aseptic precaution . About 10 ml of marrow was aspirated in each case for bacterial, myocbacterial and fungal cultures. For bacterial culture aspirate were inoculated into biphasic brain heart infusion medium and biphasic MacConkey medium and incubated at 37°C for seven days with regular subculture on third and sixth days till the growth was observed . Subcultures were done and incubated at 37°C for 18-24 hours. The growths in the slant were Gram stained and the isolates were identified by biochemical and serological tests. For Mycobacteria, aspirates were inoculated into Lowenstain Jensen medium and incubated at 370 C till the appearance of the growth, maximum for eight weeks. For fungi aspirates were inoculated into Sabourad dextrose agar medium and incubated at room temperature till the appearance of the growth, maximum for 4 weeks.",1
48,7,BMCs in nine (15.78%) out of 57 patients exhibited bacterial growth and in three cases (5.26%) corresponding BCs also exhibited bacterial growth (Table 3 and 4). None of the BMCs showed mycobacterial or fungal growth. Frequencies of various bacteria isolated in BMCs are shown in table 4; the commonest was Salmonella typhi (33.5%). In two cases bacterial growth in BMCs and BCs were comparable (Table 3).,1
48,8,"In a study by Haq et al, infectious disease accounted for 63.21% of cases of FUO. Tuberculosis was the commonest accounting for 24.53%, followed by enteric fever (12.74%) and visceral leishmaniasis (9.43%).8 In a study by Jung et al, commonest cause of FUO was infections (46.4%) and enteric fever was the commonest (29.6%) among that followed by malaria (9%), and tuberculosis (5.2%).9 But these studies were not based only on BMCs and BCs, as in the present study. Nonetheless in this study enteric fever was the commonest cause of infection related FUO.",1
48,9,"A bone marrow examination including BMCs is important part of investigation of FUO, but this alone is insufficient to trace specific etiology in all the cases. A good clinical history, radiological and hematological evaluation including bone marrow coupled with BMC and serology would yield diagnosis in a high proportion of cases. Yield of BMCs is more than BCs especially in cases of suspected salmonella infection and in patients treated with antibiotics as was the case in present study; however, its role is insignificant in isolating mycobacteria or fungi in immuno-competent patients.",1
49,1,"Conventional culture methods using temperature-responsive culture dishes require 4–5 weeks to prepare layered chondrocyte sheets that can be used in articular cartilage repair and regeneration. This study investigated whether the use of synovial tissue obtained from the same joint as the chondrocyte nutritive supply source could more quickly facilitate the preparation of chondrocyte sheets. After culturing derived synoviocytes and chondrocytes together (i.e. combined culture or co-culture) on temperature-responsive inserts, chondrocyte growth was assessed and a molecular analysis of the chondrocyte sheets was performed. Transplantable tissue could be obtained more quickly using this method (average 10.5 days). Real-time polymerase chain reaction and immunostaining of the three-layer chondrocyte sheets confirmed the significant expression of genes critical to cartilage maintenance, including type II collagen (COL2), aggrecan-1 and tissue metallopeptidase inhibitor 1. However, the expression of COL1, matrix metalloproteinase 3 (MMP3), MMP13 and A-disintegrin and metalloproteinase with thrombospondin motifs 5 was suppressed. The adhesive factor fibronectin-1 (FN1) was observed in all sheet layers, whereas in sheets generated using conventional preparation methods positive FN1 immunostaining was observed only on the surface of the sheets. ",1
49,2,"Articular cartilage plays an important role in maintaining joint function but has a low capacity for self-propagation. The main reasons cited for this are the lack of blood vessels in cartilage, relative immobility of chondrocytes inside the abundant extracellular matrix, and age-related loss of proliferative ability in mature chondrocytes. Thus, when cartilage is damaged, the injured cartilage is replaced by fibrous tissue and the surrounding cartilage degenerates, often leading to osteoarthritis (OA). In addition, both aging and joint overuse lead to a wide range of cartilage defects (Convery et al., 1972). Currently, various methods of therapy are used to try to repair full-thickness articular cartilage injuries (Skoog et al., 1972). However, regardless of the defect type, regeneration of hyaline cartilage is impossible (Hunziker, 2002).",1
49,3,"Alternative methods of autologous periosteal implantation, including concealment using type I/III porcine collagen (Gomoll et al., 2009), have been used in recent years. Seeding multilayered collagen with chondrocytes (Bartlett et al., 2005) is a common method used for matrix-induced autologous chondrocyte transplantation. Although useful, these techniques could still benefit from improvements such as reducing cytotoxicity and increasing biocompatibility and treatment efficacy.",1
49,4,"Various methods have been developed to promote in vitro cell growth, including the use of feeder cells or the addition of growth factors to the culture medium (Fujisato et al., 1996; Wakitani et al., 1997; van Osch et al., 1998). However, few agents can be applied clinically and their effects are temporary. In vivo, articular cartilage obtains its nutrients mainly from the synovial fluid secreted by the synovial membranes in the same joint (Hodge and McKibbin, 1969). Synovial tissue is thought to help in the repair of damaged cartilage (Hunziker and Rosenberg, 1996) and possesses exceptional capacity for repair, regeneration and growth. A large number of cells can be harvested from synovial tissue and synoviumderived MSCs have excellent musculoskeletal differentiation potential (Fan et al., 2009). We have previously investigated whether layered chondrocyte sheets co-cultured with synovial cells could be transplanted into a porcine fullthickness cartilage defect model, and we found more favourable repair compared with the control group (Ebihara et al., 2012).",1
49,5,"In the current study, simple techniques were applied to try to increase the proliferative activity of chondrocytes. chondrocytes were co-cultured with synoviocytes on inserts to mimic the intra-articular provision of nutrients by synovial fluid. Three-layered chondrocyte sheets were also prepared using the combined culture method. Finally, the molecular properties of single-layered and multilayered chondrocyte sheets were compared to simulate their ability to encourage articular cartilage repair. A preliminary investigation of combined culture using porcine cells was conducted and a greater increase in chondrocyte numbers in co-cultures than in chondrocyte single cultures was observed.",1
49,6,"Cartilage and synovium were obtained from 10 patients (median age: 29 years, age range 20–42 years; six men and four women) who underwent reconstruction surgery of the anterior cruciate ligament at Tokai University Hospital. Cells were separated enzymatically using previously described methods (Sato et al., 2003). All patients consented to participate in the study and the research was conducted with the approval of the Tokai University Ethics Committee.",1
49,7,"First-generation cell cultures (P0), first successive generation cell cultures (P1) and second successive generation cell cultures (P2) were used in this study. Chondrocytes were initially cultured alone (S group) in a six-well culture dish (BD Falcon) with cell culture inserts (BD Falcon) and a pore size of 0.4 mm. Synoviocytes were seeded into these inserts to form the combined culture group (C group). A 7-day culture group (layered chondrocyte, or CL group) was prepared concurrently in which the combined culture was performed with heat-sensitive inserts that produced three layers by culture day 14. Throughout the study, the same culture medium protocol was used for chondrocyte maintenance.",1
49,8,"Cell proliferation ability was measured in 24-well and plate culture dishes. The S group and C group were prepared by seeding 1  104 cells/cm2 into the chondrocyte and synoviocyte cultures. Proliferation was measured using a 3-(4,5-dimethyl-2-thiazolyl)-2,5-diphenyl-2H-tetrazolium bromide (MTT; Dojindo, Kumamoto, Japan) assay on culture days 3, 5, 7, 9, 11 and 14. There were six replicates per experimental condition.",1
49,9,"The data are presented as the mean and standard error of the mean (SEM). Analysis of variance (ANOVA) was used to investigate differences between single chondrocyte sheets and layered chondrocyte sheets. In cases where p < 0.05, we used the Student–Newman–Keuls test for multiple paired comparisons.",1
49,10,"Genes important for maintaining articular joint characteristics, such as COL2, ITGa10, TIMP1 and SOX9, were expressed at consistently higher levels in the CL group than in the S group. The difference was also definitive in P0 and P1 (Figure 4A,C, D). The levels of COL2, ITGa10 and TIMP1, particularly in P0 and P1, were higher in the CL group than in the other groups. Significant inhibition of the catabolic genes MMP3, MMP13 and ADAMTS5 was observed until P1, although gene expression during P2 was similar in all groups (Figure 4E–G). High expression of the COL2 gene and low expression of COL1 gene – hallmarks of articular cartilage – were observed in the layered chondrocyte sheets during every successive generation (Figure 4A,I). However, the treatment groups did not significantly differ in expression of the AGC1 and FN1 genes (Figure 4B,I).",1
49,11,"This work was supported by a Health Labour Sciences Research Grant from the Japanese Ministry of Health, Labour and Welfare and a Grant-in-aid for Young Scientists (B) from the Ministry of Education, Culture, Sports, Science and Technology. We gratefully acknowledge CellSeed, Inc., for supplying the temperatureresponsive culture inserts used in this study. We are grateful to the Education and Research Support Center, Tokai University.",1
49,12,"In summary, a novel technique has been developed for co-culturing chondrocytes and synoviocytes using temperature-responsive culture inserts. Layered chondrocyte sheets fabricated using this technique expressed genes critical to cartilaginous differentiation and the maintenance of cartilaginous characteristics, as well as genes for adhesion factors. Compared with conventional methods, this technique requires much less culture time. However, our method still requires up to 21 days to produce transplantable P0 cell sheets. A further reduction in culture times may be required for clinical applications.",1
50,1,"This article examines the alignment of learning and safety culture in organisations. It tests the hypothesis that factors that indicate a good learning culture might also signify good safety and vice versa. The hypothesis was tested through an intensive literature review. Areas of alignment of learning culture and safety culture were identified. Six components of learning culture and safety culture can be measured by the same instrument. These components form guiding principles for measurement of safety culture and learning culture. Another eight component areas were identified where learning culture and safety culture partially align. Four further components were found to be relevant to either safety culture or learning culture and do not align. Overall, there is a relationship between learning culture and safety culture, but gauging one does not provide a reliable measure of the other.",1
50,2,"The focus on culture across the learning and safety domain is grounded in a more general shift in organisationals towards exploring social and environmental factors that impact work. The terms culture and climate are sometimes used interchangeably in relation to safety and learning in the workplace. However, some studies have delineated these terms such that culture embodies values, beliefs and underlying assumptions, whereas climate describes the perceptions of the workforce in relation to the organisational ‘ambiance’ (González-Romá et al, 1999; Flin et al, 2000). This means that culture is a relatively stable, overarching feature of an organisation. Climate, on the other hand, is measured through workforce attitudes and perceptions that evolve and can be different when measured at any given point in time. Climate evolves in relation to culture and can therefore be viewed as a sub-set or feature of culture. Culture is normally viewed and measured through observable indicators (Flin et al, 2000). However, these indicators tend to be multi-faceted, tacit and complex. Therefore safety culture and learning culture are difficult to observe and measure directly. Nevertheless, culture is a useful lens through which to conceptualise safety and learning in the workplace.",1
50,3,"The ways in which safety is perceived has evolved to aid organisations in the operationalisation of employee well-being and the creation of safer workspaces (Dedobbeleer and Béland, 1991; Cooper, 2000; Glendon and Stanton, 2000). Early conceptualisations of safety focused on the development of technical solutions. As new and safer mechanical systems developed rapidly, safety science tended to focus on technical malfunction. As mechanical systems improved, attention turned towards human error and human operational problems, rather than technical malfunctions. Unsafe practices and judgements are still viewed as a key source of system breakdown. Other sources of errors and accidents are socio-technical factors, which relate to the interaction between human and technical factor. Over the past decade, culture has became a critical factor in safety science and organisational psychology research as a means of interpreting incidents and understanding safety in organisations.",1
50,4,"One way to improve the measurement of safety and learning culture could be to identify common factors. Factors that indicate an affirmative learning culture may point to good safety. Similarly, factors that indicate a positive safety culture may signify good learning. Any association of safety culture and learning culture measurement could be helpful for organisations. However, the relationship between learning culture and safety culture is not well understood. Interdisciplinary research across these fields has been limited (Lukic et al, 2010). To improve measurement methods, this study explored whether and in what ways safety and learning culture interrelate, specifically examining to what extent they occupy the same conceptual space. Drawing on literature spanning a number of disciplines, the aim was to identify whether and how measures of learning culture could be used to assess safety culture and vice versa.",1
50,5,"This research identifies which factors of learning culture and safety culture are aligned. It examines whether and how measures of learning culture could indicate good safety and vice versa. The study contributes to organisational practice by identifying key principles that can be used by organisations to streamline safety and learning culture. The analysis advances the theoretical understanding of learning culture and safety culture by aligning key constructs across two disciplines that are usually unrelated, laying a foundation for future empirical studies.",1
50,6,"The article begins with a detailed review of safety culture and learning culture literature, explaining how relevant papers from both areas were sourced, selected and summarised. The article then classifies key indicators of learning culture and safety culture abstracted from these articles. The method used to synthesise these key indicators into broad themes for learning culture and for safety culture is outlined. These broad themes are compared and aligned across the safety culture–learning culture nexus. Finally, the article concludes by defining principles for effective learning and safety culture.",1
50,7,"The key criterion for selecting articles was that the papers included either indicators of safety culture or of learning culture. Empirical papers and review papers were incorporated only if they included some key indicators. From an initial (extended) list, a shortlist was created using a two-stage filtering process. Initially, non-relevant papers were filtered out by reading the abstracts. All remaining papers were then examined to identify and abstract the key indicators. A number of articles were discarded at the second stage of filtering, since these papers did not focus on safety culture or learning culture or did not include indicators of either.",1
50,8,"Broad and narrow indicators of learning culture and safety culture were analysed and grouped into themes, as illustrated in Table 2. Themes include commitment, collaboration, workplace conditions and so on. Two distinct thematic analyses were carried out – one for learning culture and one for safety culture. Analysis was completed by colour-coding the indicators depending on which article the indicator was abstracted from, which construct the indicator referred to (safety culture or learning culture), and the type of indicator (general indicator or specific measure). The indicators were grouped into emergent themes and then the results were transferred to a database.",1
50,9,The final phase of the study was a thematic alignment across the safety culturelearning culture nexus. The learning culture themes were reviewed and compared with the safety culture themes. Synthesised summary statements and individual indicators (grouped under each theme) were used to determine the degree of alignment across the themes. Three researchers carried out the thematic alignment independently. The results were compared and any disagreement was resolved through debate and discussion. The output was the set of aligned themes outlined in Table 2 and described in the following section.,1
50,10,"Six themes of safety culture and learning culture have a degree of association. These themes are open communication, employee empowerment, collaboration, alignment of espoused and enacted priorities, internal systemic alignment and management. These themes are summarised in Table 2. The table indicates the number of articles representing each theme (out of the total number of papers reviewed).",1
50,11,"Another shared theme is collaboration. From the literature we identified that safety and learning should be a collaborative task shared by employees across each organisation (Lähteenmäki et al, 2001; France et al, 2010). Collaboration is critical for safety, as safe and productive operation requires effective work practices both within and across teams. Learning also requires opportunities for collaboration both within and outside the organisation to develop team and groupwork skills. Collaboration is most effective when individuals have confidence in colleagues’ knowledge and expertise. Mutual support in achieving collaborative goals is essential for a positive safety and learning culture (Grote, 2008; Westerberg and Hauer, 2009).",1
50,12,"The alignment of enacted and espoused priorities is a critical theme bridging safety culture and learning culture (Argyris and Schon, 1978; Wiegmann et al, 2004). This theme refers to the alignment between an employee’s intentions and their actions: what people do and their intended outcome (Leung, 2006; Zohar, 2010). If an employee carries out a learning activity with the intention to achieve accreditation, rather than to learn, the result could be surface, rather than deep learning. Similarly, if an employee reports a colleague who is behaving in an unsafe manner with malicious intent, rather than to improve safety, the outcome may be harmful. Therefore individual and organisational values have to be aligned with professional practice.",1
50,13,"In the literature, we identified a range of job-specific and meta-cognitive competencies that were critical for work (Clarke, 2005). The meta-cognitive competencies described in the organisational learning literature are similar to those outlined in the safety literature. These competencies include the ability of employees to judge their ability relative to others and their confidence to engage in learning or safety behaviours. However, there are also noticeable differences. Safety competencies are explicitly trained in organisations. There is an underlying assumption that employees may not have even the most basic of safety competencies; for example how to exit a building in the event of fire. By contrast, it is often assumed that personnel know how to learn, even though this is not always the case. Few initiatives are in place to allow employees to expand their learning competencies and learn how to learn.",1
51,1,"In this study, an optimized method was developed to detect Salmonella by using immunomagnetic separation coupled with culture to selective agar (IMS/culture). To test the effectiveness of the methods and develop a rapid and sensitive detection procedure, direct culture, IMS/culture, and multiplex PCR (mPCR) were compared for the detection of Salmonella in 700 food samples. After selective enrichment, all samples were (I) subjected to direct culture, plated on xylose-lysine-tergitol 4 agar, and identified as Salmonella via biochemical and serological methods; (II) subjected to IMS then identified as (I); and (III) subjected to DNA extraction and mPCR analysis. A total of 83, 95, and 104 samples were found positive for Salmonella by direct culture, IMS/culture, and mPCR, respectively. Results suggested higher sensitivity in mPCR than in direct culture and IMS/culture methods. IMS/culture increased the detection rate of Salmonella and compared well with mPCR. This study demonstrated that the use of mPCR in pre-screening of samples and further identification by IMS/culture should enhance the positive identification and increase the number of isolates of Salmonella.",1
51,2,"Outbreaks of foodborne salmonellosis in recent years have raised serious concern regarding the rapid diagnosis of pathogens with high specificity and sensitivity. Conventional culture methods for the detection of Salmonella are most widely used and considered “gold standard” (Alocilja et al., 2003). However, such methods are laborious, time-consuming, and less sensitive. To overcome these disadvantages, several methods for the detection of Salmonella in food have been developed to increase the sensitivity and decrease the detection time. These methods include immunoassays and nucleic acid-based techniques. Among these strategies, immunomagnetic separation (IMS) and polymerase chain reaction (PCR) have been selected as potential approaches.",1
51,3,"PCR techniques allow highly sensitive detection in few hours and have been described as rapid alternatives to culture for detecting Salmonella in food (Glynn et al., 2006; Moganedi et al., 2007). PCR targeting Salmonella virulence genes, such as fimA (Moreira et al., 2008), invA (Rahn et al., 1992; Upadhyay et al., 2010), and hilA (Guo et al., 2000), has been developed. Recently, multiplex PCR (mPCR) targeting two or more genes has been widely used in Salmonella detection to increase the specificity (Fach et al., 2009; Kim et al., 2006; Woods et al., 2008).",1
51,4,"IMS, which uses anti-Salmonella polystyrene beads, can specifically capture and concentrate target bacteria from food samples, thereby improving the specificity and sensitivity of detection. Moreover, isolated cells can be identified via culture, ELISA, or molecular methods (Cudjoe et al., 1995; Hagren et al., 2008; Jordan et al., 2004; Lynch et al., 2004).",1
51,5,"Each method presents individual characteristics and suitability for application. To date, few attempts have been focused on the comparison of various methods for the detection of Salmonella in different types of food. Although the above methods have achieved some success, a simple, rapid, and robust procedure is still needed to increase the sensitivity and reduce the work of detection, especially when numerous food samples will be examined. Therefore, this study aimed to compare and evaluate the three methods, conventional direct culture, IMS followed by culture to selective agars (IMS/culture), and mPCR analysis, for the detection of Salmonella in food samples.",1
51,6,"Samples A total of 700 food samples purchased from retail markets in China were examined, including chicken (104), pork (117), duck (41), beef (17), mutton (15), fish (109), shrimp (29), milk (36), vegetables (84), mushroom (70), and ready-to-eat food (78). All samples were transported to the laboratory in a chilled container and stored at 4°C prior to examination within 24 h of purchase.",1
51,7,"Enrichment and direct culture Samples were prepared and enriched in accordance with the National Food Safety Standards of China (document GB 4789.4-2010). A 25 g sample was randomly collected from each sample and pre-enriched in 225 mL of buffered peptone broth (Huankai, Guangzhou, China). About 1 mL cultures were incubated in 10 mL of selenite cystine broth (SC) (Huankai) at 37°C and 10 mL of tetrathionate brilliant green broth (TTB) at 42°C for 24 h. Loopfuls of SC and TTB cultures were streaked onto xylose-lysine-tergitol 4 (XLT4) selective agar plates (Difco, Detroit, MI, USA) then incubated at 37°C for 24 h.",1
51,8,"The results for all food samples are summarized in Table 1. Among the 700 food samples tested, 110 were detected positive for Salmonella. Direct culture, IMS/culture, and mPCR detected 83, 95, and 104 positive samples, respectively. A total of 122 strains of Salmonella were isolated from 103 culture-positive samples, 115 were from IMS/culture and 104 were from direct culture. The distribution of isolated serotypes is presented in Table 2. The isolated Salmonella strains represented 9 different serogroups and 32 different serotypes, which were all detected by IMS/culture.",1
51,9,"After selective enrichment, IMS was performed simultaneously as follows: 1 mL aliquots of SC broths and 1 mL aliquots of TTB broths were transferred to an Eppendorf tube containing 5 μL of the prepared immunomagnetic beads (10 mg/mL) and incubated at room temperature for 10 min with slight agitation. About 50 μL of PBS containing 1% Tween-20 was added to the tube, mixed, and then separated with Dynal MPC-S. After washing twice with PBS containing 0.05% Tween-20 (PBST), the beads were resuspended in 100 μL of PBST and transferred onto XLT4 plates for incubation at 37°C for 24 h.",1
51,10,"The results for all food samples are summarized in Table 1. Among the 700 food samples tested, 110 were detected positive for Salmonella. Direct culture, IMS/culture, and mPCR detected 83, 95, and 104 positive samples, respectively. A total of 122 strains of Salmonella were isolated from 103 culture-positive samples, 115 were from IMS/culture and 104 were from direct culture. The distribution of isolated serotypes is presented in Table 2. The isolated Salmonella strains represented 9 different serogroups and 32 different serotypes, which were all detected by IMS/culture.",1
51,11,"Among 103 culture-positive samples, 20 were tested positive by IMS/culture but not by direct culture, and 18 of which were also detected positive by mPCR. The number of Salmonella strains in two mPCR-negative samples was low (only one presumptive positive Salmonella colony was found on the XLT4 agar plates), which may explain that they were detected by IMS/culture but not by direct culture. IMS/culture captured Salmonella from enrichment broths and was more effective than direct culture in detecting a small number of pathogens in food. This result provides important diagnostic implications in detection cases with very few Salmonella organisms in the samples, which can be missed by direct culture.",1
51,12,"The three other samples with mPCR-negative results were all detected positive by SC broth only and not by TTB broth through direct culture; their positive isolates were all serotyped as S. Enteritidis. The SC broth was less selective than the TTB broth and is always suitable for special samples, in which the number of Salmonella was low. The negative mPCR results can also prove the presence of low-level Salmonella in broths from another standpoint. This finding indicated that the IMS/culture method for the detection of S. Enteritidis at low level may yield false-negative results.",1
51,13,"Other reasons exist for the eight false-negative results of IMS/ culture: (a) matrix effects can influence the IMS, and immunomagnetic beads may have been lost because of extremely high fat content of meat during IMS (Skjerve and Olsvik, 1991); and (b) the culture plates from the eight samples consisted of a heavy growth of other Enterobacteriaceae organisms, which may interfere with the growth of isolated Salmonella colonies. This non-specific adherence to the beads of organisms other than Salmonella occurred with particular samples that have been previously reported. Cudjoe and Krona (1997) found that the growth of mucoid colonies of Proteus spp. and coliforms, such as Escherichia coli, Klebsiella aerogenes, and Enterobacter spp., presents difficulty in the isolation of Salmonella in selective agar after IMS.",1
51,14,"Furthermore, mPCR detected 97 of 103 culture-positive samples. From the six culture-positive samples that were not detected by mPCR, four isolates were identified as S. Enteritidis, one was S. Heidelberg, and one was S. Typhimurium. The pure culture of these isolates gave a Salmonella-positive result after mPCR analysis. Seven other Salmonella-positive results were generated by mPCR only (Table 1). The carriage of the target gene of mPCR was confirmed by DNA sequencing. These results were all attributed to the higher sensitivity of molecular detection than that of culture methods. Compared with the culture method, which provides a result after 5 d to 7 d, the mPCR assay detects Salmonella after 12 h to 13 h. Hence, the rapid mPCR method allows early intervention and makes preventive consumer protection possible. However, the mPCR assay is prone to yield positive results that cannot be confirmed by culture. Thus, this method may be valuable in primarily screening or evaluating the significance of organisms containing virulence genes.",1
51,15,"This study demonstrated that mPCR is more rapid and sensitive than direct culture and IMS/culture methods. IMS/culture has been shown to be more sensitive than direct culture for the isolation of Salmonella. Unlike mPCR, IMS/culture leads to the isolation of a viable organism, thereby contributing to future epidemiological studies on Salmonella infection. Thus, the combination of mPCR for primary screening and IMS/culture for confirmation of positive samples as an easy, rapid, and efficient workflow can be recommended for use in large amounts of food samples.",1
52,1,"Firms have to strive for innovation constantly in order to gain and retain a competitive advantage, which renders absorptive capacity (ACAP) – a firm’s ability to absorb and apply external knowledge – highly relevant. Based on data obtained from 592 CEOs and managers of firms in Austria, Brazil, Germany, India, Singapore, and the United States, we show how ACAP can be fostered in an international context. We analyze how corporate culture affects potential as well as realized ACAP and how national culture dimensions moderate these relationships in a fit-as-moderation model. We reveal that the adhocracy culture supports potential and realized ACAP, whereas the market and hierarchy cultures hinder both potential and realized ACAP. Moreover, the relationship between corporate culture and potential ACAP is stable across national culture dimensions, whereas selected national and corporate cultures are more effective in fostering realized ACAP. These results open up opportunities for researchers and support firms in their attempts to foster their firms’ knowledge management processes.",1
52,2,"In current times of higher innovation speed, increased competition, and radical technological changes (Morris, Kuratko, & Covin, 2008), innovation is becoming an increasingly important factor for firm success (Rosenbusch, Brinckmann, & Bausch, 2011). Firms have to acquire and process new information constantly and exploit this knowledge in the innovation process in order to be competitive in the marketplace (Hitt, 1998). They hence have to ensure that knowledge management processes are sufficiently supported and fostered within their organizations.",1
52,3,"The concept of absorptive capacity (ACAP), referring to a firm’s ability to acquire, analyze, and utilize external knowledge (Cohen & Levinthal, 1990), captures these knowledge management processes. ACAP has been shown to support innovation processes and has therefore received much recognition in management research over the past twenty years (Lewin, Massini, & Peeters, 2011). Various researchers have studied the concept as independent variable, thereby proving its positive impact on innovation (Cockburn & Henderson, 1998), interorganizational knowledge transfer (Lane & Lubatkin, 1998), and overall performance across national borders (Tsai, 2001). Studies on ACAP as dependent variable are more scarce and largely focus on knowledge-based antecedents (e.g., Lenox & King, 2004). Particularly intraorganizational antecedents, such as corporate culture, have been largely neglected to date (Volberda, Foss, & Lyles, 2010). This is surprising as it is widely known that corporate culture influences individuals’ behavior in organizations (Deshpandé & Webster Jr., 1989).",1
52,4,"When studying the effect of corporate culture on ACAP, however, an overarching cultural impact should not be neglected: national culture strongly influences the way people think, feel, and act (Kluckhohn, 1951 ). National culture has been proven to have an impact on the effectiveness of organizational value systems (Hofstede, 1985). Hence, the question arises how corporate and national culture interact in affecting ACAP. National culture shall therefore also be included in the present study. By including national culture dimensions, we also respond to research calling for cross-cultural studies on ACAP (Flatten, Greve et al., 2011). Thereby, the present study is of a comparative nature by focusing on a comparison of national cultural settings of domestic firms.",1
52,5,"Furthermore, the study has significant managerial relevance as it shows which type of corporate culture companies should foster to support knowledge management processes in their organizations. Additionally, the study acknowledges the challenges firms encounter with increasing multiculturalism (Schoemaker, 2008) by providing an understanding of how national culture affects their strive for knowledge exploration and exploitation",1
52,6,"Absorptive capacity (ACAP) is defined as “the ability of a firm to recognize the value of new, external information, assimilate it, and apply it to commercial ends” (Cohen & Levinthal, 1990, 128). ACAP is conceptually strongly related to a number of different research streams of which the most prominent are dynamic capabilities (Zahra & George, 2002), innovation (Cohen & Levinthal, 1990), and learning (Lane & Lubatkin, 1998). We view ACAP as a “dynamic capability pertaining to knowledge creation and utilization” (Zahra & George, 2002, 185 ).",1
52,7,"Since its inception over twenty years ago, the concept of ACAP has received significant attention (Park, 2011) and has undergone a number of reviews and extensions (Lewin et al., 2011; Todorova & Durisin, 2007; Zahra & George, 2002). We follow Zahra and George (2002) in their reconceptualization of ACAP as a four-step process since their model has been confirmed by multiple empirical studies (Brettel et al., 2011; Flatten, Greve et al., 2011; Jansen, van den Bosch, & Volberda, 2005). The first process step, acquisition, consists of identifying and taking in potentially relevant knowledge (Zahra & George, 2002). The second step, assimilation, covers the analysis and interpretation of the newly acquired knowledge (Zahra & George, 2002). This new knowledge is then combined with the existing knowledge in the third process step, transformation (Flatten, Greve et al., 2011; Zahra & George, 2002), in which organizational processes are updated according to the new knowledge (Zahra & George, 2002). The final process step, exploitation, consists of the commercial usage of the new knowledge (Cohen & Levinthal, 1989).",1
52,8,"Even if each dimension has an individual importance for the firm, research indicates that firms benefit even more from a parallel implementation of both dimensions since pieces of knowledge that have already been absorbed migrate between the assimilation and transformation stages before they can be exploited (Todorova & Durisin, 2007). However, regarded as mutually independent, each dimension of ACAP has particular shortcomings which can only be overcome by the complementary use of all process dimensions (Todorova & Durisin, 2007). If a firm, e.g., only focuses on the dimension of realized ACAP, it may achieve short-term profits through new products and innovations, but it will not develop a new and innovative knowledge base (Ahuja & Lampert, 2001). Such a knowledge base, however, would be necessary for the firm to be able to recognize strategically important opportunities (Raff, 2000) and to secure a first-mover advantage in the market (Ferrier et al., 1999).",1
52,9,"Firms should therefore support all aspects of ACAP by promoting the right intraorganizational values and behaviors. Corporate culture is believed to be a lever by which firms can foster ACAP (Volberda et al., 2010) as cultural values are known to affect knowledge management processes (Zhao & Anand, 2009) and innovation (Tellis, Prabhu, & Chandy, 2009). Yet, by employing simplified constructs (Khoja & Maranville, 2010) or focusing on a single industry (Harrington & Guimaraes, 2005), researchers to date fall short of assessing the role of corporate culture in managing ACAP, which is why further studies on this relationship are called for (Flatten, Greve et al., 2011).",1
52,10,"A clan culture emphasizes consensus and highly values personal relationships, loyalty, and tradition (Deshpandé & Farley, 2004). Dominant attributes of this corporate culture are cohesiveness, participation, teamwork, and a sense of family. The according leadership style includes a mentor or facilitator whose strategic emphasis it is to develop human resources and to achieve high commitment of employees (Cameron & Freeman, 1991; Deshpandé et al., 1993; Quinn, 1988). An adhocracy culture focuses on an entrepreneurial spirit as well as on creativity and adaptability as dominant attributes. The typical leadership style calls for an entrepreneurial innovator and risk taker who places strategic emphasis on innovations, growth, and the acquisition of new resources (Cameron & Freeman, 1991; Deshpandé et al., 1993; Quinn, 1988). Furthermore, entrepreneurship, flexibility, and risktaking are key organizational bonding mechanisms (Cameron & Freeman, 1991). Market culture is characterized by an orientation toward market superiority and a clear goal orientation (Deshpandé et al., 1993). Characteristic attributes for this corporate culture are competitiveness and goal achievement. ",1
52,11,"These four types of corporate culture are not mutually exclusive (Deshpandé et al., 1993). Organizations usually display one dominant culture, but also show attributes of the other cultures (Cameron & Freeman, 1991). Members of the organization tend to acquire the corresponding values of the dominant culture in an organization over time, and therefore act accordingly (Cameron & Quinn, 2006). Research on corporate culture has already shown that corporate culture affects strategic postures related to innovation and that this relationship varies across different national culture settings (Engelen, Flatten, Thalmann, & Brettel, 2014). Accordingly, the concept of Deshpandé et al. (1993) provides an appropriate set of mechanisms in order to answer the research questions of the present study.",1
52,12,"A second cultural concept applies to an overarching level and may therefore superimpose the impact of corporate culture. While corporate culture is a set of common norms and values on the organizational level (Deshpandé & Webster Jr., 1989), national culture consists of “patterned ways of thinking, feeling and reacting [ . . . ] and especially their attached values” (Kluckhohn, 1951, 86) among members of one culture. Equally to corporate culture, national culture is learned over time from other members of the same culture (Hofstede & Bond, 1988). While corporate cultures focus largely on “the way things get done” in an organization (Deal & Kennedy, 1982, 4), national culture refers to how members of a culture generally act, regardless of whether the setting is professional, social, or private. In this sense, firms are able to influence their corporate culture, whereas national culture has to be seen as a circumstance that cannot be changed (Hofstede, 1994).",1
52,13,"To capture national culture in the present study, we applied Hofstede’s (1980) cultural dimensions. We chose to integrate the particular Hofstede scores for the dimensions of power distance, individualism, and uncertainty avoidance for each of our six sample countries. Power distance refers to “the extent to which the members of a society accept that power in institutions and organizations is distributed unequally” (Hofstede, 1985, 347). Individualism, as opposed to collectivism, captures whether individuals primarily cater to their own needs instead of acting in the interest of their group (Hofstede, 1984). The third national cultural dimension, uncertainty avoidance, assesses “the extent to which a society feels threatened by uncertain and ambiguous situations and tries to avoid these situations” (Hofstede, 1980, 45). We focus on these three dimensions since those are of utmost importance for the innovation research stream and influence innovation-related factors such as the nature of innovations (Shane, Venkataraman, & MacMillan, 1995). ",1
52,14,"We decided to exclude the three further Hofstede dimensions masculinity, long-term orientation, and indulgence from analysis since the nations in our sample, selected for their recognized or emergent economic importance, display the highest variation among power distance, individualism, and uncertainty avoidance compared to the variation among the excluded dimensions. Furthermore, masculinity “has been criticized as being timeand context-specific” (Steenkamp, 2001, 32). Therefore, balancing the need for a parsimonious research model with the need to cover the most relevant cultural dimensions, we believe that the focus on the three dimensions power distance, individualism, and uncertainty avoidance is reasonable. Summarizing, we analyze the interplay of corporate culture, ACAP, and national culture, as displayed in Fig. 2.",1
52,15,"We build our research model on the strategic fit perspective. The general notion of fit, or congruence, has long been important in organizational behavior (Nadler & Tushman, 1980). The concept of fit was applied to examine a multitude of internal and external factors such as organizational climate, (innovation) strategy, technology, environment, management style, and organizational structure and the implication of fit or misfit toward an efficient, effective, and viable organization (Burton, Lauridsen, & Obel, 2002). Furthermore, the strategic fit perspective is relevant in our context since organizations face the challenge to adapt to the environment if they are to survive (Aldrich, 1979) and it has been researched in the context of organizational culture (O’Reilly et al., 19 91 ).",1
52,16,"In order to develop hypotheses on the direct effects of corporate culture, we build on the model of organizational culture types of Deshpandé et al. (1993) as illustrated in Fig. 1 above. The model combines two major streams of research, namely the systemsstructural perspective (Van de Ven, 1976) and the transaction cost perspective (Williamson, 1975, 1981). This concept characterizes each of the four types of corporate culture included in our research model along four dimensions: dominant organizational attributes, leadership styles, organizational bonding mechanisms, and overall strategic emphases. We follow those four dimensions in developing our hypotheses for (1) the effects on potential ACAP before (2) developing our hypotheses for the effects on realized ACAP.",1
52,17,"First, regarding clan culture, dominant attributes are cohesiveness, participation, teamwork, and sense of family (Cameron & Freeman, 1991). Such an atmosphere fosters extensive and free knowledge sharing among members and across departments which is required for knowledge assimilation (Cohen & Levinthal, 1990; Zahra & George, 2002). Moreover, this may support the acquisition and assimilation of knowledge, a process during which frequent cross-departmental communication is needed and newly acquired knowledge has to be made available to others (Flatten, Engelen et al., 2011). Second, the characteristic leadership style in a clan culture includes a mentor or facilitator (Deshpandé et al., 1993). Such a leadership style encourages creative and innovative thinking (Sun & Anderson, 2012). CEOs and leading managers in such a culture tend to inspire their subordinates by clearly stating their visions (Sosik, Kahai, & Avolio, 1998). Facilitative leaders create a nurturing atmosphere in which members feel free to take risks and explore new opportunities (Sarin & McDermott, 2003). This may create a fruitful environment for gathering knowledge which requires a certain openness to identify external knowledge from various sources and activities (Auster & Choo, 1993) as well as the ability to solve complex problems (Tergan, 2003). ",1
52,18,"Regarding market culture, dominant attributes are competitiveness and goal achievement (Deshpandé et al., 1993). In order to discover new trends or technologies, and hence be competitive, firms constantly have to renew their knowledge base, that is, conduct knowledge acquisition and assimilation (Flatten, Engelen et al., 2011). However, since this corporate culture highly relies on goal achievement, it might hinder companies to foster potential ACAP for several reasons. First, it is difficult to translate the exploratory ability of knowledge acquisition and assimilation into measurable goals. It is rather openness with a broad range of formal and informal activities (Auster & Choo, 1993) and constant knowledge sharing (Cohen & Levinthal, 1990) that is required for potential ACAP. Accordingly, it is doubtful whether this corporate culture may be appropriate to foster knowledge acquisition and assimilation. Second, the typical leadership style within a market culture is highly decisive and achievement-oriented (Deshpandé et al., 1993), which might decrease time-to-market in innovation exploitation. Contrarily, exploratory knowledge acquisition is based on open-mindedness and flexible procedures (Auster & Choo, 1993). ",1
52,19,"First, regarding hierarchy culture, dominant attributes are order, rules and regulations, and uniformity, placing a strict focus on high efficiency with mechanistic processes (Deshpandé et al., 1993; Quinn & Rohrbaugh, 1983). Such organizations focus on formalized and structured procedures and are governed by rules and policies (Cameron & Freeman, 1991). Furthermore, the emphasis on uniformity might impede the development of new intellectual approaches (Cameron & Freeman, 1991). We therefore argue that the dominant attributes of a hierarchy culture negatively influence potential ACAP. Second, dominant leadership styles in a hierarchical culture involve a strong coordinator and administrator (Deshpandé et al., 1993). However, strictly implemented hierarchical structures related to this corporate culture make it difficult for subordinates to present novel ideas (Garrett, Buisson, & Yap, 2006), creating an atmosphere which might not foster the acquisition and assimilation of knowledge. Third, the focus on formalization and the emphasis on orders and rules in organizational bonding restrain a company’s flexibility (Walsh & Dewar, 1987). ",1
52,20,"Regarding realized ACAP, we argue that a clan culture’s dominant attributes lead to a positive influence. First, realized ACAP requires creativity (Kotler & Armstrong, 1991), the ability to transform knowledge into products, processes, and systems (Lawson & Samson, 2001), and commercialization capabilities (Liu, 2006). The attribute participation ensures commitment of organizational members (Deshpandé et al., 1993) and, due to the high degree of teamwork, knowledge might be well utilized in the pursuit of opportunity exploitation (Zahra & George, 2002). Second, a company with a clan culture is largely shaped by its strong leaders who act as mentors and facilitators (Deshpandé et al., 1993). Such leaders tend to be a role model for their employees and can themselves demonstrate how important the transformation and exploitation of knowledge are for the company. If effectively exemplified by the firm’s top management, subordinates will follow their actions, values, and beliefs (Hambrick & Mason, 1984). Consequently, employees in such a culture should exert significant efforts attempting to realize ACAP. Third, a clan culture bonds based on values such as loyalty, tradition, and interpersonal cohesion (Deshpandé et al., 1993). ",1
52,21,"First, regarding adhocracy culture, dominant attributes are entrepreneurship and creativity (Deshpandé et al., 1993). Accordingly, this culture might be appropriate to encourage creative approaches (Kotler & Armstrong, 1991) for combining the newly acquired knowledge with the existing organizational knowledge base (Flatten, Engelen et al., 2011), which is essential for the transformation phase of realized ACAP (Zahra & George, 2002). Second, dominant leadership styles in an adhocracy culture involve an entrepreneurial innovator and risk taker (Deshpandé et al., 1993). Such leaders encourage members to act on their own initiative, which should support an effective implementation of opportunities at all hierarchical levels (Shane, 1994). Third, organizational bonding mechanisms are based on an entrepreneurial mindset as well as on flexibility and creativity (Deshpandé et al., 1993) which may foster a risk-taking attitude among organizational members. In addition, the tendency to hire leaders who are entrepreneurs helps penetrate a risk-taking attitude at all hierarchical levels of the organization (Engelen et al., 2014). Subordinates following this attitude will not hesitate to quickly update organizational processes, to commercialize new knowledge, or to establish new competences; all of which are key elements of realized ACAP (Brettel et al., 2011). ",1
52,22,"First, market culture is characterized by dominant attributes such as competitiveness and goal achievement with external focus and mechanistic processes (Deshpandé et al., 1993). We argue that such a competitive orientation facilitates the incorporation of acquired knowledge into organizational processes. Hence, it may support the transformational and exploitative components of realized ACAP (Zahra & George, 2002). Second, the according leadership style is decisive and achievement-oriented (Cameron & Freeman, 1991; Quinn, 1988). Such a goal-oriented leadership and task accomplishment might lead to faster implementation of decisions and hence increase the efficiency of innovation exploitation. Third, goal and production orientation are bonding mechanisms fostering adherence to time schedules, which may enable firms to exploit opportunities promptly (Deshpandé et al., 1993). Moreover, production orientation fosters technological and process innovations that can result in either new processes or new products and services. Fourth, putting strategic emphasis on competitive advantage and market superiority combined with achievement orientation (Deshpandé et al., 1993) likely increases a firm’s strive to effectively adopt new technologies or processes based on effective commercialization capabilities (Liu, 2006). ",1
52,23,"Following the framework of Venkatraman (1989) for fit-asmoderation, we first assess the moderating influence of power distance on the relationship between corporate culture and (1) potential as well as (2) realized ACAP. We thus highlight that it is necessary to have a fit between external contingencies (i.e., national culture) and internal factors (i.e., corporate culture) in order to realize a positive outcome (i.e., potential and realized ACAP).",1
52,24,"An adhocracy culture fosters the innovative behavior of all employees and therefore promotes individual autonomy (Cameron & Quinn, 2006). This is only possible if all employees have the same rights in making their own decisions and enjoy a certain freedom in their actions. High power distance countries, however, promote inequality among employees (Hofstede, 1983), thereby contradicting adhocracy culture. Similarly, the employees’ willingness to act, which is supported by adhocracy culture (Demir, Ayyildiz Unnu, & Erturk, 2011), may not fit a high power distance culture, which rather focuses on the subordinates’ strong dependency on the leader (Hofstede, 1980). According to the strategic fit paradigm, this should result in a misfit between the external and internal conditions. Therefore, the relationship between adhocracy culture and potential ACAP should become weaker under the conditions of high power distance. The reason is that under those conditions, the adhocracy culture may no longer be able to motivate employees to generate new knowledge in a creative or innovative manner. The same holds true for the relationship between adhocracy culture and realized ACAP. ",1
52,25,"Leaders in a market culture are characterized by a decisive leadership style and are known to be “hard-drivers” (Cameron & Freeman, 1991, 34). Subordinates should only follow this leadership style if they accept that they are powerless compared to their superiors, that is, if they accept a high power distance (Hofstede, 1984). Additionally, market culture is based on constant competition instead of on internal maintenance (Deshpandé & Farley, 2004). This is also in line with a high power distance culture in which employees compete instead of cooperate since they view each other as threats and hence tend not to trust each other (Hofstede, 1980). Trust, however, is essential for an efficient exchange within organizations and furthermore promotes flexibility (Sinha & Van de Ven, 2005). Based on the strategic fit paradigm, we postulate that under the conditions of high power distance, the relationship between market culture and potential ACAP becomes even weaker. The reason is that communication and trust are essential components of potential ACAP (Cohen & Levinthal, 1990). These are largely neglected by the combination of those internal and external conditions. Regarding the relationship between market culture and realized ACAP, this effect is different. ",1
52,26,"An organization with a hierarchy culture is heavily formalized and relies on rules and policies (Deshpandé & Farley, 2004). In order for employees to accept these regulations, they must first acknowledge the privileged role of their superiors and understand that power is unequally distributed among members of the organization. This is the case in a high power distance culture (Hofstede, 1980). Furthermore, leaders in a hierarchy culture typically act as administrators or coordinators (Cameron & Quinn, 2006); they display their power over the employees they coordinate. This behavior is generally practiced and accepted in a high power distance culture in which leaders aim to display their superiority over employees (Hofstede, 1983). This combination of internal and external conditions might represent an appropriate fit in terms of cultural aspects. Thus, it will likely increase the negative implications resulting from highly formalized, stable, and predictable processes that hinder organizations to transform and exploit assimilated knowledge. Accordingly, we expect that the hypothesized negative effect of hierarchy culture on realized ACAP is strengthened in a cultural setting characterized by high power distance. ",1
52,27,"In an adhocracy culture, the emphasis lies on differentiation and competition (Deshpandé et al., 1993). Consequently, the focus is more on individual achievement rather than on group cohesion (Cameron & Freeman, 1991) which is common in an individualistic national culture (Hofstede, 1983). Additionally, flexibility, as a core value of the adhocracy culture (Deshpandé et al., 1993), better matches individualistic countries where members are more autonomous and less emotionally dependent (Hofstede, 1980). Thus, this type of culture may support creative and explorative thinking. Adhocracy culture and individualism offer a high fit of underlying values. The adhocracy culture thus seems to be the appropriate culture for individuals to stand out and pursue their personal projects in terms of new knowledge acquisition and assimilation, that is, potential ACAP, as well as with regard to knowledge exploitation, that is, realized ACAP. Concluding, we expect high levels of individualism to intensify the hypothesized positive relationships between adhocracy culture and both potential as well as realized ACAP.",1
52,28,"A market culture focuses on differentiation and is dominated by the pursuit of competitiveness (Cameron & Freeman, 1991). Such organizations support internal competition instead of fostering harmony or integration (Deshpandé et al., 1993). This may appeal to individualistic national cultures in which the focus is set on the individual rather than on the group (Hofstede, 1984). Furthermore, market mechanisms govern transactions within a market culture (Ouchi, 1980), which may match individualistic national cultures in which the “involvement of individuals with organizations is primary calculative” (Hofstede, 1983, 62). Concluding, we expect high levels of individualism to intensify the hypothesized negative relationship between market culture and potential ACAP and intensify the hypothesized positive relationship with realized ACAP.",1
52,29,"Hierarchy culture, which some researchers also call “bureaucratic culture” (Deshpandé & Farley, 2004), is strictly governed by rules and regulations (Deshpandé et al., 1993). In this regard, it may fit the national cultural understanding of collectivist countries where the organization is expected to provide order and assurance for its members (Hofstede, 1980). Furthermore, a hierarchy culture strives toward stability and predictable processes (Cameron & Freeman, 1991), which is in line with the collectivist national culture’s desire for stable relationships and security within the organization (Hofstede, 1983). In other words, the combination of hierarchy culture and high levels of individualism might be a misfit. Accordingly, the already expected negative relationship between hierarchy culture and potential ACAP should be strengthened since individualistic employees rarely produce unique ideas under such internal conditions. A similar strengthening of the negative impact is expected regarding realized ACAP since stability and predictability of processes may not fit to an individualistic national culture setting with rather unstable and unsecure relationships. Concluding, we expect high levels of individualism to intensify the hypothesized negative relationships between hierarchy culture and both potential as well as realized ACAP.",1
52,30,"Lastly, we assess the moderating impact of uncertainty avoidance on the relationship between corporate culture and ACAP. Members of countries scoring high on uncertainty avoidance tend to feel uncomfortable in uncertain situations. Therefore, these individuals try to avoid such situations (Hofstede, 1984).",1
52,31,"Clan culture holds interpersonal cohesion, integration, and morale as important values (Cameron & Freeman, 1991). Hence, it has even been relabeled “consensual culture” in some contributions (Deshpandé & Farley, 2004, 5). This might match a national culture with high uncertainty avoidance in which the desire for consensus is high and disagreements are avoided (Hofstede, 1980). Furthermore, a clan culture’s emphasis on tradition (Deshpandé et al., 1993) is in line with high uncertainty avoidance national culture in which differing views and approaches are not tolerated and rules are not to be changed (Hofstede, 1983). Additionally, a high uncertainty avoidance national culture in which members gladly share their emotions (Hofstede, 1983) reflects the sharing and caring nature of a clan culture (Cameron & Freeman, 1991). This may particularly foster the dimension of potential ACAP as knowledge sharing is an integral component of this dimension (Flatten, Engelen et al., 2011). Thus, one can postulate that high levels of uncertainty avoidance strengthen the relationship between clan culture and potential ACAP. The same holds true for the relationship between clan culture and realized ACAP under the conditions of high uncertainty avoidance. ",1
52,32,"Leaders in an adhocracy culture are seen as entrepreneurs and innovators (McLaurin, 2008). They therefore might seize uncertainty or ambiguity as an opportunity that they can exploit. Instead of fearing unclear situations, they accept and learn to deal with them. This is typical for countries with low uncertainty avoidance (Hofstede, 1980). Furthermore, members of organizations dominated by an adhocracy culture “are willing to stick their necks out and take risks” (Cameron & Freeman, 1991, 34). Actively taking risks instead of avoiding such situations is also a characteristic of low uncertainty avoidance countries (Hofstede, 1984). Overall, high uncertainty avoidance culture and adhocracy culture should represent a mismatch. Therefore, one can postulate that a high level of uncertainty avoidance weakens the relationship between adhocracy culture and potential ACAP. The reason is that employees tend to avoid situations related to the acquisition of unknown knowledge (Hofstede, 1984). Similarly, the relationship between adhocracy culture and realized ACAP should be weakened by a high level of uncertainty avoidance. In such a context, employees would rather rely on existing products or processes than create and exploit new ones. Hence, we expect that high uncertainty avoidance culture and adhocracy culture are also a mismatch in the case of realized ACAP. ",1
52,33,"Market culture is characterized by competitiveness, which is fostered through a determined leadership style (Deshpandé et al., 1993 ). This is contrary to a high uncertainty avoidance national culture in which members try to evade competition and value consensus more than disagreement (Hofstede,1980). Furthermore, a market culture is production-oriented and its members do not demonstrate personal involvement (Cameron & Freeman, 1991). It thus may rather fit the values of a low uncertainty avoidance national culture in which members of an organization tend not to share their emotions (Hofstede,1983). This misfit between internal and external conditions should weaken the relationship between market culture and potential as well as realized ACAP in cases of high levels of uncertainty avoidance. On the one hand, this might affect the communication and trust dimensions, which are essential for developing potential ACAP (Zahra & George, 2002). On the other hand, this might influence the implementation of newly gathered knowledge (Cohen & Levinthal, 1990), which is required for knowledge transformation and exploitation and, consequently, for realized ACAP. ",1
52,34,"A hierarchy culture is strongly dependent on formal guidelines, rules, and procedures (Hartnell, Ou, & Kinicki, 2011). This should be supported by high uncertainty avoidance countries as their members prefer to have clear policies and regulations (Hofstede, 1980). Furthermore, uniformity as a dominant attribute of a hierarchy culture (Deshpandé et al., 1993) may also match the values of a high uncertainty national culture because members of such a culture consider diverging views and people a threat (Hofstede, 1983). Based on this fit between external and internal conditions, one can postulate that high levels of uncertainty avoidance should strengthen the already negative relationship between hierarchy culture and potential ACAP since creative, controversial, and open-minded thinking is completely suppressed. This should make it difficult to acquire and assimilate new relevant knowledge. In addition, this combination should also strengthen the already negative relationship between hierarchy culture and realized ACAP. Since uncertainty avoidance might even reinforce the negative influence resulting from the strong focus on formalization, an organization will be impeded in its attempt to flexibly adapt processes.",1
52,35,"Firm age (LN) refers to the natural logarithm of the years since foundation and firm size (LN) represents the natural logarithm of the number of employees (Danneels, 2008; Engelen & Brettel, 2011). Additionally, we asked participants in which primary sector their firms operate and included 15 sectors as control variables (Flatten, Adams, & Brettel, 2015). Furthermore, we included the Human Development Index (HDI) and the logarithm of the gross domestic product per capita (GDP log) to control for countryspecific effects in our model (Flatten et al., 2015). Additionally, we added a single-item measure on technological dynamism where we asked respondents to rate if their “industry is characterized by constant change in product technology” in order to account for industry-specific effects within each country driving our results (adapted from Homburg, Jensen, & Krohmer, 2008).",1
53,1,"The purpose of this paper is to present adaptive culture structuration, a new approach for theorizing and analyzing culture change and for creating an “adaptive cultural structurated learning environment”.",1
53,2,"Incorporating a case study in the financial sector the paper explores 12 employees’ narrated accounts of living through a culture change initiative. A constructivist, interpretive, qualitative research study followed grounded theory principles. Organizational documentation provided secondary data. Semi structured interview data were analyzed using content analysis, constant comparison and theoretical sensitivity and were managed by ATLAS.ti software.",1
53,3,"Three themes emerged: respondents’ investment of self, accepting the culture change initiative and its values; employees’ epistemic analyses of the embedded value promises including experiencing a critical incident that interrupted managers’ enactment of values; employees’ resulting “received practice” which represented the enacted (versus the espoused) values and was not visible to managers.",1
53,4,"An adaptive culture structurated learning environment fosters a relationship of “negotiated practice” instead of “received practice” between managers and employees in the constitution of corporate culture change. In this space, employee interpretations and assessments, which may otherwise remain hidden from managers and thereby prevent workplace learning opportunities, can be drawn upon, shared meaning co-produced and psychological contract issues explained.",1
53,5,"Global competitiveness operates in a time of economic uncertainty and social change (Rugman et al., 2012). The prevailing unpredictability of contemporary change sets the scene for organizations to utilize as many people-oriented resources as possible in the service of business competitiveness, especially as Albert et al. (2000, p. 13) suggest, structural and institutional methods of organizing are not so reliable and more dependent on “the heads and hearts of its members”",1
53,6,"The construct, adaptive culture structuration, provides a perspective pertaining to employees as they go through culture change, addressing the values of such an initiative in a constitutive and re-constitutive way, in a manner resonant with Giddens’ (1984) structuration theory. In our case study, employees’ reconstitutive activity came into sharp focus when additional and unexpected change interrupted the ongoing culture change program.",1
53,7,"From our research, employees’ accounts regarding their experiences of a current organizational culture change initiative provide insights on how they interpreted persuasive managerial discourses as their “received practice”. Employees appeared to conduct epistemic analyses of cultural discourses based on alignment or non-alignment of the espoused values with managers’ behaviors. Whether managers “walked the talk” in their actions was a critical issue for employees.",1
53,8,"Just as organizations’ use of corporate culture as “soft” controls may be hidden from employees (Ray, 1986; Willmott, 1993), we propose that employees’ epistemic interpretations and assessments may be hidden from managers, thereby preventing workplace learning opportunities utilizing employees’ “knowledgeability” (Giddens, 1976, 1979, 1984). Consequently, and considering employees’ felt need to validate cultural discourses through the corresponding behavior of managers, we propose a new theoretical approach of “adaptive culture structuration” which draws on Giddens (1976, 1984) and Poole and McPhee’s (1983) structuration theory, and DeSanctis and Poole’s (1994) adaptive structuration theory.",1
53,9,"The recognition of employees’ agentic capability (Billett and Pavlova, 2005; Campbell, 2009) encourages an environment in which managers and employees can co-produce meaning (Billett, 2001, 2008; Gergen, 1994), transforming the “received practice” activity in to a “negotiated” one.",1
53,10,"The paper is structured around the flow of activities in the case study, as presented in Figure 1, from the culture change initiative and its associated persuasive discourses, to the perceived embedded promises in the “received” form of psychological contract. As this was happening, employees were engaging in identity work (Beech, 2008; Down and Reveley, 2009; Driver, 2009; Watson, 2008) demonstrating personal investment in the organization and for some employees, deep structure identification (Rousseau, 1998). Managers appeared decoupled from the impacts of their behaviors on employees (see Meyer and Rowan, 1977), going about their managerial business whilst employees interpreted discourses and assessed them for validity (see Dixon, 2000), sometimes with negative trust consequences (Breuer and McDermott, 2011). In this vein, we continue to follow the activities of the culture program (see Figure 2), giving consideration to the intrusion of unexpected change, the consequential employee epistemic activities and later discussing the creation of an adaptive culture structuration learning environment built through negotiated (rather than received) practices.",1
53,11,"With this backdrop to considering a negotiated practice environment however, it is necessary to consider three relevant themes from the literature: corporate culture, psychological contract and identity, concluding with a fourth theme; an original construct of adaptive culture structuration.",1
53,12,"For individuals who deeply connect with the cultural values and subsume themselves in the organizational identity, the assumption is that, much like communities, identity is sustainable. However, organizations vulnerable to external and internal change face the risk of losing the energy and commitment given by employees who support the organizational values and cultural rhetoric, but suddenly find themselves disenfranchised. We propose that an organization’s values which are deemed to be shared among all individuals within the organization constitute deep generative promises and psychological contracts.",1
53,13,"Significantly, Dick and Nadin (2011, p. 294) propose “certain, essentially managerial, understandings of the employment relationship, embodied in the concept of the psychological contract...act to shape contemporary workplace identities”. They point to managers’ perceptions of themselves as legitimate power holders such that they will succeed if they manage properly and their employees respond “appropriately” (see Alvesson and Willmott, 2002). Such perceptions do not take into account the active agentic power of employees and their interpretations of themselves as being “being properly managed”.",1
53,14,"Hamel (2009) reports on employees’ intentions and strategies in light of psychological contract violation impacts, supported in the literature by Dulac et al. (2008) and Turnley and Feldman (1999). A review of the literature, however, reveals a lack of research examining organizational shared values as very deep promises and psychological contracts. Richard et al.’s (2009) study is one of the few connecting psychological contract and organizational culture, and identifies psychological contract as a mediator between organizational culture and employee commitment. They conclude with the assertion that managers can, by understanding how psychological contracts are generated and sustained, beneficially leverage them in order to avoid detrimental effects of violation.",1
53,15,"Workplace identities are embedded in social/psychological interactions as social constructions between employees and their managers as representatives of the organization (Hatch and Schultz, 2004). Embodied in formal institutional arrangements (such as culture) are legitimating processes which critical writers suggest organizations use to shape their employees’ identities (Alvesson and Willmott, 2002) thus creating a sense of belonging to and identification with the organization. This can manifest, proposes Rousseau (1998) as both deep structure organizational identity and situated identity. Situated identity fosters a sense of we-ness via its focus on situational cues, tasks and teams. On the other hand, deep structure identification is described by Rousseau (1998, p. 222) as fashioned through “exchange relationships where employee and employer act to benefit each other and when the locus of control shifts from individual to firm”. Such a process may flourish in strong corporate cultures, but might also be viewed cautiously by some (see Alvesson and Willmott, 2002) as further attempts to secure organizational control of employees’ organizational identification.",1
53,16,"Driver (2009, p. 55) comments, “there continues to be vibrant dialog about what organizational identity is or should be ...”, but suggests that there are less conscious identity processes than the cognitive explanations in much of the literature. Rather than look for functional explanations, she suggests a less definable and determinate understanding of identity is possible using psychoanalytic theory. Driver (2009) adopts a Lacanian notion of the imaginary character of identity discourse. Harding, (2007, p. 1763), also referring to Lacan, challenges the “self-evident truth of the self” suggesting it is, “... nothing but imaginary, an imagined object, one that is a lack, a negative, a void we seek to fill with others’ recognition”.",1
53,17,"Organizational “identities” are narrative constructions, conversations which reflect or impart the deep, enduring character or identity, not only of the organization (Whetten, 2006) but of the individual (Beech, 2008). Employees respond, say Dutton et al. (1994, p. 239) to organizational images, thus enhancing self-esteem and making them voluntary members of, and contributors to, the organization’s symbolic order. This is consistent with the agility and complexity of individual identity found in Tracy and Trethewey (2005) who use the crystal metaphor to convey identity’s inaccessible but multifaceted nature.",1
53,18,"Belonging to a symbolic order is nevertheless problematic (Brown, 2006) when the order becomes disturbed. While Driver (2009) views identity crises as positive steps to “wholeness”, she suggests that such a disturbance is more likely to be recognized as negative, as a failure and a lack, instead of an opportunity to respond to one’s own deep human essence. Moreover, identification’s problematic notion is critically reflected in Rousseau’s (1998, p. 231) conclusion to her paper where she warns that whilst “deep structure identification can be expected to promote employee retention and flexibility in response to change, it is not appropriate for all forms of employment relations”.",1
53,19,"Corporate culture management reflects managerial designs whilst psychological contract reflects employee perceptions of such changes and impacts on the investment they make in identifying with the organization. These perspectives come together in an adaptive way as employees structurate formal rules and resources. Together, they offer the possibility of co-production of meaning as negotiated practice.",1
53,20,"A theory offering insight into an alternative understanding of the possibilities of negotiated practice is Giddens’ (1976, 1984) structuration theory, described by Poole and McPhee (1983) as an inter-subjective construct that brings members’ perspectives together. Giddens (1979, p. 66), defines the duality in structuration as “conditions governing the continuity or transformation of structures, and therefore the reproduction of systems” via the application of generative rules and resources.",1
53,21,"Poole and McPhee (1983) and Poole et al. (1985) propose structuration as an organizational theory, positing that formal structures and agents act in mutually constitutive ways. Bastien et al. (1995) writing on organizational climate, support Giddens’ argument that individuals are neither purely free nor pawns at the mercy of social structural forces. Studying organizational climate, they use structuration theory to emerge what they call “kernels” of structure agency duality. Whittington (1992) theorizes manager agency, noting that managers, by following their own ideology, adopt an agency role. Festing and Maletzky (2011) employ structuration in their examination of cross-cultural leadership adjustment as a reciprocal process. Leydesdorff’s (2010) focus is on communication and expectations such that organizations engage in structured structures and structuring structures as reconstructive of each other.",1
53,22,"The expansion of structuration theory by DeSanctis and Poole (1994, p. 12) as adaptive structuration theory (AST) along with its technological application, finds clarity in their comment, “...technology does not determine behavior; rather people generate social constructions of technology using resources, interpretive schemes and norms embedded in the larger institutional context”. This interplay between embedded formal institutional structures and human interaction, which allows constitutive adaptation, is a theme running through literature on structuration (Festing and Maletzky, 2011). Witmer (1997) one of the few scholars to link structuration theory to organizational culture suggests the theory provides a fuller understanding of organizational phenomena and this study expands the thinking to adaptive culture structuration.",1
53,23,"We define adaptive culture structuration (ACS) as the interplay between managerially espoused values, employees’ epistemic analyzes and managers’ engagement in negotiated practice. The difference between ACS and DeSanctis and Poole’s (1994) AST lies in the dynamic interplay of two human forces, managers and employees as power holders. Notwithstanding issues such as managers’ asymmetrical power and the less visible employees’ agentic power, they “act upon” organizational rules and resources in a particular way. A first assumption of successful ACS activities is that both managers and employees are free to make their interpretations and assessments visible to the other. A second assumption is that an organizational environment will be designed in which both groups can engage in learning with and from each other. For this purpose, we suggest a “negotiated space” which takes the form of an ACS environment. A third assumption is that changes in deep and generative “values-promises” shall be addressed and explained by managers.",1
53,24,"We conducted a study within an 800-strong division of a large financial institution which had itself been recently acquired by a much larger financial entity. The opportunity arose for a small exploratory study during the unfolding of a new culture change initiative, administered by senior managers and a human resource department.",1
53,25,"Discourses were managerially initiated and, using a variety of formal and informal communication processes, designed to persuade. Values-orientated activities, during which “required values-based practices” were transmitted, occurred frequently. Additionally, they were discussed and practiced at team meetings and further enriched in values-focused, interactive workshops. Over the calendar year, every employee was expected to attend a “vital-values” three day, live-in retreat.",1
53,26,"The researchers were interested to explore qualitatively the meaning employees attributed to the espoused values and their interpretations of living through cultural change. Emerging from the data, and not appreciated going in to the study, were issues pertaining to employee perceptions of values as deep, shared and abiding promises, of organizations as sites for deep structure identification and the capabilities of employees to interpret, assess and judge the validity of received messages (for example, the espoused values) in terms of managerial behavior. These issues were brought to light for a number of the respondents through negatively interpreted interruption experiences – critical incidents – and revealed in their reported epistemic evaluations.",1
53,27,"Turning to the research design (see Table II), and the choices and actions involved in this exploratory investigation, we interviewed twelve employees regarding personal and organizational values at a time when they were living through a managerially designed culture change initiative. This proved serendipitous, and flexibility was needed to allow unforeseen constructs to emerge. Our particular research questions initially guiding this study were: How do employees narrate their personal values, their work values; and their organization’s values? and How do employees’ work and personal values intersect with organizational values? Interview data were supported by organizational documentation (see Creswell, 2012) which explicated the new values.",1
53,28,"In the sense described by Fenton and Langley (2011), employees’ narrative accounts of living through the culture initiative were incorporated into the study at the design stage. The semi-structured interview protocol supported the narrative interview approach, “a mode through which individuals express their understandings of events and experiences” (Mishler, 1991, p. 68). Second, in keeping with the interpretive epistemology selected, we sought to primarily elicit participants’ subjective stories and interpretations and therefore, the relationship between researcher and participant was interactive and intersubjective and established through one-on-one conversations.",1
53,29,"A six-stage research design included: literature review; preliminary fieldwork; data collection; data analysis and management; results; further literature review (in particular, structuration theory (Giddens, 1976, 1984) and discussion. Table II shows the reasoning and actions of data collection analysis, management and the audit trail element of rigor.",1
53,30,"The pathway to developing themes began with a decision about the unit of analysis. A respondent utterance related to the cultural initiative was chosen. The second decision was whether, at the beginning to open code or invivo code. Invivo coding was chosen and where possible throughout the data analysis activity authentic responses were used as labels. The constant comparative method entailed identifying incidents or comments and locating them in a category of meaning. Properties of each category contained codes that “belonged” together, including sub categories; for example positive cases, negative cases, cases that linked to other categories (see Figure 3).",1
53,31,"Category formation in the beginning was expansive so as to allow gradation of meaning. As the analysis developed, categories were considered within the broader context of themes and this echoes Cortazzi’s (1994, p. 160) approach, “... if the evaluations in a large number of stories, told on a specific topic by a particular occupational (or other) group are isolated, collected and analyzed they will reveal speakers’ cultural perceptions on that content”.",1
53,32,"Concurrently with the thematic development, literature was accessed for theoretical sensitivity (Glaser, 1998). Corporate culture literature going in to the study was expanded to contain more critical literature. The identity literature was similarly expanded to include Lacanian theorists such as Driver (2009) and Harding (2007) who undertook a Lacan-ian analysis. As suggestions of unmet expectations further developed, theories of psychological contract informed the analysis. This was especially so in the case of Rousseau’s (1998) deep and situated structures of organizational identity. As it became evident that employees as agents were active and creative in reconstituting messages and promises embedded in the cultural initiative, the literature on agency was used for concept development.",1
53,33,"Initially, respondents were accepting of the espoused values-in-use (no participant spoke negatively about any of them), for it seemed these values aligned to their own and they readily narrated their increased personal aspirations and productivity.",1
53,34,"The success of the change process and its subsequent longevity may rise or fall on these interpretations. Rather than remaining covert and folkloric, it may be to an organization’s benefit to facilitate ways for such interpretations to become visible where they can be the “elephant-in-the-room” that all organization members can safely discuss in the form of negotiated practice. In this vein, the discussion focuses on practical workplace learning opportunities for both managers and employees, emerging from constructs presented earlier of “received practice” and “negotiated practice”.",1
53,35,"The discussion’s second strand focuses on a theorized “epistemic lens” through which employees interpret, assess and judge the validity of formal organizational structures as realized through behaviors. The third suggests ideas for construction of structurated adaptive learning environment such that managers and employees can socially interact, communicate their interpretations and assessments and discuss problems and issues that might cause the inability for some promises to be kept.",1
53,36,A distinguishing point in this study’s corporate culture cycle is that the management change initiative and cultural discourse emphasized the espoused and required shared values. Figure 6 shows employees’ positive interpretations and assessment of the validity of management’s message received by them in the corporate culture change initiative.,1
54,1,"In this paper, I reread Raymond Williams’s genealogy of the concept of culture from the perspective of the contemporary context. I argue for a more contextual approach to take note of the way the concept has changed and how it has been deployed differently in different historical moments.",1
54,2,"There is something both ironic and iconic in writing about “culture” as a “keyword,” for it was, arguably, the starting point for the genre. Famously, in the original Keywords, Raymond Williams (1976, 76) wrote that “culture is one of the two or three most complicated words in the English language.” Three years later, in Politics and Letters (1979, 154), he admitted, “I don’t know how many times I’ve wished I’d never heard the damned word,” although he never gave it up and continuously came back to it. Such statements might seem like a call to conceptual arms, for such an important concept would seem to demand either more rigorous conceptual work or a recognition that the ambiguities of the term simply serve to naturalize contingent articulations. Still, just recently, Étienne Balibar (Bojadžijev and Saint-Saëns 2004, 12) described the concept of culture as “the most confusing of all.”",1
54,3,"If, in the first instance, culture is a problem rather than a concept, we might assume that the category surfaces as an object of attention and scrutiny at those moments when culture matters because it condenses real material and experienced problems and contradictions. Any attempt to understand the concept must then look to its specific form and content at any moment and ask: What work is the category doing? What forms of disembeddedness (autonomy) are claimed for it, and what forms of embeddedness (within the social totality) remain effective, whether acknowledged or not?",1
54,4,"The story Williams tells takes place at the moment of the emergence of a selfconscious Euromodernity in the late eighteenth and early nineteenth centuries. But when retelling this story, Williams fails to take note of the moment of telling itself and this moment’s own determining effects. First among these effects is that Williams constructs a history of culture precisely because he is writing at a moment when the category itself has, once again, come to articulate a set of historical problems. As I shall suggest, at that moment Williams’s own efforts were defined by the intersection of two historical sets of problems traversing the terrain of culture. And second, although Williams tells the story of the separation of culture from society (in what he constructs as “the Culture and Society tradition”), his own project (what he calls cultural studies) is precisely to escape this tradition, to escape the separation that is at the heart of Euromodernity, and to reconstitute a social totality that has been broken apart at least in part by the very discourses he brings together.",1
54,5,"Williams’s story is about the moment when the difference between civilization and barbarity becomes insufficient for the self-understanding of an emerging Euromodernity. This distinction, whether understood in static or processual terms, was inadequate to the demanding assumptions of a world that increasingly put the human at its center, not merely as the site of rationality, but as the maker of worlds. “Civilization” as a standard of judgment was simultaneously too absolute, too superficial (focused on matters of manners and civility, for example), and too materialist (focused on displays of wealth and achievement). Instead, modern critics, over a range of political, ethical, and aesthetic positions, turned (somewhat paradoxically) to the place where the agencies of human beings and nature meetculture as the tending of natural growth—in order to find the possibility of more human, more humane, and more “interior” standards of separation, differentiation, and judgment. In so doing, modernity as culture distinguished itself not only from both civilization and barbarity but also from (pure) nature—as untended, undomesticated—and from tradition.",1
54,6,"This is the fundamental ontology of Euromodernity, a constructionist ontology of mediation in which culture is always the third term and becomes the repository if not reconciler of the contradictions of such a metaphysics of human reality as a “second nature.” If cultural mediation—meaning, value, imagination—defines the universal condition of human existence, then culture embraces the creative power of all human activities even as it privileges a subset of activities as the concrete existence of the universal. Battles over the definition and parameters of that subset (ranging from the symbolic/expressive/discursive to the “best that has been thought and said”) constantly reenact, normatively, the problem of the capacity for judging historical change. As human beings make themselves and their world (whether their selves through the world or the world through their selves), culture is the problematic answer to an impossible normative question in the face of contradiction between the universalism of mediation and the necessary relativism that the very concept of culture as the making of a second reality introduces into the world. Culture is, as Williams argues, the search for a position and standard by which to describe and judge the recursive fabrication of the modern.",1
54,7,"At the same time, the specificity of culture is defined not only by the set of activities that is privileged within a geohistorical context but also by that context itself understood as a culture, a whole way of life as it were. Culture defines not only the Being of the human, but also the particularity of and the differences among the multiplicity of humans. It is this doubled contradiction that defines the impossible logic of mediation itself, which is inevitably the last instance that never comes. That is, culture is both the fact of mediation and the content of mediation, providing both the position and standard for judging all social change. Culture itself becomes the basis of a reconciliation between the universality of culture as the specifically human and the specificity of different (e.g., national) cultures.",1
54,8,"In one sense Marx’s contribution to the question of culture was minimal, but in another sense it was crucial. Marx overturned the often-overpowering idealism of “culture” by reframing the processes by which people make their own history in terms of the practices by which they produce the very means of their lives, replacing cultural constructionism with social constructionism. Without denying the intelligence and creativity of human practice, often implicitly linked to language (although this was too often reduced to a unilinear abstract historical universalism), Marx nevertheless largely (albeit not entirely—here see the work of Lee Baxandall and Stefan Morawski [1973] and others in gathering Marx’s writings on art and aesthetics) relegated those elements condensed in culture to a secondary (superstructural) role in which they were determined or expressive but rarely determining.",1
54,9,"The problems articulated into the concept of culture were transformed into the simpler model of base and superstructure, economics versus culture, with the former representing the material dimensions and the latter reduced to largely idealist understandings for the most part. Yet two important consequences followed. First, the effects of which were perhaps not to be as strongly felt until the mid-twentieth century, was the “recovery of the wholeness of history” (Williams 1977, 19)—that is, the centrality of the social totality. More immediately, Marx’s theory of ideology no doubt helped to solidify and expand earlier arguments about the constitutive emergence of new forms of power in Euromodernity: what one might call “the ideology of ideology”—that is, the belief that Euromodernity was characterized by the diminishing role of force and coercion (at least within national boundaries) in favor of other forms of power, including ideological consent, consensus, bureaucracy, and discipline.",1
54,10,"But the place of culture in Marxist theory changed radically, especially following the Russian Revolution and its subsequent decline into Stalinism, when Russian “success” had to be seen against the revolutionary failures of the following decades in the rest of Europe and the resulting culture of defeat. So-called Western Marxism (including Lukács, Adorno, Brecht, Gramsci, et al.), as Perry Anderson (1976) dubbed it, confronted the historical contradictions between the actualization of Marx’s predictions of uprisings against capitalism and the frequent victories of capitalism by now offering analyses not only of art but also of language and ideology, of the beginnings of a culture of consumption, and even of capitalist culture more generally in order to explain why capitalism was able to win despite conditions that seemed to demand revolutionary change and why revolution took the forms of fascism when it came.",1
54,11,"Such work importantly set the grounds on which the category of culture was deployed following the Second World War, in response to both continuing and emergent problematics circulating around the concept. The result was, once again, a moment in which culture moved to the foreground and took on renewed importance across a wide range of intellectual paradigms. The story that Williams told was as much about the problems of culture in this context as it was about the emergence of the category 150 years earlier. Denning (2004) has suggested that this conjuncture posed two new challenges, which were almost seamlessly articulated to the concept of culture: first, the cold war and its resulting tripartite division of the world, which was largely understood in cultural and ideological terms, although these appealed, in the last instance, to “deeper” economic and military realities; second, the enormous expansion of the culture industries with their associated technologies and popular cultural forms as the visibly dominant part of a continuing expansion of consumer economies/cultures. To this, one might add a third (related) development: namely, the gradual disappearance of a taken-for-granted working-class culture connected with a diminishing sense of the privilege and universality of working-class politics. ",1
54,12,"But I think we would be remiss not to recognize that the context within which culture is called upon to do important contextual work has changed in significant ways even since the 1970s. It is perhaps more difficult to quickly summarize the present context since we are, I believe, still living in the midst of an as-yet-inchoate set of crises and struggles. Yet culture continues to be important: categorically, conceptually, and materially.",1
54,13,"Bennett (2005) has described the proliferation of discourses of culture in the contemporary context, to the point where culture seems almost omnipresent not only as a noun but also as an adjective. It is used to mark not only differences among populations but also lifestyles (subcultures, countercultures), aspects of social life (cultural economy, body culture, media culture), social activity (sport culture, cyberculture, technoculture), and sensuous pursuits (visual culture, audio culture). It describes forms of politics (bioculture, identity politics) and is even used to suggest the increasing dominance of culture as that upon which power acts: culture as a malleable set of behaviors that can be managed, either from above or through practices of self-management and self-fashioning. And certainly the “culture wars” have become as important in political terms as economic and ideological struggles. Some critics, including Jameson (1991) and McRobbie (1998), have even talked about the “culturalization” of society and economies.",1
54,14,"All this bespeaks a category in trouble, even as it attempts to condense and articulate a set of social and political problems. No doubt, the category of culture continues to resonate with many of the problems that have marked its operation in previous moments: questions of managing and directing change, both personal and social; of making judgments in a changing (and even) relativistic world; of constructing identities out of differences; of constructing differences and distributing values; of relating the part and the whole.",1
54,15,"The fact that the present context cannot be grasped as a totality (yet?) and that the various crises and struggles have not come together to define an “organic crisis”although it is clear that we are living in the midst of such a crisis—may suggest a more fundamental set of challenges to the domination by and the privilege of the various Euromodernities, challenges that might be said to have taken their first widely visible forms in the movements of the 1960s.",1
54,16,"The resulting searches for and struggles over new conceptions and formations of ways of being modern have propelled culture into new depths of ontological exploration. If culture has traditionally defined a terrain marked by the instability of identity in relation to practices, it is increasingly concerned with the instability of practice in the face of processes. If culture has traditionally defined a terrain marked by the negativity of differences, it is increasingly open to the positivity of multiplicities. Some intellectuals and critics, driven by the growing contradictions of culture, have sought other categories that do not have to overcome a fragmentation they themselves produce. If culture has traditionally defined a terrain marked by the conflicts between intellect and creativity, rationality and emotion, significance and signification, then these critics have offered “affect” as a challenge to the weight of culture even as they reproduce culture’s internal confusions and contradictions. Affect describes complex articulations among imagination, bodies, and expression. Affect makes visible the multiplicity of cultural apparatuses and effectivities (see Grossberg 2010).",1
54,17,"And finally, affect refuses the position of culture as the necessary third term of a dialectic between the subject and object, between the particular and the universala position in which culture has established itself as the very being of mediation (the third in Peirce’s sense). Affect proposes constructionism, mediation, without a third term. The result is that Williams’s grounding question of culture—the dialectic of the part and the whole, the material and the ideal—is now transformed into a more immediately political question of the relation between change and imagination, between the actual and the virtual—the real that is not yet and may never become actual.",1
55,1,"Invoking Zygmunt Bauman’s acute exposition of a left-critical hesitation between intellectuals as saviours and intellectuals as oppressors, this essay argues that while Bauman reveals this hesitation as crucial and symptomatic, nevertheless he leaves it unresolved. The essay shows how the human nature/ culture distinction (which is also a continuity) is, in fact, constitutive of human culture as such; moreover, the essay argues that this constitutive distinction reproduces itself within culture in terms of reciprocal hierarchies of social division – intellectual/non-intellectual, shamanistic/folk, aristocratic/popular. This pattern of vertical reciprocity is precisely what the purely horizontal axis of capitalist-bureaucratic liberalism excludes, collapsing the hierarchical axis of political culture into the horizontal false-binary of ‘left’ versus ‘right’. In this way the essay argues that the crux of an authentic resistance to capitalistbureaucratic liberalism will involve not a triumph of the ‘left’ over the ‘right’ , but the retrieval of the dynamic paradox of the vertical axis of the hierarchical communion of guiding excellence fused with popular spontaneity. The hierarchical yet dynamically educative interplay between innovators and those being constantly innovated is the organic root of human culture and the means of the authentic practice of human justice.",1
55,2,"This ambiguity is underscored by Bauman’s equally double view that the dominance of the intellectuals is specifically modern and yet also primordial. The thesis that the intellectual/non-intellectual separation is the initial social and economic division is taken from the American anthropologist Paul Rabin, who discussed the role of the inspired shaman as both undertaking to solve existing problems and to solve new ones that arise from his very claim to be in touch with a spirit-world. This seems to be regarded by both Rabin and Bauman as a ruse of power. Original social oppression therefore concerns at once a monopolization of expertise and the erection of a pseudo-expertise linked to the invention of religious delusions that prey upon human beings’ fears and uncertainties.",1
55,3,"Given this primary socio-historical diagnosis, Bauman’s approach to the European Enlightenment is infected by more than one paradox. The philosophes, as he explains, were a caste of anti-priests, whose historically unique chance came with the circumstances of absolute kingly rule, when a rule by centralized surveillance and regulation was required in order to fill the void left by the decay of the integral socio-economic-juridical role of the feudal nobility. They formed a kind of new ‘fourth estate’, by exploiting (in anticipation of our own times) the possibilities of ‘networking’ allowed by printing, faster travel and urbanization. In general they scorned at first the role of the school and the university as being too linked to clerical contemplation and other-worldliness, and sought rather a new kind of educational formation that would be seamlessly fused with reforming political purpose.",1
55,4,"Probably Bauman here exaggerates the importance of a purely secular thrust before the French revolution: as equally ‘modern’ as the few deists of this period were the larger number of Jesuits also supporting royal absolutism, or the equally large number of Jansenists anticipating Rousseau in calling for a more constitutional mode of reform in support of the claims of local parlements (Barnett, 2003: 130^67). What characterized ‘enlightenment’ was not so much ‘secularity’, which remained contested, as rather an ‘experimentalist’ approach to reform, which in its drive towards the disciplining and often the con¢ning of the masses remained much in continuity with reforming e¡orts ever since the later Middle Ages (see Taylor, 2007). Yet religious or not, these reforming drives undoubtedly sought to eradicate the superstitions, ritual obsessions and festive aberrations of popular religiosity. And in this sense they all, indeed, clerical or otherwise, composed a kind of ‘counter-priesthood’ which opposed a new rule through reason to an older priestly rule through the encouragement of ‘superstition’ itself.",1
55,5,"By affirming instead the leading role of the intelligentsia, Bauman does indeed work another aspect of Rousseau’s political outlook. Restored and enhanced freedom can only be won through the right sort of education: for freedom is not simply negative, but positive in the sense of being an autonomous fulfilling of one’s highest creative capacities. In this benign sense people must be encouraged to be free through an educative programme that will release them from the shackles of credulity and arbitrary hierarchy.",1
55,6,"However, Bauman’s enlightenment advocacy in this vein is never convincing and always arrives at the end of his books like an unwarranted conclusion that seems more like an afterthought. This is for two reasons. First, all his best work (supremely that on the origins of the Holocaust) concerns a narration of the ‘dialectic of enlightenment’ ^ a detailed demonstration of the many ways in which the intention to emancipate leads to its very opposite: to the abolition of local autonomy, to modern bureaucratic stifling of the individual and later to a more subtle postmodern stifling of the same via the erosion of public space in favour of merely market norms (Bauman, 1991). Indeed, the way Bauman tells the story, it is not even a matter of dialectic any more, since a heavily Foucauldian overlay upon Adorno means that enlightenment purposes are ‘sociologically’ unmasked as, right from the outset, basically a will to power through the acquiring of social information and the proposal of social remedies. He is by far at his most convincing when he shows in detail how the rise of a mass democratic culture in fact involved an extreme destruction of local modes of political participation and of folkways that had been completely impervious to control by either dispersed market or remote sovereign state. ",1
55,7,"As Bauman mentions, ‘ideology’ mutated into ‘sociology’. But as he disdainfully records, the claim to have discovered the pure principles of social order led to the most draconian government experiments in the re-education of all ^ like those advocated by John Stuart Mill, who was most crucially a Comtian, as Maurice Cowling (2005) rightly emphasized. It would seem, then, that the paradox of Bauman’s approach can be resolved by noting that he is still himself a ‘sociologist’: therefore he can exercise a ‘sociological’ suspicion of the seeming rationalism of the philosophes and yet continue their fundamental reform programme on the basis of ‘sociological’ insights.2 However, his evident disdain for Comte suggests that this resolution could be problematic for him: does not his more Marxisant, wouldbe non-positivist sociology rather suggest a suspicion of all clerisies? A possible redundancy of any guiding intellectual elite? But the problem then, of course, is that if the ideal is still an ‘emancipatory’ one, a quest for ‘autonomy’, then this ideal has never emerged anywhere except inside Western intellectuals’ heads. The choice for Bauman would in consequence become one between either outright populism or else a continued elitist support for ‘emancipation’. But all Bauman’s elegantly insightful metanarrative work casts extreme suspicion on the outworking of this latter ideal.",1
55,8,"One can therefore argue that consumerist freedom simply is a mass transcription of enlightenment freedom. It is because of this transcription that, as Bauman well describes, the work of the ‘legislators’ is now over and done with, and public intellectuals are confined to the more modest role of interpretative commentary. For now that everyone accepts the norm of autonomy, market mechanisms are almost sufficient to distil indirectly a public order from this norm. I say ‘almost’, for while Bauman is right to say that surveillance from a visible centre of power has diminished, he somewhat ignores our present doubling of every transaction by a record, and therefore the manner in which the economy is tracked by a bureaucracy which still keeps dispersed watch on the risks of a marketplace which increase the more it becomes deregulated.",1
55,9,"The upshot is the same as Bauman describes: postmodern government regulators simply follow procedures; they no longer require ideals or theories. But in the face of this circumstance and the rise of ‘the interpreter’ in general, is not Bauman’s final call for the restoration of the legislative role somewhat wistful? All he can do is to appeal to the lure of ‘genuine’ freedom as an ideal that a few educated people will embrace and seek to extend to others for their fully human benefit. But I have tried to show that he has no adequate metaphysical basis for speaking of such freedom at all. The nearest he comes to this are the points where he cites Richard Sennett, and speaks of the need for a debate concerning ‘the common good’ (Sennett, 1976). Here he is close to recognizing, like Alasdair Macintyre and Michael Sandel, that we cannot have ‘thicker’ senses of ful¢lment without the publicly mediated ascription of norms and roles that have been gradually shaped by a tradition. But accord with a tradition assumes that it discloses something of the nature of an objective good that exceeds mere human election.",1
55,10,"Without such a notion, Bauman is caught in an aporetic trap that is typical of the contemporary liberal left. Does he scorn the masses and their proneness to religiosity, thereby inviting the charge of elitism (besides the charge that he continues to endorse the pseudo-religiosity of intellectuals), or does he rather scorn intellectual elites, thereby compromising the advocacy of progress? Emancipation is supposed to be from unequal power inhibiting freedom, yet the power to liberate still derives from knowledge, and so we need learning in order to free ourselves both from our natural condition and from all the uncertainties and fears that are generated by that condition. But how can there be an ‘equal learning’, since learning by definition divides the learned from the less learned?",1
55,11,"In other words, because he fundamentally cannot decide whether the clerisy is good or bad, Bauman also cannot decide whether it is culture or nature that is the liberator, and in consequence cannot assign a ‘just’ and ‘justified’ position to culture over against nature, just as he cannot assign a ‘just’ and ‘justified’ position to the intellectuals over against the folk-mass of people (see Boltanski and Th ¤ evenot, 2006). Therefore what he is not facing up to is the way in which the nature/culture divide is constitutive for culture as such and reproduces itself within culture, above all as social division and as a kind of experiment that society performs upon itself in order to constitute society at all. An experiment that always involves a division (not necessarily iniquitous) between the experimenters and the experimented upon.",1
55,12,"Bauman remains a typically 20th-century social thinker in that he imagines instead that human society is a sort of charmed circle that can operate according to autonomous cultural or ‘social’ norms, while bracketing any metaphysical views about nature beneath us, spirits around us or gods above us. Most typical of such a perspective is Habermas (2009) who, in the liberal-fascistic mode of Mill, desires to outlaw from publicly valid discourse any metaphysical claims, whether these be naturalistic or religious (or at least to permit them only when ‘translated’ into pragmatic-normative terminology). But this allows a remainder of mere formal consistency, observation of what is publicly accepted as neutral fact, and collective aims towards a democratic consensus which is supposed to establish a pragmatic ‘truth’ if one can show that no-one has been prevented from contributing (in the pre-restricted terms just described) to this discourse. Yet universal formal ability to take part in a conversation is no surety whatsoever against the universal triumph of sophistry, unless we take it that truth is indeed merely whatever commands democratic assent.",1
55,13,"In retrospect it would seem that the 20th-century sense of cultural self-referentiality was merely the consequence of a religious aftermath which left behind a certain humanistic consensus that is now dissolving. It is hopeless for Habermas to say that somehow or other evolution has produced an irreducible sphere of intentional referentiality that assists human survival (2009: 151^80). For if one accepts this, then inevitably it would seem that the appropriate human uses of this sphere must be sheerly utilitarian ones, in accord with evolutionary purpose. And this is in effect to embrace a naturalistic metaphysics after all, since if ‘physical nature’ is taken to be ontologically comprehensive, there can be no real case for an ontological space for spirit or mind, and therefore we have to assume that imagining that there is such a thing as real intentionality and so forth is but a useful illusion. If, to the contrary, we hold that there can be objectively valid human ends beyond the utilitarian and beyond the mere augmentation of the possibilities for random desiring, then we have to subscribe to some sort of ontology of a spiritual realm.",1
55,14,"Is a metacritical discourse available which would point to some sort of resolution of his problems? Decisive here is the issue of whether it is possible to find a ‘just’ and ‘justifiable’ placing for the clerisy which would prevent the aporetic oscillation between seeing them as either demonic witch-doctors or as savant-saviours. And this would be in effect to return to Plato’s position for which the intellectual rulers may indeed be self-serving sophists, but need not be if they ascribe to the right metaphysics which subordinates their social height in turn to the transcendent Good. Plato’s position should also be endorsed in the sense that only if those who can judge are granted their proper and highest place is it possible that all other people and things can in general (in space) and in particular (in time) be ‘given their due’ according to justice in terms of correct relative positioning. In other words, there can only be a just division of labour allowing reciprocal sharing of diverse talents and goods if, first of all, there is a division of labour between the wise (or the relatively wise) and all other social actors.",1
55,15,"This sounds of course for us today totally unacceptable. There aren’t supposed to be any people who ‘know better’ than others concerning values as opposed to facts. But we have just seen how a modern sociologist like Bauman symptomatically oscillates between a suspicious total rejection of anyone ‘knowing better’ and an all too hyperbolic embrace of that very idea. Do we not need instead a more modest notion of ‘organic intellectuals’ (in a non-Leninist sense) whose educative knowledge would be somewhat distanced from immediate exercise of power and whose social experiments would be more subject to the test of populist feedback? Further, do we not need such intellectuals to be less contemptuous of the folk-wisdom of ages which has stood the test of time? Is there not something highly ironic about the way elite experimenters tend to distrust the most long conducted experiments of all? Here we should heed the insight of Bruno Latour when he says that the worse naivety is the naivety of the learned and the iconoclastic, who nearly always over-estimate through caricature the naivety of the beliefs which they call into doubt (Bauman, 1999: 266^92).",1
55,16,"However, Bauman himself speaks of circumstances of something like ‘just balance’ in the roles of elites. This is the medieval situation in which noble rulers were also landowners, in symbiotic interaction with popular participation. Likewise, as he does not mention, clerical teachers were locally rooted and in symbiotic interaction with popular piety. Obviously this balance was very far indeed from being perfectly just. But that is not really what matters. Of far more significance is the point seemingly overlooked by Bauman (but not, of course, long ago by Tocqueville) that popular participation can only be enabled if one has an ‘organic’ intelligentsia. Unless, that is, one thinks that the role of the clerisy can be abolished altogether; but for reasons I shall explain presently, I do not think that that is possible ^ the nearest one gets to this is the thoroughly sinister domination of a hidden monied and technocratic elite as prevails today and is so well described by Bauman himself. The counter-historical question one has to ask here is: was a different development out of the Middle Ages possible ^ one partially adumbrated by ‘guild theorists’ like Bodin and Althusius in early modern times (see Black, 1984)? ",1
55,17,"It is this educatively transitive condition of human beings which tends to ensure a division between the relatively informed and articulate and those less so. However, if one were asked to choose between the justice of a religious as against a secular clerisy, then surely it is obvious that the former is more organic and less removed from folk wisdom. For the prestige of the shaman is established not simply by his ability to articulate the myths and organize the rituals, but also by his unique ability to return to the dreaming ‘infancy’. It is not therefore simply that he speaks but also that he kenotically speaks the mystery. And it is the mystery that is more the common property.",1
55,18,"It could be, then, that typically modern, critical, secular thought poses the wrong sets of alternatives. In trying to get rid of the religious it also threatens to get rid of demotic culture and of the kind of learned elite who are less likely to repress this culture, even though they are needed to guide it ^ this function being itself a component of the popular, from the beginning and for all times, just as folk tales so generally concern kings and queens. We construe our modern politics as high versus low, right versus left ^ but suppose instead that the real political crux is the triumph of the middle and the possibility that only the natural organic alliance of high and low can question this triumph. After all, an aristocratic right without a popular left has engaged only in either nostalgia or a kitsch gloss upon the middle, while a popular left without an aristocratic right has usually and in whatever complex disguise (including most Marxisms) merely promoted a resentful aspiration of the masses towards the middling mode of economy and culture. Is it not by now obvious that, as John Ruskin suggested, any viable resistance to the capitalist-bureaucratic liberal centre would have to come from a continuously dynamic and paradoxical blue/red fusion of guiding excellence with populist spontaneity?",1
55,19,"Should one therefore conclude that Bauman’s better insight is into the sinister face of enlightenment and that we should turn our backs upon its legacy? That would be far too simple. For once we have endured the long human experiment upon itself, which is still underway, then we cannot unlearn the fact that it is possible to perform this experiment ^ radically to remake ourselves. Pre-modernity was but dimly aware of this possibility and we cannot now ignore its reality.",1
55,20,"Nevertheless, if we take this insight to mean: now we can remake ourselves, before we could not do so, then we go astray with a higher naivety. For once we have become aware that we can experimentally remake both ourselves and surrounding nature, then we see that, after all, to echo Latour, ‘we have never been na « |ve’ and so, in a sense, directly citing him, ‘are not really modern’ at all (Latour, 2001). For we can also see that although experimentation is now more wide-ranging and culturally central, that in a sense ‘experimentation’ is just what speci¢cally human society is.",1
55,21,"Humans emerge dreamily from an obscure semiotic threshold of the non-referential and unmeaning play of signs into semantic consciousness. In thereby limiting the play, they initially construct rituals whereby they present themselves with patterns of archetypal repeatable action. This mode of action is by no means ‘secondary’ in relation to normal action ^ rather, it enables that action to arrive in the first place as meaningful action, because such action must first of all be ‘patterned’ action, in terms of recognizable ‘lines’ of trajectory and ‘curves’ of circumscription, inducing a kind of familiar wonder. Such ritual action also permits interior reflection to arise, because ritual ‘stills’ movement and thereby allows us to ‘identify’ with it and so to identify ourselves. Ritual is an experiment ^ an attempt to see if certain patterns will ‘hold’. It is not a conscious testing of a hypothesis, because there is no hypothesis before the experiment ^ but then even scientific hypotheses (as the Baconian 17th century well knew) can only really be understood as experiments vaguely sketched out in advance. Nor is ritual only a ‘social experiment’, it is also an attempt to see if those portions of nature with which we are in relation will ‘go that way’, and if thereby certain natural forces can be enticed or so re-directed that they are recreated. ",1
55,22,"That is why, as Latour says, one should speak of a ‘faitiche’ratherthan of either mere ‘facts’ or sacred ‘fetishes’.5 And as he also says, scienti¢c facts remain faitiches because they are not natural realities which we represent, but rather things that we co-produce along with nature. Nor, anymore than rituals, are they exactly planned: instead we are, as Latour says, ‘surprised’ by the arrival of the experiment and its result. They both ‘occur’ to us, because both ourselves and nature are jointly caught up in an arriving event.",1
55,23,"Because, to the contrary, the ritual-experiment which shapes humanity is the work also of nature, it is never possible to exclude metaphysical considerations or to decide that invisible or half-visible actors like motions, genies or genes are unreal. Only Bentham’s utilitarianism requires, as he said, that all such entities be seen as convenient fictions, because for Bentham the only thing that counts as socially real is the subject of physical or sensory stimuli that the mind can (supposedly) quantitatively represent to itself (Bentham, 1959). But if our world is composed of faitiches,thenit is composed of inscrutable and undoable relations and we do not know what is really at work, even though we are bound experimentally to speculate about this if we wish to have meanings and so a social order at all. As Latour says, once one has tried to deny the space of mind and has rightly denied that it is ‘inside’ the brain, then one is left wondering just where imaginary entities do belong and, short of complete naturalistic reductionism (which is theoretically unwarranted), it becomes possible once more to think of them as being ‘out there’ as well as ‘in here’ (Latour, 1999: 285^6).",1
55,24,"Or to put this another way: if culture itself includes and is constituted by the nature/culture tension, then there is, for a metacritique, no critical possibility of deciding that meanings or imaginings, spontaneities or purposes, are not just as natural as they are cultural. Inversely, one cannot necessarily conclude that cultural nomos is any exception to the habituations of physis.",1
55,25,"For the ritual which initially composes human culture is a kind of experimental risk that can itself only be established through habit (Ravaisson, 2008). As risk, it is also the gift of instruction from an initiator which sacri¢cially breaks the deadlock of potential human isolation, and as habit it is something which has ‘worked’ with the populace, often through modi¢cation, and so has been received.6 Ritual is in this way indissociably aristocratic and democratic. The same applies to the experiment. But a society like ours that has become excessively ‘experimentalized’ is one in which a scienti¢c aristocracy totally dominates the mass of people, such that the real secret of their attempted control of nature is the control of society itself. It is this culpable elitism which is reproduced by the illusion of representation where representations ‘capture’ facts, just as experts manipulate populations. Here ritual has ceased to be a gift of wisdom but become instead either an imposed law or a contract enforced by a wealthier party. And its reception is either punctiliar or identically repeated without variation. It is no longer received as an authentic habit which imparts an artistic or craft skill.",1
55,26,"This does indeed involve the role of money, but of money as a measure of proportionately relative socio-ethical value, as Aristotle suggested. The individualistic will of Cohen to evade all comparison is actually, as explicitly declared by other communistic socialists like Boris Groys and (curiously) Alain Badiou, a will finally to evade all number in favour of a purely linguistic or else subjective articulation of social reality (see Groys, 2009; Badiou, 2008: 211^14). Yet this evasion cannot occur, because all words and all subjective judgements are entangled in numeration, and the refusal of all comparison is a nominalist election only of endless ‘number ones’, taken always in isolation and therefore reduced to abstract identity of essential content, whether by market or state. This refusal is in reality a refusal of justice, which follows from the rejection of a cooperative division of labour grounded in the crucially supreme (but kenotic) role of the always £uctuating class of judges themselves (without which there can be no true judgement based on the vision of the true and the good) and so of the only real means possible of resisting our current brutal hierarchy based upon the dominance of numbers alone, which Bauman so e¡ectively analyses and assaults.",1
55,27,"But the suggestion of a literal equality of capacity and resource is also finally impossible, for the reason that we have seen. Human culture simply is the hierarchical yet dynamically educative interplay between the initiators and those being constantly initiated. There is no society outside the performance of this experiment, at once upon humans by humans, upon nature by humans, and upon humans by nature, since we ourselves fully belong to nature.",1
55,28,"Perhaps the latter is all that is really going on, in which case human transcendence is an illusion. But if it is not, then we can respect what is revealed by ritual-experimental results without collapsing all the revelata into one univocal manipulative process in which it must be proud humanity that is finally the real sacrificial victim of levelled immanence. Instead, the many revelations can only fall consistently into one analogically-unified whole if, all together, they entice one transcendent reality.",1
56,1,"The literature on cross-cultural negotiation has expanded considerably over the past few decades, but the findings are often ambiguous and sometimes even contradictory. This introduction highlights the critical areas where objections are commonly raised about the relevance of national culture, the applicability of typologies that treat cultures as static, and the problem of ambiguous terminology. It may not be surprising that studies contradict each other given the ambiguity of the national cultural construct and variations in the context of the negotiating situations that are studied. The articles in this issue contribute to deepening our understanding about cross-cultural negotiation processes.",1
56,2,"The study of intercultural negotiations has immense benefits both for the practitioner and the researcher. Practitioners benefit from the ability to predict how their negotiating partner from a different culture might behave. This then gives them the opportunity to develop and pursue strategies that might better fit with the negotiating style of their counterpart. The more causally unambiguous the predictions, the better for the negotiator, and hence the preference for assessing the impact of the dominant cultural traits on negotiation processes. Researchers, on the other hand, benefit by both testing the viability of their preexisting assumptions and developing new perspectives for understanding intercultural negotiation processes. Thus the conventional question of “What traits or values are characteristic of this culture?” is superseded by questions that seek to unpack commonplace understandings about culture, such as “What traits or values are salient for this group in these circumstances?” and “How do results compare between groups?” and “What happens to the salient features when representatives of two groups interact?”",1
56,3,"The literature in the subfields of cultural psychology, and cross-cultural and intercultural negotiation studies relies heavily on the use of experimental methods. The literature is complex and burgeoning; it is a feature of the field that new editions of well-researched textbooks and survey articles appear from time to time, like Brett’s Negotiating Globally (2007), the Handbook of Negotiation and Culture (Gelfand and Brett 2004), and other anthologies and overviews such as Adair and Brett (2004), Cai and Drake (1998), Gelfand and Dyer (2000), Ghauri and Usunier (2003), and Weiss (2004, 2006). A journal search for the combination of “negotiation,” “culture” and “communication” yields almost half a million hits, as scholars examine the impact of such features as communicative characteristics on the negotiation process. The large majority of these studies are crosscultural comparisons, rather than studies of intercultural interaction. Recent studies that directly address this general issue are Fisher (2009), Leung, Bhagat, Buchan, Erez and Gibson (2005, 2011), Leung and van de Vijver (2011), Smith, Peterson et al. (2005), and Tsui, Nifadkar and Ou (2007).",1
56,4,"It should perhaps come as no surprise that the results of many studies are ambiguous. We should recognize that it is difficult to generalize and we should therefore meet the challenge rather than pretend that we have final descriptions that will provide a single sheet of dos and don’ts in a given culture. Most of the empirical articles in this special issue make generalizations about large cultural groups. Generalizations are useful, but they also have some limitations and it is perhaps in finding the right balance between generalizations and the task-related specificity of the situation that we can begin to deepen our understanding about negotiations across cultures. We begin by highlighting some of the commonly raised objections to culturally-based negotiation studies. In particular, we will critically review the four areas where concern has been raised about the utility and relevance of relying on national culture per se as an explanatory variable. We will then suggest how the studies in this special issue seek to mitigate some of these concerns and deepen our knowledge about culture and negotiation.",1
56,5,"It goes without saying that no cultural group is composed of individuals who react without reference to their multidimensional personal experiences and surroundings. First, there is the matter of size. A nation like Denmark covers a geographic area somewhat larger than Maryland, but academic researchers do not hesitate to ascribe to it a cultural identity, as they do for much larger countries, such as the United States or India. Secondly, even within a relatively homogenous cultural grouping not all individuals will necessarily demonstrate the same level of identification with the shared consensus in their national culture. This further complicates our task of getting a firm grasp of the interplay between culture and negotiation practice. In this issue, the article by Gelfand, Lun, Lyons and Shteynberg acknowledges this problem and proposes a descriptive norm approach to the study of culture and negotiation.",1
56,6,"The other point of note is that professional culture and corporate culture may be at least as significant in predicting negotiating choices as any national affiliation. This was clearly demonstrated by Salacuse’s survey (1998), where respondents from all parts of the world listed their preferences in such matters as negotiation outcome (“win-win” or “win-lose”) or negotiation process (“one leader” or “team”). While there were visible cultural similarities at the national level, there were also preferences mediated by profession, so that, for example, groups of diplomats and military personnel made markedly similar group choices regardless of nationality. In a similar vein, the relative status or role of the negotiators may trump that of national culture. Brett and Okumura (1998) and Drake (2001) report that in comparison with roles such as buyer/seller, culture is not a particularly important variable.",1
56,7,Context is therefore a serious issue in the study of culture and negotiations and it has many ramifications. The context of experimental studies is an important one. Many experimental studies on negotiation note that risk propensity in experiments may not be the same as when actual corporate contracts are at stake. Negotiators may behave differently in intracultural as opposed to intercultural negotiations. Graham (1990) uses acculturation theory to explain how a less powerful national group in an experiment adjusts to the more powerful host group’s culture.,1
56,8,"It would seem that the higher the level of role and power difference, and the higher the level of uncertainty and ambiguity in the situation, the more important it is for studies to explore the interaction between culture and context, an observation that has been echoed by Leung et al. (2005). In this issue, the article by Kumar and Patriotta addresses this point, suggesting that a “tertius iungens” or third person that joins may help with the process of sense-making that can reconcile task- and culture-related ambiguity in cross-cultural negotiations.",1
56,9,"Many studies use data from one or more nations as examples of a larger, regional culture, such as “East Asian culture,” “Arabic culture” or “Latino culture.” Two articles in this issue address the idea of cultural characteristics that apply to a large group of people. In one, Ramirez-Marin and Brett advance the idea that a cultural construal turns the accepted sequence of cause and effect upside-down: for relationship-oriented cultures, such as the Latino culture, the relationship itself may be on the table and business may spring from the relationship, rather than vice-versa. In the other article, Ott studies bundles of characteristics as a basis for predictions; she tests the possible clashes that may occur for three large, aggregated negotiation styles (linear-active, multi-active, and reactive), which are synthesized from regional characteristics such as time sensitivity, use of information and level of agency. It would appear that while the idea of regions and cultural groupings is vaguer than nations, it is also easier to handle in terms of broad expectations and predictors of possible conflicts.",1
56,10,"The second challenge that we need to consider is closely related to the idea of cultural typologies (e.g., Hofstede, Hofstede and Minkov 2010). These typologies do not lead to clarity in assessing the impact of culture, as various empirical studies often stand in opposition to each other.",1
56,11,"The extent of agency is also in question. In this issue, the article by Maddux, Kim, Okumura and Brett argues that in contrast to their Japanese participants, Americans treat the individual person as the locus of agency and responsibility i.e., the same feature that was shown to be characteristic of un-American thinking above. In comparison, their Japanese group would express regret in a manner that represented not their personal responsibility, but rather regret on behalf of the system or organization, which was seen to have agency – i.e., the feature that was singled out as Western style thinking in agency ascription above.",1
56,12,"Similarly, stereotypes that come from decades of both surveys and collected anecdotal evidence from negotiation practitioners can point in different directions. For example, in two articles in this issue, two different assumptions spring from the accepted idea that for some cultural groups, relationship matters a great deal. Ramirez-Marin and Brett make the assumption that since Latinos are relationship-oriented they make low initial demands and tend towards integrative deals; in Ott’s article the assumption of relationship-oriented Latinos is inherited from Lewis (2006) who, however, expects inflated initial demands and large concessions. Other relationship-oriented negotiation cultures like Russia will reportedly trade very little information and hence tend to make distributive deals.",1
56,13,"Consider also the finding that Americans are seen as prone to a fixed-pie bias, because they strive for fair solutions (Leung and Tong 2004), while other studies suggest that Americans are seen as seeking creative solutions, because being egalitarian, they have a freer mandate than a partner tied by a hierarchy (Tinsley 2004). Similarly Kumar (2004) suggests that Indian negotiators are stubborn and expect to make few concessions, but in contrast to this, Hernández Requejo and Graham (2008) note that Indian offers are very heavily padded and concessions are large.",1
56,14,"The point is that there is good evidence for all of these generalizations, even when they are contradictory. It is necessary to be aware of the precise research question behind each of the studies to explore the underlying cultural assumptions of the study.",1
56,15,"For collectivism, countless studies have found explanatory value in the notion, so that a heuristically user-friendly East-West dichotomy has formed with many studies focusing on comparisons between North America, on one hand, and China or Japan, on the other. However, the notion of collectivism itself is open to interpretation, as is shown in the review by Brewer and Chen (2007), as the idea of in-group varies: the literature uses the idea of an in-group for circles of different sizes, i.e. not just family, but also extended family, friends, teams, companies or nations. This means that, depending on the specific definition used, it is possible to show that for a particular situation, the idea of connections, friends in high places and in-group favoritism is alive and well even in the most individualistic national culture, while fierce group competition, such as the goal to be number one in class, is common even in the most collectivistic of communities. We need similarities of definitions for the studies to be comparable.",1
56,16,"In a similar fashion, the idea of hierarchy acceptance or egalitarianism can be shown to be context-dependent within a given national culture (for a review of studies, see Chen, Leung and Chen 2009; Gelfand et al. 2007; Tsui et al. 2007). In interaction studies, it is natural to assume that harmony is the result of a sort of Habermasian best-argument-wins consensus process among equals. However, it is not really a paradox to find group harmony and consensus decisions that depend on a steep hierarchy, because the process may mean that those low in prestige seek to second-guess what the top wants (while egalitarian groups tend to squabble). Arguably, this kind of harmony is on the rise in the West as organizations hire staff on the basis of their declared personal enthusiasm for the structure – a stance that does not encourage dissent and, for negotiation purposes, everyone needs to know their mandate (and hence their place in the hierarchy). Corporate culture will play a large role in this, and it may or may not be influenced by the country where the organization has its headquarters.",1
56,17,"In this issue the article by Semnani-Azad and Adair takes up this challenge by differentiating elements of dominance. In describing non-verbal power moves, they show how seemingly inoffensive, relaxed posture is characteristic of their Canadian group’s stance (especially the men); this lack of care may signal a negotiator who does not have to try so very hard and thus fails to honor the opponent’s face. In comparison, the Chinese group makes use of forward-leaning, paperspreading space occupation. Thus, the unpacking of features that carry dominance eliminates the discussion of which party shows more dominance by a common standard.",1
56,18,"The fourth and last area of concern is that cross-cultural research is often accused of essentialism. Since intercultural negotiation is often carried out in the context of multi-national organizations with a multi-cultural, international staff, it is fair to ask to what extent a particular norm can be isolated as a valid cultural consensus.",1
56,19,"Bi-culturals in particular are hard to pigeonhole, as they can handle ambiguity and even switch when primed with cultural artifacts to react with a bias towards either of their two cultures (Oyserman et al. 2002). Looking for shared norms, scripts and values, which are basic issues in cross-cultural comparisons, makes sense primarily if we assume that basic norms shift very slowly (if at all) in a community. On the other hand, any survey is a snapshot of the respondents’ assumptions at a given time, and it is perfectly arguable that each negotiation creates a transient mini-culture, a so-called transaction culture, constructed by the discourse and actions of the participants. But even shifting cultural values are amenable to comparisons. For example, in 1995, Wegener and Liebig showed that values for justice differed between generations in Germany: in the former East Germany, older people tended towards egalitarian distribution, while younger people chose equity, while in West Germany, the young tended towards egalitarianism and the older generation to equity. Shifts in business values are reported to be noticeable across the generations in many emerging economies, and since discrepancies between groups in national surveys are not often reported, some aspects of ongoing dynamic shifts may be lost.",1
56,20,"The picture of shared norms can be formed by surveys, where the norm transpires from aggregated individual self-reports (“in situation X, I would do Y”) or it can come from a reference-shifted survey, where respondents report on their perception of the norms of others (“in situation X, other people around here do Y”). For a review of methods and results, see Chan (1998) and Fisher (2009).",1
56,21,"A particularly interesting case is the addition of the individual’s assessment of the norms and/or prejudices that have just been probed (“but I myself am not like that”). The discrepancy is often robust – in 1995, Billig reminded us of the many surveys that had asked the British population if the then bachelor Prince Charles could marry a Catholic, and the large majority said that personally they did not care one way or the other, but that they believed that other people would not accept it. It is impossible to gauge if this reference-shifted consensus represents a vivid concern, i.e. a cultural norm, or whether it is in fact a monument to a defunct norm after a de facto shift.",1
56,22,"In this issue, the article by Tinsley, Turan, Weingart and Aslani shows how a survey of such attitudes can contain information when mental models are compared along several tacks. The study elicits data about the assumptions that the respondents hold regarding a standard buyer/seller business dispute in America and the Middle East, with the Middle Eastern role occupied by the seller. It shows that at least off-the-cuff expectations in the surveys of younger people are different in the US, Turkey and Qatar – with Qatari respondents being more prone to imagine a solution where the Western buyer opts for compromise and face-saving for the Middle Eastern seller, while American and Turkish respondents tend towards goals that protect the buyer or their joint gains.",1
56,23,"Several of the empirical studies also explore under-researched regions such as Europe, Latin America and the Middle East. The empirical studies and the theoretical contributions in this special issue should be of interest not only to crosscultural and intercultural negotiation researchers but also to a broader academic audience interested in studying the impact of cultural influences on negotiating processes.",1
57,1,"Culture has become a legitimate concern and part of the basic conceptual toolkit in much of contemporary organization theory. This article historically traces the contested place of culture in organization theory—from acultural rationalist theorizing at the turn of the twentieth century; to the accidental “discovery” of shop floor culture by human relations scholars in the 1920s; to mid-twentieth-century explorations of informal and institutionalized relations in organizations; to presentday approaches that blend concepts from organizational culture frameworks, neoinstitutional analysis, sociology of culture, and social movement theory. This historical backdrop provides a context for raising several research questions relevant to organizational change, boundaries, and deviance. In closing, the author suggests that an analytic nexus between culture, power, and agency is emerging in contemporary organization theory that ultimately may yield a theory of society.",1
57,2,"It was not until the 1980s, however, that ideas from mid-twentieth-century institutional and ethnographic studies of organizations bore fruit in two significant developments. The first of these occurred with the emergence of organizational culture frameworks that emphasized organizations as systems of meaning and symbols; the second fused elements of early institutionalism, symbolic interactionism, and ethnomethodology into neoinstitutional theories of organizations that highlighted the cultural-cognitive construction of organizational structures and practices. From the 1980s to the present, cultural arguments and questions in organization theory have increasingly focused on the constitutive effects of culture with respect to organizational members’ inner lives, the meanings they attribute to organizational life, and the construction and maintenance of instrumental social structures. In contemporary organization theory, the study of culture in organizations has become the study of cultural organization (Van Maanen and Barley 1985; Dobbin 1994a).",1
57,3,"In the next several pages, I trace the historical ebb and flow of cultural arguments in organization theory over the past century. I use this discussion as a backdrop for discussing key culturally inflected questions about organizational change, boundaries, and deviance.",1
57,4,"Early organization theory emerged in the crux of the nineteenth- and earlytwentieth-century project of creating self-regulating markets in Europe and, ultimately, across the globe. As the cause for free markets and capitalist gain became both the utopian ends and grand motives underlying most social institutions, the rational organization, de-contextualized from local customs, came to be seen as the linchpin for realizing and sustaining market society (Polanyi 1944/1957).",1
57,5,"As markets and capitalist enterprises thrived, early organizational researchers, which Dobbin (1994a, 117) rightly pointed out produced “hybrids” of theory and “applied practical discipline,” often viewed culture as superfluous to rational organizations, if not regarding it with outright hostility. Organization theory was about the hard edge of rationality, means-end thinking, and goals. Cultural arguments, by which most theorists meant nonrational “noise,” were relegated to the study of custom and local social practice. Given the antipathy it received, culture ironically played important yet unacknowledged roles in early organization theory. This was especially the case in applied organization theory. With respect to factory life, applied theorists viewed workers’ traditions and local practices regarding the pace of work as disruptive to rational production. At the same time, they recognized the value of workers’ considerable knowledge about how factories operate. Because of these twin realizations—culture as threat and resource—applied organization theorists often developed prescriptions for disrupting and then wresting away from workers their decades-old work traditions (Hobsbawn 1974). In this way, early theorists insinuated culture into their work without explicitly acknowledging they were doing so.",1
57,6,"American Frederick Taylor’s (1912/1984) early-twentieth-century “scientific management” emerged as the purest and most famous expression of early applied organization theory. Taylor’s primary question focused on the efficient construction of workers’ tasks. His method for answering this question involved a two-step process that first harvested traditional work practices via “time and motion” studies of jobs and then restructured them into simple task sequences that supervisors and owners could more easily control and deploy. Along the way, Taylor argued that scientifically reengineered jobs should be coupled with incentive wages based on piece rates and decoupled from the bargaining power of unions and local traditions of compensation and production. In effect, scientific management stripped organizations of workers’ collective knowledge (while not touching the collective knowledge of managers and owners), only to bring it back, repackaged as “scientifically” constructed procedures. Taylor intended his system as a means to calm labor strife and substitute scientific objectivity for workers’ subjective orientations toward the rhythms of industrial work and production. The realities of scientific management, however, proved quite different. ",1
57,7,"As Taylor and Fayol attempted to create universal principles for structuring work and management, academic theorists began developing general, transcontextual laws and abstracted descriptions of formal organization. This style of theorizing is readily apparent in Weber’s classic description of “ideal-typical” rational-legal bureaucracies as rule-governed, hierarchical meritocracies with specialized career lines and rational accounting methods (Weber 1978, 956-63).",1
57,8,"The gap between cultural action and rational organization has informed analytic arguments in organization theory for much of the twentieth century (Dobbin 1994a, 119). Parsons (1956) explicitly built on Weber’s differentiation between cultural and instrumental action by arguing that the “concrete” functions of organizations, involving goal attainment and instrumentality, could be separated from the nonrational “human element” in organizations oriented toward solving “integrative problem[s]” (p. 81). Barnard (1938) addressed culture indirectly and rationality more subtly, yet still maintained their boundary, by defining organizations as cooperative systems in which members voluntarily commit themselves to organization goals. Executives play key roles in these processes by setting the moral tone for members’ full participation and effectiveness in organizations. By investing organizations with a kind of morality, Barnard could argue that rational organization emerged out of individuals’ commitments to morally infused collective goals.",1
57,9,"The analytic distinction between culture and rationality ultimately split organizational research into two camps: a larger camp investigating instrumental action (largely without reference to culture) and a much smaller camp concerned with the “softer” side of organizations, such as norms, symbols, and legitimacy. Beyond organization theory, this analytic distinction carried broader disciplinary and institutional implications. The rhetoric of whole disciplines, such as economics and portions of political science, primarily formulate frameworks about organizations based in “asocial, acultural, universal economic laws”; while other disciplines, namely, sociology, anthropology, and parts of applied psychology, ground many of their arguments in the nonrational aspects of historical contexts and social practice (Dobbin 1994a, 119). This same balkanization emerged in business schools where acultural streams of economics, finance accounting, and psychology coexist with sociology and a smattering of other social sciences.",1
57,10,"Subsequent studies involved hundreds of workers in observational experiments and a broad interviewing program to investigate workers’ experiences and feelings about work. Despite AT&T being a “progressive” company for its day, most manufacturing jobs were still incredibly monotonous (Perrow 1986). Based on results from the illumination experiments and subsequent studies, the researchers believed that the managerial attention lavished on the workers in the original illumination experiments made workers feel important, which, in turn, motivated them to work harder regardless of the physical conditions. Researchers later generalized this dynamic as the “Hawthorne Effect”—responses of experimental subjects to being studied (and feeling important) rather than the intended stimuli. More generally, Roethlisberger and Dickson (1939) argued that workers develop collective beliefs and “nonrational” values that influence their productivity. These insights laid the foundations for the human relations (HR) school, which elevated the place of workplace norms and sentiments to unprecedented importance in organization theory.",1
57,11,"For the next few decades, HR researchers examined workers’ norms and sentiments via the original Hawthorne techniques of qualitative observation and open-ended questionnaires. Other researchers, hailing from sociology, applied psychology, and labor economics, used increasingly sophisticated quantitative techniques to analyze the data gathered from highly structured surveys and field experiments. These findings formed the basis for a barrage of organizational interventions—from nondirected interviewing by sympathetic personnel staff to internal mass media campaigns to early forms of sensitivity training all aimed at reconstructing shop floor cultures “on management’s terms and in management’s image” (Perrow 1986, 83). To be sure, HR softened the hard edges of scientific management-inspired control, and remnants of HR can be found in nearly every contemporary organization in the form of personnel departments and other employee accommodations. But the HR movement foundered in 1950s as its evidentiary basis and techniques came under intense criticism (Perrow 1986).",1
57,12,"Based on his case study of the Tennessee Valley Authority published in TVA and the Grassroots, Philip Selznick (1948, 27) argued that internal “unwritten laws” and “informal associations” both subverted and facilitated the accomplishment of “official” goals in formal organizations. Selznick thus turned the old question of informal and formal structure on its head. Rather than only asking how formal structure constrained the irrationality of the informal, he investigated how the informal could channel rationality by “expand[ing] executive control” to achieve organizational goals (Selznick 1948, 27). Moreover, by using concepts like “law” and “association” to describe informal relations, he invoked language conventionally reserved for characterizing formal institutions, which conveyed a sense of permanence and gravitas to informal relations. Selznick (1957, 140) ultimately pushed far beyond this initial brush with institutionalization in his well-known treatise, Leadership in Administration, to argue that the job of leadership is to guide “the transition from organization to institution so that the ultimate result effectively embodies desired aims and standards.” Organizations begin, so Selznick claimed, as technical, instrumental building blocks. ",1
57,13,"While Selznick spun out the first versions of a functionalist institutionalism, elsewhere in the academic universe sociologists at the University of Chicago ethnographically delved into the day-to-day worlds of occupations and communities, which necessarily took them deep into the informal sides of bureaucracies. For Chicago fieldworkers, a key objective, especially inspired by Chicago faculty member Everett Hughes (1970), was to empirically map out the actual workings of occupations via close and sustained observation—more generally, to see and understand “behavior in its particular and situated forms” (Gusfield 1995, xii).",1
57,14,"Chicago-style fieldwork did not respond directly to the grand organizational portraits of Barnard, Parsons, and Weber but challenged the idea that formal organizations function as static, uniformly rational enterprises. Indeed, midcentury Chicago-style forays into organizations underscore the instability of organizations that only appear stable from afar (Fine 1984, 243). Such challenges emerge, for example, from Strauss and colleagues’ (1963) psychiatric hospital study of everyday negotiations among diverse occupational groups (doctors, nurses, patients, lay workers) about the meanings, routines, and tacit agreements of work. Their work, which drew explicitly from symbolic interactionism (coined by Chicagoan Herbert Blumer), became the basis for the “negotiated order” approach to organizations that centers on the construction of meaning in organizations via social interaction. In Boys in White (1961), Howard Becker, with colleagues Strauss, Hughes, and Blanch Geer, examined the paradoxes of student socialization and survival amid conflicting expectations at the University of Kansas medical school.",1
57,15,"Erving Goffman, while never a negotiated order theorist per se, developed a dramaturgical approach to organizations (based in Chicago-inspired symbolic interactionism) as he explored how people navigate the less visible sides of formal organizations. Goffman intended his now-classic Presentation of Self in Everyday Life as a “handbook” for understanding how organizations are sustained via individual and collective “performances” of roles and identities “within the physical confines of a building or plant” (Goffman 1959, xi). Likewise, his Asylums (Goffman 1961), long celebrated for its depiction of the vicissitudes of organizational underlives, provides a theoretical rationale for analyzing the maintenance of the self as key to organizational functioning (Morrill and Fine 1997).",1
57,16,"All of these mid-twentieth-century approaches—institutional analysis, negotiated order, and dramaturgy—as well as other culturally inflected works, such as Bendix’s (1956) comparative analysis of managerial ideologies in the rise of capitalist and socialist industry or Dalton’s (1959) analysis of the informal norms and micropolitics of managers in an American corporation, became well known to organization theorists of the time. Moreover, they inspired future generations of interactionistoriented researchers to explore the informal sides of organizations and their negotiated orders across a variety of institutional environments (e.g., Barley 1983; Fine 1996; Hallett 2007). But these frameworks did not dislodge dominant rationalist organization theory. As Barley and Kunda (1992) argued, the theoretical and managerial ideological pendulum historically swings back and forth between eras of organization theory that are almost purely rationalist (e.g., scientific management during the first two decades of the twentieth century) and eras during which aspects of culture creep into prevailing rationalist frameworks (e.g., HR, institutionalism, and the Chicago-style fieldwork/negotiated order approaches during the 1930s1950s). ",1
57,17,"As organizational culture research gathered adherents in the 1980s and 1990s, newer generations of scholars departed from the emphases of the first generation. Some researchers bought into the survey techniques used in crosscultural attitudinal research on “individualism” and “collectivism” (e.g., Hofstede 2001). Other researchers experimented with mathematical techniques to recover patterns of meanings through cultural artifacts and practices (Mohr 1998). Still other researchers drew from the humanities, adapting textual deconstruction to study gender inequality in organizations (e.g., Martin 1990), narrative analysis to study organizational change (e.g., Czarniawska 1997; Feldman et al. 2004), and critical hermeneutics to explore the possibilities of emancipatory organizational practice (Alvesson and Willmott 1992). The study of organizational culture thus helped create opportunities for “rapprochement” between organizational studies and the humanities (Zald 1996) but also fomented conflict within organizational studies. What was once a small confederation of approaches grew into a chaotic archipelago of “warring” factions fighting over differences in theory, method, assumptions about the unity or fragmentation of culture, and, especially, cultural interventions into managerial practice (Martin 1992; Martin, Frost, and O’Neil 2006).",1
57,18,"Business consultants early on recognized organizational culture’s potential for molding individuals and collaborative relations in the service of management. Building organizational cultures became akin to building communities and tight-knit “clans,” with their attendant images of mutual support, solidarity, and commitment (Ouchi 1980). Unlike HR or early institutionalism, which stopped at the level of normative commitment, applied organizational culture proponents argued for pushing culture more deeply into individual and group psyches by transforming people’s identities and selves—in essence restructuring their inner and interactional lives (Schein 1984). In this way, the rhetoric of commitment and cooperation in applied organizational culture work evoked aspects of Barnard’s (1938) arguments about the moral dimensions of organizational membership.",1
57,19,"Business consultants early on recognized organizational culture’s potential for molding individuals and collaborative relations in the service of management. Building organizational cultures became akin to building communities and tight-knit “clans,” with their attendant images of mutual support, solidarity, and commitment (Ouchi 1980). Unlike HR or early institutionalism, which stopped at the level of normative commitment, applied organizational culture proponents argued for pushing culture more deeply into individual and group psyches by transforming people’s identities and selves—in essence restructuring their inner and interactional lives (Schein 1984). In this way, the rhetoric of commitment and cooperation in applied organizational culture work evoked aspects of Barnard’s (1938) arguments about the moral dimensions of organizational membership.",1
57,20,"At nearly the same time as the first academic articles on organizational culture appeared, the first statements of what became the neoinstitutional framework were published. Like the organizational culture perspective, these pieces focused on the nonrational aspects of organizations, especially ritual, myth, and symbols. Instead of using these concepts to explore the cultural molding of organizational members (either for managerialist, critical, or emancipatory purposes), neoinstitutionalists drew on them to understand the cultural constitution of organizational rationality and structure. Building on the insights of early institutional theory, as well as symbolic interactionism and the cognitive-behavioral decision-making theories of James G. March and Herbert Simon (1958), John Meyer and Brian Rowan (1977) argued that rational instrumental organizations symbolize broad cultural myths about rationality that have come to be regarded as objective truths. Specifically, they claimed that organizations signal their conformity to the ideas represented in such myths by adopting particular structures and strategies. It is not rationality that is technically superior but rationality that communicates appropriateness, which, in turn, leads to perceptions of legitimacy and resources necessary for survival.",1
57,21,"The neoinstitutional theoretical agenda thus pushed beyond the boundaries of organizations and particular sectors in society to investigate the historical origins of modernity, including contemporary conceptions of rationality and instantiations of instrumental social organization. An underlying question informing much of this work became, Why did instrumental rational organizations come to dominate all other forms of social organization (Dobbin 1994a, 123)? Neoinstitutionalists answered this question by documenting the pervasive diffusion of cultural-cognitive models that emerged out of the Western European cultural watersheds of the Enlightenment, the Industrial and French Revolutions, and “market” projects of the eighteenth and nineteenth centuries. These models privileged Western rationalist, means-end assumptions about reality and social organization at all levels of analysis, thus creating a world culture dominated by the “Western cultural account” (Meyer et al. 1997). DiMaggio and Powell (1983) specified the mechanisms through which this diffusion operated, arguing that mimetic, normative (professional), and coercive pressures ensured institutional “isomorphism” among organizations, especially within organizational “fields” of similar producers, clients, relations to governments, and rules of the game.",1
57,22,"At the micro level, Feldman and Pentland (2003) theorize a cultural-political theory of change as it occurs through the performance of organizational routines—interdependent, repetitive actions performed by multiple parties (e.g., hiring, budgeting). Organization theorists typically regard routines as a source of stability, if not organizational inertia. Feldman and Pentland (2003), drawing from Latour (1986), argued that actors perceive routines as objective in their accounts about them, yet by performing them in subjectively different ways, they can introduce variation in patterns of action and practice. The retention of such variation can lead to incremental change over time. This approach also casts a very different light on power relations in organizations. Rather than being a function only of top-down authority or bottom-up collective action, power is relational, involving multiple lines of interaction up, down, and across hierarchies. Hallett (2007) illustrated this broad tack in his ethnography of deference and leadership during change in an elementary school. Ewick and Silbey (2003) likewise underscored the relational character of power in their narrative analysis of how powerless individuals use their working knowledge of institutionalized authority to resist it.",1
58,1,"The meanings and implications of cultural relativism have been debated for decades. Reprising this debate, Roger Sandall offers a pointed critique of the anthropological concept of culture and identifies relativism as the internal and corrosive enemy of the open society. I challenge his reading of our predicament. Considering the work of Franz Boas and his debts to the philosopher Johann Gottfried Herder, I distance the social science concept of culture from positions—the rejection of standards of truth, beauty, and morality; the belief that cultural value systems and practices are all equally true (or untrue); the valorization of primitivism—that are not intrinsic to it. Next, I consider the use of culture in the “philosophy of primitivism” and its meanings in multiculturalism and identity politics. I argue that many ostensibly relativist claims are used to serve non-relativist agendas, or hide universalistic claims in unstated but essential premises and background assumptions. Rather than a world dominated by relativism, where cultural differences are held to be inviolable and cross-cultural judgments have been rendered impossible, I see something like the reverse. Our problem is not that we overvalue cultural differences but that we underestimate them. Even in our multiculturalism, we imagine a sameness of outlook and aspiration, an unwitting projection of ourselves in the end.",1
58,2,"Roger Sandall’s story goes like this. Once upon a time, we in the West had a unified and robust scheme of cultural evolution. The scheme was hierarchical, with stages leading from tribalism in all its forms up to advanced civilization, was based on universal principles, and was “concerned with judging both aesthetic and moral values on a scale of better and worse.” Then, “something happened.” And what happened was that an anthropological concept of culture, shaped in part by an eighteenth century philosopher named Johann Gottfried Herder, “took hold in America.” The new concept emphasized the distinctiveness of each culture and value system, rejected hierarchical ordering and “all questions of quality,” and affirmed the importance of a way of life to personal and collective identity. Wielded by a contemporary “Culture Cult”—devoted to “romantic primitivism” and motivated by resentment against Western civilization—this relativistic and proprietorial view of culture has worked like a “moral acid” to level all meaningful distinctions and universal standards.",1
58,3,"There is little debate that the concept of culture, as deployed by anthropologists and other social scientists, played a critical role in discrediting linear notions of cultural evolution, the accompanying idea that the “primitives” were inferior members of the human species, and older, Eurocentric standards of comparison. Schemes of cultural evolution were very popular in the nineteenth century, embraced by intellectuals across the political spectrum, including the early anthropologists, the social Darwinists, and others. These schemes had the familiar stages of savagery, barbarism, and civilization; they were hierarchical, with societies ranked on a scale of comparison with Europe; and they were based on biological assumptions about race. One of the most important social scientists attacking these schemes as ethnocentric and racist was Franz Boas, the father of American anthropology. He and his many influential students rejected evolutionary schemes as inconsistent with the ethnographic record and entirely speculative. They affirmed a common humanity, emphasized that cultural traditions not racial differences explained diversity, and stressed cultural relativism as a descriptive and methodological tool for approaching cultures (plural), historically and scientifically. ",1
58,4,"Clifford Geertz argued some years ago in a paper titled “Anti Anti-Relativism,” that it is not anthropological theory that drives concerns about relativism but anthropological data. The steady flow of reports from the field can induce what Geertz called a “relativist bent.” The sheer diversity of human practices across the world and through historymarriage customs, courtship rituals, food taboos, aesthetic standards, metaphysical beliefs, musical forms, clothing styles, and the like—challenges our taken-for-granted assumptions about the world and our easy certainty that our way is always the best way. Reading the “news from elsewhere” for very long, Geertz suggested, can incline the “mind to an ‘other beasts other mores’ view of things,” to contemplate the possibility, to quote Pascal’sfamous aphorism, that “what is truth on one side of the Pyrenees is error on the other.” The debate over cultural relativism, then, which appears to be a debate about the wider implications of anthropological research, is, Geertz maintained, “really a debate about how to live with them.” Exposure to cultural pluralism can and does have unsettling effects, though, Geertz added, “genuine nihilism,” a rare phenomenon in his view, is unlikely to be one of them (Geertz 1984/2000).",1
58,5,"Sandall traces the culture doctrine he is concerned with to Herder; contemporary multiculturalists are his “romantic heirs.” Herder is an interesting figure and his name brings together all the strands of Sandall’s critique: the culture concept, the Romantic reaction to Western civilization, the politics of multiculturalism, and the moral psychology of resentment. Oddly, given the emphasis on Herder, Sandall is apparently only familiar with his ideas through Isaiah Berlin, whose book Vico and Herder was published in the mid-1970s. There is available an historical literature on Herder and the origins of the human sciences. That Sandall’s interpretations are uninformed by this work does not speak in favor of them. Nor does he help his case by attributing such outsized philosophical influence to Berlin. The philosopher Charles Taylor says that Berlin “helped to rescue Herder from his relative neglect by philosophers” (Taylor 1991). A noteworthy contribution, no doubt, but that is really the most that can be said. The important claim here, however, concerns the relationship of Herder to the anthropological concept of culture. Did his ideas, as Sandall intimates, somehow contaminate it right from the start?",1
58,6,"Sandall does not provide evidence for his claims. Is there any? In lieu of an easy answer, which I am not sure can be given, I want to offer two general objections to Sandall’s position. The first concerns the question of Herder’s views. Is he the Counter-Enlightenment figure that some, like Berlin, have argued him to be? The recent literature on Herder directly challenges this apparent oversimplification. John Zammito’s Kant, Herder, and the Birth of Anthropology, published in 2002, to name one major example, rehistoricizes Herder’s thinking and situates him within rather than against the Enlightenment.",1
58,7,"The sketch of Herder as opponent of important Enlightenment ideas is the familiar one. Denby’s next move is to complicate that picture, to show that Herder’s hermeneutic approach to history and his nascent anthropology are not a reaction against the Enlightenment but a part of it. To summarize: Denby argues, persuasively in my view, that Herder’s conception of culture “is much closer to a unitary Enlightenment model of civilization than is frequently suggested.” Herder’s relativism is “open to question,” he continues, because Herder “retains an ethical universalism which holds that it is possible to judge a culture by some standards existing outside it.” And, finally, Herder also “holds on to a circumscribed notion of progress, which maintains first that one civilization builds upon another, and second that the urge to improve and perfect our life constitutes a universal spring of human action....” Perhaps Herder is not some poison well after all.",1
58,8,"My second general objection to Sandall’scharges concern Herder’s influence on the discipline of anthropology. There is no question that Herder influenced anthropology; such influence has long been recognized, if, perhaps, misunderstood. Among historians, there is some general agreement that the influence runs through a German tradition from Herder to Wilhelm Humboldt, his students Heymann Steinthal and others, and on to Franz Boas. Some have viewed Herder as the originator of the notion of “cultures,” in the plural, a view challenged by the new scholarship on Herder. “Kultur,” Denby notes, “remains a singular noun in Herder.” Others, including the historian of anthropology George Stocking, have argued that Boas was the originator (Stocking 1968). Stocking’s evidence and the writings of Boas himself demonstrate that Boas in fact inherited from the nineteenth century a singular notion of culture, a concept of culture as a universal human property present to a higher or lower degree in all peoples. Only slowly did he help effect a change in its meaning.",1
58,9,"In rejecting unilinear evolutionary schemes and notions of organic growth, Boas effectively replaced cultural stages with the multiplicity of cultures. Each culture had a history; each was an integrated way of life that developed gradually and by borrowing from other peoples. In this configurational conception, Boas saw each people as having a “genius” of its own, a notion, Stocking argued, that has resonances in the social psychology of Herder. Herder held that the human spirit was embodied in organic ethnic or national forms, though this essentialist view existed in tension with other of his ideas about the connectedness of culture. The “genius” idea also had links to later thinkers like Steinthal and Adolf Bastian, whose theories of “folk psychology” had a direct influence on Boas. It even recalls nineteenth century racialist thought, whose roots too have been traced to Herder and against which Boas’ work was explicitly set. If Boas, then, retained elements of this philosophical legacy, and he did, it is also the case that he broke with it in important ways. Most significantly, he accounted for ethnic diversity not in terms of racial heredity but in terms of cultural traditions. Peoples are different because their cultures are different. ",1
58,10,"Something of the same trivializing dynamic plagues much of multiculturalism. Here, most assuredly, is the claim that we owe equal respect to all cultures, that no culture is better or worse than another. Though multiculturalism is not a single, coherent movement, its political agenda is driven by calls for the recognition and the empowerment of minority or “subaltern” groups and cultures. On this point, at least, everyone agrees. In the United States, multiculturalism evolved from a long tradition of thinking about assimilation and national identity and from past strategies for dealing with a society marked by racial, ethnic, religious and other differences. The immediate precursor in education, as sociologist James Davison Hunter argues in his Before the Shooting Begins, was the so-called interculturalism movement that was institutionalized in the public schools beginning in the inter-war years (Hunter 1994). In key respects, multiculturalism more broadly embodies many of the same ideals it inherited from interculturalism, including the celebration of difference and tolerance and the condemnation of ethnocentrism and parochialism. But multiculturalism purportedly takes diversity more seriously, stressing not simply the fact of difference but its preservation, emphasizing a vital link between recognition and identity and, in more strident forms, a deep cultural determinism.",1
58,11,"The all-cultures-are-equal principle, however, has serious problems. Taylor argues that it makes sense, is in fact righttoapproachthestudyofcultureswithapresumption of their value. But it is quite a different matter to demand as a matter of justice that all cultures have, a priori, great value or are equal. In support of such a “favorable judgment on demand,” defenders of the principle often invoke neo-Nietzschean theories, typically derived from Foucault or Derrida, that equate all standards with power. Yet because the judgment prescinds from the actual study of other cultures and the application of non-subjective standards of value (standards of excellence that are not fixed but are enlarged by actual studies), it cannot be an act of respect for other cultures. It is better understood, Taylor argues, as a form of condescension, and not in the end an expression of praise for the other but a praise of the other “for being like us.”",1
58,12,"The all-cultures-are-equal principle arises from the stress on the recognition of identities. Charles Taylor, in his influential essay “The Politics of Recognition,” draws out the connection (Taylor 1994). He identifies a certain understanding of the ideal of authenticity, combined with a democratic imperative to equality, as giving rise to universalistic claims to public recognition of two types. One is the recognition of the equal dignity of all citizens. This recognition takes concrete form in the legal equalization of political rights and entitlements. The other and more problematic claim is the recognition of difference. Boiled down, this claim has several key premises. First, individuals and groups have distinct, original identities they are called to live. Second, failing to live this originality because of non-recognition or misrecognition by others causes psychic damage. Third, dominant groups often entrench their hegemony by imposing an image of inferiority on minority individuals and cultural groups. Fourth, these individuals and groups, whose distinctness has been ignored or denied, internalize the images of inferiority and are injured by them. Therefore, public recognition cannot stop at equal dignity but must also extend to individual identity differences (genders, sexual orientations, etc.) and to the value of different cultures on an equal basis.",1
58,13,"These remarks hardly cover all the varied expressions of multiculturalism. It could be argued that if some forms are “culture lite” there are others that recognize deeper cultural differences. Perhaps there are. In movement and some academic multiculturalism, we hear of the incommensurability of cultures, of “fundamental Otherness,” “radical alterity,” and the like. In these discourses, culture, understood configurationally, is ostensibly powerful and determining of group differences. Much of this talk, however, arises from the fusion of multiculturalism and identity politics. To counter exclusionary practices, minority collective identities—racial, ethnic, gendered, sexual—areframedintermsofdiscrete cultural memberships. Each such culture has its own values and symbols, and oppression is defined as the failure of the dominant group to recognize their equality and equivalence. These cultures —women, gay/lesbian, African-American, and so on—in turn represent constituencies that make moral and political claims of the state and seek recognition and legitimacy in the wider society. ",1
58,14,"Some relativist claims about the good, the true, and the beautiful, then, are inconsistent or self-refuting, used for a normative purpose or are devoid of meaningful content. And some are not what they appear or are advertised to be, hiding universalistic claims in unstated but essential premises or background assumptions. Saying this, of course, does not rule out the possibility that some claims, made in the name of cultural difference, are the genuine relativist article. Yet many, perhaps most, are not. The ostensible relativists often turn out to have a non-relativist agenda of their own, or share assumptions about transcultural standards and values sub rosa. As the anthropologist Robin Fox recently wrote in these pages (Society, September/October 2007): “It is hard to find any fervent post-colonialist who will agree that having thrown off the imperial yoke the ex-colonial peoples should be free to choose dictatorship, theocracy, tribalism, nepotism, clitoridectomy or the rule of warlords. Respect for ‘indigenous cultures’ goes only so far.” Why? Because, Fox argues, the post-colonialists, like many others, assume that people everywhere want liberal democratic rights and “given free choice, ‘they’ will opt for a form of freedom we recognize and approve of....”",1
58,15,"This optimistic assumption of generic, culture-free sameness is pervasive. Let me offer another example, drawn from a research paper I wrote some years ago (Davis 1996). The paper concerned the public conflict that erupted over the Programme of Action at the U.N. Population Conference in Cairo in September 1994. The previous two decennial population conferences had focused on making birth control technology available, promoting family planning, and encouraging governments to set goals for reducing birth rates. The recommended programs were aimed at giving people more choice in family planning. By themselves, it turns out, such programs do not automatically change people’s view of family size. Some people use birth control to space births and not necessarily to have fewer children. From the population control standpoint, they make the wrong choice. What existing programs had failed to do, according to the secretary general of the Cairo conference, “was establish an enabling environment in which people could make the right decisions” (emphasis added). The new thing at Cairo was to add this dimension. The Programme of Action laid out key components of the “enabling environment” and outlined steps to implement them.",1
58,16,"Whom indeed? As far as I can see there is a lot of trafficking in universal values going on. There are cultural globalizers, NGOs and moral entrepreneurs out there evangelizing the underdeveloped. There are economic globalizers, multinational corporations out winning the world for capitalist modes of production and consumption. There are new and extensive efforts to ground universal values in evolutionary conceptions of human nature. With evolutionary psychology leading the way, the “human nature industry,” as Ward Cannel and June Macklin once called it, is at full production. The list goes on, including, not incidentally, the mission to plant democracy in Iraq. I do not see a world dominated by relativism, a world where cultural differences are held to be inviolable, where traditional cultures are honored, or where cross-cultural judgments have been rendered impossible. My sense is that something like the reverse is true. Our problem is not that we overvalue cultural differences but that we underestimate them. Even in our multiculturalism, we imagine a sameness of outlook and aspiration, an unwitting projection of ourselves in the end.",1
58,17,"As I write, the Anglican Archbishop of Canterbury, Rowan Williams, has come under fire for a lecture and radio interview in which he called for “constructive accommodation” with some features of Muslim religious law (sharia), and predicted that the integration of parts of the sharia into the British legal system was “unavoidable.” The response has been predictably intense. Such nervetouching moments are coming more frequently. They are reminders that there are other cultures, other normative orders, and that we live together more and more. We do not need to exaggerate differences but we also cannot wish them away either. Undoubtedly troubled waters lie ahead, and neither reassertions of ethnocentric standards nor more empty fluff about tolerance will help us navigate our way.",1
59,1,"One of the core ethical principles of nursing care is nonmaleficence, or the imperative to do no harm.1 However, the reality of health care does not always meet this ideal. The problem of health care error was first brought to light by the Institute of Medicine’s (IOM) groundbreaking report, To Err is Human.2 In this report,2 the IOM suggested that health care error was responsible for as many as 98,000 deaths annually in the United States. The IOM recommended that health care change from an individual blame response to error to a system-focused approach. The IOM drew on the history of other high-risk industries to advocate for a culture of safety, in which errors and near misses could be used as opportunities to learn and improve. Many efforts have been initiated since the IOM’s 2000 report to decrease the incidence of health care error. However, health care has not yet achieved the success of other industries with high potential for error, such as aviation or the nuclear industry.3 Chassin and Loeb report that “no hospitals or health care systems have achieved consistent excellence throughout their institutions,” and the rate of health care error may be even higher than originally estimated.",1
59,2,"The Agency for Healthcare Research and Quality (AHRQ) reports that the term culture of safety originated with high-reliability organizations (HROs). An HRO is an organization that operates with a high potential for error but has few adverse outcomes.6 The nuclear and aviation industries are among the more commonly referenced HROs. The comparison of health care and aviation is useful in showing the disparity between HROs and health care institutions. James7 estimated that the death rate in the United States caused by hospital-associated preventable harm may be as high as 400,000 people annually. Weick and Sutcliffe6 pointed out that this number is the equivalent of 2 747 passenger jets full of people crashing every day of the year. A situation like this would be untenable to the aviation industry, yet in health care it is simply business as usual.",1
59,3,"According to the Joint Commission, a safety culture is one that promotes trust and empowers staff to report errors, near misses, and risks. The Joint Commission defines safety culture in health care as “the summary of knowledge, attitudes, behaviors, and beliefs that staff share about the primary importance of the well-being and care of the patients they serve, supported by systems and structures that reinforce the focus on patient safety.”8 It is important to note the emphasis of a safety culture on systems, not only on individual health care workers. However, individual workers affect the safety culture by the contribution of their own attitudes, knowledge, and behaviors.",1
59,4,"The system focus in safety culture is key, because problems with safety often originate from the system itself. Reason9 refers to individual error as active error and systems error as latent error.9 An active error is one that occurs at the sharp end of health care. This is an error with immediate consequences, committed by a frontline worker. An example is a nurse who failed to check a patient’s identification and gave medication to the wrong patient. Latent errors, on the other hand, may be hidden until they combine with other factors.9 These errors typically involve those removed from direct care, such as managers, administrators, system designers, and maintenance personnel.9 In the example given earlier, if a faulty or cumbersome barcode scanning process contributed to the nurse not identifying the patient, a system or latent error would be at work. Reason9 indicates that latent errors are the greatest threat to complex systems and are the root cause of most error. Reason’s model for error is often referred to as the Swiss cheese model. Holes represent places where the potential for error exists, but these are often offset by other system and individual defenses. Error reaches the patient only when the holes line up and defenses fail.",1
59,5,"Frankel and colleagues11 have indicated that accountability is a key factor in safety culture. Accountability occurs when workers are not only able to admit their own concerns but also comfortable monitoring the work of those around them. The simple issue of hand hygiene is 1 example of how accountability can be improved. A recent Centers for Disease Control and Prevention study12 found that there are more than 200 deaths daily in the United States from hospital-associated infection. This 1 type of adverse event alone accounts for approximately 75,000 preventable deaths per year. Hand hygiene compliance is the most effective way to prevent this type of error, yet compliance rates average only 40%.3 The Joint Commission Center for Transforming Healthcare lists accountability as a key strategy to help promote hand hygiene compliance.13 They recommend that every employee, including management, physicians, housekeepers, and chaplains, be held accountable for performing hand hygiene at the appropriate time, as well as helping to monitor the hand hygiene of other employees.13 Just in time coaching is 1 approach to increasing accountability. For those without access to hospital training on these types of strategies, You Tube videos can help to show this type of coaching in action. ",1
59,6,"Although a key component of a safety culture is trust, trust cannot be achieved without the assurance that workers will be treated fairly. When the responsibility for latent error falls exclusively on the frontline worker, a safety culture is hindered. The concept of a just culture is used to refer to a fair and reasonable response to error, or what is sometimes referred to as a nonpunitive response to error. The American Nurses Association (ANA) has issued a position statement19 supporting the concept of just culture in health care and recommending that direct-care nurses advocate for its use in their institutions.",1
59,7,"Marx contended that punishment for slips, lapses, and mistakes has little to no impact on those who did not intend to make an error. In health care, Marx reports, our current system of discipline often places more emphasis on the outcome of the error, rather than the action behind it. An error in which a patient is seriously harmed, even if it was caused by a simple slip or lapse, results in discipline to the health care provider more than reckless conduct that did not result in harm. For example, a nurse who administered a harmful dose of a medication to a patient because of a lapse in attention may be disciplined more harshly than a nurse who administered aspirin instead of acetaminophen and deliberately disregarded safety procedures.",1
59,8,"A just culture is one that promotes trust and enhances reporting. Responding to error by analyzing the behavior, rather than the result, as well as examining system or latent causes for error, gives frontline workers the security to report problems. A safety culture cannot exist without a just culture. A culture that is overly harsh or punitive simply results in errors being hidden and underreported. Safety is 1 area in which the idiom “no news is good news” does not apply.",1
59,9,"A patient transition occurs when a patient moves from one care setting to another, or from the care of one health care worker to another. Handoffs are the communication between health care workers during these transitions. The period of handoffs and transitions has been documented as an especially dangerous time for patients. It has been estimated that up to 80% of serious medical errors may be related to miscommunication during health care provider handoffs.",1
59,10,"Despite the best efforts and intentions of workers, errors and near misses still occur. When they do occur, it is essential that frontline nurses are aware of best practices in managing error. Two practices are discussed in this section: root-cause analysis (RCA) and supporting the second victim.",1
59,11,"Nurses involved in RCA should be prepared to look at errors and near misses through the lens of these factors, rather than just identifying the active cause of error.",1
60,1,"Microfluidic cell culture devices allow for perfusion culture of three dimensional (3D) tissue, which mimics the flow of blood in vascularized 3D tissue in our body. Here, we report a microfluidic device composed of a detachably assembled microfluidic chamber chip and multi-microwell array chip. This device enables the perfusion culture of spheroids in a microarray format and subsequent detailed post-culture analysis of the spheroids collected from the disassembled device. The microfluidic device provides four simultaneous advantages: uniform spheroid formation, growth analysis in a microarray format, controlled proliferation via perfusion flow rate, and post-culture analysis of collected spheroids. We used the detachably assembled microfluidic device to culture spheroids of human hepatocellular carcinoma (HepG2) cells under two controlled perfusion flow rates. HepG2 spheroids exhibited greater cell growth at higher perfusion flow rates than at lower perfusion flow rates, and exhibited different metabolic activity and mRNA and protein expression compared with static culture conditions. These results show the potential of perfusion culture to precisely control the culture environment in microfluidic devices. The detachably assembled microfluidic device is a convenient approach for post-culture analysis after perfusion culture.",1
60,2,"Three-dimensional (3D) cell aggregates emulate in vivo microenvironments more accurately than do conventional two-dimensional monolayer cultures [1, 2]. In particular, spherical multicellular aggregates (spheroids) display tissue-like architectures and are able to maintain the liver-specific functions of hepatocytes [3], provide hypoxic conditions for cancer cells in therapeutic studies [4], and induce controlled differentiation of stem cells [5, 6]. Recently, in addition to several other research groups, we developed spheroid arrays by using a microwell structure that enabled the mass production of spheroids with controlled diameters [7-14].",1
60,3,"Generally, nutrients and oxygen must be supplied to spheroid cultures [15, 16]. The removal of waste is also important for cell culture [17, 18]. Many research groups have created microfluidic devices that enable control of the mass transfer of nutrients and oxygen in the perfusion culture of spheroids [19-28]. However, most of these devices allow for the formation of only one spheroid per chamber, or spheroids are only formed in a few chambers [19-27]. For practical drug-screening applications, the production of spheroids in a microchamber array is desirable for high-throughput analysis on a single chip. A perfused multiwell plate for 3D liver tissue culture has been designed that allows for the control of oxygen supply and cell viability; however, this device produces non-uniform spheroids [29]. In addition, array-formatted spheroids are essential to investigate the effect of nutrients and oxygen supply. However, only a few devices reported in the cited studies have been capable of perfusion culture of a spheroid array, probably because of the difficulty associated with loading cells uniformly into the microchambers. On the other hand, we have reported a multi-microwell array chip that was used to produce a high-density spheroid array with uniform size [6-11]. ",1
60,4,"In most of the perfusion culture microfluidic devices previously reported, it is difficult to collect the spheroids after culturing because the spheroids were cultured in closed microchambers [21-30]. This limitation prevents further biological analyses, such as mRNA and protein expression analyses by applying off chip traditional analytical methods, including polymerase chain reaction (PCR), and southern and western blotting, to perfusion cultured spheroids in a microfluidic device. Therefore, the detailed mechanisms of the effects of perfusion on spheroid culture remain unknown. In fact, for array-formatted 3D liver tissue cultures, only viability and cell morphologies have ever been assessed [29].",1
60,5,"In the present study, we addressed these issues associated with perfusion culture of spheroid arrays by constructing a detachably assembled microfluidic device composed of a microfluidic chamber chip and a multi-microwell array chip. The combination of microfluidic chamber chip and multi-microwell array chip enabled precise control of the spheroid perfusion culture in an array-formatted geometry. Furthermore, our reversibly assembled microfluidic device enabled detailed post-culture analysis of the spheroids after perfusion culture. Using our detachably assembled microfluidic device, we cultured human hepatocellular carcinoma (HepG2) cells under controlled perfusion conditions and analyzed the effects of perfusion on spheroid culture.",1
60,6,"Figure 1E shows an enlargement of a culture chamber in the assembled microfluidic culture chip. The microfluidic network on the microfluidic chamber chip was designed based on the perfusion culture microchamber array chip in our previous report [30]. The flow rate of the culture media in each culture chamber was determined by using the dimensions of the fluidic resistance channels and the pressure applied to the medium-inlet ports. The fluidic resistance channels are significantly narrower than the other channels and so exhibit the largest fluidic resistance in the microfluidic device. The design of the multi-microwell array chip was optimized for the spheroid culture in our previous report [9]. In the present study, an 8 × 8 array of microwells (diameter, 300 μm; depth, 300 μm; pitch, 330 μm) was fabricated in each culture chamber (Fig. 1F) (detailed materials and fabrication protocols of the microfluidic chamber chip and multi-microwell array chip are available in Section S1 and S3 Supporting Information).",1
60,7,"To evaluate the integrity of the seal created by the fixtures, colored dye solutions (Red: New coccine, Green: Fast green, Blue: Gardenia blue, Yellow: Gardenia yellow, Wako Pure Chemical Industries, Osaka, Japan) were introduced into the microfluidic device by applying a pressure of 7.2 kPa (Fig. 1G). To detect the colors easily, a transparent PMMA support frame was used instead of the stainless steel support frame. No leakage and no mixing of the solutions were observed, indicating that the microfluidic chamber chip and the multi-microwell array chip were sufficiently sealed by the fixtures.",1
60,8,"The viability of spheroids under static culture and low-flow-rate perfusion was evaluated on day 7 of culture. The microfluidic device was disassembled, and the spheroids were washed with Dulbecco’s phosphate-buffered saline and stained using a live/dead viability kit (Life Technologies, Carlsbad, CA). Images of the spheroids were obtained by an IX-71 inverted microscope (Olympus, Tokyo, Japan). Brightness and contrast of the obtained images were adjusted for clear visibility of live and dead cells",1
60,9,"Glucose consumption and lactate production were evaluated as an index of basal metabolism. The concentrations of glucose and lactate in the culture medium were measured using a glucose test kit (Wako Pure Chemical Industries, Osaka, Japan) and a Lactate Assay Kit II (BioVision Inc., Milpitas, CA), respectively.",1
60,10,"Molar ratios of lactate production and glucose consumption, albumin synthesis, cell number, and mRNA expressions are presented as mean ± SD and correspond to 2 to 10 time points. Statistical analyses were performed by using repeated-measures analysis of variance. Values of P < 0.01 and P < 0.05 were considered significant.",1
60,11,"Figure 2 shows phase-contrast micrographs obtained under static, low-flow-rate perfusion, and high-flow-rate perfusion culture conditions at 3, 7, and 10 days of culture. Under all culture conditions, HepG2 cells aggregated within 1 day of culture and spontaneously formed one spheroid in each microwell after 3 days of culture, which is consistent with our previous studies [9-11]. HepG2 cells adhered to each other because the surface of the microwells was non-adhesive, much like a rotating flask. Under all culture conditions, the HepG2 cells proliferated while maintaining spheroid morphology for at least 10 days of culture, and spheroid size continuously increased. Fortunately, the inoculation process before assembling the microfluidic device prevented the cells from accumulating in the microchannels of the device, which would have led to cell proliferation and blockage of the microchannels.",1
60,12,"The changes in diameter of the HepG2 spheroids are shown in Figure 3C. Under static culture, the increase in spheroid diameter had slowed at 7 days of culture and followed by increase moderately until 10 days of culture, which was similar to the results in our previous report where we examined the static cultivation of spheroids in multi-microwell chips containing large numbers of wells [8]. In contrast, spheroid diameter under perfusion culture continued to increase at 10 days of culture, and growth rate under high-flow-rate perfusion culture was faster than that under low-flow-rate perfusion culture.",1
60,13,A live/dead cell-viability assay was performed to confirm the viability of the spheroids in static and low-flow-rate perfusion culture at 7 days of culture (Fig. 4). Almost all of the cells in the spheroids in the culture chambers were alive in both culture conditions.,1
60,14,"The high viability of spheroids indicates the applicability of the device for drug toxicity testing using the spheroids array. In addition, the device is useful for simultaneous testing of multiple drugs on a single device because the microfluidic device was able to provide four unique culture conditions simultaneously in its culture chamber arrays (Fig. 1F).",1
60,15,Figure 5B shows the rate of albumin synthesis at 9 to 11 days of culture. Albumin synthesis correlated with the culture conditions: the spheroid array under high-flow-rate perfusion showed significantly higher albumin synthesis activity compared with that under low-flow-rate perfusion (P < 0.01). The albumin synthesis activities under static and low-flow-rate perfusion were similar. These results indicate that our microfluidic device may be useful for the analysis of liver cell–specific functions at different perfusion rates using the regularly collected medium.,1
60,16,"We developed a novel microfluidic device for the controlled perfusion culture of spheroids with a uniform diameter. The microfluidic device (overall size, 47 mm × 96 mm × 35 mm; microfluidic culture chip size, 26 mm × 76 mm × 2 mm) successfully provided controlled perfusion culture conditions for spheroids formed in microwell arrays. Our microfludic device contained 16 culture chambers, which was smaller than that in the previous perfused multiwell plate (86 mm × 128 mm × 35 mm) [29]. Our reversibly assembled device enabled the collection of spheroids from the culture chambers, thus overcoming one of the major limitations of microfluidic cell-culture devices [21-27, 29, 30]. The collected spheroids and medium were used for subsequent traditional biological analyses including live/dead assay, ELISA, and real-time PCR. Furthermore, these collected spheroids could be used for other biological assays such as cell sorting, microarray analysis, imaging analysis, and immunohistochemistry in the future. Using our microfluidic device, we were, for the first time, able to quantitatively assess the effect of perfusion on the proliferation of spheroids in comparison with a static culture. Our findings indicate the importance of nutrient supply and/or waste removal for spheroid growth. ",1
61,1,"Research has typically examined culture as an independent or moderating variable. In this empirical study, we examine culture as a dependent variable and specifically investigate whether higher levels of economic performance might shape a national culture more supportive of entrepreneurial activities. Analysis controlling for the effects of unobserved country-specific factors and prior levels of economic development reveals that people in nations with greater gains in per capita GDP tend to place greater value on jobs that allow for achievement, the exercise of initiative, and more interesting and challenging work. Results show that people in nations with below average economic performance become less enterprising/entrepreneurial and that the propensity for nations to converge on pro-entrepreneurial values will depend on how economic performance is distributed across countries. Theoretical and practical implications are discussed.",1
61,2,"The argument that countries with more enterprising cultures will have better-performing economies has become prominent, with proponents drawn from fields that have traditionally eschewed cultural explanations. Economics Nobel laureate, Edmund Phelps (2007) argues that a population that values personal development and achievement is essential for the economic dynamism that leads to high economic performance. Business strategy scholar Michael Porter (2000) highlights the importance of a ‘productivity culture’ of beliefs that economic progress is built on efficiencies created through innovation and vigorous market competition. These positions are in line with the opinion of several historians, such as Weiner (1981), who trace the decline of early industrial powers (such as Britain) to a decline in entrepreneurial motivation, and with the actions of politicians, such as Margaret Thatcher, who in the 1980s sought to restore the British economic position with policies to create an ‘enterprise culture’ of innovation, self-reliance, and profit seeking.",1
61,3,"Estimates of the effect of economic performance on culture would inform business decisions about market entry and the adaptation of management practices to local conditions. On the other hand, evidence that national culture is not affected by economic performance would strengthen the case for assuming that national cultures are fixed, indicating that firms should base decisions on available point estimates of national culture (i.e. Hofstede, 2000). If culture is affected by performance, however, there is a case for combining culture data with economic performance projections to forecast cultural environments that will exist within the firm’s planning horizon. Insight into the formation of enterprising or “entrepreneurial” values will be particularly valuable given that contemporary business models based on speed work best with employees who are innovative and achievementoriented – qualities likely found in enterprising populations. The evidence can be used to evaluate the hypothesis that national cultures will converge as more nations achieve economic development (Kerr et al., 1960; Munusamy et al., 2009) and help generate understanding regarding the post-World War II shift toward more individualistic values that has been associated with generally greater economic growth during this period (Inglehart and Baker, 2000). ",1
61,4,"Second, there are statistical studies relating cross-sectional measures of national culture to economic performance. Franke et al. (1991) explored the effect of Hofstede’s measures of individualism, power distance, masculinity, and uncertainty avoidance and Bond’s measure of Confucian dynamism (value placed on perseverance, thrift, and long term view). While individualism was negatively associated with the growth in per capita GDP from 1965 to 1980 and from 1980 to 1987, it was positively associated with the level of per capita GDP in 1965 and 1980. Franke and colleagues also found that Confucian dynamism was positively associated with growth in GDP but not associated with level of GDP. In Hofstede’s(2005) further analysis using the same national culture scores, individualism was positively related to more recent (1990 and 2000) measures of per capita GDP. Several other studies associating Hofstede-type measures with firm-level performance measures have produced mixed results. For example, Ringov and Zollo (2007) found that power distance and masculinity negatively affected corporate social and environmental performance whilst individualism and uncertainty avoidance had no effect.",1
61,5,"Third, there are studies of specific aspects of enterprising culture. McClelland’s (1961) landmark investigation found that nations with higher need for Achievement (nAch), measured for 1925, had greater economic growth over the next 25 years. However, subsequent analysis by Mazur and Roza (1977) found that the effect of nAch was unstable over time, with McClelland’s nAch scores for 1950 not predicting economic growth over the next 21 years. More recently, there have been several investigations of measures of national entrepreneurial orientation constructed from large scale national surveys, such as the European Values Surveys and World Values Surveys. A measure of entrepreneurial values derived from the 1990 EVS was positively associated with regional growth rates from 1950 to 1998 (Beugelsdijk and Noorderhaven, 2004). A measure of entrepreneurship propensity from the Global Entrepreneurship Monitor (GEM) data for 2002 was associated with economic growth with the relationship moderated by national income (Wennekers et al., 2005; Van Stel et al., 2005). ",1
61,6,"Taken as a whole, there is no absolute agreement among scholars about the relationship between national culture and economic performance. Since most studies use culture measures only for a single point in time, the scope for causal inferences is limited. It is not possible to control for unobservable country-specific correlates of national culture that might affect economic performance. Further, estimates of the culture-performance relationship at a particular point in time can easily be confounded by major events that impact performance measures at these times. Wars or radical institutional shifts could depress economic output below potentially achievable levels, setting the stage for impressive ‘catch-up’ gains later on. Since such episodes are often concentrated in a specific region and countries within a region tend to have similar national cultures (Huntington, 1996; Inglehart and Baker, 2000), cultural variables could receive undue credit for performance levels that are either particularly high or low, depending on when and how performance is measured.",1
61,7,"Further, to the extent that values of national populations are learned responses to the challenges of national environments (Erez and Gati, 2004; Javidan and House, 2001; Trompenaars and Hampden-Turner, 1998), they will be impacted by the contingencies posed by national economic performance. There are some indications that economic growth has caused values to shift, even in a relatively short time frame. The world-wide shift to more secular/rational values since World War II has been attributed by some (e.g. Inglehart, 1990; Inglehart and Baker, 2000) to global prosperity. Hofstede and Hofstede (2005) argued that increased individualism between the years 1968 and 1972 resulted from increased national income that provided more resources for individuals to “do their own thing” (2005: 112). Yang (1986) documents how the values of the Chinese populations in the rapidly growing post-war market economies of Taiwan and Hong Kong changed markedly over periods of a decade or less, with value orientations that favor inner development, individualism, future perspective and mastery of nature supplanting collectivism, past orientation and submissiveness. Similarly, Nakata and Sivakumar (1996) suggest that, in line with Maslow’s hierarchy of needs (see Maslow, 1987), as lower needs have been fulfilled, higher needs have emerged.",1
61,8,"A national environment of superior economic performance can enhance entrepreneurial values in several ways. First, individuals will develop more favorable estimates of the likely gains to entrepreneurial activity in general. In times of more rapidly expanding market opportunities, more successes and relatively fewer failures will be observed. Further, failures will be judged as less costly, providing would-be entrepreneurs with valuable learning.",1
61,9,"Second, in higher income societies, entrepreneurial activities will be made more attractive by mechanisms that mitigate the downside risk of entrepreneurship. Most wealthy societies have well-established social insurance and welfare programs, and individuals in these societies will have larger pools of personal savings and access to financial support from other family members. The greater impact of these devices in wealthier societies is supported by Sahm’s(2007) finding that populations are more risk tolerant when and where better economic conditions are better.",1
61,10,"Third, higher order needs of the type that can be met by entrepreneurial activities are more salient in wealthier economies. When incomes are low, priority must be given to basic needs for survival and security, requiring individuals to pool resources and work together in mutually supportive groups (Oyserman et al., 2002), thus reinforcing the collective values that help cope with a world of limited resources (Inglehart, 1971). At higher income levels, however, entrepreneurial activities become valued because of the role they play in satisfying higher-order needs for self-expression, personal growth and accomplishment.",1
61,11,"Finally, in wealthier nations, we expect entrepreneurial activities to be valued over a wider range of the population. Assuming some population heterogeneity, more market segments, each reflecting demand for a specific service or activity will emerge as the economy grows and the discretionary income within various sub-groups increases. Thus, more individuals will discern entrepreneurial opportunities consistent with their idiosyncratic values and capabilities. As Blau (1987) has observed, higher income societies present more market opportunities outside agriculture and mass production and more ways for the entrepreneurially inclined to respond to demands for specialized, professional, and niche-marketed goods and services.",1
61,12,"Although not the typical Hofstede (1980) measures of “culture” (i.e. individualism, collectivism, etc.), we chose to use the values we did in this study because (1) they are indeed values (and culture is arguably aggregate values), and (2) they closely correspond to attributes of “enterprising” or “entrepreneurial” culture proposed by others. For example, the values of achievement, initiative, and interesting work are precisely those used by Phelps (2007), the value of income is seen by some as a major motivator for entrepreneurs (Gasse, 1982), and a high value attached to money is seen as central to the capitalist system (Hirschman, 1977) (however, this value may be less strongly impacted by economic performance, as basic material needs that are satisfied through monetary transactions will be less salient when or where incomes are high).",1
61,13,"Measures of national economic performance are taken from the World Bank’s World Development Indicators (WDI) which provides annual observations on national output, demographics, employment for more than 200 countries and entities. As in previous studies, per capita GDP (in constant dollars) is the measure of economic performance.",1
61,14,"Estimates of the coefficients from models augmented by the regional/ cultural grouping dummies to control for the region-specific factors that may be correlated with economic performance are, as shown in Table 3, substantively the same, except for the effect of increased per capita gross domestic product on job challenge (which while positive, is no longer different from zero at usual levels of significance). The values of achievement, interest, and initiative are enhanced by greater economic performance. Table 4 includes regional/cultural group effects in the regressions.",1
61,15,"The results of this pioneering study reveal that the formation of national enterprising culture might indeed be affected by economic performance. Specifically, over a ten year interval, countries with greater increases in per capita output finished the decade with greater entrepreneurial orientations, placing relatively greater importance on jobs that allow for achievement, exercise of initiative, and the conduct of interesting work. The short time frame within which entrepreneurial values are affected by economic performance is noteworthy, consistent with other evidence (Yang, 1986) that values can change quite quickly as a result of experience in growing market economies.",1
61,16,"Not all entrepreneurial values will be equally sensitive to economic performance, if at all. That the value of income is less responsive to increased national wealth is unsurprising. Greater national wealth will result in the needs for material well-being that are typically met through incomebased transactions being more readily met. At the same time, the needs for individual expression and personal development that can be directly fulfilled by entrepreneurial activities will clearly become more salient.",1
61,17,"The results of this study also potentially serve to clarify our understanding of the forces underlying the general post-World War II shift toward values favoring individualism and self-expression. According to some, this movement has been attributed to general world-wide economic growth and improvement in living standards that give people the freedom to engage in more expressive activities without being preoccupied with the physical security and satisfaction of more basic needs (Inglehart and Baker, 2000). Specifically, with regard to the finding of country-level effects where countries with better economic performance develop more entrepreneurial values, whereas those with relatively poor performance have less entrepreneurial values, global values shift should not be attributed to general spread of pro-market values regardless of national economic performance. Indeed, any movement toward more entrepreneurial values may easily be reversed when nations suffer economic reversals.",1
62,1,"This paper explores whether we can interpret the notion of ‘forensic culture’ as something akin to what Knorr-Cetina called an ‘epistemic culture’. Can we speak of a ‘forensic culture’, and, if so, how is it similar to, or different from, other epistemic cultures that exist in what is conventionally called ‘science’? This question has important policy implications given the National Academy Science’s (NAS) recent identification of ‘culture’ as one of the problems at the root of what it identified as ‘serious deficiencies’ in U.S. forensic science and ‘scientific culture’ as an antidote to those problems. Finding the NAS’s characterisation of ‘scientific culture’ overly general and naïve, this paper offers a preliminary exploration of what might be called a ‘forensic culture’. Specifically, the paper explores the way in which few of the empirical findings accumulated by sociologists of science about research science seem to apply to forensic science. Instead, forensic science seems to have developed a distinct culture for which a sociological analysis will require new explanatory tools. Faithful sociological analysis of ‘forensic culture’ will be a necessary prerequisite for the kind of culture change prescribed by external reformist bodies like the NAS.",1
62,2,"The notion of ‘forensic culture’, as explored in this special section and the conference that produced it is a flexible one. Various contributions deploy this term to mean a variety of things ranging from race and ethnicity to cultural (or media) representations of forensic science to the impact of forensic science on popular culture. In this paper, I take the term ‘culture’ to refer to something closer to Knorr-Cetina’s ‘epistemic culture’ or, as a recent report on forensic science by the U.S. National Academy of Science (NAS) would have it, ‘scientific culture’.In this sense, ‘culture’ is a social medium that produces knowledge, knowledge that is often conventionally labeled ‘scientific’. This paper explores whether and how it is possible to append the term ‘forensic’ to this notion of culture. Is it possible to speak of a ‘forensic culture’ that produces scientific knowledge? Would such a culture simply be ‘scientific culture’ or would it be different, and, if so, how?",1
62,3,"An underlying assumption of the exploration undertaken here is the idea that sociology of science represents an appropriate framework from which to endeavour to answer this question. Sociology of science seeks to understand the social process of knowledge production, and over the past several decades, it has produced a corpus of empirical observations on this processes. Most, though by no means all, of these observations have been derived from studies of what we might call ‘research science’ aimed at producing new knowledge about the natural world at the expense of more mundane activities such as industrial science or ‘regulatory science’, despite full awareness that within the universe of things we call ‘science’ such ‘mundane’ activities may well exceed activities we call research science.2 To be sure, one important impulse of early science studies was to contest precisely this equating of ‘science’ with high science experiments. This produced a line of research which valorised ‘mundane’, quotidian, practical, hands-on scientific work: tacit knowledge, invisible technicians, good hands, and so on.",1
62,4,"To be sure, the distinction I am drawing is an oversimplified one, and there are many individuals who occupy a liminal space between the categories I have drawn: ‘scientist’ and ‘forensic scientist’. These would include, for example, both individuals employed by forensic laboratories and independent or privately employed individuals who have the luxury (or burden) of dividing their time between casework and research. While I acknowledge the existence and importance of these liminal individuals, their existence is ignored for purposes of the schematic discussion of a distinct ‘forensic culture’ which I wish to lay out. What is said in this paper about ‘forensic culture’ probably applies only partially to such individuals and institutional settings.",1
62,5,"Second, I want to draw attention to another meaning of the term ‘culture’. If there is a ‘forensic culture’, it is unlikely to be a unitary thing, but rather multiple ‘forensic cultures’ that intersect with national cultures. My remarks in this paper pertain primarily to American ‘forensic culture’, and they may pertain more or less to other national forensic cultures. Third, in positing a notion of ‘forensic culture’, I am necessarily lumping together a variety of different disciplines that differ from one another in various ways. Such a discussion will not necessarily apply equally to all these disciplines, and DNA profiling, in particular, will often, but not always, be an exception to some of my comments.30 Nonetheless I do assert that the forensic disciplines have enough in common to be discussed coherently under the auspices of the term ‘forensic culture’. Fourth, by using the term ‘culture’, some readers may assume that my data is ethnographic. My data primarily consist of texts, such as published articles and legal briefs, opinions, and transcripts. Some of my observations, however, derive from my role as what might be called a ‘participant-intervener’ in debates surrounding the validity and legal admissibility of forensic science over more than a decade.",1
62,6,"Perhaps the most commonly made observation about forensic science focuses on the contrast between the open-endedness of scientific inquiry and the temporally limited nature of legal truth-finding processes. While law must settle on a truth within a period of time set by the end of the case, research science, in principle, recognises no temporal limits on inquiry into truth. Forensic culture enacts the former principle; it does not enjoy the luxury of temporally open-ended inquiries, though such extraordinary practices as cold case review and post-conviction litigation to some extent cut against this generalisation.31 This point is well taken, but it is in some sense only one aspect of larger differences between research science and forensic science with regard to the specificity of their knowledge claims and the nature of the data they employ.",1
62,7,"Philosophers and sociologists of science have both endeavoured to explain how scientists can make general knowledge claims. The twentieth century philosophy of science advanced both by Popper and his critics has focused on the making of general statements about the natural world.32 While there is great disagreement among those who study the production of scientific knowledge as to how these general knowledge claims can actually be made, broadly speaking, general knowledge claims rest upon converging lines of evidence from a variety of different scientific activities (experiments, observations, models, etc.), each of which is, ideally, based upon large amounts of data. Recent debates within philosophy, sociology, and history of science have focused on how and when these converging lines of evidence become what we call ‘scientific knowledge’.",1
62,8,"Reproducibility, often called ‘replication’, has been considered by many philosophers to be a key—if not the key—hallmark of ‘science’ precisely because it tests the generalisability of scientific knowledge claims. A scientific knowledge claim, if valid, should hold in places and times other than where and when the claim was initially proposed. Replication has also played a key role in sociology of science. Sociologists pointed out that replication studies provide little social capital in the prestige economy of academic science. Therefore, replications were rarely actually performed. Among the most celebrated findings of sociology of science is Collins’ notion of the ‘experimenter’s regress’. Collins showed that no single replication experiment could function as a definitive referendum on a theory in the way proposed by some philosophies of science. Instead, he showed that cherished theories could survive failures to replicate by positing ad hoc explanations and that there was no natural limit to scientists’ ability to resort to such explanation (hence the notion of a ‘regress’).35 For our purposes, it is not necessary to arbitrate whether it is philosophers or sociologists who give a correct account of the role of replication in the development of scientific knowledge. ",1
62,9,"It may be thought that the process of double-checking, sometimes called ‘verification’, which is quite common in forensic science protocols today, constitutes replication. However, such activities produce what philosophers of science call ‘repeatability’, rather than ‘reproducibility’. Repeatability refers to repeating the same analysis on the same materials by the same researchers, in the same laboratory. Reproducibility refers to reproducing the original researcher’s experimental or analytic setup and procedures by other researchers, with different materials, in another laboratory.36 Reproducibility is necessary to ensure the results are ‘universal’ or ‘general’ and not somehow explained by some peculiarity of the original researchers, materials, or laboratory. Reproducibility, thus, is rarely possible for forensic knowledge claims.",1
62,10,"The high value of this ‘currency’, of course, underlies many of the self-regulatory mechanisms that supposedly govern and police the production of scientific knowledge. In theory, it is because of the deterrent effect of the implicit threat of losing this currency that scientists avoid plagiarising, falsifying results, corrupting the peer review process, or conducting other forms of scientific fraud and misconduct.44 The existence of these implicit threats, in theory, serves as society’s guarantee of the validity of scientific knowledge: understanding that scientists live in a complex prestige economy surrounded by implicit threats to reputation for bad behaviour and rewards to reputation for good behaviour supposedly gives us reasons to trust the knowledge claims that emerge seemingly ‘certified’ by the scientific community through superficial markers of prestige like journals, books, conferences, and so on.",1
62,11,"Scientific peer review may, to some extent, be characterised as ‘adversarial’. Proper peer review is understood to require a certain critical stance on the part of the reviewer. The reviewer is expected to look for flaws. The homology between this critical stance and the adverarialism that lies at the heart of Anglo-American legal systems—in which the truthful account of events is supposed to be revealed as such by its ability to withstand vigorous efforts to undermine it—is clear.49 This superficial similarity notwithstanding, however, the adversarialism of scientific peer review is not entirely equivalent to legal adversarialism. As Jasanoff found for ‘regulatory science’, we might say that forensic science is often even more adversarial than research science.50 Journal referees, for example, are expected to be rigorous, but not unreasonably so: they are expected to make warranted and justified criticisms, but not to engage in radical scepticism or to criticise simply for criticism’s sake. Academic laboratories are not subject to the sort of ‘audit culture’ that is increasingly being demanded of forensic laboratories.51 In countries with adversarial legal systems, however, forensic scientists’ conclusions are thrust into an adversarial legal process in which some actors (typically the defence attorney) may be ethically bound to engage in any possible form of criticism. ",1
62,12,"The way to prevent this from happening is, of course, to keep such materials out of the hands of ‘outsiders’. There are many techniques for accomplishing this. Much information is simply never compiled in the first place. For example, the number of internal disagreements within the laboratory is almost never recorded. Records of errors are often not compiled at all. Even if they are compiled by some laboratories, they are not made publicly available and thus must be requested through discovery in a particular legal case. The discovery process is itself problematic. Defendants, who do not know what information the laboratory holds, tend to issue broad discovery requests that prosecutors, with some justification, characterise as ‘fishing expeditions’. However, without such broad discovery requests, fundamental items of information, like the number of exposed errors committed by a particular laboratory in a particular discipline, will never be known.",1
62,13,"Beyond fear of impeachment, forensic scientists’ experiences with the adversarial systems lead them to have more negative views about the adversarial process than scientists do about peer review. While it is common for scientists to complain about peer review—its perceived unfairness, poor quality, and time-consuming nature—even these criticisms are not as wholly negative as forensic scientists’ attitudes toward the adversarial process. Crucially, academic peer review is a mutual process. Most working scientists serve on both ends of the peer review process: as reviewers and reviewees. Scientists’ negative experiences as reviewees are tempered by their experiences as reviewers, in which they themselves experience how difficult it can be to judge one’s colleagues’ work. Forensic scientists only play one role in the adversarial process: as reviewees. They thus experience adversarialism merely as a relentless barrage of disparagement, rather than as a difficult process of trying to ferret out truth through vigorous criticism. Forensic scientists only rarely express true belief in the ideal of adversarialism—the belief oft expressed in Anglo-American legal circles that adversarialism is perhaps unpleasant and imperfect, but is nonetheless the best process for determining truth in a legal forum.",1
62,14,"There is perhaps another reason that forensic scientists view adversarialism as a negative attribute of their practice. In theory, scientists are taught to believe that adversarialism has salutary effects on knowledge production. Either adversarialism weeds out bad theories or data, through refusal of publication, funding, tenure, etc., or adversarialism improves knowledge; discussion among the principals leads to better knowledge. Such a view of forensic knowledge production is untenable. While forensic scientists may claim to have healthy discussions when they disagree on the interpretation of evidence, such disagreements inherently cause problems for the forensic laboratory. The laboratory must either report the disagreement, and thus undermine the value of the evidence, or conceal the disagreement, and thus be open to internal or external accusations of lack of candour.",1
63,1,"This article is a response to Birgit Meyer’s chapter ‘Mediating Traditional Culture’ from her book Sensational Movies: Video, Vision, and Christianity in Ghana.Itreflects on her argument about heritage as a dominant discourse in debates about religion and culture in the Ghanaian video film industry, raises questions about the dynamics of this politics of representation, and outlines the significance of her approach for theorising heritage. It draws on a series of observations about sites of culture and heritage in contemporary Ghana to frame a discussion about dominant themes that emerge in Meyer’s chapter, namely, chiefs and chiefly authority, the genre of the ’epic,’ and audience perceptions of mediations of tradition and culture. It concludes by pointing out the usefulness and value that a focus on imaginaries, media, and mediation brings to the study of heritage.",1
63,2,"The titles of the films say it all: The Good Old Days, Heritage Africa and Spirit of Heritage convey a sense of heritage’s currency in Ghanaian popular cinematic culture. Cycled through the aesthetics of audio-visual entertainment, heritage is imbricated in the religious and cultural politics of contemporary Ghana, the neo-liberalisation of the state, and the rise of Pentecostal Christianity over the last 30 years. This is different from the registers through which heritage usually travels in South Africa, where I work. Here it has been taken up by the state and deployed for purposes of national healing and nation-building (Jethro 2013). Certainly it manifests in popular culture, to reinforce claims about new cultural forms like the vuvuzela (Jethro 2014) or for rebranding commemorative days like Heritage Day to national barbecue day. In thinking about Birgit Meyer’s analysis of heritage, culture and tradition in Ghana I cannot help but wonder about parallels with South Africa.",1
63,3,"The social significance of the terms culture, heritage and tradition is framed within a debate about cultural and entertainment value, which, respectively, appear to represent the opposing wishes of the state and independent popular video filmmakers. To illustrate, the Cultural Policy, the document guiding the state’spositiononfilm, insists that filmmakers produce African films or films by Africans for Africans which profile romantic, traditional images of Ghana as representative of the continent. Filmmakers were urged to draw on and reinforce the philosophy of Sankofa,ofAfricanpersonhood,developedandpromotedby independent Ghana’s first Prime Minister and President, Kwame Nkrumah. According to the state, films should depict forms of ‘good’ tradition and African culture that hail from a prelapsarian past following the well-known Sankofa saying ‘Go back and fetch it.’ The irony of Sankofa is, as is eloquently shown, that these ideas of distinct African culture and tradition have deep colonial and missionary roots. Here we can not only recognise heritage as a form of power, servicing the maintenance of certain institutions and forms of dominance, but also how it masks its own historical construction to make these forms of dominance appear natural.",1
63,4,"Independent filmmakers, however, were not interested in producing ‘flattering representations of Ghanaian culture’ for the sake of it. Instead, they hoped to draw on ‘popular imaginaries as a source of inspiration’, punctuated as they were with sometimes disturbing, extraordinary elements (p. 263). The kind of past framed by Sankofa was seen as restrictive, or simply boring, and a drain on creativity. ‘[G]o back and pick what? ... Should we wear loincloth?’ retorts one frustrated independent filmmaker (p. 263). ‘Sankofa is a cultural whirlpool; we cannot get out of it and are bound to the past, which is not good,’ adds another (p. 262). Of course, these strict distinctions between ideas of culture and entertainment are untenable as Meyer adeptly shows. The complexity of these dynamics are laid bare in her extended discussion of chiefs.",1
63,5,"The final part of the chapter discusses the genre of the epic. This new type of film focusing on the deep time of the past, explicitly engages with a village world from time immemorial. The aesthetic styling of the epic breaks with dominant conceptions of heritage and culture suggested by Sankofa as well as dominant ideas in the Western anthropological canon. As Emeka Nwabueze, a set designer and film producer explained: ‘We create an unexisting culture or an unexisting tradition, something absolutely new’ (p. 278). The epic was intended to showcase cultures and traditions in the fictional past that did not yet exist in the present. The pressure of the entertainment industry also required that the epic breaks with historical and cultural continuity across films, meaning set designers created new indigenous groups with new cultural repertoires for each film. As Nwabueze explained, it was ‘important to create something unique for every film or story; there should be no repetition in making tradition’ (p. 278). Each film required new dress codes, new traditional architecture, new dance routines as part of the discovery of historical traditions not yet known. ",1
63,6,"This is a riveting chapter, and I would like to draw on my memories of Ghana, memories accrued while attending a conference in 2010, to structure my response. Held in the context of the Heritage Dynamics project, which was co-led by Birgit Meyer, the conference brought together scholars and PhD students studying religion, anthropology, dance, performance and history, as well as heritage and museum studies. Focusing on questions of the aesthetics of persuasion and the politics of authentication, the conference took delegates across Ghana, in a travelling conversation about heritage, culture, and tradition. I would like to draw on three moments from that time, and the theoretical tools developed within the forum of the project, to reflect on the mediation of culture in Ghanaian video films.",1
63,7,"Later, we stopped at the National Museum of Ghana a short distance away. Displaying the history, culture and arts of the nation, the museum was decidedly more run-down, the exhibits more aged, than the Memorial Park. We passed Independence Arch and Black Star Square, and the truly monolithic presidential palace. Shaped like a chiefly stool, it visually announced the associations Nkrumah tried to create between state power and traditional authority, specifically chieftaincy. Adopting the Black Stool, the State Sword, and the Linguist’s Staff as symbols of state, Nkrumah installed new material signifiers of independent sovereign authority (Senah 2013).",1
63,8,"Meyer and others stress that chiefly authority still holds currency in Ghana. Thinking about the city, thinking about chiefs and chiefly power, I wondered, besides claiming that spiritual powers exclusive to their office of authority disrupt the operation of modern audio-visual technology, what other claims have they made to shore up their authority, particularly in urban contexts like the city where, just like the deterioration affecting some commemorative forms in Accra, their power or appeal appears to be waning? Relatedly, I wondered, what about the foil of tradition, what about priests and pastors of new charismatic churches? How have they tried to explain and defend their spiritual authority in light of the apparent revelation of mysteries unfolding in contemporary Ghanaian video films?",1
63,9,"We were requested to take our seats at the outer edge of a dusty courtyard that would serve as the stage for the performance. Young men drummed rhythmically while the lead priestess, Dashi, executed her repertoire, and, against reassurances, fell in and out of trance, with the support of her female apprentices. It was a dramatic ritual performance that stretched long into the afternoon. The evocative ritual display caused a stir amongst the touring party, triggering conversation about performance, trance, dance, staging and authenticity that echoed all the way back to Accra.",1
63,10,"I could not help but think of this trip when I read about the genre of the epic. While we encountered a near ‘concrete’ cultural tradition, one that was near fully made, set designers and stylists involved with the epic actively made up Ghanaian heritage as they went along. Like bricoleurs, they make up cultures and traditions not of the past, but that which was yet to be conceived. While these aesthetic choices are a response to the dominant moral binds of religion and culture in the public sphere, the epic is not without its own politics of tradition, culture and heritage. Indeed, reading Birgit Meyer’s chapter on ‘Mediating Traditional Culture’, one is left wondering what forms of power and institutions does this new cinematic genre work to enable and sustain?",1
63,11,"Children came rushing up to us as we stepped off the bus outside Cape Coast Castle. Foisting pieces of paper at us, they pleaded, ‘what is your name, what is your name?’ I reluctantly scribbled my name on a piece of paper, and pushed my way through to join the retinue heading into the white-washed castle precinct. This was the coast, and the complex, a former colonial outpost, was a node of exchange in the intercontinental slave trade. From here, distant commercial and sovereign authority was administered, and many thousands of black bodies shipped off to the colonies. Its monumentality reminded me of the Castle of Good Hope, in Cape Town, South Africa, a fortification point built by the Dutch to defend their commercial and colonial claim.",1
63,12,"In the same sense that we wondered about the authenticity of the door, I also wondered to what extent video-film audiences question the authenticity of representations of tradition cast in popular video films? Certainly, there was a crossover between popular imaginaries and ideas of religious and spiritual authenticity: audience members flinch at the appearance of ritual objects in films, for example. But I wonder about what enables this perception? Put another way, if the door of no return conveyed a material sense of historical self-evidence, what did audiences say that helped to frame representations of tradition as persuasive in popular video films?",1
63,13,"Like a video film, the door of no return offers an entry point into a popular imaginary about the past. Looking out through the door is like peering into the past, a past imagined in the present. Yet it is also a threshold, a border between the real and the imagined. How do we attend to these exchanges? ‘Mediating Traditional Culture’ provides us with an excellent set of theoretical tools. Attending to the exchange between the imaginary, the material and notions of religion and culture, it helps shift our understanding of how heritage is produced and mobilised to understand the past. Calling attention to material mediations, it departs from the narrow, dominant concept of heritage as a discourse by emphasising that it is a set of practices of meaning-making engaged in relation to the material. And in emphasising the imaginaries, it enables us to think about how material mediations of the past circulate and become socially binding as shared frameworks of meaning. As such, the chapter ‘Mediating Traditional Culture’, and indeed the book Sensational Movies, provides compelling, exciting theory with which to engage a range of contemporary mediations of the past.",1
63,14,"Duane Jethro is a post-doctoral fellow in the Archive and Public Culture Research Initiative at the University of Cape Town. A graduate of the University of Utrecht, his thesis, entitled ‘Aesthetics of Power: Heritage Formation and the Senses in Post-Apartheid South Africa’, looked at relationships between heritage, materiality, aesthetics and the senses. He has published in Material Religion, African Diaspora and Tourist Studies.",1
64,1,"Queries into the creation of collective meaning through social processes arise in both organization culture and institutional theory. This paper applies DiMaggio and Powell’s (1983) three isomorphic processes (mimetic, normative and coercive) from institutional theory to re-think how structural and dynamic aspects of culture become nested, taken-for-granted and transmitted. We consider both acquiescence and resistance to isomorphic pressures in an effort to understand cultural persistence and transmission, forms of resistance to culture, change, the role of sub-cultures and power usage through Oliver’s (1992) deinstitutionalization thesis. Our purpose in applying isomorphic processes to organizational culture is to offer another layer of understanding enhanced by the growing body of research in institutional theory, bridge one division between micro and macro theory and provide some suggestions for future research.",1
64,2,"Institutional theory deals mainly with inter-organizational processes and assumes that forces shaping an organization and its behaviour are largely external to the organization, whereas much of organizational culture deals with intra-organizational processes (Barley and Tolbert 1997; DiMaggio and Powell 1991; Pedersen and Dobbin 1997, 2006). Shared across the approaches are ideas on patterned behaviours that persist over time and shared collective processes and meanings that are value based, ideational in nature and contain explicit and taken for granted elements. Both focus on the ‘creation of collective meaning structures through social processes’ (italics in the original, Pedersen and Dobbin 2006, 899). While Pedersen and Dobbin (2006) consider how organizations respond to external institutional pressures that shape culture, they do not discuss how culture is spread and maintained. This article takes the next step to examine how institutional processes normally applied at the macro level can be applied to internal organization processes and analyze how coercive, mimetic and normative pressures work to maintain culture. In turn, we consider Oliver’s (1992) perspective on deinstitutionalization to explore issues of resistance to isomorphic pressures, sub-cultures, change and power within organizations.",1
64,3,"Institutional theory has taken on a variety of guises (DiMaggio 1988; DiMaggio and Powell 1991; Scott 1987), but the central thrust has been to explain the homogeneity of structure, culture and output of organizations sharing an organizational field or ‘organizations that, in aggregate, constitute a recognized area of institutional life’ (DiMaggio and Powell 1991, 148). This homogenization is referred to as isomorphism and deals with domains of operation, principles of organizing and criteria of evaluation (Hinings and Greenwood 1988). As such, organizational environments are ‘characterized by the elaboration of rules and requirements to which individual organizations must conform if they are to receive support and legitimacy’, and regardless of motivation, social-cultural values and beliefs external to the organization play a significant role in determining those organizational norms (Scott and Meyer 1983, 149). In other words, organizational fields are key in shaping organizational forms, processes and beliefs. Structures and processes that are institutionally derived may be idiosyncratic to organizational fields and conformity is facilitated by normative, coercive and mimetic processes (DiMaggio and Powell 1983). ",1
64,4,"An example of coercive processes creating external pressures for compliance with institutional norms are found in government imposed regulatory environments. Coercive pressures are also imposed through formal and informal processes that may be explicit or tacit, and proscribe and prescribe acceptable organizational behaviour. For example, suspending or expelling an organization from a trade body or industry group would be formal retaliation for the violation of group norms.",1
64,5,"Mimetic processes are usually undertaken to deal with uncertainty. Some organizations mimic others to provide viable solutions to unknown, poorly understood or highly ambiguous environmental problems. If the link between organizational structures, processes and outcomes are unclear, such modelling activities are a prime method for increasing the certainty of outcomes without incurring the expense or effort to understand the link between inputs and outputs. This risk averse strategy increases the certainty of organizational outcomes and may be actively undertaken or assumed and taken for granted (Kondra and Hinings 1998).",1
64,6,"More recently, institutional theory researchers have moved beyond the maintenance of norms to address criticisms regarding the accommodation of change and strategic choice within a framework that was initially intended to explain isomorphism and stability (Oliver 1991; Powell 1991). One needs to look no further than the special issue of The Academy of Management Review (February 2002) for evidence of the growing interest among academia to explore uncertainty, change and cultural reproduction within an institutional theory framework.",1
64,7,"Organizational culture has resisted a common definition or explanation and researchers have developed quite different interpretations based on varied theoretical disciplines and assumptions (Alvesson 2002; Martin 1992, 2002; Martin and Frost 1999). Fundamental ideological and theoretical disagreements within the literature (Alvesson 2002; Martin 2002) underscores a lack of paradigm consensus.",1
64,8,"Perspectives on organization culture typically draw from Berger and Luckman (1967) regarding the symbolic and cognitive aspects of organizational life. Early culture research contributed qualitative enrichment to organizational theory research that favoured more quantitative approaches with limited ability to account for the interpretation of roles, emotion, beliefs and values in organizations. The addition of a qualitative understanding of culture provided a way to capture the emotional, more symbolic and cognitive aspects of organizational life and explain seemingly irrational behaviours (Martin and Frost 1999; Pederson and Dobbin 1997). Early descriptions of organizational culture blended emotional and cognitive aspects with core managerial concerns. Peters and Waterman’s (1982) work, In search of excellence, provides examples of how successful organizations succeed through strong, unified cultures that produce and reproduce culture by physical artefacts, symbols, ceremonies, stories, slogans, dress and settings.",1
64,9,"Such managerial perspectives assume cultural reproduction at the organization level informed largely by the business environment (Pederson and Dobbin 1997) with elements of culture used or manipulated to enhance organizational performance. Martin and Frost (1999) consider such work as value engineering or the creation of an integrative organizational approach. Others argue that due to sublimated, shared meanings, such outright manipulation may not be altogether possible (Jermier et al. 1991) making some cultural elements easier to manipulate than others. For example, visible and tangible elements such as buildings, logos, policies and written procedures are alterable, whereas sublimated and/or taken for granted elements of culture are not so easily changed. Assumptions that engineered cultural beliefs arise and are reproduced within organizations as determined by the business context alone deny the interpretive role of individuals or complexity within resident cultural elements. Consequently, the confluence of tangible artefacts, environmental determinism and value engineering with shared meaning creation and voluntary action impacting culture makes the study of culture very complex.",1
64,10,"Berger and Luckman (1967) support a perspective on culture that suggests organizations contain different segments which create various groupings of individuals with related tasks and roles, multiplying the potential for segregated sub-universes of meaning. Van Maanen and Barley (1985) describe organizational sub-cultures or counter-cultures undermining uniform cultural views, perhaps influenced by social pressures originating with external professional cultures. Sub-culture members share an understanding about phenomena which may be quite different from others in the organization (Elsbach 2002). Not only are sub-cultures likely to exist and perpetuate different and, at times, contrary points of view from the overall culture, different members may interpret the same information from different frames of mind.",1
64,11,"Martin’s (1992) conceptualization of culture through integration, differentiation and fragmentation, coupled with Hardy’s (1994) discussion of different forms of power, demonstrates how dissimilar cultural experiences and frames of mind can generate alternate interpretations. In contrast to an integrationist view, critical theorists consider differential power relations in specific cultures problematic and examine how differential use of rules, policies and procedures represent forms of embedded power. Culture thus determines how power is exercised and experienced.",1
64,12,"Instrumental, symbolic and embedded forms of power reproduce different aspects of culture that varies across different frames of reference. For example, sources of instrumental power grounded in differential access to resources create disparate access to resources that influence others (Hardy 1994). Consider also vertical sources of power such as the ability to reward and sanction found in legitimate authority. Sources of lateral power found in specialized expertise or referent power also provide the ability to persuade and influence. Symbolic power, while different, is culturally grounded and found in the ability to secure preferred outcomes while preventing conflict from arising (Hardy 1994). Cultural symbols in language, ritual and myth all serve to create legitimacy for the exercise of symbolic power.",1
64,13,"Finally, there is power embedded in the system, which unlike other sources, does not require conscious or deliberate activity to mobilize. Instead, this form of power is embedded within the organization’s structures and processes shaping individual identities (Hardy 1994). Culture allows some to wield various forms of power giving them a very different experience from those in more dependent roles, thus creating many differing cultural frames of reference.",1
64,14,"Martin’s (1992) work goes beyond frames of reference to provide for practical examination of different perceptions of culture through different viewpoints. We can consider the manager’s viewpoint versus that of a union officer or a CEO. Each perspective is equally valid drawing from different cultural artefacts and sources of power that are symbolic and material. In each case, meaning is constructed by those experiencing and perceiving the unique culture or sub-cultural form, is transferred to others, and reproduced in exact or altered form through some method of symbolization or socialization.",1
64,15,"Erez and Gati (2004) provide insight through the idea of cultural nesting to explain organizational culture and its resident multi-perspective problem. In their view, lower levels of culture are nested within higher levels, suggesting that change at any one level impacts and produces change in all other levels, upward, downward and sideways. They draw on Schein (1990) to describe impacts of external, visible culture found in an organization’s physical and social environment and to deeper cultural levels associated with values, basic assumptions and beliefs about human nature. Organization culture is thought to shape values and norms, is learned and transmitted between individuals and teams through social learning, role modelling and observation, and, as a result, assists organization members in dealing with external pressures that threaten organizational survival and/or internal integration. Shared experience, values and assumptions are created, adapted and constrained through culture. Yet the ability for a culture to adapt is also tempered by context suggesting reciprocity between culture’s structural and dynamic dimensions. Nesting allows for consideration of interplay and uniqueness of multi-levels of culture that contain both structural and dynamic characteristics",1
64,16,"Erez and Gati (2004) contribute to the definition of culture through the idea of nesting and describe how forms of culture are created, internalized, supported, shared, blocked or changed at many levels, sub-groups and locations. The structural dimension states that most internal levels of culture exist at the individual level, which is subsequently nested hierarchically within ever-increasing levels such as groups, departments, organizations and nations. The dynamic aspect of cultural nesting refers to inter-relationships existing at various levels with multi-direction impact. For example, changes as a result of globalization may require top-down behavioural changes through structural change and supported through socialization and sanction. However, individual change to behaviour through bottom-up processes may also occur to shift shared values, ethics and moral expectations. In other words, culture is a dynamic ‘interplay’ that occurs between different nested levels of culture.",1
64,17,"Following Erez and Gati’s nesting model, assumptions regarding one-way cultural flows are problematic. How can cultural manifestations regulate and prescribe behaviours that are organization-wide, containing shared unambiguous values, without evidence of conflict (Martin and Frost 1999)? Further, can such manifestations be passed on through stories, rituals, rules and procedures (Schein 1985), or do they remain tacit as governing artefacts operating through underlying values, ideas and assumptions? A key point is that culture consists of observable behaviours and artefacts as well as the invisible aspects existing at the level of tacit assumptions and values (Erez and Gati 2004).",1
64,18,"Is culture then a manifestation of rationalized organizational action, routine or myth resulting in organizational carriers? Or, does culture create or reproduce itself through the use of cognitive, structural and routine carriers? Scott (1995) examines the degree to which culture creates or is created by cognitive carriers, individual perceptions and behaviours. For example, new employees may experience cultural carriers and conformity pressures quite differently as a lone entrant than he/she would as a new employee within a group entering as a result of a merger.",1
64,19,"Socialization may occur through collective, formal training of a fixed duration and/or more individualized learning (Tolbert 1988; Trice and Beyer 1993; Van Maanen and Schein 1979). Socialization processes are thought to actively perpetuate cultures as well as produce organization wide adaptations of new cultural identities (Martin and Frost 1999). Reproduction, transmission and maintenance of culture is thought to occur through counteracting forces producing gradual change to values, meanings and ideas drifting in from the larger social world as provided through Scott’s (1995) carriers and the internal organizational world via Erez and Gati’s (2004) nesting effects. Alvesson (2002) states that culture is maintained through socialization, connecting people to strengthen interactions through networks, workshops and gatherings, careful selection and recruitment of staff according to ideals and values and developing a shared sense of ‘we’ in the organization (Alvesson 2002) through training, education, performance expectations and sanctioned rules.",1
64,20,"Nested organizational culture once again is understood in a context where socially shared meanings are created through interactions, routines and procedures and become taken-for-granted and remain reasonably stable. Culture is lived as routine behaviours, norms, dominant philosophies and rules of conduct echoing Scott’s (1995) routine, structural and cognitive cultural carriers. Behavioural expectations, norms and rules are communicated tacitly and explicitly to organization members to reduce ambiguity resulting in increased regularity and predictability (Louis 1990). Explicit cultural elements are reflected in physical artefacts such as policy and procedure manuals and collective agreements. Organizations can have highly regimented behaviours reflected in written rules relying on coercive methods or very little in terms of standard policies and procedures thereby relying on shared values and norms for enforcement.",1
64,21,Culture is thus both structural and dynamic and like institutional theory it is interested in explaining the social construction and maintenance of meaning. The key is how to maintain a balance between cultural similarity and difference as well as to account for structural and dynamic capabilities.,1
64,22,"On-going cultural reproduction can be effectively analysed and understood as institutionalized practice systematically and continuously developing and sustaining an appreciative orientation, further building, improving upon and occasionally dismantling or deinstitutionalizing and re-institutionalizing. In the following section, we consider how isomorphic processes might improve our understanding of cultural reproduction, how persistent meaning is transmitted, reality constructed and cultural ideas maintained (Elsbach 2002; Scott 1995; Zucker 1977). In this way, institutionalization is viewed as both process and property where social reality is defined and where individuals act according to tacit and explicit expectations to become part of an institutionalized culture. Following our discussion of isomorphic processes in the perpetuation of culture, we move on to consider polymorphism and ideas from Oliver’s (1992) thesis of deinstitutionalization in order to address counter-cultural movement, prevention of cultural transmission and hence provide a deeper understanding of agency nested in culture. The antecedents of deinstitutionalization and resistance to institutional pressures to investigate tensions among sub-cultures and change are useful for developing a dynamic understanding of culture.",1
64,23,"Although institutional theory treats the source of norms as exogenous to the organization, the idea of cultural phenomena explained through institutional concepts is not entirely new (Barley and Tolbert 1997; DiMaggio and Powell 1991; Elsbach 2002; Zucker 1977). Several prominent authors have recognized the interplay between institutional theory and organizational culture. Scott (1987, 499) states that ‘...institutional theory has both contributed to and benefited from the resurgence of interest in culture...’ and ‘...shared conceptions and symbols provide order not only by being mapped into organizational forms and procedures but also by their direct influence on the beliefs and behaviours of individual participants...’. Individual level action is particularly common when dealing with normative pressures. For example, DiMaggio and Powell (1983, 153) recognize that ‘...individuals in an organizational field undergo anticipatory socialization to common expectations about their personal behaviour, appropriate style of dress, organizational vocabularies...and standard methods of speaking, joking, or addressing others....’ Style of dress, personal behaviour, language and communication style have been recognized as key surface elements of organizational culture (Schein 1990). ",1
64,24,"Some writers link organizational culture and industry characteristics (Chatman and Jehn 1994; Pennings and Gresov 1986). If industry characteristics are institutionally driven, as institutional theory posits, then these studies imply that the macro level of institutionalization affects organizational culture. Chatman and Jehn (1994), however, suggest that rather than developing unique organizational cultures to derive a competitive advantage, organizations seek to imitate cultures perceived as successful, hence the drive for similarity. These works point to the use of institutional theory to help explain aspects of organizational culture.",1
64,25,"Despite previous links between industry characteristics, organizational culture and institutional theory, no work appears to explicitly bridge ideas from DiMaggio and Powell’s (1983) three isomorphic forces to organizational culture. Our article attempts this by considering how isomorphic processes (coercive, mimetic, and normative) work to transmit, reproduce and maintain organization culture drawing on different aspects of intra-organizational institutionalization.",1
64,26,Table 1 illustrates coercive pressures for cultural conformity that are informal (not sanctioned) or formal (sanctioned). Sanctioned coercive pressures include organizational rewards or punishment for undertaking certain behaviours (Nemeth and Staw 1989; Pascale 1985; Schein 1996) and behavioural expectations may require coercion (Zucker 1977). Human resource systems can be powerful tools for communicating and reinforcing aspects of organizational culture (Tolbert 1988). Rewards and sanctions administered through the performance appraisal and disciplinary processes clearly link individual behaviours and rewards to shape and reinforce culture (Tichy 1982). These pressures are akin to governmental or regulatory body prescriptions on behaviour or to market inducements at the macro level that reward certain organizational activities. Of course it works best when expected behaviours are well defined with clear linkages between expected behaviours and rewards (Edwards 1994). Individuals paid by piece rate or commission are the most obvious examples of this.,1
64,27,"What constitutes rewarded behaviour varies across jobs, organizations and industries, as does the degree to which certain cultural values and behaviours are institutionalized in any one organization. Investment banking, for example, has rigid values and norms of behaviour (Pennings and Gresov 1986) with outcomes identifiable, objective and measurable. Relationships between individual inputs, outputs and rewards are known and understood. Consequences of unsanctioned individual behaviour can be quite striking with high negative outcome potential, thereby requiring rigid control. The case of Barings Bank illustrates the point well. While trading in derivatives, a single trader, Nick Leeson, lost over US$1.4 billion, enough money to bring down a bank that was over 200 years old (Leeson 1996). The trader in question exposed the bank to a magnitude of risk that would not be sanctioned by the bank. Minimal formal or structural controls were in place as the bank appeared to rely on normative controls to limit employee behaviour. This is not unusual as normative (social) and coercive controls are often substituted for each other (Pascale 1985; Tolbert 1988). ",1
65,1,"The literature on educational leadership and management has referred to culture since at least the 1970s. Despite the concept’s mention in over one-third of articles written in this journal, there has been little in-depth engagement with how leaders might influence it and the ethical issues involved. The article argues that leadership must engage with culture as a key mediator of power within organizations. Four levels of cultural activity are suggested: the cultural context created by global phenomena; the cultures of local communities; the organizational culture; and the sub- and counter-cultures within the organization. The article considers a bifurcation in the skills assumed necessary to respond to, on one hand, multi- or intra-culture and, on the other, organizational culture. The article suggests that the degree of perceived difference from norms dictates leaders’ orientation to and engagement with culture, with cultural competence generally promoted only in relation to multicultural issues. It concludes that leaders are currently ill-served by encouragement to focus on aligning the organization’s members to a single, strong culture and that the persistent surface engagement with culture may perpetuate inequalities. The need to move leaders to engage more deeply with the power and complexity of culture is indicated.",1
65,2,"Educational leadership has engaged with the nature and significance of organizational culture since at least the 1970s (Brookover et al., 1978; Sarason, 1971). Since that time, the concept has retained a tenacious hold in the literature, despite frequent attacks on its inadequate conceptualization and doubtful practical application (Lumby and Foskett, 2011; Schoen and Teddlie, 2008). Though culture may be castigated by some as an outmoded concept, its enduring appeal is evident in the persistence of its use and in the frequent reference to culture in texts concerned with leading education.",1
65,3,"In the face of the existing extensive literature it is certainly challenging to review the concept’s use over 40 years and to take thinking forward. An initial question, then, is why we should consider culture and what might be said about it that develops our understanding? The standpoint in this article is that the concept demands attention, if only because its persistence suggests a prima facie case that it performs some necessary function. Schein (2011: xi) asserts: ‘I doubt that there is a manager or scholar alive that does not take the concepts of climate and culture seriously.’ A further imperative to consider culture is the premise that it is deeply implicated in the different and unequal experience of learners and consequently strongly related to a goal of educational leadership, contributing to social justice (Bates, 2006).",1
65,4,"The article briefly reviews the lenses through which culture has been studied and its history in educational leadership. It considers how it has been conceptualized and its place in practice. It discusses a number of arenas in which culture operates in educational organizations. It places the study of culture in a larger field which includes multi- and inter-culture issues as well as organizational culture, and considers the implications of the different perspectives. Finally, the article considers the relationship of culture to social justice and presents an argument for why leaders need to engage deeply with culture.",1
65,5,"The intention here is not to offer prescriptions for managing culture but to begin to dismantle what appears unproblematic in much educational leadership literature; in Foucault’s (2000a: 235) terms, to leave people so that they do not know what to do, rather than knowing what to do, ‘so that the acts, gestures, discourses that up until then had seemed to go without saying become problematic, difficult, dangerous’. The critique in this article is intended to disturb the current relationship between leaders and culture, and to leave them not with a recipe for action, but with a deeper understanding and remodelled agenda of what they need to consider in reflecting on their own way forward with social justice at the heart.",1
65,6,"It is possible to explore culture’s academic evolution and practical application through a number of frameworks: disciplinary, chronological, ideological and methodological. There is not space here to do more than indicate the complex mosaic of culture’s scholastic history. A number of disciplines offer distinct approaches. For example, anthropology has attempted to identify and scientifically depict the culture of individual societies. Cultural studies position the power tussles of socio-economic class, gender and ethnicity in changing everyday culture. Psychology engages with the neuro-epistemological bases of perception and the embeddedness of culturally determined patterns of thought and behaviour. Such a brief description can do no more than hint at the richness of these and other disciplines. The relevance here is that the fields of management and educational leadership have borrowed from a range of disciplines, though often in ways that have mirrored in faint form the conceptual and methodological rigour of the parent discipline.",1
65,7,"An ideological debate has unfolded over time. Bates (2006) suggests an ideological history from a critical perspective, seeing the advent of corporate culture ushering in mechanisms intended to give managers dominance. He suggests that culture is not the shared meanings stressed in many definitions, but ‘a complex mosaic of negotiation (and sometimes rebellion), constantly shaped by the exercise of various forms of power’ (2006:160).",1
65,8,"Study of culture also reflects methodological divergence (Martin et al. 2004). Divides exist between quantitative researchers, who use statistical analysis of questionnaire responses to register and influence culture or climate (Bustamante, 2006; Phillips and Wagner, 2003), and qualitative researchers, who see the necessity for substantial, rich data to make progress in understanding (Hagelund, 2007). Within each division are further sub-groups; for example, within the qualitative camp ethnographers believe that participant observation over time is axiomatic to understanding culture (Vogt, 2002). Whatever methods are adopted, there is persistent dissatisfaction with results and a sense that the culture(s) of an organization continue to elude capture by research (Prosser, 1999). Archer (2005: 17) identifies the problem as the absence of a ‘ready fund of analytical units for differentiating components of the cultural realm that corresponds to those delineating parts of the structural domain (roles, organizations, institutions, systems). Instead ... cultures are still ‘‘grasped’’ as a whole’. The way forward, she suggests, is to achieve better analytical tools.",1
65,9,"Some have attempted to offer analytical frameworks. Hofstede (1984) distinguishes deep culture, the usually tacit and unconscious shared values of many organization members, and shallow culture, the visible signals of culture or the practice of members. Bates (1987) contrasts the dominant culture, viewed across the organization from a horizontal perspective, with sub-cultures and counter-cultures perceived as going down vertically deep into the organization. In relation to schools, Prosser (1999: 7) offers a typology of ‘wider culture’ (the national and international context), ‘generic culture’ (of educators as a profession) ‘unique culture’ (the distinctive culture of a school) and ‘perceived culture’ (the culture as viewed internally and by those judging the school from outside). None of these frameworks have been widely used in relation to education.",1
65,10,"A final characteristic of the study of culture is its propensity to attract metaphors both to communicate the nature of culture as a concept and to characterize individual instances; for example, culture is computer bits (Erickson, 1987), ‘compass’, ‘social glue’ (Clayton et al., 2008: 35), or ‘pixels in the picture’ (Lumby and Foskett, 2011: 452). An individual school culture is described as ‘the shopping mall school’ (Powell et al., 1985) or, as in Stoll and Fink’s (1996) typology of five types of school culture: moving, cruising, strolling, struggling or sinking. Lumby and Foskett (2011) note that the metaphoric language used may both reflect and encourage imprecision in thinking, where the illusion is given that the complex nature of an educational organization can be adequately captured by a word or phrase.",1
65,11,"Others adopt an all-inclusive generality, ‘the peculiar and distinctive way of life’ (Sparkes, 1991: 5) and, most famously, Bolman and Deal’s (1991: 252) ‘the way we do things around here’. What most definitions hold in common is reference to a discernible pattern in human behaviour and its physical setting.",1
65,12,"Few of the attempts at definition or establishing analytic units have attracted widespread adherence. Consequently, it is tempting to turn away from the exhausting profusion of literature in the ‘culture wars’ (Martin, 2002: 6). Some have suggested abandoning the concept’s use entirely, in favour of other theoretical frameworks for studying the differences in belief and action which characterize groups and organizations (Van Oord, 2008). However, if culture can be conceived as the net effect of visible and invisible rules that shape the choice options for thought and action, it remains a powerful sculptor of educational organizations, of what is easy, difficult or virtually impossible to achieve. Consequently leaders, whether they will or not, work with culture; even ignoring culture is a cultural choice. Schein (2011) advocates that leaders set aside attempts at definition and instead focus on working with culture, understanding it and influencing it, adopting Archer’s (2005) position that culture shapes the organization’s performance and that each leader can influence culture to some degree.",1
65,13,"Links have been made between education and organizational culture from as early as the 1930s (Waller, 1932). By 1987, Erickson could already offer an overview of thinking on school culture. Prosser (1999) suggests that research in the 1960s and 1970s was dominated by quantitative studies of climate related to school effectiveness, but that this metamorphosed from the 1980s onwards into school culture research that employed a wider range of methods. The British Educational Index evidences a very wide use of the concept from the 1970s, with an exponential rise in its use since then, from 42 articles in the 70s to 829 in the first decade of the 21st century. The flow shows no sign of abating. Culture is indicated as a distinct phenomenon invested in a range of units; in socio-economic classes, such as the white, working class, in education sectors, the culture of higher or further education, in an organization, the school culture, in a location within the organization, a classroom culture, in professional groups – for example, particular subject teachers or even in approaches to teaching and learning, the culture of a subject’s curriculum A range of adjectives is used to describe culture, some with positive or pejorative connotations: a learning culture, a professional development culture, an entrepreneurial culture, an audit culture or an examination culture.",1
65,14,"The conviction that culture and the performance of an organization are linked is strong. The origins of this may lie in part with 1980s and 1990s corporate evangelists, such as Peters and Waterman (1982) or Kotter and Heskett (1992), whose espousal of culture as a performance enhancing tool has been taken up enthusiastically in education. Spillane (2005) notes the widespread adherence to the notion of a charismatic leader who can transform culture and thereby a school’s fortunes. Recent commentators have suggested that the evidence linking culture and performance is tenuous (Clayton et al., 2008; Martin et al., 2004). Such assertions have not dented the attachment of many educators and researchers to culture as key to an organization’s performance (Harris, 2003; Woods et al., 2004).",1
65,15,"The nature of literature on culture in EMAL and elsewhere may reflect in some sense the practice of many educational leaders. The articles in EMAL with ‘culture’ in the text fall into two categories; the minority that focus on defining and discerning organizational culture in some depth, and the large majority that refer to culture in indistinct terms, synonymous with organizational context or with a general approach to a particular area of activity. The most prevalent orientation to culture is reference to a single organizational culture, presenting it as a loose, undefined context, referred to rather as cultural wallpaper or background culture ‘muzak’. There are many references to changing culture (Busher, 2005; Lance, 2010), but infrequent deep engagement with how this might be understood and the ethical implications of doing so.",1
65,16,"The integrationist ideological perspective is strongly evident and deeply embedded in normative prescriptions for educational leadership. For example, the UK National College for School Leadership (NCSL) has offered a range of publications where a recommended process is the production of a clear vision as precursor to a strong culture, as in a case study ‘A strong leadership culture emanating from a clear vision’ (NCSL, n.d.). Strong culture is taken to be desirable. The integrationist perspective assumes that organizations can unite behind a single culture that is benign and supports the interests of learners (Gold et al., 2003). It is doubtful if this is a credible position in the light of much evidence that schools and colleges do not work equally well for all learners (Carter and Osler, 2000; Martina, 2006). The dominant culture is likely to be working in each school or college in favour of some and disadvantaging others. In other words, culture is implicated in the modulation of power.",1
65,17,"The effect of organizational culture matches Lukes’ (2002) description of covert power. It makes ways of thinking and acting seem natural and unchangeable (Lakomski, 2001). Without obvious coercion, nevertheless it shapes possibilities. It is not possible to transgress cultural boundaries without risking serious penalties (Freidenberg, 2009; Gilligan, 1988). Viewed as an embedded shaping of human activity, culture matches exactly what Bachrach and Baratz (2002) call the ‘mobilization of bias in the community’, privileging the values and interests of one group over others by means that may not be overtly or consciously intended to dominate. Culture is one structure for the negotiation of power exercised through mundane everyday activity (Willis, 2008). It is one of the ‘dividing practices’ sought by Foucault (2000b: 326) that cannot be escaped. An individual or organization may determine to step outside an existing culture or to change it, but it remains the defining point of reference (Bishop et al., 2006; Spicer and B ̈ ohm, 2007). Culture is a fundamental shaping and disciplinary force on which organizations depend. Culture and the divisions it embodies are therefore a necessary focus of leaders and a particularly potent medium for those who aim to support social justice.",1
65,18,"The good and ill resulting from globalization, or even whether such a thing exists, is deeply contested. Nevertheless, there are widespread expressions of concern that transformed technologies and communication have in turn transformed economic and political relations and, of particular relevance, shifted the contract between the state and education (Apple, 2000). The new relationship cascades down through schools and colleges, reflected in cultures that strongly influence what is perceived as possible.",1
65,19,"The second arena of culture relevant to educational leaders is that of local communities. There is some agreement that the external cultures of local communities influence, in many cases decisively, the progress of learners (Lee, 2008). Educators’ judgements about the nature and worth of external cultures are habitually filtered through a viewpoint shaped by the professional acculturation of teaching. Erickson (1987) outlines a range of professional assumptions about, for example, whether ability is innate and relatively fixed, and the necessity for schools to intervene strongly to compensate for family deficits in developing language and reading. Educational leaders may feel intuitively that these are correct assumptions, though Erickson points out that they are both contested and culturally specific. Assumptions about goals may also be culturally influenced. Quiroz et al. (1999) highlight a Latino parent’s negative response to a teacher’s report of ‘outstanding’ work. Standing out is viewed negatively within collectivist cultures. External cultures therefore impact directly on students’ attitudes and practice and are also refracted and impact through the assumptions and value judgements embedded in how educators view external cultures.",1
65,20,"To change outcomes for many learners, not only internal but external cultures or the relationship between the two may need to change. The debate then moves to how educational leaders can exert influence on community cultures or shape their internal culture to reduce friction between the two. Pe ́rez Carreo ́n et al. (2005) document the cultural tensions between immigrant parents and their children’s school in the USA. The authors conclude that a meaningful relationship based on trust is needed, with at least one social actor in the school in order for there to be genuine communication and interaction between cultures. Writing on Native American learners in the USA, Kincheloe and Staley (1985) find students for whom the experience of school is so alien there is no conflict of culture, because there is no perceived connection between school and home. Disconnection relates to educational failure (Bates, 1987; Willis, 1977). Other students hold the two as distinct options, moving between them, adapting to each. A third category of student is those who experience home and school as culturally aligned and find no disjunction. The values embedded in the dominant organizational culture and in the curriculum are arguably aligned more strongly with the culture of the middle or upper socio-economic class of the majority of policymakers and teachers (Ara ́ ujo, 2005; Lumby, 2012).",1
65,21,"Statements of vision or mission are cultural markers, public testimony to the educational equivalent of a corporate culture. Their typical content commits to develop the potential of all students and may be part of a general culture of hyperactive promotion of positive and optimistic attitudes presented to the public gaze in a performative environment.",1
65,22,"Assumptions about thinking and learning, curricula, teaching and assessment are culturally shaped (Hilberg and Tharp, 2002; Merriam, 2008). Periodic reviews of curricula rarely result in radical change as the latter is confined to what is culturally valued by the dominant group. For example, vocational education, however defined, is more culturally valued in some countries and by those from some cultural backgrounds than others. Its place in the curriculum reflects its local cultural value. Sailes (2008: 76) suggests that the platform for much teaching is ethnocentric and middle class, but that this is concealed behind a belief that ‘good teaching is transcendent’, rather than shaped by the culture of the dominant group. Even though demonstrably ineffective for many out-groups, the accepted technical processes of ‘good’ teaching and assessment remain the gold standard (Sparkes, 1991). By a cultural sleight of hand this mechanism of cultural dominance may be supported by out-groups as much as the in-group. The response to children’s resistance to curricula and learning that they experience as in tension with their cultural background is often reactive disciplinary measures (Slee, 1994; Thompson and Bell, 2005) that take little account of the perspective of learners but instead bolster the culturally shaped experience of schooling. ",1
65,23,"People create cultures that underlie the quasi-corporate culture by forming groups around the multiple identities of staff and learners; for example, relating to subject specialism, length of tenure of role or geographic location of one’s home. As West (1999) points out, such groups are usually led by an individual who establishes cultural norms of attitude or behaviour or even territory. Resistance to whatever action a head teacher or teacher requests may be an auto reflex embedded in the group cultural norms.",1
65,24,"Becher’s (1988) metaphor of a theatre stage may capture how sub-cultures function. There is the public performance of culture projected from the stage to all in the auditorium. Backstage, there may be less open manipulations, hidden from the wider public view; finally, there is understage activity buried deep, even from the view of the main actors. On the open stage are the symbols and rituals of the corporate culture; the physical signs of uniform, how space is used, to whom it is allocated, the tenor of meetings of staff and students, the way community members are expected to address one another, and the vision/mission statement. Backstage are other less openly communicated cultural strategies, for example, controlling entry. Which students and staff are recruited is a powerful shaper of culture (Van Houtte, 2005). Under-stage is a melee of countercultures, where students and staff resist and subvert the cultural boundaries of the organization by tactics such as aberrant dress and hairstyles, acts of disruption, or humour directed against management or teachers (Prasad and Prasad, 2000). Myriad intentional and post hoc constructed acts of resistance reflect the power interplay of students and staff as they attempt to strengthen or dismantle cultural restrictions.",1
65,25,"Each group serves the psychological needs of its members by providing protection and self-affirmation (Schein, 1965). A primary concern is status within the group and in relation to other groups, achieved by demonstrated conformance to whatever the norms of their own group may be. Adolescent gangs in school are cultural groups that, denied the status of academic attainment, construct other criteria, such as toughness or risk taking. It is beyond the scope of the article to explore further the culture of learners’ gangs or those of professionals. It is, however, evident that whatever the purported rationale for such groups, at the heart is a desire to be safe from psychological or physical attack and to be valued and rewarded. Leaders who wish to encourage sub-culture groups to move in a particular direction will need to consider how far the direction suggested actually respects the group’s cultural choices or the contrary. Communicating ‘care’ in a way that implies disrespect or disagreement with the cultural choices of a learner is a weak counter to the power of his or her group culture.",1
65,26,"Adopting a differentiation perspective and engaging with sub-cultures and community cultures is arguably more challenging for education leaders than dealing with a single organizational culture. Bryson (2008) suggests a methodology to achieve a fuller picture of the multiple and developing cultures of an organization. She uses Williams’ (1980) analysis of dominant, emerging and residual cultures. Emerging cultures are those in formation, perhaps triggered by new staff or new circumstances; residual cultures are those that linger from an earlier time, perhaps before the current principal arrived or in earlier funding regimes. Both emergent and residual cultures may present alternatives to the dominant culture or be actively in opposition to it. She suggests using a wide range of data from many people internal and external to the organization to identify the residual and emerging cultures from multiple perspectives in order to better understand culture as a dynamic and contested phenomenon and not a static, unitary reality.",1
65,27,"How then can leaders respond to the phenomenon of culture? In reviewing educational management and leadership literature over 40 years, several perspectives are apparent in relation to managing culture and the competence necessary to do so. The skills to influence organizational culture do not figure largely. Far more evident are the skills necessary to respond to ‘multi’ cultural issues, related to the notion of increased diversity and particularly ethnic diversity in learners and educators (Grobler, 2006; Henze et al., 2001; Shah, 2006). There is also interest arising from notions of internationalization, particularly in higher education, leading to interest in ‘inter’ cultural issues (Trahar, 2011). Implicit in these distinctions are judgements about engaging with ‘culture’. On the one hand, multi-cultural and inter-cultural perspectives are widely perceived to demand cultural competence of a particular kind to accommodate the cultures deemed most distant from the norm, those of visibly different ethnic minority students (Lumby with Coleman, 2007). On the other hand, are integrationist perspectives on organizational culture, where similar cultural competence is not indicated as a requirement. ",1
65,28,"There are, of course, potentially many ways of interpreting the reasons for this bifurcation in attitude. One perspective might argue that the cultures of ethnic minorities are indeed different enough from the majority culture to demand the development of skills to read the multi-cultures to ensure that minority students and staff are not excluded by the majority culture (Lopez, 2003; Mackay and Etienne, 2006). Simultaneous maintenance of a strong organizational culture is also beneficial, because this embeds values and attitudes supportive of learning and good citizenship and so of advantage to all. A more critical interpretation would view the motivation and aims quite differently. On both sides of the bifurcation, cultures of those perceived as other are subject to control, not by overt aggression but by subtle cultural power plays that attempt to enrol the other in the core values and life view of the dominant group (Bourdieu, 1993). The greater attention paid to understanding minority ethnic cultures perceived as having a greater degree of difference, and the concessions made in some changed practice, may be proportionate to the perceived degree of threat (Milliken and Martins, 1996). ",1
65,29,"The position suggested in this article is different, assuming that, while organizational cultures cannot be controlled, they can be influenced to some degree and that deciding on the direction of influence is a key moral challenge for leaders. In doing so leaders may need to accept both conceptual and methodological limitations as a product of the problem. Lukes (2002) believes that there are certain concepts that will be inevitably and continuously disputed. Culture may be such a concept, yet we may need to set aside the frustrations and engage, because culture has generally sat in our peripheral vision since the initiation of this journal. Educational leaders are aware of it, but we have neither the tools to see it completely and straight on, nor the critical perspective that may be necessary to engage deeply. Nevertheless, the juggernaut that is only partially seen at the edge of our vision remains a juggernaut with considerable potential constructive or destructive power. Superficial engagement with culture is, in effect, a decision to perpetuate the status quo with all its inherent inequalities.",1
65,30,"In line with this stance and with an interactionist understanding of the relentless persistent negotiation of culture and community (Fernback, 2007), this article does not offer a formula for creating a strong culture or for re-culturing (Dimmock and Walker, 2005; Hargreaves, 1999; Schein, 1997). It has used a review of culture in the field for the last 40 years to suggest that integrationist perspectives embedded in normative encouragement to action are likely to perpetuate the kind of inequities that currently exist in much education. Rather than focusing on changing others, the goal is changing oneself, and understanding more fully one’s own culture and its relationship with the alternative and oppositional cultures that exist in each organization. If it is not possible to capture in full the rich, diverse and often conflicting melee of cultures evolving over time in an organization, some progress may be achieved in understanding and engaging with the richness. Currently, knowledge and understanding derived from research are not valued unless there is impact, suggesting a separation between the two, one distinct from the other. The contrary belief is that knowledge and understanding are change in themselves. ",1
66,1,"Psychologists interested in culture have focused primarily on East–West differences in individualism– collectivism, or independent–interdependent self-construal. As important as this dimension is, there are many other forms of culture with many dimensions of cultural variability. Selecting from among the many understudied cultures in psychology, the author considers three kinds of cultures: religion, socioeconomic status, and region within a country. These cultures vary in a number of psychologically interesting ways. By studying more types of culture, psychologists stand to enrich how they define culture, how they think about universality and cultural specificity, their views of multiculturalism, how they do research on culture, and what dimensions of culture they study. Broadening the study of culture will have far-reaching implications for clinical issues, intergroup relations, and applied domains.",1
66,2,"Psychological understanding of culture has advanced in many ways as a result of work in this theoretical tradition. Nevertheless, the intensive focus on geographic or ethnic variation in self-construal does have certain drawbacks. For one, Hui and Yee (1994) noted that individualism– collectivism is commonly invoked to explain any observed cultural difference despite the fact that Oyserman et al. (2002, p. 40) concluded that cultural differences in individualism and collectivism “were neither as large nor as systematic as often perceived” and that findings from student samples were likely not generalizable. Second, there seems to be a tendency to equate culture with country, so much so that Triandis (1995) felt it necessary to point out that countries are not the same as cultures. Nevertheless, Triandis’s view of cultural syndromes best fits people living in a certain country, speaking a certain language, at a certain time: A cultural syndrome is a pattern of shared attitudes, beliefs, categorizations, self-definitions, norms, role definitions, and values that is organized around a theme that can be identified among those who speak a particular language, during a specific historic period, and in a definable geographic region. (Triandis, 1996, p. 408)",1
66,3,"A Southern Baptist male from Sacramento, a Sephardic Jewish grandmother from San Francisco, and an agnostic Chinese American student at the University of California, Berkeley share a language, a historic time period, and a geographic region yet might not share their most important attitudes, beliefs, norms, or values.",1
66,4,"The purpose of this article is to suggest that psychologists explore more kinds of variation among more kinds of cultures. An example of the kind of question that inspired this article is: In what ways does an English-speaking male Jew, raised in the United States, share a cultural outlook with his Yiddish-speaking Jewish great grandmother (of blessed memory), who lived in Eastern Europe, or with a modern, Hebrew-speaking Jew who lives in Israel? These are people speaking different languages, separated in time and space, but surely there is some shared culture as well as some cultural differences. Perhaps they recite the same prayers and observe the same holidays—important aspects of culture. Perhaps they have similar views about which foods may or may not be eaten, a culturally significant activity that shapes social relationships and provides clues about the culture’s worldview (Douglas, 2002; Meigs, 1991; Rozin, 1990). In other domains, the American Jew may have more in common with the Christian who lives next door. Perhaps certain aspects of individualism characterize the American Jew and Christian but not the Israeli or Eastern European Jew.",1
66,5,"There is a large array of cultural influences I could discuss. For example, take an individual who is Ashkenazic Jewish, middle class, a social psychologist, American, from Philadelphia, and now living in the Southwest. Probably all of these, as well as many other identities, can be fruitfully viewed as cultural identities. Selecting from among the many kinds of culture that are worthy of study, I focus here on three kinds of cultures: religion, socioeconomic status, and region within a country. I chose these three types of cultural variation for three main reasons. First, they are marked by different kinds of group affiliations and have cultural dynamics different from one another, and reviewing these diverse types of cultural variation will hopefully show the many interesting distinctions among cultures. A second reason is that each of these influences has been explicitly discussed and explored within psychology as a cultural influence, so there is already a burgeoning conceptual and empirical platform on which to base my discussions. Third these three kinds of cultures seem especially influential. Along with ethnicity or nationality, religion, region, and social class probably account for an especially large amount of variation in transmitted norms, values, beliefs, behaviors, and the like. ",1
66,6,"It is perhaps not often enough stressed that James saw religion as a diverse set of phenomena and that he was not trying to provide a comprehensive definition. Rather, he was defining religion for the purpose of the lectures on which Varieties of Religious Experience is based, and a large focus of the work was on highly personal, born-again experiences.",1
66,7,"Members of different religious groups, even within one country, differ in many psychological processes. One elegant line of work examined cultural differences between Calvinist Protestants and members of other religions (e.g., Catholics) on whether they were focused on a business task, or were interpersonally oriented, while in work contexts. Sanchez-Burks (2002) took his theoretical grounding from the highly elaborated Calvinist values regarding finding a calling in work. In one experiment, participants were put into a workplace frame of mind by having them don shirts and ties and discuss how to reduce business costs. Or participants were put into a casual frame of mind by having them wear Hawaiian shirts and play a card game. In a work context, but not in a casual context, Calvinist Protestants were less attentive to relationality and therefore able to tune out the emotional tone of a list of words they listened to and focus only on the words’ meanings. Members of other religions did not vary in this task depending on condition. In an experiment on nonconscious mimicry as a cue to whether people were focusing on others or on the work task, Calvinist Protestants did not mimic the foot-shaking behavior of a confederate while in a work context but did in a more casual context. Cues to business versus casualness had little effect on members of other religions.",1
66,8,"Religious cultures also differ in what it means to be religious. For example, some religions focus more on practice (orthopractic religions) and others on belief (orthodox religions). For Jews, religiousness is primarily reckoned by the extent to which one behaviorally adheres to the prescriptions and proscriptions present in Jewish law. If one knows whether a Jewish man practices the dietary laws, whether he observes the Sabbath, and how often he prays, one does not need to know whether he believes in God to predict how religious he considers himself to be— despite the fact that belief in one God is at the theological core of Judaism and that Jewish law assumes, and perhaps commands, belief in God (A. B. Cohen, Siegel, & Rozin, 2003). It seems fair to say, however, that such belief does not occupy the same place in Jewish culture as it does in Christian culture. In contrast, the idea that one could estimate a born-again Christian woman’s religiousness without knowing her beliefs about God is oxymoronic, if not heretical. Empirically, for Christians, both belief and practice make unique contributions to predicting self-rated religiousness (A. B. Cohen et al., 2003; reviewed in A. B. Cohen, Hall, Koenig, & Meador, 2005).",1
66,9,"In the domain of moral judgment, religious cultures also show important differences. Christian doctrine considers thoughts about immoral actions to be as morally relevant as the actions themselves—reflecting Jesus’ pronouncement that “whosoever looketh on a woman to lust after her hath committed adultery with her already in his heart” (Matthew 5:28). In Judaism, however, thinking about an immoral action does not have the moral status of the action. Jews in fact consider thoughts about various immoral actions, such as thinking about having an affair, or thinking about being cruel to an animal, to be much less morally important than do Protestants (A. B. Cohen & Rozin, 2001). Although Protestants consistently rate thoughts about immoral actions to be more likely to be acted upon than do Jews, this is not why Protestants attribute more moral status to thoughts. Even thoughts about very unlikely immoral actions (such as a man thinking about having an extramarital affair with Julia Roberts) are judged more immoral by Protestants than by Jews (A. B. Cohen, 2003).",1
66,10,"These tendencies are nuanced by the specifics of theology. The Jewish Talmud explains that God does not consider an intention to commit an immoral action to be morally consequential but does consider an intention to commit a positive action to be virtuous. The reasoning is that Talmudic scholars assumed people would overcome their evil inclinations when given the opportunity to act on them but that people would cultivate and try to act on their inclinations to do good. Reflecting this reasoning, Jews give as much moral credit as do Protestants to thoughts about highly virtuous actions, such as giving a large amount of money to charity (A. B. Cohen & Rankin, 2004). Insofar as it is unlikely that their Jewish subjects actually had ever directly read the Talmudic discussions of these issues, Cohen and Rankin proposed that Jewish culture (as distinct from the texts per se) contains these notions.",1
66,11,"The American Psychological Association’s Task Force on Socioeconomic Status (2007) recently noted that differences in socioeconomic status and social class have important implications for human development, well-being, and physical health. In particular, poorer people show considerably worse trajectories of development, worse physical health, and lower well-being. In research on socioeconomic status and social class, these are commonly operationalized as combinations of variables such as income, education, and occupational prestige. When investigating social class and socioeconomic status, many investigators also probe subjective social class, or individuals’ estimation of their own social class. People may perceive their social class to be different from what objective indicators might suggest. For instance, a plumber may have several times the income of a college-educated bookstore clerk, yet the clerk may regard herself as middle class, whereas the plumber may regard himself as lower in social class. Socioeconomic and class inequity may be perceived not only in terms of tangible resources such as income but also in terms of structural aspects such as power, privilege, and social capital",1
66,12,"Whereas much attention has been paid to the effects that socioeconomic status and social class have on domains such as health, development, and well-being, psychologists have not often taken a culturally informed approach or considered the rich culturally textured beliefs, values, and practices of higher versus lower social class individuals. Like the work on religion I have reviewed, theorizing and empirical work on socioeconomic and social class differences also document cultural differences in values, norms, and practices, as well as artifacts (such as music) that cultural groups create and that affect their worldviews. These may be important to understand in linking socioeconomic and class differences to health and well-being outcomes.",1
66,13,"Snibbe and Markus (2005) focused on how people of low and high socioeconomic status differ in their views of agency. Those of high socioeconomic status are more able to control their environments and influence others. Those of low socioeconomic status are more likely to have to adapt to their surroundings and maintain their integrity because of their inability to directly control their environments. Thus, Snibbe and Markus claimed that the culture of high socioeconomic status values control and agency, whereas the culture of low socioeconomic status more highly values flexibility, integrity, and resilience.",1
66,14,"Further experiments performed by Snibbe and Markus (2005) suggested similar conclusions. Imagine participating in a psychology experiment and being asked to choose a pen, from among several alternatives, as a reward. How important to you is it that you get the pen that you chose? Snibbe and Markus told participants that the pen they chose was actually not available—thus usurping their choice. High socioeconomic status subjects found this more upsetting than low socioeconomic status subjects, who are more used to having their choices overturned and more used to adapting to not getting what they want.",1
66,15,"Snibbe and Markus (2005) also performed several experiments using educational attainment as their indicator of socioeconomic status. They focused only on European Americans, so that racial identification was not confounded with their cultural variable—socioeconomic status. In one experiment, they examined the spreading alternatives effect. This effect describes the tendency for people to value more highly, after some time has passed, an alternative that they chose, relative to an equally attractive alternative that they did not choose. Snibbe and Markus demonstrated that this effect occurs among college-educated participants but not among high-school-educated participants. When asked to choose between two equally attractive compact discs, college-educated people came to value more highly the disc they chose, whereas high-schooleducated people did not later see the disc they chose as more valuable.",1
66,16,"One additional cultural variable that I wish to review is regional differences within a country. People from different geographic regions within countries differ in their norms and values, such as in the importance of honor and reputation, and in aspects of individualism and collectivism. First I review work on the culture of honor (D. Cohen, Nisbett, Bowdle, & Schwarz, 1996). Cultures that subsist by herding typically attach more importance to honor and reputation than do people from agrarian societies. If a person in a herding culture develops a reputation as someone who vociferously defends threats against his honor, his livelihood is less likely to be taken away by rustlers. A person who has a reputation as a pushover is more likely to have his herd rustled. Whites in the southern United States derive historically from Scotch-Irish herding societies, but Whites in the North are more likely to be descended from farmers. Therefore, D. Cohen and colleagues proposed that values about honor and reputation are more likely to be present in Southerners and that Southerners are more likely to respond to insults with violence.",1
66,17,"There are interesting regional differences in other countries, as well. Recent work by Kitayama, Ishii, Imada, Takemura, and Ramaswamy (2006) examined residents of Hokkaido, Japan. Hokkaido, which can be thought of as Japan’s northern frontier (Japan’s “Wild North”), shares certain historical features with the American Wild West frontier. Hokkaido was settled by jobless samurai during the Meiji government in the late 1800s. Kitayama et al. theorized that settling a frontier may depend on a desire for personal wealth and achievement, may promote self-reliance, which is necessary to survive, and may promote a lay theory of behavior as internally motivated because settlers are goal oriented. This is similar to the reasoning offered for American individualism being related partly to a frontier history (Oyserman et al., 2002).",1
66,18,"This research team generated compelling, converging evidence for this hypothesis by using survey studies, field experiments, and lab experiments. In surveys, Southerners are much more likely than Northerners to espouse the use of violence in response to threats to a person’s honor. For example, Southerners are more likely to agree than Northerners that a person would not be much of a man if he did not fight a person who insulted his wife. In field experiments, Southern businesses were more likely to consider a male job applicant who had been in jail for violently defending his reputation (by killing a man who claimed to be sleeping with the protagonist’s fianc ́ e and publicly challenged him to do something about it). Southern and Northern businesses, on the other hand, were not different in their responses to a male job applicant who had committed a crime that was not relevant to honor (stealing cars). In the lab, White Southern males responded angrily to being insulted, behaviorally asserted their masculinity by being more aggressive and confrontational with a physically intimidating research assistant, and showed spikes in their salivary cortisol and testosterone— hormones related to stress and aggression. White Northern males were more likely to respond with confusion or even amusement to being insulted. ",1
66,19,"Regional differences within countries can show consistent patterns across countries. Small towns in Australia may look a bit like small towns in Japan. Kashima et al. (2004) examined regional differences in the self in Japan in Tokyo (a large metropolitan city) and Kagoshima (a regional city) as well as in Australia in Melbourne (a large metropolitan city) and Wodonga (a regional city). The aspects of the self that were of interest were agency (assessed with items such as “I act more on the basis of my own judgment than on other people’s decision”), assertiveness (e.g., “I assert my opposition when I disagree strongly with other people”), the relational self (e.g., “I feel like doing something for people in trouble because I can almost feel their pains”), and the collective self (e.g., “I would act as a member of my group rather than alone as an individual”). The authors found that Australians had a more individualistic self, scoring higher on agency and assertiveness, than the Japanese. Women were more relational. However, in both countries, metropolitan residents were less collective than their regional counterparts.",1
66,20,"In a study that points to another form of interesting variation among people of differing socioeconomic status, Haidt, Koller, and Dias (1993) examined moral judgments of higher and lower socioeconomic status adults and children in three cities in the United States and in Brazil. These investigators were particularly interested in actions that were highly disgusting or disrespectful but were not harmful to others—such as a person having sex with a dead chicken before cooking it for dinner, a son breaking a promise he had made to his dying mother, and a brother and sister passionately kissing each other. (Of course, child participants were not presented with the more provocative scenarios.) Both country and socioeconomic status differences were found. Brazilians found the actions more immoral than Americans, and in both countries, those of low socioeconomic status were more likely to judge the offenses to be immoral rather than a personal choice or a violation of a social convention. Socioeconomic-statusbased differences were in fact bigger than the country differences.",1
66,21,"A middle ground is the view that all cultures contain to some extent the same ideas and meanings but that they elaborate or make more accessible a certain set of these ideas and meanings while deemphasizing others. Kluckhohn and Strodtbeck’s (1961) values orientation theory proposed that all cultures contain the same values but that different cultures will prefer some values over others. Rozin (2003) has similarly proposed that many cultural differences derive from differences in default responses to a stimulus, though members of different cultures can likely understand the responses of people from other cultures. However, default differences can result in more divergence down the road as they take people in different directions.",1
66,22,"In a related point, people become exposed to their own and other cultures in many ways, including assimilation, acculturation, socialization, enculturation, and even tourism. Researchers who work on such topics often rely on two perspectives. First, there is likely a sensitive period for the acquisition of culture (as there is for language), after which one cannot ever fully acquire a culture the way a native has. A second focus of research is the stress that can be experienced as a person has difficulty coping with unfamiliar worldviews, norms, languages, and foods of other cultures (Berno & Ward, 2005; Gonzales, Knight, Morgan-Lopez, Saenz, & Sirolli, 2002; LaFramboise, Coleman, & Gerton, 1993). These processes have been given considerable attention, yet the focus is almost always cultural transitions between countries.",1
66,23,"Different forms of culture could have interesting differences in these processes. Moving between socioeconomic status groups could be in some ways similar to, and in some ways very different from, moving between countries. Being the first in one’s family to go to college often means one is put in a situation that highlights the vastly different cultural environments that upper versus lower social classes entail. Moving from one part of a country (such as Philadelphia) to another (such as Tempe) may not seem as much of a cultural transition as moving from one country to another. People in Philadelphia are American, and so too are people in Tempe. English is spoken in both places, and perhaps most people in these American cities are essentially individualistic. Nevertheless, different regions of a country have their own norms, practices, and values. The 2008 presidential electoral map showed Pennsylvania as a blue state but Arizona as red.",1
66,24,"Religious conversions represent a kind of cultural change that would have its own dynamics. Converting from one religion to another, going from having no religion to having one, or losing one’s religion may have their own unique processes. These processes can differ among religions, as well. Some religions, such as Judaism and Hinduism, decide their membership primarily on the basis of biological descent. Other religions base membership on what one believes, and conversion processes are often informal or absent (Morris, 1996). Some processes of religious conversion may be gradual and highly ritualized, whereas others may be informal and sudden (James, 1902/ 1997). Various types of cultural changes will have different dynamics depending on the type of cultures an individual is moving among.",1
66,25,"Last, I recommend greater specificity in how psychologists carve group memberships. Fiske (2002) pointed out that “Asian American” is often treated as a meaningful category despite the fact that this label applies to people from thousands of cultures (and so too for terms like Latino American, African American, and others). Perhaps high versus low socioeconomic status, Jewish versus Christian, and Northern versus Southern are also too coarse a set of labels.",1
66,26,"A final reason to widen our view of forms of culture is that it would inevitably suggest new kinds of interesting cultural variation. As reviewed above, culture affects not only between-country differences in individualism versus collectivism, or independent versus interdependent self-construal, but also moral judgment and moral reasoning, agency, relationality, defense of honor, as well as withincountry differences in aspects of individualism and collectivism. Broadening our view of the domains affected by culture can even have an impact on well-studied theories in psychology. Here I consider one example, terror management theory (Rosenblatt, Greenberg, Solomon, Pyszczynski, & Lyon, 1989). Terror management theory proposes that people respond to reminders of their mortality by affiliating with their own cultures and by derogating people from other cultures. Beliefs about death and the afterlife differ markedly among religious cultures. Whereas some attention has been paid to religious beliefs in terror management (Dechesne et al., 2003; Norenzayan, Dar-Nimrod, Hansen, & Proulx, 2009; Norenzayan & Hansen, 2006), there are many interesting but unanswered questions about group differences. Whereas fundamentalist Christian culture strongly emphasizes belief in the afterlife, Judaism does not, at least not in quite the same way. ",1
66,27,"Last, from a practical or applied perspective, there are many domains that can be much better understood by appreciating the role of culture, such as in educational settings, organizational settings, and health settings. Just to take one example, I briefly consider some implications of the above discussions for health psychology. It is well established that people of lower social class suffer from poorer health, and this is often understood to reflect factors such as lower education (and hence lower knowledge about healthy lifestyles) and worse access to medical care. Although these factors are surely part of the explanation, perhaps other cultural factors come into play as well. As lower socioeconomic status individuals more highly value resilience in the face of adversity, as opposed to focusing on altering their environments, perhaps lower social class people are less likely to seek out solutions to their health problems or even to feel that this is the most appropriate avenue to deal with them. Rather, they may seek to adapt to their health problems with integrity. Furthermore, religiosity and socioeconomic status are negatively correlated, and people of low socioeconomic status may feel that their illness is God’s will and has some greater meaning and that their task is to discover this meaning. ",1
67,1,"It is now possible to make mouse spermatogonial stem cells (SSCs) proliferate in vitro. However, these cultured cells, called germ-line stem (GS) cells, consist of not only SSCs but also a greater number of progenitor spermatogonia. Moreover, isolated GS cells barely proliferate. To elucidate the nature of SSCs and progenitor spermatogonia, we adapted a microdrop culture system to GS cells. Using a micromanipulator, individual microdrops were seeded with clusters or dissociated known numbers of GS cells. The number of surviving colonies was determined after 30 days. The proliferation rate of GS cells in microdrops increased as the number of GS cells seeded increased. It was observed that as few as three GS cells seeded in a microdrop can proliferate and expand the colony size. Those GS cells of expanded colonies were able to proliferate following subculture and underwent spermatogenesis in the host testis after transplantation into the seminiferous tubules of recipient mice. These data revealed that SSCs can multiply in a microdrop culture system. Microdrop culture offers a novel tool to elucidate the nature of SSCs in regard to their self-renewing capacity and can serve as a monitoring system of culture conditions for the self-renewal of SSCs.",1
67,2,"The lifelong production of sperm is made possible by spermatogonial stem cells (SSCs), which are defined as possessing the ability to self-renew and the potential to differentiate into spermatozoa. The daughter cells of SSCs can be either SSCs or progenitor spermatogonia. The spermatogonia, defined as mitotic germ cells in the mature testis, represent every premeiotic male germ cell residing on the basement membrane of the seminiferous tubules. SSCs are therefore a subpopulation of spermatogonia, while progenitor spermatogonia work as so-called progenitor cells or transit amplifying cells to expand their population by sequential cell division. This expansion of spermatogonia is the basis for the production of enormous numbers of sperm.",1
67,3,"SSCs have long been proposed and generally considered to be singly isolated type A spermatogonia (Asingle,orAs spermatogonia), while progenitor spermatogonia are regularly connected to each other by cytoplasmic bridges with siblings forming chains of cells [1, 2]. Recent studies have shown that such a hierarchical stem-progenitor system basically holds true, but it is more flexible and adaptable, meaning that progenitor cells retain some stem cell activity as well [3]. Some molecular markers for undifferentiated spermatogonia, which include SSCs, were also identified, including Zbtb16 (also known as PLZF), Gfra1, Thy1, and so on [4]. In addition, it was reported that glial cell line-derived neurotrophic factor (GDNF) was a master factor for the expansion, survival, and/or self-renewal of SSCs [5]. Using GDNF as a soluble factor in culture medium, it became possible to expand and maintain long-term cultures of mouse SSCs in vitro, called germ-line stem (GS) cells [6]. Now, rat and hamster SSCs can also survive and multiply for long periods in culture [7, 8]. The development of these culture methods made the study of SSCs at the molecular level possible [4]",1
67,4,"In the first set of experiments testing the microdrop method, relatively large GS cell colonies (estimated 40–300 cells per colony) were chosen from the maintenance culture dishes. These GS cell colonies were picked up and transferred into microdrops of three different sizes: 5, 10, or 20 ll. Every GS cell colony (N ¼ 27 microdrops) grew and steadily increased in size during the culture period (Fig. 1A). The colony size increased exponentially regardless of the drop size (Fig. 2A). Therefore, the volume of the drop did not affect the proliferation rate of GS cells in this experiment. The proliferation speed of GS cells in microdrops was approximately calculated from the size of the colonies. The colony size doubling time was about 7 days in the first 3 wk. Thereafter, it slowed in all three groups, indicating that the rate of proliferation decreased, probably because of space or nutrient limitations and the accumulation of waste products in the limited culture volume (Fig. 2B).",1
67,5,"In the second experiment, we tested the microdrop culture method for smaller colonies of GS cells. The GS cell colonies cultured in regular dishes were fragmented with a 26-gauge needle to produce small cell clusters of 2–12 cells. Each fragment was picked up and seeded into a 5-ll microdrop. In some drops, the GS cell colonies grew and enlarged by day 7. Most of these colonies continued to proliferate (Fig. 1B). In contrast, GS cell clumps that did not show any growth by day 7 generally disappeared at 2 wk. Of the 45 total drops, eight drops showed the sustained expansion of GS cell colonies until the end of the study period (30 days) (Table 1). The expansion efficiency per drop was eight out of 45 drops (17.8%). The 45 drops contained a total of 297 GS cells at the start of the culture period; therefore, the development of eight colonies indicates a proliferation efficiency of each GS cell of 2.7% (8/297), assuming that each colony originated from a single GS cell. This proliferation efficiency may reflect the percentage of SSCs in the GS population, as only SSCs can form colonies.",1
67,6,"The microdrop culture method was developed by Ralph L. Brinster [14]. In his efforts to establish culture techniques for ova and embryos, he showed that methods using small droplets of media under liquid paraffin oil were effective and especially useful for the observation of ova and embryos and for collecting quantitative data [15]. The microdrop method has since been employed by many researchers and is now a standard practice in many IVF programs [16–18]. The benefits of a microdrop-under-oil culture result from both the oil overlay and reduced incubation volume. The oil provides protection from contamination, reduces evaporation, and stabilizes the temperature and pH. It has also been shown that an oil overlay can act as a sink for toxic substances [19]. However, the use of the microdrop method has been restricted mostly to embryo cultures.",1
67,7,"Finally, we examined if the expansion of GS cells in the microdrop in vitro culture reflects the expansion of SSCs in vivo by transplanting the daughter cells into recipient mouse testes. The GS colonies from experiment 3 were subcultured for further expansion. Cells from those lines were transplanted into the seminiferous tubules of the testes of W mice. Testes of 11 mice, with each receiving independent GS cells, showed the extensive colonization of donor GS cells and complete spermatogenesis histologically (Fig. 3, A–D). Testes of four mice showed the colonization of GS cells but not complete spermatogenesis (Fig. 3, E and F). The remaining three exhibited no colonization (Table 3).",1
67,8,"In experiment 2, smaller clumps of GS cells comprising 212 cells were transferred into microdrops. From a total of 45 microdrops, GS cell colonies expanded in eight of these drops. GS cell colonies require SSCs for expansion. As progenitor spermatogonia can divide only a few to several times, their proliferation is limited. Even SSCs, if their self-renewing probability is less than 0.5, cannot sustain colony expansion. In fact, we observed the expansion of several colonies for a week or two and then their subsequent shrinkage and disappearance. Such limited expansion may represent colonies of progenitor spermatogonia alone or colonies with SSCs that failed to increase their number because of the low probability of selfrenewal. We suggest that the colonies that successfully expanded in microdrops contained at least one or more SSCs on the initiation of culturing.",1
68,1,"Recently economists, even many in the mainstream, have come to acknowledge the influence of culture on the economic process. Some, like original institutionalists, have a thorough understanding of and appreciation for the richness of culture and are, therefore, suspicious of any attempt to quantify cultural information. Others, particularly those trained in the use of statistical methods, are anxious to incorporate culture into statistical/quantitative models and may rush to quantify and include cultural information in their models without a full appreciation of the meaning(s) of culture. This paper reiterates the role of culture in the economy, explores several attempts to quantify culture, and reviews a number of papers that incorporate cultural information into statistical analyses. The broad purpose is to evaluate the prospects for incorporating culture into statistical models in ways that respect the richness of culture as it is perceived by institutionalists.",1
68,2,"As with economic reality, economic ideas evolve, often with a substantial lag. As John Maynard Keynes (1964, 383) famously stated, “[p]ractical men, who believe themselves to be quite exempt from any intellectual influences, are usually the slaves of some defunct economist.” However slowly change may come, economic thinking does adapt to address new economic realities and incorporate new analytical opportunities as they arise. The recently dominant economic model, perhaps mistakenly called the neoclassical model (Colander 2000), is fading in significance while other models are emerging to fill the analytical voids left behind (Colander, Holt, and Rosser 2004). The influence of the neoclassical orthodoxy lingers, but new trends suggest that economics has taken on a more pluralistic flavor.",1
68,3,"While recognizing the theoretical opening referred to above, most mainstream economists still value the modeling techniques, primarily econometric modeling, developed over the last half century or so. Thus, while they may be more open to new ideas, mainstream economists still look to incorporate the ideas into their existing empirical methods (Pinto 2011). Incorporating what previously have been considered heterodox ideas (in this case, the importance of culture) can potentially enrich econometric/statistical analyses, and potentially lend credence to longstanding institutionalist ideas. Still, the efficacy of quantifying culture is in doubt, at least among institutional and other heterodox economists.",1
68,4,"This paper will explore a single question: Can cultural information be incorporated into mainstream empirical models in a way that both enriches mainstream analysis and honors the richness of culture? Alternatively, can culture be quantified in a meaningful way? While culture will be discussed in more general terms, the paper is primarily focused on broad cultural measures, typically national cultural values.",1
68,5,"Tylor’s is a broad definition. It includes the core aspects of culture, those things that lie below the surface of consciousness (Hall 1989), and the more visible products or expressions of culture (art, morals, laws, etc.). The key point is that culture is received by someone by virtue of their membership in a society. It becomes part of one’s consciousness without the consent of the recipient. Similarly, Hofstede (1994, 2) refers to culture as “the collective programming of the mind which distinguishes the members of one category of people from another.” David W. McCurdy, James P. Spradley, and Dianna J. Shandy (2005) emphasize that culture is learned and shared, and that it generates behavior and interprets experience.",1
68,6,"Students of culture have tended to discuss culture as having multiple aspects or layers. For example, McCurdy, Spradley and Shandy (2005, 8) distinguish tacit culture from explicit culture. “Tacit culture is the cultural knowledge people don’t put into words,” while “[e]xplicit culture consists of cultural categories that are coded in language.” David M. Schneider (1968, 1) proposes that culture “consists of a system of units (or parts) which are defined in certain ways and which are differentiated according to certain criteria. These units define the world or the universe, the way the things in it relate to each other, and what these things should be and do.”",1
68,7,"F. Gregory Hayden (1988) distinguishes between culture and its expressions as cultural values, beliefs, and attitudes. According to Hayden (415), culture is transcendent, “a collective systemic mental construct ... It contains a group’s abstract ideas, ideals, and values ..., and it is found in legends, mythology, supernatural visions, folklore, literature, elaborated superstitions, and sagas.” “Values are cultural criteria or evaluative standards for judgment with regard to what is ideal” (1988, 416). At the value level, culture is slow to change, although novel experiences or technological and/or environmental changes can inspire cultural evolution over time (Jennings and Waller 1994). Alternatively, “social beliefs are activity- and institutionspecific” (Hayden 1988, 418). As such, beliefs and attitudes (situation specific) are more malleable than values and can adapt as necessary to align the demands of social participation with slower to evolve cultural value criteria.",1
68,8,"To argue that orthodox economists have failed to include cultural concepts in their analyses is not to say that original institutionalists have been completely successful in connecting culture to economic behavior. In fact, Anne Mayhew (1987a, 602) claims that “[o]ne of the great failures of institutionalists has been their failure to provide more and better, truly cultural, truly institutional descriptions and analyses of our own economies.”",1
68,9,"For at least fifty years, management scholars and other social scientists have worked to identify broad cultural characteristics and measure them — at least in relative terms across nations or regions. Their purposes vary with their interests. Where anthropologists have used ethnographic fieldwork to reveal subtle cultural similarities and differences across peoples, and no doubt have the deepest general understanding of culture, others have had narrower goals. Management scholars are most interested in understanding culture in order to help business people work in cross/multicultural situations. Political scientists are interested in the ways culture relates to political decisions and policy successes or failures. Similarly, economists seek to understand the cultural influences on economic behavior and the social provisioning process. The work discussed below focuses on identifying the broad “meta” aspects of culture that shape behavior across nations or broad regions, and that change slowly. Although not exhaustive, the following section reviews several of the more well-known efforts to quantify culture, and discusses their strengths and weaknesses.",1
68,10,"Among international management scholars, the best known and most widely used measures of culture are those developed by Geert Hofstede (1980). During the late 1960s and early 1970s, Hoftede surveyed employees of IBM subsidiaries in 72 countries. The survey included many questions about values. Then statistical analysis and theoretical reasoning were used to identify four cultural dimensions and their relative influence across the nations studied. A fifth dimension was added later as a result of work done in China by Michael H. Bond (Hofstede 1994, 1998).",1
68,11,"Elsewhere in Hofstede (2001), the connotations of each of these classifications is discussed as are the details of how the research was conducted. In the end, Hofstede calculates national indices for each dimension for every nation for which he had sufficient data.",1
68,12,"While Kirkman, Lowe and Gibson (2006) find a great deal of redundancy in Hofstede-inspired work, others have attempted to improve upon the original results. K. Sivikkumar and Cheryl Nakata (2001) developed a method to better select samples for cross-cultural studies. Using their methods, cultural distance and differences between nations can be better identified in order that cross-national differences identified in the research process can more reliably be attributed to cultural differences. Vas Taras, Steel Piers, and Bradley L. Kirkman (2012) conducted a metaanalysis wherein they gathered data from several Hofstede-type studies and analyzed the ongoing validity of Hofstede’s indices, essentially using the larger meta-sample to identify cultural changes through time. They claim to have generated more accurate indices that initially correlate very closely with Hofstede’s indices, but the correlations weaken when the indices are based on data newer than that used by Hofstede. All agree that Hofstede’s work will continue to be important, so future research should concentrate on improving the measures and assuring their continuing validity.",1
68,13,"Another line of research aimed at measuring and comparing national cultures has been undertaken by Trompenaars and Hampden-Turner (1998). While these authors are deeply familiar with the work of Hofstede, they begin with different data and identify a different — if overlapping — set of national cultural dimensions (see below). In their analysis, they identify seven cultural dilemmas that must be resolved in management (and other) situations. Trompenaars and Hampden-Turner identify their cultural dimensions (dilemmas), generate national indices for each dimension, and apply the indices in cross-national cultural comparisons.",1
68,14,"While providing an excellent and understandable insight into international cultural differences, Trompenaars and Hampden-Turner’s work has not received nearly the academic attention given to Hofstede. The main advantages of their work are that they identify an alternative set of cultural dimensions, and explain their development and interpretation in very understandable language.",1
68,15,"A more recent and ongoing attempt to identify and quantify cultural dimensions is Project GLOBE (Global Leadership and Organizational Behavior Research Program). GLOBE researchers (House et al. 2004) gather information from some 17,000 managers across 951 organizations, primarily in the financial, food-processing, and telecommunications industries. Their analysis of the results identifies several dimensions of culture and assigns dimensional values for each of the 62 nations, thus allowing cross-national cultural comparisons. The nine cultural dimensions quantified are: power distance, uncertainty avoidance, humane orientation, institutional collectivism, in-group collectivism, assertiveness, gender egalitarianism, future orientation, and performance orientation. Although GLOBE began as a replication of Hofstede’s work, Hofstede (2006) has been mildly critical of their findings, questioning whether nine dimensions are more than can be justified, given GLOBE’s data and analysis.",1
68,16,"Shalom H. Schwartz and Wolfgang Bilsky (1987) set off on a research journey that continues after two decades. Their initial purpose is to construct a theory of universal types of human values based on biological needs, interactional requirements, and societal demands for group welfare and survival. Then they sample various national populations to gain insights into the relative importance different groups placed on particular values and other evidence regarding the universality of the values. In essence, they try to identify value dilemmas that must be resolved by any society and identify value variations across nations. Initially they use samples from Germany and Israel. Later, Schwartz and Bilsky (1990) expand their study to include Australia, Finland, Hong Kong, Spain, and the United States, and still later expand their analysis to twenty total countries (Schwartz 1992). At each step the theory was refined and new insights into the universality of values was gained. In its most recent iteration, Schwartz et al. (2012) identify nineteen basic values arrayed on a circular motivation continuum to help understand the hierarchy of values and the tensions that exist among them. This line of work focuses less on the quantification of culture/ values than do those reviewed above. ",1
68,17,"Any source of quantitative information about culture will have its weaknesses. None of the authors above claim to have perfectly captured culture and, in fact, all recognize the impossibility of doing so. None of the sources provide information on all countries or all subcultures. Still, the information they do provide helps to make culture more understandable and at least opens the possibility of incorporating more cultural information in empirical and theoretical models. Electronic searches of common article databases and citation indices provide little evidence that the measures discussed above have been widely used in empirical economics, although there are signs of increasing interest. The next section provides a review of several works where researchers have incorporated cultural information into empirical models designed to explain/understand economic phenomena.",1
68,18,"In response to the criticisms of Franke, Hofstede and Bond (1991), Johnson and Lenartowicz (1998) explore the culture-growth connection by incorporating both Hofstede and Schwartz’s measures of culture. Reasoning that economic freedom, operationalized as an index created by James Gwartney, Robert Lawson and Joshua Hall (1996) is positively related to economic growth, Franke, Hofstede and Bond (1991) adopt an informal two-stage approach. First, they explore the relationship between culture and economic freedom and then the relation of economic freedom to growth. They focus on data from the 26 nations common to Hofstede, Schwartz, and the Economic Freedom Index. They find a statistically detectable relationship between economic freedom and GDP per capita, also documented in other studies. Of more interest here are the statistically significant correlations between cultural measures and economic freedom. They find that Hofstede’s measure of uncertainty avoidance is negatively correlated to economic freedom, while masculinity (as defined by Hofstede) is positively correlated, but not statistically significant. On the other hand, they find that Schwartz’s conservatism is negatively correlated, while his measures of autonomy are positively correlated with economic freedom.",1
68,19,"Duane Swank (1996) examines the influence culture has on a country’s political institutions and ultimately on its rate of economic growth. He begins by replicating Granato, Inglehart and Leblang’s (1996) work. Then, using World Values Survey data, Swank constructs a measure that he calls communitarian polities (Confucian statist and social corporatist) or civic virtue. Social corporatist societies are associated with advanced industrialized nations, while statist societies are characterized by “longlived rule by mass-based parties” (1996, 668). He argues that civic virtue is a key determinant of political stability, and it is political stability that is important to economic growth. The basic finding is that countries that are classified as Confucian statist have a three-point higher growth rate, while social statist countries have a twothirds point higher growth rate than non-communitarian polities (1996, 674). In the end, Swank argues that culture is likely important, but that substantial work will be required to reveal the extent and direction of cultural influence on economic growth.",1
68,20,"David C. McClelland (1961) examines the content of children’s stories from several countries for achievement emphasis, creates national scores for N achievement (need for achievement), and presents evidence relating N achievement to growth. Since that time, McClelland’s findings have been challenged on many grounds. Sjoerd Beugelsdijk and Roger Smeets (2008) provide a recent analysis that brings McClelland’s findings into question. Following several other authors, including Granato, Inglehart and Leblang (1996) cited above, they estimate a growth equation that includes McClelland’s N achievement scores as an independent variable. As robustness checks, they estimated several established alternative models and found little evidence of a statistical relationship between the N scores and growth. They report three possible conclusions, but prefer the conclusion that their empirical test is correct, although there is still a theoretical relationship between entrepreneurial culture and growth. The problem is that McClelland’s N scores are not up to the complicated task of measuring entrepreneurial culture.",1
68,21,"Rachel L. Mathers and Claudia R. Williamson (2011) explore the interaction between culture and capitalist institutions, and how they jointly effect economic growth. They employ a panel of data that includes 74 countries for the years 19802004. Their dependent variable is the growth of per capita GDP. Included as dependent variables are the Economic Freedom of the World Index from the Fraser Institute and a cultural index based on World Values Survey data on trust, respect, individual self-determination, and obedience. They are most interested in discovering how their cultural index and the Economic Freedom Index relate to economic growth. They use a basic growth model and experiment by including a variety of control variables. In the end, they conclude that capitalism performs better (in growth terms) when embedded in certain cultures. Thus, the presence of capitalist institutions (private property, etc.) cannot be relied upon to guarantee economic growth. They must be legitimized by culture to have their full effect.",1
68,22,"An interesting turn in the analysis of culture and growth/development comes from Sjoerd Beugelsdijk, Ton van Schaik, and Will Arts (2006). As Europe has become more and more economically integrated, modernists have predicted regional cultural convergence (culture as endogenous), while cultural theorists anticipate cultural path dependency (culture as exogenous) across regions. The authors examine regional changes in European Values Survey data between 1990 and 1999 to see if regional cultural change is detectable. They find evidence to support a synthetic view, whereby some cultural change has occurred but where path dependency is still evident. They suggest that the narrow focus of their work in terms of time periods and cultural dimensions calls for additional study before the issue can be resolved with confidence.",1
68,23,"Most of the cultural measures discussed above were built on responses to questions posed to samples of people across geopolitical space. It is worth asking whether the samples from which the cultural information was collected are appropriate, given the population being studied. For example, if one is studying the institutions of subsistence farming in developing countries, it may not be appropriate to incorporate cultural information collected from a sample of corporate executives. If one did, it would almost certainly require a thoughtful justification for the use of the data. The cultural measures mentioned above all identify national cultural characteristics at the national level, special care should be taken when using the indices in situations where there are significant regional or group-specific subcultures. When choosing among several sources of cultural information, one should carefully select the source that most clearly reflects the population under study.",1
68,24,"In several of the cited cases, researchers enter several cultural measures into their models and then discuss their impacts, or lack thereof. Some might call this data mining. As we have been well warned by Deirdre N. McCloskey (1998), statistical significance and scientific significance are not the same thing. Rather than simply reformulate a statistical model until a tight statistical fit is found, one should have a reasoned argument for the inclusion or exclusion of particular cultural information. A cultural variable may have “oomph” (McCloskey 2000), even when it does not have a “good” statistical fit. Alternatively, a cultural variable may have a great statistical fit, but still have little to say about real world economic phenomena. A good understanding of cultural theory is needed to guide empirical practice.",1
68,25,"Hayden (1988) reminds institutionalists to beware of deterministic conclusions. As discussed above, culture influences all aspects of human and social behavior but, with respect to institutions, culture is a limiting rather than deterministic factor. It limits the range of institutional possibilities, but does not force a particular outcome. “[C]ultural values are not deterministic because numerous alternative beliefs and institutional arrangements can satisfy a set of [cultural] criteria” (Hayden 1988, 417). For example, some of the studies cited above find statistical relationships between Confucian values and economic growth. Perhaps, this is because the studies were conducted during a time of Asian economic ascendance that was driven by other factors. Could it be instead that technology evolved to a state where it was better embedded in an Asian institutional milieu than a Western one (and thus the culturegrowth relation was transitory)? Researchers must weigh the statistical results in light of historical and other evidence.",1
68,26,"If one accepts Hayden’s proposition that culture, at least core culture (values rather than beliefs or attitudes), does not change regularly, then the endogeniety problem becomes a problem of selecting variables carefully. “Values are cultural criteria or evaluative standards for judgment with regard to what is ideal” (Hayden 1988, 416). Social beliefs, on the other hand, “are activity- and institutionspecific” (Hayden 1988, 418). Thus, if one’s cultural variable reflects a social belief, it will likely be endogenous over any but very short time periods. Alternatively, if one has actually quantified a core cultural value, it could be considered exogenous, at least over time periods typically analyzed.",1
68,27,"To be meaningful, a cultural measure should satisfy the criteria of construct validity — that “the indicators are valid measurements of what they purport to measure” (Thomas 2010, 37). Likewise, measures that purport to measure one thing rather than the other should be largely independent. This seems to be what Hofstede (2001) was concerned about when others were pushing to expand beyond his five cultural dimensions. One might be tempted to try to refine cultural measures to unwarranted levels that go beyond the broad, slow-to-change, and seemingly ubiquitous national meta-values which seem most reliable for statistical studies.",1
68,28,"Finally, as with any attempt to quantify economic/social information, errors in measurement will be encountered. Just as GDP measures output imperfectly and price indices measure inflation imperfectly, so too will any quantitative measure of culture imperfectly capture cultural information. These imperfections have not prevented extensive use of other quantitative data. However, in all cases, cultural or otherwise, care must be taken to minimize the impact of measurement errors, and conclusions should be carefully crafted to reflect only the amount of confidence that the quality of the data warrants. Still, to say that one must be careful is not to say one should not try.",1
68,29,This paper asked whether cultural information can be incorporated into statistical models in a way that both enriches mainstream analysis and honors the richness of culture. The question is timely as mainstream economists have recently begun to pay greater attention to cultural influences on economic activity. These same economists are generally well-trained in statistical/econometric methods and are — like anyone would be — inclined to look in their existing (analytical) toolbox as they incorporate new elements into their work.,1
68,30,The review and discussion above revealed several real or potential problems on the road to cultural quantification. There are sampling issues: (i) difficulty in clearly identifying cultural-economic relationships when multiple values are in play; (ii) problems with endogeneity; (iii) issues with distinguishing between core cultural values and more transitive beliefs and attitudes; and (iv) insights into the timing and pace of cultural change. Given all these things it seems that the quantification of culture is still very early in its (possible) development.,1
68,31,"Alternatively, to date, researchers seem to recognize these limitations and have been careful about giving their empirical results too much weight. There does seem to be an appreciation of the difficulties in quantifying culture appropriately, even among more mainstream researchers. The key to progress seems to be to exercise care in the application of the existing data, to use statistical methods appropriate for the task, and to interpret the results with care while simultaneously working to develop a richer understanding of culture and better methods of gathering and quantifying cultural information. Work along this line has begun in the economic-growth literature, and a foundation for further research is taking shape. Still, caution is in order. The danger would be to build an empirical cultural-economic edifice on a wobbly foundation.",1
69,1,"We retrospectively reviewed 140 patients with culture-positive and 102 patients with culture-negative infected TKAs. We determined the infection control rate and clinical outcome after repeated debridement, and repeated 2-stage TKA in the culture-positive and culturenegative groups. The mean follow-up was 9.3 years (range 5–14 years) in the culture-positive group and 10.6 years (5–22) in the culture-negative group.",1
69,2,The overall infection control rate was 56 % in both groups after the first treatment. The overall infection control rate was 90 % in the culture-positive group and 95 % in the culture-negative group. A functional knee was obtained in 90 % in the culture-positive group and 95 % in the culture-negative group.,1
69,3,The data suggest that treatment according to the types of infection in both culture-positive and culturenegative groups after TKA controlled infection and maintained functional TKA with a firm level of fixation for most patients. Repeated debridement and repeated two-stage exchange TKA further improved infection control rates after the initial treatment and increased the likelihood of maintaining a functional TKA,1
69,4,"Periprosthetic joint infection is one of the most challenging complications after total knee arthroplasty (TKA) with an incidence of 1 to 4 % after primary TKA [9–11, 29, 30]. Accurate diagnosis of periprosthetic joint infection is essential and often involves withholding antibiotic therapy in hopes of isolating an organism from a preoperative joint aspiration or intraoperative tissue cultures. Determining the causative organism then allows tailored local and systemic antibiotic therapy. Despite extensive efforts, the cultures often have a high false-negative rate despite adequate clinical, radiographic, and surgical suspicion for periprosthetic joint infection. Incidence of negative cultures in most infection series ranged from 0 to 25 % [1, 5, 7, 21, 23, 24, 38].",1
69,5,"To confirm previous reports, we (1) compared each type of infected TKA that did not yield positive cultures at the time of treatment with those that had positive cultures to determine the control rates of infection, and (2) determined whether repeated debridement and repeated two-stage exchange arthroplasty would improve further the control rate of infection after failed first treatment in culture-positive and culture-negative cases.",1
69,6,"We retrospectively reviewed data for 209 patients with 209 infected total knee arthroplasties from January 1991 to March 2008. Of the 209 patients, 11 were lost to follow-up before 2 years, and 7 died, leaving 191 patients (191 knees) for review. The records of the 191 patients had been entered into an ongoing computerized database that was updated continuously. The study was approved by the institutional review board, and patients provided written informed consent. The primary diagnosis for the indication for TKA was osteoarthritis in all patients. There were 44 men and 147 women with a mean age index TKA of 66.3 ± 8.65 years (range 40–90 years). Their mean body mass index was 28.29 ± 4.31 kg/m2 (range 20.1–41.3 kg/ m2). The minimum duration of follow-up monitoring was 5 years (mean 10 ± 0.92 years, range 5–22 years) (Table 1).",1
69,7,"Infection after TKA was diagnosed if the patient fulfilled any one of the following criteria: (1) an abscess or sinus tract communicating with the joint space; (2) positive preoperative aspiration culture findings on solid media; (3) positive cultures on 2 or more intraoperative cultures; or (4) one positive culture on solid media in conjunction with the presence of pus. In patients with negative cultures, infection was diagnosed when there were the following findings: elevated erythrocyte sedimentation rate ([ESR] [20 mm/h, C-reactive protein [CRP] level [0.5 mg/dL), elevated synovial WBC count C2000/lL, and synovial neutrophil percentage [PMN %] C65 %, presence of pus in the affected joint, and more than 5 neutrophils per highpower field on histologic examination [9, 12, 28, 31, 35]. In the 45 patients who underwent total knee arthroplasty for infection from 1999 to 2004, serologic counts in the aspirated synovial fluid were not available and there was no threshold value of serologic counts available. Infection in these patients was diagnosed by the findings of serum serology and joint fluid culture. Each infection was classified as early postoperative deep, late chronic, and acute hematogenous infection according to Tsukayama et al. [36, 37] ",1
69,8,"Study patients were divided into 2 groups based on culture results from both preoperative joint aspirate and intraoperative periprosthetic tissues from the affected joint at the time of initial surgical treatment at our institution, which totaled 140 patients with positive-culture results (culture-positive group), and 51 patients with negativeculture results (culture-negative group). All of the patients with culture-negative had PCR analysis. Gram-positive cocci were isolated from 84 knees, and gram-negative bacilli were cultured from 38 knees. The fungal (candida albicans) isolates in 8 knees and mycobacterium (mycobacterium tuberculosis) isolates in 10 knees came from late chronic infections (Table 2). Twenty-one of 140 patients had culture-negative initially and turned culturepositive later. Patients’ demographics, clinical characteristics, and treatment results were compared between the 2 study groups. The history of previous antibiotic treatment for infected TKA of the same joints and follow-up cultures of the same joints after failure of our initial surgical treatment were also documented to outline the pattern of 51 patients with negative-culture results (Table 1).",1
69,9,"Chi-square, descriptive, and Student’s t test analyses were used to compare demographics and comorbidities between the culture-negative and culture-positive groups. The differences among the 4 types of infection in culture-positive and culture-negative groups for discrete variables (including age, period of follow-up, CRP, ESR, leukocyte count, and leukocyte differential) were compared using Fisher’s exact probability two-tailed t test. Logistic regression was used to assess the rate of failure associated with the different types of infection in both groups. One-way analysis of variance was used to confirm differences among the different types of infection with respect to the final clinical score. The level of significance was set at P \ 0.05. All analyses were performed with use of SPSS software (version 18; SPSS, Chicago, Illinois).",1
69,10,"There are a few limitations in our study. First, although all patients in this study were prospectively followed, the design of the study was to test retrospectively our classification-based treatment algorithm for infected TKA with the hypothesis that it would be successful. Second, owing to limited patient numbers, we were unable to analyze data for patients stratified according to infecting organism. It is possible that the infection control after infected TKA was influenced by the virulence of the infecting organism. Third, 11 of 209 patients (4 %) were lost to follow-up, and 7 (3 %) died. Nevertheless, the percentage of patients who died or were lost to follow-up was small and likely did not influence the findings of our study, unless the majority of these lost and died cases had become reinfected. Fourth, in patients with negative cultures, infection was diagnosed by the findings of serological markers. However, serological markers can lead to false negative diagnosis [19]. Finally, in the 45 patients who underwent total knee arthroplasty for infection from 1999 to 2004, serologic counts in the aspirated synovial fluid were not used and there was no threshold value of serologic count available. Infection in these patients was diagnosed by the findings of serum serology and joint fluid culture. This can lead to false negative diagnosis of infection.",1
69,11,"In the culture-positive group, 7 knees (5 %) were revised for aseptic loosening of femoral and/or tibial components, and 2 knees were required above-knee amputation for persistent infection after 2 revisions. These 2 patients who underwent above-knee amputation were immuno-compromised by prolonged antibiotic therapy and superimposed MRSA with candida albicans infection. In the culture-negative group, 4 knees (8 %) were revised for aseptic loosening of the femoral and tibial components. Survivorship of total knee prosthesis at 9.3 years as the end point of revision, or arthrodesis, or amputation was 94 % (95 % confidence interval 0.91–0.97) in the culture-positive group, and it was 92 % (95 % confidence interval 0.89–0.98) in the culture-negative group.",1
69,12,"In conclusion, the results of present study demonstrate that no significant differences exist in the infection control rate and clinical outcomes between culture-positive and culture-negative groups. The data suggest that treatment according to the types of infection in both culture-positive and culture-negative groups after TKA controlled infection and maintained functional TKA with a firm level of fixation for most patients. Repeated debridement and repeated two-stage exchange TKA further improved infection control rates after the initial treatment and increased the likelihood of maintaining a functional TKA.",1
69,13,"Segawa et al. [33] reported that 5 of 10 patients with early deep postoperative infection, and 24 of 29 with late chronic postoperative infection were able to walk with no or only slight pain (some with the assistance of a cane). None of their patients had radiographic findings (such as evidence of implant migration or progressive osteolysis) that would have indicated a need for immediate or impending surgical intervention. In the current series, 7 knees (5 %) in the culture-positive group and 4 knees (8 %) in the culture-negative group were revised for aseptic loosening of femoral and/or tibial components. Two patients in the culture-positive group required above-knee amputation for persistent infection after 2 revisions.",1
70,1,"Studies of organizational culture are almost always based on two assumptions: (a) Senior leaders are the prime determinant of the culture, and (b) culture is related to consequential organizational outcomes. Although intuitively reasonable and often accepted as fact, the empirical evidence for these is surprisingly thin, and the results are quite mixed. Almost no research has jointly investigated these assumptions and how they are linked. The purpose of this article is to empirically link CEO personality to culture and organizational culture to objective measures of firm performance. Using data from respondents in 32 high-technology companies, we show that CEO personality affects a firm’s culture and that culture is subsequently related to a broad set of organizational outcomes including a firm’s financial performance (revenue growth, Tobin’s Q), reputation, analysts’ stock recommendations, and employee attitudes. We discuss the implications of these findings for future research on organizational culture.",1
70,2,"In the late 1970s and early 1980s, the topic of “organizational culture” captured managers and scholars’ interest. A series of poplar books (e.g., Davis, 1984; Peters & Waterman, 1982), academic conferences, and special issues of scholarly journals (Administrative Science Quarterly, 1979, 1983; Journal of Management, 1985; Journal of Management Studies, 1982) highlighted the promise of organizational culture as a way to understand how organizations operate and succeed. The logic offered had two components that were intuitive and seductively simple: (a) Cultures largely reflect the values and actions of their senior leaders, and (b) cultures are important determinants of firm performance.",1
70,3,"The first premise was that organizational cultures—defined most commonly as “the basic assumptions and beliefs that are shared by organizational members” (Schein, 1985, p. 9), or “a system of shared values defining what is important, and norms, defining appropriate attitudes and behaviors” (O’Reilly & Chatman, 1996, p. 166)—are largely created by an organization’s senior leaders. For example, in the very beginning of his seminal book, Schein (1985) claims that “the only thing of real importance that leaders do is to create and manage culture” (p. 2). He concludes some 300 pages later asserting, “The unique and essential function of leadership is the manipulation of culture” (p. 317). The widespread assumption has been that cultures reflect the values, beliefs, and actions of their senior leaders (e.g., Baron & Hannan, 2002; Davis, 1984; Kotter & Heskett, 1992). However, in a recent review of the culture literature, Schneider, Ehrhart, and Macey (2013) noted that “although the theoretical literature on organizational culture is replete with discussions of the influence of the founder and upper management have on an organization’s culture, empirical studies of that relationship are hard to find” (p. 372).",1
70,4,"The second intuitively reasonable part of the argument was that organizational culture was a significant determinant of organizational performance. Again, however, the evidence for this is mixed. Establishing a consistent direct link between culture and objective firm performance has been hampered by a number of conceptual challenges including disagreements about defining culture and the dimensions associated with it (e.g., Schneider et al., 2013), and a number of methodological challenges such as small samples, measures designed for other purposes besides assessing culture, and variance introduced by assessing multiple industries (e.g., Detert, Schroeder, & Mauriel, 2000).",1
70,5,"More than 40 years later, these two fundamental assumptions, with some minor modifications, remain intact: Organizational culture is largely shaped by an organization’s leaders and is presumed to be important because it can have consequential effects on firm performance. Yet, the empirical evidence for these claims remains fragmented and inconclusive (Hartnell, Ou, & Kinicki, 2011). In a recent review, Sackmann (2011) concluded that even as research on culture is becoming more methodologically sophisticated, researchers’ use of diverse measures of culture and performance is stalling paradigm development. Almost no studies have attempted to simultaneously test these two fundamental assumptions by providing an empirical test of the effects of senior leadership personality on organizational culture and the subsequent effects of culture on objective indicators of organizational performance. In doing this, we provide a clearer picture of the origins of organizational cultures and clarify how culture can affect organizational performance.",1
70,6,"We begin by reviewing previous research on the effects of CEO personality and leadership on culture and firm performance. We then use data from more than 1,000 respondents to revalidate a measure of organizational culture originally developed by O’Reilly, Chatman, and Caldwell (1991) and investigate the associations between CEO personality, culture, and firm performance for 32 high-technology firms over a 3-year period.",1
70,7,"How do senior leaders affect organizational culture? When culture is conceived of as a consensus about norms (e.g., Cooke & Rousseau, 1988; Schein, 1985), then the recurring patterns of behavior of senior leaders becomes a critical source of information about the normative order for those in the organization (Bandura, 1986). Based on this social learning perspective, several authors have identified the mechanisms through which managers might develop and change cultures. O’Reilly and Chatman (1996) argue that the mechanisms for developing and changing culture can be seen in the socialpsychological processes of normative and informational influence. Schein (1985) and others have suggested similar mechanisms that act to signal the desired normative order, including systems, structures, and processes designed to reinforce ways of thinking and behaving. While useful, these do not answer the question of where the desired behavioral regularities come from. Several scholars have suggested that the true origins of culture can be found in the fundamental dispositions (values and personalities) of the organizations’ leaders (Schein, 1985). In this sense, leaders’ values and personalities may be the primary building blocks of organizational culture (Baron & Hannan, 2002; Detert et al., 2000; Fu, Tsui, Liu, & Li, 2010).",1
70,8,"Schneider and Smith (2004) define personality broadly to refer to those individual attributes that “give form, structure, and consistency to people’s behavior over time and situations” (p. 347). Personality traits are patterns of thought, emotion, and behavior that are relatively consistent over time and across situations. Similar to personality, values are enduring subjective judgments or perspectives on what is seen as important that reflect basic dispositions. Values represent one translation of dispositions into situational preferences (Parks & Guay, 2009). As such, personality and values are important precursors of patterns of behavior. With regard to organizational culture, the patterns of behavior of the CEO may then become a salient source of information about the normative order.",1
70,9,"Overall, the evidence suggests that personality as manifested in values and behavior is associated with leadership at the CEO level (Peterson et al., 2003; Tsui, Zhang, Wang, Xin, & Wu, 2006) and that these may affect the culture of the organization, although the specific form of these relationships is not clear. One implication of this argument is that an organization’s senior leaders, because of their salience, responsibility, authority, and presumed status, have a disproportionate impact on culture and may be a significant source of cultural influence.",1
70,10,"Given the widespread interest in the potential effects of culture on firm performance, it is noteworthy how little clarity there is about this connection. In an early study, Siehl and Martin (1990) concluded that a link between culture and firm performance “has not been—and may well never be—empirically demonstrated” (p. 242). Almost 20 years later, Gregory, Harris, Armenakis, and Shook (2009) observed that “few empirical studies have provided detailed insight into the relationship” (p. 673). In a recent review of the associations between culture and organizational effectiveness broadly defined, Hartnell et al. (2011) found significant correlations between culture and employee job satisfaction, obtained mixed results for culture and subjective ratings of organizational processes and performance, but found too few studies of studies of objective performance indicators and culture to come to any conclusions.",1
70,11,"There are several understandable reasons for this lack of clarity. First, designing studies and obtaining data that allow for the assessment of culture across organizations, especially with the CEO’s participation, has been a daunting task, often resulting in studies with very small samples and low power (e.g., Calori & Sarnin, 1991; Gordon & DiTomaso, 1992). For example, Denison and Mishra (1995) used archival data on five firms to develop a theory of culture and then used survey data in an attempt to refine their theory. While useful, they acknowledge that, “Neither the survey instrument nor the traits operationalized were ideal for culture research” (p. 207). Similarly, other researchers have made use of pre-existing surveys that were not designed for culture research but, post hoc, relabeled the constructs as “culture” (e.g., Marcoulides & Heck, 1993). Further compounding the issue is that the relationship between culture and firm performance has been shown to vary across industries (e.g., Christensen & Gordon, 1999) such that a significant result obtained in one setting may not apply in another. This is not to criticize these efforts but to simply note the difficulty that culture research poses.",1
70,12,"Second, there have been disagreements about the definition and measurement of both culture and performance that has resulted in the use of different frameworks and metrics that make aggregation of results difficult (e.g., Schneider et al., 2013). Hartnell et al. (2011) concluded that one reason for the failure to find culture-performance relationships may be that simple measures of culture may be too broad. In one of the first published articles on organizational culture, Andrew Pettigrew (1979) echoed this concern against the use of simple categorizations: “While providing a general sense of orientation, culture treated as a unitary concept in this way lacks analytical bite” (p. 574).",1
70,13,"Finally, as researchers have explored the possible associations between organizational culture and firm performance, there has been an evolution in understanding the form that this relationship might take, ranging from a simple direct association to contingent relationships dependent on firm strategy and environmental conditions (e.g., Christensen & Gordon, 1999; Khazanchi, Lewis, & Boyer, 2007; Sørensen, 2002). However, in spite of the strong intuition that organizational culture should be directly linked to firm effectiveness, the empirical results remain equivocal.",1
70,14,"The argument proposed thus far is that a leader’s personality is manifested in regularities in his or her attitudes and behaviors and these, in turn, shape cultural norms and expectations. Although there is no expectation that a CEO’s personality should directly affect firm performance, their patterns of behavior (expressed in what questions they ask, what they pay attention to and reward, the types of people they hire, etc.) are likely to shape their firm’s culture (e.g., norms regarding what people pay attention to, what behaviors are seen as important) through a process of social learning. Thus, we expect that certain CEO personality attributes, expressed in terms of the Big Five, may be associated with certain types of organizational culture. Culture, in turn, may be associated with subsequent firm performance.",1
70,15,"Previous research has shown that, under certain conditions, each of the Big Five dimensions may be associated with leader emergence, job performance, culture, and possibly even the organization’s strategy (Berson et al., 2008; Giberson et al., 2009; Judge, Bono, Iles, & Gerhardt, 2002; Nadkarni & Herrmann, 2010). Although one could easily hypothesize how combinations of the Big Five dimensions might affect organizational culture, for simplicity, we focus here solely on the potential direct effects on organizational culture",1
70,16,"Conscientiousness refers to the tendency to control impulses and tenaciously pursue goals. At very high levels, those high on Conscientiousness can also be careful, compulsive, preoccupied with rules, and concerned with avoiding mistakes. Therefore, at the CEO level, high levels of Conscientiousness may produce cultures that are more rule oriented, centralized, and careful (e.g., Peterson et al., 2003). Thus, we expect that CEOs who are high on Conscientiousness will be more likely to be associated with cultures that are more detail oriented and emphasize analysis, precision, and attention to detail.",1
70,17,"Individuals high on Agreeableness are typically seen as modest, helpful, and willing to compromise (e.g., Peterson et al., 2003). People who are low on Agreeableness are more competitive than cooperative and can be seen as skeptical, unconcerned about others’ feelings and antagonistic. There is some evidence that low Agreeableness can lead to higher performance (e.g., Lepine & Van Dyne, 2001). At the CEO level, we predict CEOs who are lower on Agreeableness will have cultures that are more competitive and achievement oriented with higher expectations for performance.",1
70,18,"People who score high on Neuroticism tend to be anxious, emotionally unstable, defensive, and upset by minor threats or frustrations. Those who are low on Neuroticism are seen as emotionally stable, relaxed, and secure. In a metaanalysis, Judge et al. (2002) found that Neuroticism was negatively associated with leader emergence. Because of this, leaders who score high on this dimension are seen as more likely to be associated with cultures that are less collaborative.",1
70,19,"The most obvious aspect of Extraversion is the propensity to prefer extensive interactions with others. However, extraverts are also characterized by optimism, energy, and a preference for excitement (e.g., Judge et al., 2002). Extraverts have been shown to be socially engaging and able to involve others. For example, Giberson et al. (2009) found that CEOs who were higher on Extraversion were associated with more market-oriented cultures. Thus, we expect that CEOs who are more optimistic and sociable to be more likely to create cultures that emphasize a customer orientation than those who are more introverted.",1
71,1,"This paper examines the main reasons behind why Islamic culture is different than other cultures. In the introduction part of the paper, the usage area of the words culture and civilization were tackled. In the first part of the paper, an evaluation of the uniqueness of Islamic culture was made and examples about this were given. In the second part of the paper, evaluations about how Islamic culture has struggled with modernization and secularization and how it has shaped itself as a result of this were made. In the third part of the paper, the situation in which Islamic civilization has regressed against the Western civilization causing emerging arguments and the current situation in Islamic civilization have been addressed by making evaluations on culture and civilization. In the final part, evaluations on thesis this paper has used were made.",1
71,2,"Culture and civilizations are two words that sometimes mistaken for each other even though they are two completely different terms. Sociologists and historians still have not reached a settlement on the scopes of these words. The word “Umran” famous Muslim historian and sociologist Ibn Khaldun had used means both civilization and culture. On the other hand, Ziya Gokalp inserted that the word “Harth” meant culture, making a differentiation between the words culture and civilization and supported that a culture in the circle of Islamic culture can join the circle of Western culture.",1
71,3,"Gokalp has taken the word “harth”, which he had used to define culture, from Qur’an: “And when he is in authority, he runs about in the land to create disorder in it and destroy the crops and the progeny of men; and Allah loves not disorder (AlBaqarah, 206). In this verse, the word “harth” stands for “crop”. The crop of a population is its culture and if the culture of a country were to decline a disorder or chaos takes place.",1
71,4,"It seems a better approach to say that civilization has a wider usage range than culture does considering that a civilization brings different people from different cultures together. The word culture refers to the material products and spiritual values of a population. Then, in this situation, the values which were produced by societies with small population and even small groups could be classified as culture. On the contrary, the world “civilization” has a broad usage area and could include all the cultures that show common characteristics in a civilization.",1
71,5,"When we accept the broad spectrum of the words culture and civilization, we could say that it is possible for Islamic civilization to house more than one culture under its roof. Therefore, different societies and groups that have different languages, cuisine culture, birth and death customs, and etc... could live in unity under the Islamic civilization.",1
71,6,"The Islamic Culture is different from all of the other cultures, and it is a unique culture. The reason of this is its challenging to the all of the cultures with the claim of being the representative of the justice and truth. There are some verses indicating the uniqueness of the Islamic Culture in the Quran. We can exemplify the following verses: “Do They seek a religion other than Allah’s ..... (Âl-e Imrân, 84); “And who seeks a religion other than Islam, it shall not be accepted from him, and in the life to come he shall be among the losers (Âl-e Imrân, 86); He it is Who has sent his Messenger with guidance and the religion of truth, that He may make it prevail over all other religions (Al-Fath, 29).",1
71,7,"In fact, the statements we have made thus far set forth the uniqueness of the Islamic Culture. As the verses mentioned above indicate that Islam is the only valid religion, the Islamic Culture should also be the only valid culture among the other cultures. It is also possible that we can evaluate this claim according to rules of logic. According to rules of logic, an inference has more than one truth values. The inference’s having only one truth value in all of the truth values means that it is true. However, in order for this inference is considered valid, all of the truth values should be true. Similarly, in order to consider any cultural factor as Islamic, it should not conflict with the rules and values established by Islam. On the other hand, it is certain that the other cultures conflict with The Islamic Culture in some aspects. This is what causes the Islamic Culture being unique among the other cultures.",1
71,8,"The claims stated here bring the question to mind that in case the Muslims behave improperly according to Islamic spirit, how this case can be explained by means of the Islamic Culture. In order to overcome this problem, we need to distinguish the Islamic Culture and the cultures of the Muslims.",1
71,9,"Even if the statement of “The Cultures of Muslims” seems like the statement of “The Islamic Culture” at first glance, in fact; it is not correct. Just as the other people who do not believe in God, the Muslims are human beings too and they sometimes may make individual mistakes. However, the mistakes that the people had made individually concern themselves and other members of their groups or the religion that they believe in cannot be held responsible for those mistakes; because Allah would not order people to do wrong. There are a lot of verses expressing this case. This is one of them: “Verily, Allah enjoins justice, and the doing of good to others, and giving like kindred; and forbids indecency, and manifest evil and wrongful transgression (AlNahl, 91).",1
71,10,"And so, although culture is stated as set of material and moral values that a society produces, cultural values that Muslims have produced noncompliantly to the spirit and the rules of Islam cannot be described as Islamic. Therefore, some western journalists’ effort of harmonization of Islam and terrorism is an injudicious one. This effort is a rhetoric form of dispraising Islam by combining the word of Islam and with a negative meaning word, terrorism. However, it is nothing more than fallacy when analyzed.",1
71,11,"To be able to keep away from this fallacy, it is required to differentiate the concept of Islamic Culture and the culture of Muslims. Of all the cultural values of the Muslim societies have produced, the ones not contrary to the spirit of Islam and compatible with the rules of Islam are Islamic Culture. The cultural elements that are seen in Muslim societies, but are against the rules and spirit of Islam can be called the culture that belongs to some Muslims not Islam. Therefore, in the overall assessment of the culture of Muslim societies, it should be preferred to use the concept of the Muslim Culture or the cultures of the Muslims instead of the concept of the Islamic Culture.",1
71,12,"The concept’s being used in this way also paves the way for cultures’ being different and various in the face of oneness and universality of Islam. When we take The Prophet Mohammad’s (s.a.w.) statement “The dispute of the Ummah is God’s compassion.” into consideration, it comes forward that being different is not an obstacle for being Islamic, and cultural factors belonging to the Muslims having different mentality can be assembled under the same roof. The best method to explain this situation is the usage of the words ‘culture and civilization’ together. Here, civilization corresponds to religion and Islam. For this reason, just like the religion, which is indivisible, the civilization is also the same and unique. In that case, it is possible for us to mention that there are Turkish Culture, Arabic Culture and Persian Culture under the umbrella of Islam Civilization. This situation will be studied in detail below.",1
71,13,"We want to evaluate the relationship between culture and civilization based on the thoughts of the founder of sociology in Turkey, Ziya Gokalp. Gokalp is known in Turkey as the founder of sociology. The time in which he lived was the time period in which Islamic societies have shown the greatest decline against the Western Societies around the World War I. Not only Gokalp but also other intellectuals of the Ottoman Empire were looking for a solution to this decline. Arguments they had were focused on modernization, westernization and Islamization. While some of the thinkers suggested that the society should hold on tightly to their Islamic values to end the decline while some suggested that the society should take western countries as examples.",1
71,14,"The main focus of the arguments they had in those times was how Western culture and Islamic culture or Western civilization and Islamic civilization could blend together. Those who were in favor of Islamic values clearly knew that this blend could never happen. In addition, they did not think this was necessary. However, those who were in favor of westernization thought that being Muslim could in no way act like a barrier to westernize. One of the greatest representatives of this argument was Gokalp, who expressed his opinions by saying” I am from the nationality of Turks, the Ummah of Islam, the civilization of West. Gokalp has tried to explain the westernization process of his time with the division of culture and civilization. According to him, a culture belongs to a nation, but a civilization belongs to the nations or societies.",1
71,15,"Furthermore, with the establishment of the republic in Turkey, as it started to become modernized, it also became westernized. Modernization actually has the same meaning as westernization. The main reason why western civilizations have succeeded over the past two centuries is that they had exported their culture into other nations. This cultural export has happened because of people adapting to western culture values, whether forcefully or willingly, as they start to adopt western culture as a role model. Thus, nations that are not a member of western civilizations have westernized as they having modernized.",1
71,16,"Then we have to discuss how a culture could be affected by another one and is this possible or not. In order to do this, we first have to talk about the theories of disappearance of cultures and civilizations over time. Because, some sociologists think that this is possible but the other not.",1
71,17,"Modernization is a general term which points out to the social processes like industrialization, individualization and secularization which western societies experienced before all other nations of the world. Modernization began with the western societies; then other societies, including Muslim societies, experienced the same processes more or less.",1
71,18,"When Muslim societies began to modernize then they imitated western societies. But the religion of Islam would not accept the similarity to Christian societies. This verse is very deducible: “O ye who believe! Whose among you turns back from his religion, then let it be known that in his stead Allah will soon bring a people whom He will love and who will love him...” (Maidah, 54). And the prophet Mohammad (s.a.w.) says: “Whoever resembles to a society then he is from them”. Islam is the religion of truth and would not accept elements contrary to its main principles. Consequently, during the last two centuries which the western culture was the dominant culture, Islamic culture has severely resisted to the western culture. The most important part of it was about secularism.",1
71,19,"Consequently, the civilization of Islam and different Muslim cultures which taking part under this civilization, even if they were affected by the western culture and civilization, have not lost their own characters. Yet, in the last few decades the speed of this process gradually decreasing and even in some Muslim societies has ended. Today Muslim societies have begun to seek their bases and hold on their own customs. The most important example is the case of Turkey.",1
72,1,"Despite a great interest in the concept of ‘‘safety culture”, there is little common understanding of the concept. Anthropologists disagree with management consultants, organization theorists and psychologists on important issues. In particular, much of the ‘‘management literature” seems to have a more instrumental treatment of the concept. There are several ways of understanding culture – from the linguistic level with a focus on discourse and conflicts, to a ‘‘taken for granted” level where ‘‘tacit knowledge” is the key phrase, whereas culture as ‘‘webs of significance” can be understood from an epistemological position, in short, how we grasp the world. In addition, different cultural perspectives like integration, differentiation and ambiguity are important in cultural analyzes, but whether one is dealing with a single unitary culture, many subcultures, or no culture at all, is not a theoretical question but an empirical one, as will be demonstrated using oil drilling as a case. One implication of this is that researchers should be more sensitive to different cultural levels/perspectives and methodological triangulation in their cultural analyses – and managers should be a little more modest in their efforts to manage cultures.",1
72,2,"The concept of ‘‘safety culture” has generated a great deal of attention in recent years (Vaughan, 1996; Reason, 1997; Pidgeon, 1998; Cooper, 2000; Cox and Cheyne, 2000; Hale, 2000; Richter and Koch, 2004). The concept was introduced in the Norwegian oil industry in the late 1980s (Haukelid, 1991, 1st ed. 1990). Today almost every oil and drilling company in the North Sea has a program to improve its safety culture and in this paper I will use the history of oil drilling in the North Sea to demonstrate the theoretical points. Despite the great interest in cultural perspectives, it is easy to agree with James Reason when he writes: ‘‘Few phrases occur more frequently in discussions about hazardous technologies than safety culture. Few things are so sought after and yet so little understood” (1997, p. 191).",1
72,3,"There are many different answers to central questions like: what do we mean by ‘‘culture” and ‘‘safety culture”? Can it be managed or controlled? Is it possible to ‘‘measure”? Do we deal with one unitary culture, many sub-cultures or nothing that can be called culture at all? Is integration, differentiation or ambiguity its main characteristics? (Ref. Richter and Kochs‘ paper in Safety Science volume 42, 2004, and the exchange of letters to the Editor that followed (2004).",1
72,4,"Much of this discussion echoes the tremendous interest in organizational culture in the 1980s (and safety culture should naturally constitute an integrated part of an organizational culture). As I will discuss below, anthropologists have a different understanding of culture from that of many management and organization theorists. In particular, much of the management literature seem to have a more instrumental (and less nuanced) understanding of the concept. Before I say anything more about safety culture, I would like to review the key points of this debate. But first of all we need to have a closer look at what anthropologists mean when they talk about culture, and my discussion will draw on the works of traditional anthropologists like Clifford Geertz, Robert Keesing, Maurice Bloch and others. Mary Douglas is also an important figure in this debate, but unlike Douglas and her ‘‘grid/group theory” (Douglas, 1970; Douglas and Wildavsky, 1982; Douglas, 1996) I will suggest a more open-ended approach.",1
72,5,"There are many definitions of culture in anthropology. One definition of culture would be the common set of ideas, values, attitudes, and norms that characterizes a group of people. Culture used in this sense of the word is an aspect of all sides of a society and thus influences how we approach safety, technology, politics, economics etc., and last but not least, how we act and think in our everyday lives. In other words; culture is ‘‘something” that has an influence on most things, perhaps everything, that we do.",1
72,6,"Some of the culture definitions in anthropology are broad and include material and social conditions. But others, including that of Geertz (1973), argue that such a general concept of culture would be of limited analytical value because it covers ‘‘everything”. Since some of the papers and discussions regarding safety culture use Geertz and the symbolic approach as a starting point (Haukelid, 1998; Richter and Koch, 2004), it is wise to read him in a little more detail.",1
72,7,"Thus culture should be seen as a separate system of ideas or, more correctly, ‘‘an ordered system of meaning”. Indeed, isolating culture as a separate system makes it possible to analyze changes (or lack thereof) in the culture versus the social system. But it is important to emphasize that this is an analytical point: ...to distinguish analytically between the cultural and social aspects of human life, and to treat them as independently variable yet mutually interdependent factors.” (Geertz, 1973, p. 144). Geertz also emphasizes that ‘‘cultural systems must have a minimal degree of coherence, else we would not call them systems...’ (Geertz, 1973, p. 7).",1
72,8,"For Geertz, then, culture becomes ‘‘the fabric of meaning in terms of which human beings interpret their experience and guide their action” (Geertz, 1973, p. 145). Or, to use his most famous remark: ‘‘Man is an animal suspended in webs of significance he himself has spun; I take culture to be those webs” (Geertz, 1973, p. 5). And it is through the interpretation of various types of symbols that we can untangle these webs. These symbols are bearers of meaning, and according to Geertz, such symbols are as public as weddings and as observable as agriculture. The point is not to find laws in a positivistic sense, but meaning (Geertz, 1973, p. 45 and 362).",1
72,9,"Geertz has been criticized by various authors. Keesing argues that culture is not a homogeneous whole (Keesing, 1987; Keesing, 1994). There are always conflicts between individuals and between different subcultures, conflicts over power, values, knowledge and ‘‘truth”. In short, Keesing claims that culture is not merely made up of ‘‘webs of significance” but also ideologies and power. And following Scholte’s criticism of Geertz (Scholte, 1986), Keesing points out that few do the actual spinning while the majority is simply caught. Both Keesing and Scholte thus believe that culture is not something that most people ‘‘make,” but rather something we are captured in and by – that is, ideologies.",1
72,10,"Keesing’s conclusion is that symbolic and interpretive anthropology must be put in the context of a broader social theory, because culture is historically situated and continually produced through struggle between competing sets of interests. How symbolic production is connected to power and politics is thus the most important question for Keesing. Following Keesing, as well as authors like Foucault and Bourdieu (Foucault, 1977; Bourdieu, 1979); power has become a central issue in many cultural studies. Keesing concludes his critique by saying that we should talk about the ‘‘cultural” rather than culture per se. Today this is common knowledge for most anthropologists, and they tend to speak about cultural processes rather than culture–culture as an adjective rather than a noun.",1
72,11,"Keesing makes some valid points, but it is questionable whether discussing ‘‘cultural conditions” instead of ‘‘culture” resolves that many problems. If one realizes that culture is not a fixed entity, but rather something that continually changes as a result of, for instance, external influence and internal conflict, it may seem like splitting hairs to use the term ‘‘cultural conditions.” Keesing also appears to make a logical fallacy; while on the one hand he argues against the concept of culture, he also argues that most people are actually trapped in ‘‘webs of significance,” that is, culture. I also believe that Keesing avoids a more philosophical, metaphysical or ontological discussion: are power, politics, and economy ‘‘givens,” while, for example, culture and beliefs are ‘‘dependent variables”? If so, we are dealing with a type of reductionism, which in my view is not very fruitful. This is a question to which Keesing does not attempt to provide any satisfactory answer, nor is he interested in more epistemological questions.",1
72,12,"Bloch argues that the concept of culture is essential for both social and cultural anthropologists. Thus Bloch is unwilling to abandon culture as a useful concept, but rather aims to challenge certain received wisdom related to the culture concept. A more or less underlying assumption in the field is that culture is inextricably connected to language, either because culture is conceptual and translated as text through language, or because culture is similar to language in the absolute sense (Bloch, 1998).",1
72,13,"Bloch claims (somewhat paradoxically) that language is not essential for conceptual thinking, and that much of our knowledge is non-linguistic in nature. Concepts build on networks of implicit meanings that are formed though experience and practice. Under special circumstances this non-linguistic knowledge is translated and takes the form of explicit discourse, but it changes character in the process. Practical, everyday tasks are learned through imitation and participation. A linguistic model, that is, a linear and logical syntax, cannot explain the rapidity and effectiveness that characterize our daily tasks. Language is not essential, and constitutes only a part of what we call culture (Bloch, 1998, p. 14).",1
72,14,"This means that we should put greater emphasis on embodied experience, and that we should treat all knowledge that presumes an explicit linguistic form with caution, because it is special and removed from the knowledge that is used in practical activities under normal circumstances – e.g. how we work. Bloch’s perspective is a interesting one, and fits nicely with a broad tradition in anthropology that focuses on ‘‘tacit knowledge” (Polanyi, 1967).",1
72,15,"There is clearly a difference between what Geertz, Bloch and Keesing mean by ‘‘culture.” For Geertz, culture is a virtual prerequisite for action and thought, but not necessarily in an ahistorical or static form. Bloch is primarily interested in phenomena such as experience, practice, and tacit knowledge. From Keesing’s perspective, power, conflict and discourse appear to have primacy – that is, social phenomena to which conceptualization and language are central. All the three perspectives are important, and as a consequence, cultural analyzes should be performed at several levels: from the discursive, linguistic level, to a more tacit and ‘‘taken for granted” level, and finally at a more basic philosophical or epistemological level, where culture is considered a prerequisite for knowledge.",1
72,16,"A conclusion that can be drawn from this is that restriction to a single definition of culture is unlikely to be fruitful. As demonstrated above, the concept has many meanings, and a more pragmatic approach will often be more advisable. For analytical purposes, it can be useful to consider culture as a separate system of meaning, as Geertz does. This does not necessarily mean treating it as a unitary system. Nor does it mean that we should consider culture as isolated from social organization, technology, practice or power. Rather, it is the relationship between these ‘‘subsystems” that is important to clarify in any good anthropological analysis.",1
72,17,"The 1980s saw the growth of an intense interest in organizational culture and management. Several popular scientific books were published, of which In Search of Excellence (Peters and Waterman, 1982)) and Corporate Cultures (Deal and Kennedy, 1982) were two of the most well known. The books describe the qualities of successful corporations and how they work, and were bestsellers both in the United States and Europe.",1
72,18,"The main message in these books is that corporations with a ‘‘strong culture” do well, particularly if their management style emphasizes basic values and common goals. By directing attention to what an important management tool culture can be, culture can be used as a control instrument and as an alternative to other forms of control in organizations (such as bureaucratic control).",1
72,19,"One positive characteristic that these books have in common is an emphasis on the employees as the organization’s greatest resource. Much of the literature also emphasizes the importance of management to organizational culture. This is undoubtedly important, but at the same time there are also several reasons to remain skeptical of some of these theories.",1
72,20,"First of all, part of what is written about organizational culture and management in the 1980s was influenced by Japanese organizational philosophy, but it is relatively obvious that many of the measures implemented in Japanese industry would not be desirable or even possible in Europe, precisely because of cultural differences. In other words, measures that are implemented to improve organizational culture neither can nor should be considered in isolation from the national culture.",1
72,21,"This literature also expresses a somewhat exaggerated belief in what managers can accomplish. For example, Sørhaug claims that in this literature the potential for good management is unlimited, that it is shamelessly uncritical and gushingly positive (Sørhaug, 1996). That management is important is one thing. That it means everything is demonstrably wrong. Examples are plentiful of how leaders come and go, but organizational culture stays the same. A second problem with this literature is its emphasis on manipulation. Sejersted notes after a careful reading of In Search of Excellence that ‘‘in reality, authors recommend that managers should simultaneously brainwash their employees and treat them as individuals. The potential conflict between these two strategies is not addressed” (Sejersted, 1993).",1
72,22,"This point is also maid by Reynolds: ‘‘Culture is not an ideological gimmick, to be imposed from above by management-consulting firms, but a stubborn fact of human social organization that can scuttle the best of Corporate plans if not first taken into account” (Reynolds, 1994). A number of organizational studies support these views. As a rule, several sub-cultures compete within a single company, and those who work on the shop floor will often have a ‘‘counterculture” that conflicts with management’s goals and values (see e.g. Krackhardt and Kilduff, 1990 and Tompson and Mchugh, 2002, p. 205). These studies conclude that culture cannot be managed or controlled, but that to a certain degree, it may be influenced. Certainly, many will refute this statement and point to cases where culture has been successfully managed – I will return to this discussion at the end of the paper.",1
72,23,"The extent to which it is ethically defensible to influence a culture will obviously depend on the ends achieved and the means by which this influence takes place. When the intent is to create a good safety culture, it is of course possible to defend extensive measures, but there is also a limit – a point that not all safety experts and managers have understood. Some measures work against their intended purpose. If the employees do not find a given measure meaningful, one result will be that they sabotage such measures.",1
72,24,"I want to emphasize that organizational culture is a useful concept, but much of the management literature (and some organization theory) often takes an instrumental and superficial approach. To achieve a deeper understanding of this complex phenomenon, the analysis should be holistically oriented and cover various levels from the manifest and discursive to the more essential ‘‘taken for granted”.",1
72,25,"Of course, there are many interesting studies of organizational culture in which culture is treated like the complex phenomenon that it is. In fact, the literature is overwhelming, so my intension here is to limit the discussion to the authors discussed in Richter and Kochs‘ paper in Safety Science Volume 42, Issue 8, 2004, and the exchange of letters to the Editor (Hale) that followed in Volume 42, Issue 10, 2004. In my opinion, both the paper and the letters are very interesting and give us a deeper understanding of both organizational culture and safety culture.",1
72,26,"Their definition is clearly inspired by Geertz, but Richter and Koch set out to analyze safety culture in light of Martin’s three cultural perspectives: integration, differentiation and fragmentation (Martin, 1992). Within the integration perspective, culture is perceived as the shared understandings in a given organization and these studies identify a consistency across cultural manifestations. Schein is mentioned as probably the most significant scholar within this perspective (Richter and Koch, 2004, p. 705). The differentiation perspective emphasize the lack of consensus between interpretations and meanings in an organization and the focus is usually on sub-cultures (2004, p. 706). Richter and Koch understand the fragmentation perspective as ambiguity: cultural manifestations are ambiguous and there is a lack of clarity when it comes to interpretations and meanings (2004, p. 707). In this perspective there seems to be no common ground, but Martin (1992) is not quite clear on this matter. Nvestad (2006) has pointed out that Richter and Koch (2004, p. 705 and 710) unwittingly operationalize culture in a way that excludes the fragmentation perspective, as they define and understand culture as shared understandings and meanings.",1
72,27,"Following Alvesson, Richter and Koch (2004) try to synthesize these perspectives into the concept of multiple cultural configurations understood as a combination of macro-culture, local culture and situations (Alvesson, 1993). Alvesson, however, adopts a critical stance towards Martin’s concept of fragmentation and claims that we do not need a particular paradigm to handle ambiguity – it is more like a research strategy (1993, p. 117). According to Nvestad, Richter and Koch seem to have missed this point, and Nvestad also comments that an overriding paradox in analyses of cultural fragmentation is that it seems impossible to act and co-ordinate activities; in short function as an organization since there is a lack of common understandings (Nvestad, 2006).",1
72,28,"Both Alvesson and Martin are skeptical to the integration perspective represented by authors like Schein. Schein considers culture to be a pattern of fundamental assumptions for mastering external adaptations and internal integration and his cultural analyses cover several levels, from manifest expressions and artefacts, to more underlying themes of a more unconscious character (Schein, 1987; Schein, 1992). Schein also argues that by definition culture has to be unitary (Schein, 2004). I will return to this discussion at the end of the paper.",1
72,29,"How do all this fit in with the anthropological perspectives discussed in the beginning of the paper? Alvesson is often linked to Geertz and symbolism due to his focus on metaphors and meanings, but Alvesson also has a lot (more) in common with Keesing, particularly his focus on sub-cultures, cultural ambiguity and power. The same goes for Martin. If we have a closer look at Schein, it is quite clear that there is some important similarities between him and Geertz – specially the focus on cultural integration – despite the fact that Schein is usually labeled as a functionalist, while Geertz belongs to the interpretative school.",1
72,30,"As we have seen; the theoretical picture is quite blurred. For my own part, I find all these perspectives to be useful when studying safety culture, but the real test is (of course) how these perspectives fit with empirical studies – and here we shall have a closer look at the oil industry.",1
72,31,"Consistent with Schein’s definition, organizational culture is a pattern of assumptions in relation to problems with external adjustments and internal integration that have functioned well enough to be perceived as true, and are passed on to new members as the right way to conceive, think and feel (Schein, 1992). On ‘‘Texas”, all workers knew the assumptions that governed their job performance. The job had to be done as fast as possible and a lost finger or two did not matter that much. An effective socialization process led the ‘‘newcomers” to learn and accept these ‘‘assumptions” as true. The reason for this is simple enough: only those who accepted the values were allowed to stay. This was a trait borrowed from the American drilling-tradition: ‘‘If you can’t hack it, you can’t stay” (Lynch, 1987). In this process, power is also an important issue to consider and in this case it is quite obvious: if you did not agree on basic assumptions you were fired.",1
72,32,"An elimination process such as this led to a high degree of internal integration, in which both the bosses and the roughnecks agreed on fundamental values – which again were embodied as tacit knowledge. Cultural reproduction, not change, was the rule. ‘‘Texas” was a closed community, whose values and norms were completely at odds with Norwegian society. At odds with the nation’s wish for ‘‘Norwegianizing,” the Norwegian drill workers were Americanized.",1
72,33,"These opinions can be hastily written off as pure conservative nostalgia, but many of the workers on the new rigs were glorifying the recent past. Even if most of the management and the workers on ‘‘Welfare” were Norwegians, they had, through an extended socialization process claimed for themselves important elements of the ‘‘Texas-culture” and their values, norms, assumptions and tacit knowledge were resistant to change.",1
72,34,"Safety Management Systems are of course important, but not all comprehensive systems are synonymous with a sound safety culture. The employees must also embrace these measures and systems as meaningful. Within drilling especially, there was much resistance to these systems and certain measures that went with them (reporting of incidents, use of protective gear, etc.). Many of the roughnecks did not find these measures meaningful and they strongly disliked the bureaucracy that went with it. In short, the measures and the bureaucracy were at odds with the tacit knowledge you will find on most drilling rigs. The result was that the roughnecks sabotaged some measures and paid lip service to others, and in some contexts they even talked about ‘‘the good old days” back in the ‘‘Texas”-stage with no bureaucracy. Some of the roughnecks would also hesitate to visit the medic for smaller injuries.",1
72,35,"Some will find all this surprising, but along with the ‘‘Systems” there was a lot of ‘‘double communication” from the management, e.g.: ‘‘Take your time – but be quick!”, ‘‘Report incidents – but don’t do foolish things!” ‘‘Don’t break safety rules – but use your head!” etc. Likewise, typical statements from the roughnecks at this stage were: ‘‘Safety rules are ok – but it takes to long time if we always should follow them!”, ‘‘We report many minor incidents – then we don’t need to report the serious ones!”, ‘‘Protective equipment is important – but unpleasant to wear!”",1
72,36,"The history of oil drilling tells us that it possible to change a culture, but it takes a long time, and with this case in mind, let us return to some of the questions asked in the introduction. Can culture be managed or controlled? From an anthropological point of view, culture can hardly be managed. There is an apparent similarity between Geertz’s work (especially when he speaks of culture as ‘‘a set of control mechanisms”) and much of what is written about cultural control within management literature. But for Geertz, culture is something much more fundamental and lasting, and something that is thus difficult to manipulate or control. In this discussion it is also important to have in mind that cultural content is seldom if ever static. Culture changes over time, no matter what managers or employees think or do.",1
72,37,"Can culture be measured? Anthropologists and psychologists tend to disagree on this question. Many psychologists seem to believe that it is possible to measure culture – or at least to measure the safety climate (see Safety Science, volume 34, 2000). One representative for this group is Cooper (2000). He wants to create a reciprocal model which can be used to measure and analyze safety culture. The model is connected to what he calls a ‘‘goal-setting paradigm,” and will be used to break down culture into sub-components and observable behavior (or what he calls ‘‘the safety culture product”), which can be more easily measured: ‘‘Since each of these safety culture components can be directly measured in their own right, or in combination, it becomes possible to quantify culture in a meaningful way...” (2006, p. 121).",1
73,1,"Ninety SF samples from 82 horses were included, together with 40 control samples. Seventy-one of 90 samples (79%) were culture-positive by using blood culture medium enrichment (BACTEC), which was significantly higher compared to all other methods. BACTEC enrichment was never negative while any of the other methods was positive. Although agar culture following LC and/or CE resulted in a slightly higher number of positive samples compared to DA, this difference was not significant. All control samples were culture negative by the 5 different techniques. Although the majority of samples containing isolates recovered without enrichment, culture results after BACTEC enrichment were available on the same day as for agar culture with or without LC (19/23 samples), while CE postponed recovery by at least one day in 20/23 samples.",1
73,2,Blood culture medium enrichment is superior to other techniques for isolation of bacteria from SF of horses. The use of an automated system allows enrichment without substantially postponing recovery of microorganisms.,1
73,3,"Synovial infection is an important clinical condition in horses. If not diagnosed promptly and treated aggressively, permanent disability is a major risk. Isolation of the causative microorganism is important to confirm the diagnosis and guide the antimicrobial treatment. However, isolation of bacteria from infected synovial fluid (SF) is frequently disappointing. The concentration of viable microorganisms in SF is often low while phagocytised microorganisms are generally not recovered by routine culture. Furthermore, culture may be inhibited by antibiotics and intrinsic inhibitors present in SF (Hughes et al. 2001). For agar culture, low isolation rates are reported both in human patients (von Essen 1997) and horses (Pille et al. 2007). In the latter study, isolates were recovered in only 37.5% of horses with a clinical diagnosis of synovial infection.",1
73,4,"Several techniques have been suggested to optimise isolation of bacteria from SF. Human studies showed that lysiscentrifugation (LC) pretreatment increased the rate of positive cultures as compared to standard agar culture of normally sterile body fluids (Taylor et al. 1987; Gould et al. 1988). Lysiscentrifugation pretreatment releases phagocytised microorganisms by short-term incubation of samples in lytic buffers (e.g. nonionic surfactants like Triton-X-100) and subsequently maximises the inoculum by centrifugation and pelleting of microorganisms (Hughes et al. 2001). For human SF samples, the use of a commercial LC system (Isolator 1.5 microbial tube)1 increased the number of positive agar cultures with 23% (Yagupsky and Press 1997).",1
73,5,"Another option for maximisation of the inoculum for agar culture is enrichment in broths. Conventional enrichment (CE) broths, such as brain heart infusion (BHI), tryptic soy broth (TSB) or thioglycolate broth (Thio), are known to support the growth of fastidious aerobes and anaerobes (York and Thomson 2004). Furthermore, compared to direct plate culture, enrichment in liquid media offers the advantages of the inoculation of a larger volume together with important dilution of growth inhibitors (Hughes et al. 2001). However, according to some studies, CE rarely contributes useful results for culture of body fluids, including human SF (Morris et al. 1995; Derby et al. 1997).",1
73,6,"To our knowledge, a direct comparison of the efficacy of the different methods of bacterial isolation from infected synovial fluid in horses has not yet been made. The goal of the present study was therefore to compare: 1) direct agar culture; 2) LC pretreatment + agar culture; 3) CE + agar culture; 4) combined LC pretreatment and CE + agar culture; and 5) blood culture medium enrichment in an automated setting (BACTEC) + agar culture, all performed in parallel on SF samples from horses clinically diagnosed with synovial infection.",1
73,7,"Direct agar culture (DA): A Columbia agar with 5% defibrinated sheep blood3, a Columbia agar with 5% defibrinated sheep blood supplemented with colistin and nalidixic acid (CNA agar)3 and a chocolate agar3 were inoculated with 2 drops (~50 ml) of SF each, according to standard procedures for culturing human SF (York and Thomson 2004). The plates were incubated at 35°C in a 5% CO2 atmosphere. Additionally, a Schaedler agar3 was inoculated with 2 drops (~50 ml) SF and incubated anaerobically at 35°C, using the BBL GasPak EZ Anaerobe Pouch System2. The plates were inspected daily. If no growth was detected at 4 days post inoculation, culture was regarded as negative. In case of organism growth, the number of colony forming units (CFUs) was counted on each agar plate and the sum of CFUs on the 4 agar plates was recorded.",1
73,8,"LC pretreatment + agar culture: LC pretreatment was performed by incubation of 0.5 ml of SF together with 4.5 ml of sterile saline and 50 ml of Triton X-1004 for a total of 15 min. The mixture was vortexed regularly. At the end of the incubation period, centrifugation was performed at 800 g for 20 min after which the centrifuged deposit was cultured on the different agar plates as described for DA. The number of CFUs was counted on each agar plate and the sum of CFUs on the different agar plates was compared to the result obtained for direct agar culture.",1
73,9,"The results of the present study may suggest that blood culture medium enrichment combined with automatic processing of the bottles could be the used as the sole culture technique for equine SF samples. Indeed, sample positivity was about 3 times higher than with the other techniques, blood culture medium enrichment never failed to recover microorganisms that were recovered by other methods and, importantly, culture results were not postponed compared to culture without enrichment. However, it could be argued that direct agar culture has also advantages over enrichment methods by discriminating contaminating and significant organisms based on colony counts. According to von Essen (1997), heavy growth on agar indicates a true positive result while sparse colonies may suggest isolation of a coincidental contaminant. However, the finding that all control samples were negative by the 5 different culture techniques, clearly demonstrate that contamination during collection and handling of samples is not a major issue when strictly adhering to aseptic procedures.",1
73,10,"Another restriction of blood culture medium enrichment as the sole culture technique is that the BACTEC Peds/Plus F blood culture bottle does not support the growth of obligate anaerobes. However, since low volume anaerobic BACTEC culture bottles are yet not available, other culture methods were optimised to promote their growth. Briefly, every agar culture was performed in duplicate using a rich agar (SCH) incubated in an anaerobe pouch system while thioglycolate was chosen as conventional enrichment broth because of its excellent recovery of anaerobes from human sterile body fluids (Reinhold et al. 1988; Scythes et al. 1996). Despite all efforts made, no obligate anaerobes were isolated in the present study.",1
73,11,"Growth of microorganisms was detected by the automated system in the present study for the majority of samples within 24 h. The overall short TTD together with the low percentage of instrument-false-positives and -negatives confirm the reliability of ‘automatic’ detection of microorganism growth in blood culture bottles inoculated with equine SF. The spectrum of species isolated and the fact that administration of antibiotics prior to sampling had no significant influence on the isolation rate and TTD, are in line with previous observations on culturing SF from horses with the BACTEC system (Dumoulin et al. 2010).",1
73,12,"In the present study, the median TTD of samples that were positive after BACTEC enrichment exclusively was significantly longer compared to the median TTD for samples that were also positive by at least one other culture method. In a study by Tanju (2004), BACTEC blood culture bottles were spiked with serial dilutions (into human blood) of a wide variety of microorganisms. It was found that there was a correlation between the TTD and the initial inoculum concentration for most organisms. From these observations, it is hypothesised that the concentration of microorganisms in the samples in the present study, positive after BACTEC enrichment exclusively is lower than in samples also positive by at least one other culture method. This would suggest that the BACTEC system has its value in recovering isolates from samples with a low microorganism concentration, which is often the case in synovial fluid samples (Hughes et al. 2001).",1
74,1,"The idea of investment treaty arbitration as public law is in tension with the concept of international law as a law between representative public agencies. This concept of international law is valuable for its capacity to progress a broad range of public policy aims in an integrated and coordinated manner, including aims extending beyond the economic sphere such as international social, environmental, cultural and related aims. The probable effect on this concept of international law of a radical ‘internationalized public law’ approach to investment treaty arbitration requires further thought, especially with regard to the potential implications of recognizing investor rights under international law.",1
74,2,The new literature that has advanced public law perspectives on investment treaty arbitration since the turn of the century has been invaluable in generating an awareness around the world that investment disputes with host States are public in character.,1
74,3,"The momentum behind the realization that investment treaty arbitration is, profoundly, an exercise in public law must be carried forward. A public law approach will help us understand better the nature, scope and importance of host States’ regulatory authority and help us to assess accountability and associated issues in investment treaty arbitration.",1
74,4,"This article builds on the premise that, in general, adopting a domestic or national public law perspective that regards investment treaty arbitration as judicial review of domestic agencies’ decisions is in tension with the structuring of public international law as a law between representative agencies and the idea of investment treaties as embodying inter-State relations. This is because a public law perspective views investment treaty disciplines first and foremost as constraints upon the exercise of State power vis-à-vis private interests, as in classical public and administrative law. Taking a public law perspective means that investment treaty disciplines are viewed as governing the relations between natural or corporate private persons and host States. This contrasts with a traditional public international law approach under which international legal relations between States as representative public agencies provide the conceptual framework for arbitral decision-making. Here, investment treaty disciplines are viewed primarily as governing the relations between States as representatives of their populations.",1
74,5,"A specific concern is that focussing on constraining State power in relation to private interests in the commercial realm can be expected to have a marginalizing effect on the concept of public international law as a law between representative public entities. As discussed further below, this ‘inter-representative’ quality of public international law brings with it the expectation that legal relations between States will serve as vehicles for carrying forward coordinated and integrated international public policies for economic, social, cultural, health, environmental and vital related purposes.",1
74,6,"The ‘internationalized public law’ perspective is the newest incarnation of the public law perspective on investment treaty arbitration. The ‘internationalized public law’ perspective goes beyond previous public law perspectives in presenting investment treaty arbitration in its very essence as ‘internationalized public law’. Certain additional features of the ‘internationalized public law’ perspective also render it potentially particularly concerning for international law as we know it. These features include the encouragement given to investment treaty tribunals to operationalise indeterminate balancing principles (such as proportionality) as general principles of law, and the likelihood that recognition of investor rights under international law would accompany the widespread adoption of the ‘internationalized public law’ perspective. The latter especially threatens to detract further from the concept of international law as a law between publicly representative entities.",1
74,7,"This article proceeds by introducing the ‘internationalized public law’ perspective on investment treaty arbitration in Part II. Part III then assesses, and finds wanting, justifications put forward for an ‘internationalized public law’ perspective, including legal justifications based on the consent of States and the predicted rise of general principles of law as a source of law, as well as functional justifications. In addition, Part III considers the potential justification of an ‘internationalized public law’ perspective on the basis that investors can be understood as right-holders under investment treaties, and that in investment treaty arbitration they assert those rights in the same way as citizens assert rights against governments in domestic public law proceedings. Part IV, the article’s final section, offers a few observations on questions and issues associated with the place to be accorded to private capital within public international law in an increasingly transnationalized economic environment. These questions generate further pause for thought about whether an ‘internationalized public law’ approach to investment treaty arbitration is truly desirable.",1
74,8,"Justifications put forward for the ‘internationalized public law’ perspective include legal justifications based on the consent of States and the potential rise of general principles of law as a source of law, as well as functional justifications. In the case of the legal justifications, the argument is that State consent and general principles of law provide the requisite authority for a shift in investment treaty arbitration based on an internationalized public law perspective. In the case of general principles of law, this is because such principles are envisaged as providing the substantive basis for arbitral decision-making, despite the indeterminacy of certain concepts potentially eligible for recognition as general principles of law.",1
74,9,"Conceivably, States’ consent as representatives of their people could provide a basis for viewing international investment law as ‘internationalized public law’. Surely, States must at least have expected arbitral tribunals, operating as a new global network, to develop a set of specific, implementable interpretations of investment treaty investor protection standards, going beyond the vague form taken by these standards in treaty texts?",1
74,10,"Or do we have to admit, to the contrary, that States becoming party to investment treaties are unlikely to have done so with the intention or even the expectation that arbitral jurisprudence could enhance a structural weakening of public international law? Even Gus Van Harten and Martin Loughlin, whose work can be read to suggest that consent offers a basis for the transformation of investment treaty law into global administrative law, make the point that ‘[w]hat remains unclear is the extent to which the established arbitration regime has been the subject of careful forethought by States that remain conscious of the implications of the arrangements they have signed up to’.",1
74,11,"At the same time, it is possible that, in due course, support for recognizing a new wave of general principles of law in the context of investment treaty arbitration will generate general acceptance. Alternatively, if there is a proposal that a concept such as proportionality could achieve independent force as a ‘principle of general international law’ as opposed to a ‘general principle of law’ under Article 38(1)(c) this raises significant practical, doctrinal and theoretical issues.",1
74,12,"Alternatively and additionally, functional rather than legal justifications are advanced for viewing investment treaty arbitration as internationalized public law. Functional aspects of investment treaty arbitration that are invoked to justify this analogy between investment treaty arbitration and public law include investment treaty arbitration’s authorization of individual claims against governments, the award of damages against governments (which can be viewed as a public law remedy), and the direct enforceability of awards under the ICSID Convention or the New York Convention.7",1
75,1,"It is trite to observe that the past three decades have seen an ‘explosion’ in comparative law. Equally well-worn territory is the fact that constitutional law has been a particular beneficiary of the comparative trend, despite the fact that for much of the twentieth century comparative lawyers tended to avoid public law topics. However, one field of law that has been conspicuously absent from the boom in comparison, at least outside of Europe, is administrative law. This article analyses why the use of comparison has been so vastly different between the two areas of public law. It then surveys some recent developments in administrative law and points to a number of aspects of the field that would benefit from the wider use of comparative methods across the world.",1
75,2,"Comparison is the methodology de rigueur in legal scholarship today. One need only take a cursory look at the content of articles in leading legal publications or at the curricula of top law schools to find evidence of the ‘comparative law explosion’. The same infatuation with comparison can also be found amongst legal practitioners, judges and policy-makers across the world, who frequently draw guidance and inspiration from foreign and international law. One manifestation of the trend is a greater attention to theory, though many have noted that comparative law remains quite weak in this area.",1
75,3,"A range of arguments have been made as to why comparison is inherently more suited to examining private law issues. The two main arguments relate to the greater contextual complexity of public law and its nationally-specific nature. The first contends that public law is influenced by a far broader range of external, non-legal factors than private law, including politics, history and economics. This is said to make it difficult to conduct meaningful and useful comparative study in public law because comparatists must understand this array of external factors at a sufficient level to undertake informed analysis.",1
75,4,"The second argument against comparison in public law is that public law is nationally specific, designed to meet the individual needs of a particular government and social structure. This means that public law ‘would not easily allow comparison with, let alone ‘transplants’ from, other systems’,11 and comparative study would accordingly offer no practical benefits. The argument shows comparative lawyers’ preoccupation with functionalist objectives and harmonization in particular. Again, this can be traced back to the Paris Conference and the prevailing concern that studies in comparative law have practical functions, a bias which continues to dominate comparative legal scholarship and has been argued to have stunted its development as a cohesive discipline.",1
75,5,"There are undoubtedly numerous forces that have contributed to the surge of interest in comparative constitutional law, but most scholars consider the global spread of constitutionalism and mass transplantation of certain basic constitutional ideas as pivotal.",1
75,6,"In addition to the frequent inclusion of human rights in modern constitutions, Hirschl has identified four other common features in constitutions adopted since the end of World War II: provisions establishing the key institutions of government and the relationships between them; provisions distributing government power; a method for amending the constitution; and provisions establishing relatively independent courts with jurisdiction over constitutional matters.",1
75,7,"The ADJR Act attempted to simplify the complex processes involved in applying for relief via the judicial review remedies available under the Constitution. It codifies the grounds of review, remedies and application process involved in judicial review. However, jurisdiction under the ADJR Act is limited to decisions ‘made under an enactment’, which the courts have interpreted narrowly as requiring that a decision be ‘expressly or impliedly required or authorised by the enactment’ and that it ‘confer, alter or otherwise affect legal rights or obligations, and in that sense the decision must derive from the enactment’.",1
76,1,"Good faith is a principle prominent in civil law countries but less so in common law countries, and which allows courts to deviate from black letter law. It provides them with flexibility to change the outcome of a deductive legal decision if they regard it as absurd. The principle of good faith thus empowers the judiciary to deviate. It can be used for an indefinite number of cases and might lead to almost all conceivable legal consequences. For instance, the judge can invalidate the contract, change the price, suspend or change a clause in the contract, or grant injunctive relief, compensation of damages, the disgorgement of profits or a removal claim. We argue that if the principle of good faith is used to develop contract law into an instrument for redistributing wealth in favor of poor parties, this can destroy the concept of contract as a social mechanism for generating mutual gains for parties, which might lead to unwanted economic consequences in terms of efficiency losses. We argue that the principle of good faith must be carefully and reluctantly used to reconstruct the fully specified contract and that well-informed judges, who understand the factual environment of a contract well should ask how fair bur selfinterested parties would have allocated the risk in a pre-contractual situation. ",1
76,2,"From an economic perspective the default rules of contract law try to mimic the fully specified contract. They allocate risk to the cheapest cost avoider or the cheapest insurer. They also specify norms for curbing opportunistic behavior, which leads to an unwanted redistribution of wealth between parties rather than increasing each party’s wealth. Thus contract law tries to allocate risks and imposes contractual, pre-contractual and post-contractual duties, ideally in a way which fair but self-interested parties would have chosen themselves had they cared to specify them. However, the rules as laid down in the law might sometimes lead to unintended and absurd consequences. They might fit for many, yet not for all cases.",1
76,3,"Good faith is a principle prominent in civil law countries but less so in common law countries, which allows courts to deviate from black letter law. It provides them with flexibility to change the outcome of a deductive legal decision if they regard it as absurd. The principle of good faith thus empowers the judiciary to deviate. The alternative to such a flexible blanket clause would probably not be an equally flexible contract law, which is continuously updated by parliaments, but stickiness and incapacity to react to unforeseen problems of adjudication. Parliaments cannot change the laws as often as would be required. They cannot micromanage contract law. If principles such as good faith are not used, one consequence would be that the law cannot adapt to new situations, thus lacking innovativeness and convincingness in terms of outcome. Another consequence is that parties write long contracts containing all contingencies and parties’ duties in order to come close to a fully specified contract and thus heavily invest in defensive measures against opportunism. This might explain as to why contracts in legal orders that only use the good faith principle reluctantly, like in England, are often much longer than in civil law countries like Germany, where contracts are less complete and shorter. ",1
76,4,"The principle of good faith gives much power to the judiciary and this power can be, and has been, misused for various purposes. Primarily, it can be misused through the import of ideology into contract law. Ideological import can bring about changes to contract law through the misuse of the good faith principle and the flexibility that it entails. Another danger is that it might lead to judicial activism, if the judiciary encroaches the legitimate function of parliament and democracy, and the judiciary develops the law through the principle of good faith in such a way that it—to some extent—replaces parliament. Another and perhaps the main problem today is the overuse of the concept by the judiciary under the name of ‘‘maintaining justice’’, with which social justice is meant, that is the redistribution of wealth from the rich to the poor party. Still another disadvantage, in line with Hayek’s reasoning, is that many important clauses of a contract on which parties and the black letter law remain silent are stipulated by judges, who as outside observers may not possess the information for acting in the ex-ante interest of all parties, even if they have the best intentions on doing so.",1
76,5,"In this article, we discuss the principle of good faith from an economic perspective, relating this to cases of the Turkish Supreme Court. We deal with objective, contractual good faith and leave aside subjective good faith in property law, which might—depending on the case—result in acquisition of ownership by a good faith purchaser. We argue that if the principle of good faith is used to develop contract law into an instrument for redistributing wealth in favor of poorer parties this can destroy the concept of the contract as a social mechanism for generating mutual gains for parties, which might lead to unwanted economic consequences in terms of efficiency losses. We argue that the principle of good faith must be carefully and reluctantly used to reconstruct the fully specified contract, and that well-informed judges who understand the factual environment of a contract should ask how the parties would have allocated the risk in a pre-contractual situation. ",1
76,6,"What is the consequence of this? If parties are themselves expected to explicitly allocate risks and remove contingencies—potentially leading them into the temptation of acting opportunistically—with one of the parties forced to otherwise bear the consequences, both parties will have higher incentives to do so than in a jurisdiction in which such usually remote risks are allocated through court decisions. This makes contracts potentially more authentic. But parties will also spend more time and effort on allocating risks. Consequently, drafting a contract is more costly in a jurisdiction in which the principle of good faith does not exist and in which the authority of courts to intervene with a contract is more limited. In fact, it is well known that contracts are much longer in England than, for instance, in Germany where the good faith principle is extensively used, and therefore contracts are also more costly. In England, contracts often contain long laundry lists of duties, obligations, non-competition clauses and other risks that are explicitly taken care of, whereas this cannot be observed to the same extent in German contracts.",1
76,7,"If one compares the two solutions, there is an upside and a downside to each of them. The self-restraint of English courts takes the will of the parties as displayed in the contract itself more seriously. The extended use of good faith, however, provides the parties with a valuable public service that serves the same purpose as the rules of contract law themselves, namely to fill in gaps in incomplete contracts (Ayres and Gertner 1989:87) and to reduce pre-contractual and post-contractual opportunistic behavior in parties.",1
76,8,"In those countries that accept the principle of good faith there is a general scholarly agreement that the good faith principle, which can fundamentally change a contract, should be used as a last resort where the formal rules of contract law would otherwise lead to absurd consequences. This opinion has also been expressed by the Turkish Supreme Court in its decision from 1984: ‘‘...with the rule set forth under Article 2/2 of the Civil Code, an exception is brought to the absoluteness of the Law and right. However, also considering the subsidiarity of this rule, at first the relevant legal provisions shall apply to each case; in some exceptional cases, where the legal provisions which apply cause unjust results, the rule under Article 2.2. Can be resorted to in a way to correct the injustice.’’",1
76,9,"The principle of good faith, however, as it was developed by European and especially German scholars, is not aimed at changing the contract into a mechanism for redistributing wealth, but for enhancing and increasing the genuine function of a contract, preserving it as an institution for generating mutual gains under fair conditions or, in economic terms, in order to increase economic efficiency. It saves the parties transactions costs.",1
76,10,"At this point one can make reference to the default rule regarding the rejection of partial performance. In such cases, even though the risk was explicitly specified in the default rules, an exception can be made if it is required by the principle of good faith. For instance, if the seller offers to deliver 999 packs of rice to the market (instead of 1000) and offers to deliver the remaining one pack the next morning, it would be against the principle of good faith if the buyer rejected such partial delivery. Therefore the court will suspend the default rule.",1
76,11,"Allocating risks when the law is silent There maybe cases where both contract and default rules are silent on a matter. In other words, in such cases both contract and default rules are incomplete and they remain silent on the topic of risk allocation, with the consequence that the result might be neither fair nor cost-saving. In such cases, the principle of good faith can provide an efficient risk allocation. For instance, in the example of the medical doctors who swapped their practices the good faith principle can lead to such an efficient risk allocation.",1
76,12,"In this section we show that the good faith principle is not a port leading to unlimited and willful judicial interpretation, but rather has an internal structure which limits its usage, even though it can be used for an indefinite number of cases and might lead to almost all conceivable legal consequences. For instance, the judge can invalidate the contract, change the price, suspend or change a clause in the contract, or grant injunctive relief, compensation of damages, the disgorgement of profits or a removal claim.",1
76,13,"An obvious criticism of the principle of good faith therefore is its generality and broad scope. The judge might become a kind of ‘‘philosopher king’’. In this article we abstain from giving the principle a precise legal definition or to add one to the existing catalogue of definitions. For our purposes it is enough to say that it endows the judiciary with an almost unlimited power to interfere with the contract, that it is used as a last resort when all other methods of interpretation lead to absurd consequences, and that the willfulness in most civil law jurisdictions is removed by giving the principle a highly differentiated internal structure and that like all of contract law it tries to preserve the ex ante win–win property of a contract, allocate risk in a cost efficient way and curb opportunistic behavior of one party.",1
76,14,"The plaintiff concluded a lifelong care provision contract with a person and fulfilled all of his obligations arising from the contract until the death of the other party. Following his death, when the plaintiff claimed the consideration set forth under the contract, the heirs of the deceased argued that the contract was invalid because of a breach of the form requirement. The court ruled that, once a lifelong support contract or an adoption contract is fulfilled, following the death of the party who receives lifelong support, it constitutes a misuse of right to claim invalidity of the contract due to a breach of form requirements.",1
76,15,"It is obviously inefficient if the owner of a right could make use of this right with the only purpose being the infliction of damage on another person. Therefore, under Turkish law as in the law of many other jurisdictions, one finds misuse of right as a limit to the right of the owner, which is efficiency enhancing.",1
76,16,"This case is related to the ‘‘obligation to contract’’ which originates from the principle of good faith. In this case the state water supply company rejected to make a subscription contract and to supply water services to the owner of a flat by arguing that his previous tenant, who has already been evicted from the flat, had some remaining unpaid bills. The Supreme Court decided that as the company had monopoly position, it hence had the obligation to contract.",1
76,17,"The specific aspect of this case is that the supplier of the water service is a monopoly. The customer has no other choice than to buy his water from this monopoly. Moreover, water is a basic good, whose purchase is necessary whatever the costs are. Monopolies therefore must be controlled with regard to the prices they charge and with regard to the terms and conditions under which they supply their products. Contract law here has, to a certain extent, to mimic the rules of public and administrative regulatory law. If the company operated in a competitive environment, there would be no need for the legal system to interfere, but at the same time it would then be highly improbable that a corporation would impose such a clause on a customer for fear of losing him to a competitor. It is therefore fully in line with economic reasoning that in monopoly markets the legal system must cut deeper into the freedom of contract than is reasonable or acceptable in well-functioning markets.",1
76,18,"Moreover, this case shows that the result is not only in line with fairness or justice, but also that an alternative solution would lead to wrong incentives. If one would not assume a contract in this case, which entitles the electricity company to collect the actual price for electricity, this would give incentives to all to consume electricity without contract and burden the electricity company with the costs of the burden of proof for damages or the amount of unjust enrichment later on. This would then lead to an increase of illegal electricity consumption.",1
76,19,"In this case a minor, the respondent made a gift to his prospective wife. 11 years after they married, he claimed that such a gift was invalid due to his lack of capacity. According to the Supreme Court, such a claim is against the good faith principle. In this decision, the Court did not expressly refer to any sub-categories of good faith but it can be inferred that the court sees the respondent’s act as a misuse of right.",1
76,20,"It is difficult to make a clear statement on whether this solution is not only in line with the idea of protecting women, or the idea of justice, but also whether it is in line with efficiency considerations. It is clear that this decision, if it is a general rule, comes at the cost of reducing the protection of minors by a judge-made rule. The protection of minors has high economic value because if minors could conclude valid contracts, the resources they would transfer would in many cases not go to the highest valued user. The protection of minors therefore does not only protect the minors themselves but also serves the general purpose of not wasting resources. If therefore the courts reduce this protection, it comes at a cost to the minor and the society and it is impossible to say prima facie whether these costs can be regarded as lower than the protective effect for the woman. The court, however, made it clear that it regarded the time lag between the formation and the refutation of the contract as essential. If the man had refuted the contract shortly after the marriage or after one or two years, the ruling would have come close to a revocation of the protection of minors and would then have amounted to a redistribution of wealth, which can hardly be defended on economic grounds. ",1
76,21,"In a case of joint ownership the parties allocated their immovable by a written protocol (against the official form requirement which required parties to conclude such a contract at the land registry), and each owner rented out his part of the immovable to third parties for the last couple of years. While everybody used his/ her part as such, one of the parties sold his/her share to a third person. Following such sales, one shareholder wanted to use his preemption right. The court ruled that if a party, who did not object to allocation before, wants to use his/her preemption right in a case of sale to a third party, this is against the principle of good faith. Also in this decision, the Supreme Court did not expressly refer to any sub-categories of good faith, but it can be inferred that the court assesses the respondent’s act to be a misuse of right.",1
76,22,"Again, this is a ruling in line with economic considerations. It is aimed at curbing post-contractual opportunistic behavior. The mandatory form requirement (that the parties must conclude such a contract at the land registry) is set aside by the court, because its rationale does not apply to the case and the right from it is used in an opportunistic way. Form requirements, such as written form or notarized form, have the rationale of protecting an actor against impulsive or uninformed decisions, which are not in line with his constant motives and long-term preferences. The actor might regret the decision after reconsidering it. They have therefore a similar rationale as, for instance, cooling-off periods in consumer contracts. In the present case, the joint-owners of the immovable had agreed to end their joint-ownership and replace it by single ownerships after dividing up the property. The joint-owners had also reached an agreement on the division and distribution of the assets between them. The use of the immovable by the single owners had been agreed in a former protocol and only after a considerable time after the agreement had one of the jointowners made use of his pre-emption right. ",1
76,23,"This case concerns a cell phone subscription contract and the interest rate applicable to overdue bills. The interest rate was not set in the contract, but the GSM operator was given the authority to set it unilaterally. Accordingly, the GSM operator applied an interest rate of 12 % per month, which was higher than the 8 % interest rate applied by competitors. The court ruled that the GSM operator’s freedom to set the interest rate is not unlimited and that it amounts to a misuse of right to use such a freedom in a way that applies a 12 % rather than a 8 % interest rate.",1
76,24,"The Supreme Court assumed that the clause is in principle valid, as if it had been negotiated between the parties, but maintained that the only way this clause could be used without violating the good faith principle was to fix an interest rate not higher than the interest rate of competing companies. We believe that this is overstretching the principle of good faith, because to fix an interest rate for overdue bills that is not only higher than the market rate but also even higher than that of competitors might be a legitimate business strategy. If the GSM operator makes it clear to the subscriber that it becomes very costly for a subscriber not to pay bills when they are due, this practice signals to all buyers that subscribers who pay their bills on time are very welcome but that subscribers who do not pay on time are not welcome by the company and should approach another GSM operator. The high interest rate can therefore be regarded as a kind of contractual fine for not paying bills correctly. The high interest rate deters defaulting customers and saves the company the cost of controlling money transfers by sending reminders, opening court proceedings etc. Therefore, as the company concentrates on good customers, it can offer them a lower price for the specific performance. ",1
77,1,"This article undertakes an innovative analysis of the theoretical and practical bases of world trade law by employing the interactional international law theory developed by Jutta Brunnée and Stephen Toope, and the jurisprudence of Lon L. Fuller. There are two main reasons for choosing an interactional approach. Firstly, through the constructivist notion of shared understandings, it offers a suitable framework for identifying the social foundations of world trade in terms of economic and legal inputs into the system. Secondly, Fuller’s contributions are acutely relevant to world trade law because of the economics foundation of his morality of law thesis, and his insightful reflections on fidelity to law, legality, and adjudication. Fuller’s jurisprudence pays close attention to the limits of adjudicating institutional rules that apply to the allocation of economic resources. This makes it useful for discussing the procedural challenges facing the World Trade Organization compliance regime.",1
77,2,"Despite this polarization, more reflective voices have revealed how the economic and the legal are concepts that share common ground for crossfertilization, especially with the rise of the modern state, and a world of growing interdependence.2 Viewed from this perspective, although rationality has come to define law, statecraft, and economic relations in the modern world, it has also simultaneously transformed the conceptions, ideals, practices, and institutions of economic life. In this context, world trade law can be understood as the re-articulation of legalism in a manner that is commensurate with the modern modes of economic governance. Rethinking the legal also means rethinking the economic, with its truth claims and its promises of internal and external ‘wealth maximization’.",1
77,3,"This article is structured as follows. Part two will summarise the interactionalist approach to public international law. Part three will illuminate the social foundations of the world trading system, and explore the often-neglected role of legal obligations. Part four will discuss the anti-legalist/legalist debate surrounding compliance, the debate that has contributed towards the various distorted views about the content and purpose of world trade law. Part five will argue why interactionalism is the best theory for analysing the GATT/WTO rules. Part six will give an outline of the challenges of applying the interactional approach to world trade law, and part seven will provide a conclusion.",1
77,4,"Therefore, the development of this realm is dependent on the existence of shared understandings that ‘are relevant to law’s intelligibility and to perceptions of reasonableness’. When applied in order to test the legality of an international system of rules, the authors argue that Fuller’s criteria is able to ‘force a clear-headed assessment of the posited rule’ to distinguish between a legal and social rule that can become legal over time depending on the level and type of interactions of the relevant actors.",1
77,5,"There are two main causes for misinterpreting the social foundations of world trade. One involves the relationship between the legal means for achieving trade liberalisation, and normative ideals such as human rights and environmental concerns. If the aim of opening up trade is to improve people’s lives and welfare, then how can this aim be separated from normative concerns such as respecting human rights and the environment? The other concerns division between the administration of legal rules, collectively made and maintained (but not enforced) for achieving trade liberalisation, and the individual implementation of these rules by WTO member state(s) (who are able to bring a claim against the offending member states for an injury caused by treaty violation). It appears there is a collective role for law-making, but not for law-implementation. These two causes have made it harder to determine whether a respondent state can justify any breach of the rules based on normative concerns under (GATT Article XX). It can be unclear whether a breach was made for the sake of normative concerns, or purely to reinforce protectionism. This poses a dilemma, since one cannot tell whether the rules or rulings can be fulfilled by upholding WTO law at the expense of normative concerns or vice versa.",1
77,6,"This communicative approach appears to conform to the interactional approach in two distinctive ways. Firstly, it recognises historical shifts in the formation of norms – from the logic of interests and the temporal gains of open trade benefits, to the logic of appropriateness and communication – which establishes a system of learning and mirroring (the norm-cycle). The second way Cho’s communicative approach agrees with the interactional approach, and especially with Fuller’s jurisprudence, relates to his expression of uncertainty concerning ‘the loyalty to law’.",1
77,7,"Perhaps the biggest contribution of the WTO jurisprudence may be that it promotes fidelity to law, rather than fidelity to power, and thus unites participants of the world trading system around this ideal. In the absence of fidelity to law, myopic parameters, such as political contingencies, would fill in any legal vacuum. Therefore, an essential element of community of law is the participants’ self-consciousness of the normative context of the community operation.",1
77,8,"It is true that, from a historical perspective, the WTO dispute settlement system has evolved to be an effective communication tool in the formulation and implementation of trading laws, but it can be equally regarded as having established ‘a system of reciprocity and [created] a normative reference system that imposes significant constraints on the unilateral exercise of power (right over might)’.",1
77,9,"Social norms can only emerge when they are rooted in an underlying set of shared understandings supporting first the need for normativity, and then particular norms that shape behaviour. [. . .] Once in existence, shared understandings become background knowledge or norms that shape how actors perceive themselves and the world, how they form interests and set priorities, and how they make or evaluate arguments.",1
77,10,"It has been established by legal scholars and political scientists that the world trading system under the GATT had evolved into a legal system as now represented by the WTO legalistic order. However, the anti-legalists argue that the system has evolved into a mere set of procedural rules that do not promote the idea of the rules as being intrinsically obligatory. The reference I made to political scientists is illuminating because parallels for the anti-legalist/legalist debate can be found in the field of political economy. For instance, some scientists believe that the WTO dispute settlement system primarily serves as an enforcement device (in support of the legalist account that it ought to sanction non-compliance).",1
78,1,"This article examines the recent development of mainland Chinese law and judicial practice regarding the law applicable to arbitration agreements. It identifies potential changes to mainland Chinese law and practice that may help to further develop the People’s Republic of China (PRC) into a truly international-arbitration-friendly jurisdiction. It argues that in the absence of explicit statutory provisions and a consistent approach in the People’s Courts to the determination of the place of arbitration and the law applicable to arbitration agreements, it is important for parties negotiating arbitration clauses with a seat in China and/or for contracts involving mainland Chinese elements to explicitly designate the place of arbitration as well as the law governing their arbitration agreements.",1
78,2,"It is submitted that applying the law of the seat of arbitration as the applicable law of the arbitration agreement does not necessarily hold water from a textual analysis of the current PRC law, the development of which in recent years seems to have resulted in complications and uncertainties on several related issues.",1
78,3,"More recently, Article 18 of the Law on Applicable Law in Foreign-Related Civil Matters (promulgated 28 October 2010 and effective from 1 April 2011) provides that in the absence of parties’ agreement on the law governing the validity of the arbitration agreement, the law of the place of the arbitration institution or the law of the place of arbitration shall apply. This provision, however, is silent on when to apply the law of the place of the arbitral institution; when to apply the law of the place of arbitration; and which of the two prevails in case of inconsistency.",1
78,4,"On 28 December 2012, the Supreme People’s Court issued its Opinion No 1 on Several Issues concerning the Application of the Law on Applicable Law in ForeignRelated Civil Matters (effective from 7 January 2013). Article 14 of that opinion provides that if the parties make no agreement on the law governing the arbitration agreement, or on the arbitral institution or on the place of arbitration, or the parties’ agreement on those matters is ambiguous, the People’s Court may apply the law of the PRC to determine the validity of the arbitration agreement. However, unfortunately, the Supreme People’s Court did not take the opportunity to clarify: (1) what constitutes agreement on the ‘place of arbitration’; (2) how to ascertain the ‘place of arbitration’; (3) what the exact legal effect of the place of arbitration on the arbitration agreement, on the arbitral procedures and on the resulting arbitral awards is; and (4) what the legal relationship between the place of arbitration and the place of the arbitration institution is.",1
78,5,"More importantly, it remains unclear under current PRC law whether an arbitral award is deemed to have been made at the place of arbitration or the place of the arbitral institution, or elsewhere. As we know, the New York Convention itself is silent on how to ascertain where an arbitral award has been made. According to ICCA’s Guide (2013), the vast majority of Contracting States considers that an award is made at the seat/place of arbitration. ICCA’s Guide (2013) further explains: ‘[T]he seat of the arbitration is chosen by the parties or alternatively, by the arbitral institution or the arbitral tribunal. It is a legal, not a physical, geographical concept. Hearings, deliberations and signature of the award and other parts of the arbitral process may take place elsewhere.’ This of course is in line with Article 20 of the Model Law. According to Article 31(3) of the Model Law, the award shall state its date and the place of arbitration as determined in accordance with article 20 (1); and the award shall be deemed to have been made at that place, ie the place of arbitration. Unfortunately, these crucial provisions are missing from the current PRC Arbitration Law (1995). Note that CIETAC Rules (2012), for example, does specifically fill these gaps in Article 7 (Place of Arbitration).",1
78,6,"According to Article 18(1) of the ICC Arbitration Rules (2012), the place of the arbitration shall be fixed by the Court, unless agreed upon by the parties. Thus, although physically headquartered in Paris, the ICC Court of Arbitration can fix the seat of an ICC arbitration anywhere in the world. Similarly, CIETAC Arbitration Rules (2012) provide in Article 7(2), ‘where the parties have not agreed on the place of arbitration or their agreement is ambiguous, the place of arbitration shall be the domicile of CIETAC or its sub-commission/centre administering the case. CIETAC may also determine the place of arbitration to be another location having regard to the circumstances of the case’. With the recent launch of the CIETAC Hong Kong Arbitration Centre (24 September 2012), arbitrations conducted in the CIETAC Hong Kong Arbitration Centre are likely to have their seat in Hong Kong, even though the place of the arbitration commission, arguably, refers to its headquarters in Beijing.",1
78,7,"Perhaps an even more interesting question that should be asked is whether mainland Chinese courts would uphold the validity of an arbitration agreement that stipulates arbitration administered by non-Chinese arbitration institutions, such as the ICC International Court of Arbitration, where the seat of arbitration is in China, but the governing law is non-Chinese law. For example, using the same arbitration clause in the German Züblin (2004) case, ‘Arbitration: ICC Rules, Shanghai’ but at the same time, the parties also stipulate that that arbitration agreement is governed by French law. In that case, it is submitted that the mainland Chinese courts should find that such an arbitration agreement is valid under the governing law, ie French law, as designated by the parties. A careful and specific designation of a proper law that governs the arbitration agreement could have saved it from being found invalid under the current PRC law by the People’s Courts.",1
78,8,"More importantly, in the Amoi (2009) case, the Supreme People’s Court did not consider whether the arbitration clauses could have been found valid under the law of the other agreed place of arbitration (Brussels). Given that the parties agreed on two places of arbitration, the Supreme People’s Court failed to explain why Xiamen instead of Brussels should be the preferred or relevant place of arbitration. The parties may have intended that, in the event the arbitration clauses were found invalid in one place of arbitration (Xiamen), they could have still been found valid in the other place of arbitration (Brussels). In the event that the arbitration clauses were indeed found valid under Belgian law, could the parties then seek recognition and enforcement of the resulting Belgian award back in China? Should the People’s Court then refuse to recognize or enforce that award, given the Supreme People’s Court’s prior finding that the arbitration clauses were invalid under the PRC law? Or, should the People’s Court recognize and enforce the Belgian award given that the arbitration clauses were valid under the Belgian law?",1
78,9,"It is submitted that the arbitration agreement in the Amoi (2009) case falls within the scope of the New York Convention. Firstly, although the arbitration agreement provides for the place of arbitration in China, the forum State, it also provides for the place of arbitration in Belgium, a foreign State. Both China and Belgium are contracting States to the Convention. The People’s Court in this case should have applied Article II of the Convention to recognize the arbitration agreement and refer the parties to arbitration, unless it found the said agreement was null and void, inoperative or incapable of being performed. Secondly, according to the ICCA’s Guide (2013), even though the arbitration agreement provides for a seat in China, the forum State, the People’s Court ‘must’ apply the Convention if the future award will qualify as non-domestic pursuant to the second sentence of Article I(1) of the Convention.",1
78,10,"Given that ‘Dongguan’ is the name of a specific city in Guangdong province, it may be argued that the choice of the place of arbitration could have been implied from the name of the designated arbitration commission. Although applying the law of the place of arbitration would not have led to a different outcome in this case, the Supreme People’s Court in this case took the view that the mere designation of an arbitration commission does not constitute designation of the place of arbitration.",1
78,11,"The Supreme People’s Court in the above Shenzhen Food Group (2010) case found that the stipulation to the law governing the disputes (‘Disputes arising out of the contract shall be resolved in accordance with English law’) did not constitute an agreement on the law governing the arbitration agreement; and that the stipulation to the arbitration institution did not equal the stipulation to the place of arbitration. This decision seemingly suggests that the parties’ agreements to the governing law of the arbitration agreement and to the place of arbitration both need to be very clear and specific. Otherwise, the People’s Court would be inclined to apply the law of the court of action (lex fori), ie PRC law, to determine the validity of the arbitration agreement. Furthermore, arguably, had the parties carefully worded its designation of English law to govern their arbitration clauses specifically, the People’s Court should have found those arbitration clauses valid under the English law.",1
79,1,"In the early 1990s, soon after Israel had ratified the UN Convention on the Rights of the Child, the Israeli Supreme Court issued several rulings that focused on the issue of children’s rights, which would now be addressed as a fundamentally new doctrine. Presented as reflecting a significant change in the attitude of the case law, this doctrine was ascribed to the ratification of the Convention and to the enactment in 1992 of Israel’s Basic Law: Human Dignity and Liberty. In this article, I argue that the recognition of children as rights bearers is not new and that signs of it are evident in the Court’s case law dating back to the early years of Israel’s existence. The development of the case law, however, has not been linear. In this article, I analyze the spiral progression of this process and suggest explanations for the particular course that Israeli case law has taken with regard to the recognition of children’s rights.",1
79,2,"In this article, I argue that, contrary to these Supreme Court statements, the recognition of children as rights bearers is not new.6 Significant recognition of children as rights bearers appears in decisions of the Israeli Supreme Court from the 1950s and 1960s. Indeed, regarding several elements, the recognition of children’s rights in these early cases was even more far-reaching than in decisions issued following ratification of the Convention. The development of the case law in this regard, however, has not been linear. The recognition of children as right-bearers recorded a major decline in the 1970s and 1980s but has been significantly strengthened since the mid-1990s. In this analysis, I trace the spiral progression of this process and suggest possible explanations for the distinctive course that Israeli case law has taken on this matter.",1
79,3,"In order to examine the extent of children’s recognition as rights bearers and the changes that have occurred, we must define the key features of this recognition. A survey of the literature dealing with the recognition of children as rights bearers (e.g., Doek 2007; Eekelaar 1986; Freeman 2000; Woodhouse 1993) has led me to locate three key components: (1) separateness: recognizing the child as a separate person and as a rights bearer; (2) child-centeredness: placing the child’s rights and interests at the focus of legal proceedings; and (3) agency: recognizing children as participating in and influencing decisions affecting them.",1
79,4,"Licht-Petran (2010) points to four central characteristics of the best interests principle as applied in Israeli case law that distinguish it from the children’s rights principle. The first is non-recognition of the child as a separate legal entity bearing rights, implying that neither the state nor the parents bear specific obligations toward children. The second is the vagueness and the subjectivity of the best interests principle as opposed to the children’s rights principle, which requires addressing concrete rights. The third characteristic is the paternalism typical of the best interests principle, evident in the lack of proper consideration of the children’s wishes, as opposed to the children’s rights principle, which demands consideration of the children’s rights in any decisions concerning them. The fourth is the absence of regulation or discussion regarding the place and the weight of the child’s best interests as opposed to the interests of others, unlike the children’s rights principle, which requires proper consideration of the relationship between the rights and interests of the children and those of others. A detailed examination of concrete rights exceeds the scope of this article, but the other elements that Licht-Petran pointed out as typical of the distinction between children’s rights and their best interests largely overlap the definition of the components examined for the purposes of this analysis.",1
79,5,"In the first and main part of this article, I examine the attitude of Israeli case law toward these three components and the trends of its development regarding the recognition of children as rights bearers. In the second and concluding part of the article, I suggest preliminary directions for further research that might contribute to an explanation of the interesting picture that emerges in the first part.",1
79,6,"As early as the 1950s, Supreme Court rulings contained a number of clear statements emphasizing the child as a separate person and the need for a distinction between children’s interests and rights and those of their parents. These statements were particularly prominent in the opinions of Justices Yitzhak Kister and Moshe Silberg, who presented their approach as based, inter alia, on Jewish law. One of the most prominent rulings on this issue is the 1955 Steiner case, which considered a petition to return a girl to her father living in Austria. Justice Silberg ruled as follows: “Once the legislator rose to the level of the modern view—a modern view that Jewish sages have been endorsing for generations—whereby the child is not an ‘object’ kept for the pleasure or the interests of one of the parents but is himself a ‘subject’, himself a ‘litigant’ ... his interests cannot possibly be ignored, whatever the circumstances.”",1
79,7,"This recognition of the child as a separate person is reflected in a change that took place from the mid-1990s onward. Whereas the rhetoric had not previously recognized children as rights bearers, after this point in time the case law distinctively and unequivocally presented the child’s separate legal identity as anchored in the doctrine of children’s rights. Chief Justice Shamgar pointed this out in the John Doe case involving Jehovah’s Witnesses, noted above. On the concept of children’s rights, Justice Shamgar stated: “The concept entails the view that the child is an autonomous creature, whose rights and interests are independent from those of his parents.”",1
79,8,"Complementing the separateness principle is the principle of child-centeredness, which holds that every legal issue bearing on the child should begin from the perspective of the child’s rights, needs, and interests (Woodhouse 1993, 1994). This approach, however, does not imply that this perspective will necessarily be the decisive one in legal proceedings, or that the rights of others in these proceedings should not be acknowledged. Rather, the justification for the child-centered approach relies on a widespread concern that the rights and interests of children might be neglected due to their relative weakness. Awareness of the importance of focusing on children in decision-making processes that concern them was accompanied by a growing realization that the legal and cultural discourse had, until then, focused largely on adults, often emphasizing adult interests in the definition of questions and the analysis of rights.",1
79,9,"In the early years of the Supreme Court’s jurisprudence, a prominent statement making a broad claim about the need to place the child’s rights and best interests at the center of parent-child law was that of Justice Kister in the 1986 Tsabar case. Justice Kister drew a clear distinction between a legal regime based on “the child’s rights and best interests” and a legal regime based on “parental rights.” Relying on Jewish law, he stated: “This matter finds unique expression in Jewish law, where the long-standing view had been that the child’s place of residence should be considered according to the child’s best interests, his advancement, and his rights.”",1
79,10,"Since the mid-1990s, broad recognition of the need to place children’s rights at the center is evident in several decisions. Thus, in 1995, Justice Cheshin noted: “In understanding the minor’s interest, we put ourselves in his place, and from his small body we look at the world and endeavor to favor his interests.” Similar expressions appear in the decisions of lower courts as well.",1
79,11,"Two approaches are discernible in the early case law. The first and more dominant one states that parents have no rights of custody at all. This is made clear, for instance, in Judge Kister’s decision in the Steiner case: “The father’s custody rights according to original English law derive from the father’s rights, and this is the basis for the father’s demand to keep the child. Jewish law grants no such right to the father, who is expected to do what is best for his children.”",1
79,12,"Judge Kister reiterated this view in several rulings in the 1970s, when he officiated in the Supreme Court. Thus, for instance, in 1971, in John Doe v. Richard Roe, he stated: “Jewish law has no phrase for ‘the right to keep the child,’ and only states that the child will be ‘with his father’ or ‘with his mother’. This has been interpreted to mean that these are not parental rights but rights of the child to be with a parent according to his best interests.”",1
79,13,"The second approach, which also relies on Jewish law, notes that parents do have rights but that children’s rights take precedence. In 1981, Rabbi Kafih commented in the Nagar case: “Parents are not inanimate objects. They too have a body and a soul, and they too have feelings, and the mother has a natural right to satisfy her yearning to embrace her child.”",1
79,14,"This trend culminated in the 1980s in adoption decisions that, for the first time, recognized parental rights as constitutional rights. Thus, in 1984, Justice Barak stated in State of Israel v. Jane Doe, an adoption case: “It is a parent’s legal right that he, and no other, should meet the obligations toward his child ... this right of the parents is an important constitutional right.”21 This view was expressed in other decisions, for instance: “The law recognizes the constitutional right of natural parents to fulfill their obligation toward their child. The law immunizes the family from state intrusions.”22 This ruling recognizes parental rights as constitutional, but without granting similar status to the children’s rights to custody. Although these rulings did not accord greater weight to parental rights than did the previous ones relating to adoption (evident in the rejection of requests to return children to their biological parents), their importance to the current discussion lies in the rhetorical change that they convey.",1
79,15,"The various approaches toward custody rights are represented in the decisions issued by the District Court and the Supreme Court in an adoption case dealing with a petition to revoke the family court’s decision to terminate parental rights in the absence of the father. In 2004, in the District Court, Judge Rotlevi, for the minority, relied on the Convention and explicitly claimed that the starting point on the custody question should have been the rights, the needs, and the interests of the child: “The minor before us, literally from birth, has been denied the right to grow up with his parents.”",1
79,16,"The third approach is that of Justice Cheshin, who also presented parents’ and children’s rights as intertwined, but as unequal in status. In a situation of conflict, the child’s right overrides the parent’s right: “The parents’ interest in keeping their child and the child’s interest in being kept by his parents are mutually suited, mutually compatible, and indeed mutually complementary ... and the child’s rights are not only not inferior to the parent’s rights but actually superior to them.”",1
79,17,"The third component I will examine with regard to the recognition of children as rights bearers is their right to express their views and to have their wishes respected. Freeman (1983: 3) defined the importance of this right as follows: “We have distanced ourselves from children and in doing so we have to an extent dehumanized the young ... It [this right] demands that children’s capacities be acknowledged, that they be given a say in decision-making processes concerning them whenever this is feasible.”",1
80,1,"The following contribution builds on the Swiss experience in order to reflect on the idea of codifying private international law in the EU. The Swiss Federal Act on Private International Law with its 225 articles is possibly the most complete codification of private international law (PIL) worldwide. It covers jurisdiction, international civil procedure, applicable law, and the recognition and enforcement of foreign judgments. It represents therefore a comprehensive codification of PIL. This contribution argues that having a comprehensive PIL codification has numerous advantages when compared with having PIL rules distributed over a large number of separate acts or regulations. A comprehensive codification makes all PIL rules readily accessible in one place, helps to avoid friction between the rules on jurisdiction on the one hand and applicable law on the other, promotes a uniform view of the whole matter, favours clarity and coherence between the different sets of rules, reduces complexity, increases legal certainty, and considerably adds to the user-friendliness of the rules on PIL. Based on these findings, the author recommends the commencement of preparatory work for the enactment of a comprehensive PIL regulation in the EU.",1
80,2,"At the same time, cases presenting a foreign element and raising issues of PIL are becoming more and more frequent. The reality of our everyday lives does not take account of the fact that the system of legal rules that should coordinate the diversity of national laws is regarded by many, if not most, jurists as overly complicated. Lawyers working in an international context (ie almost any lawyer today) need to be able to tell their clients with certainty where they can bring a potential claim, which law(s) will apply, what outcome they may expect and according to which rules and under which conditions foreign judgments will be recognized and enforced, even if they do not belong to the narrow circle of PIL specialists. Judges, who only occasionally deal with cross-border scenarios, need a system of private international law in which they can easily find their way and conflict of laws rules that they can handle and apply easily. In the international context, legal certainty and predictability of the outcome is just as necessary as in purely domestic situations.",1
80,3,"As outlined above, much of the current complexity is due to the fact that there are an ever increasing number of regulations. The question thus arises of whether PIL in the EU has reached a point where a new legislative act is needed. Should the EU institutions continue enacting more separate regulations or has the time come to consolidate, in one coherent act of legislation, all of the rules on PIL that are currently distributed over a large and still rapidly increasing number of EU PIL regulations?",1
80,4,"Today, it contains 225 articles, including a General Part with 38 provisions. It covers jurisdiction, international civil procedure, applicable law, and the recognition and enforcement of foreign judgements. The Swiss Federal Act on Private International Law (hereafter: Swiss PIL Act) is therefore an all-inclusive, comprehensive codification of private international law.",1
80,5,"In England, PIL is completely absent from many law schools; in others it is only taught as an optional subject. Most European practitioners therefore lack a specialized training in this matter and many do not even have a basic knowledge of PIL. Most judges only occasionally deal with questions of PIL. When this happens, they must then familiarize themselves in an ad hoc fashion with a complex area of law and find their bearings in a jungle of rules that are distributed over many sources.",1
80,6,"In the light of all this, it seems extremely important that the EU legislator makes access to the area and the rules on PIL in its legislation as easy and userfriendly as possible. This is important both from the perspective of the legal practice and the judiciary and, of course, from the perspective of the law-seeking citizen.",1
80,7,"Once again the PIL Act is extremely user-friendly: first, Article 1, section 2of the PIL Act reminds the judge that he has to carefully double-check if there is an international convention that may prevail over the application of the Act; in addition, the sections of the PIL Act that deal with specific subject matters contain specific references to prevailing international treaties. In fact, the PIL Act contains a number of explicit references to specific Hague Conventions that take precedence over the PIL Act. This allows the practitioner to locate the relevant rules accurately and avoid overlooking them and making mistakes.",1
80,8,The European Union legislator would arguably be well-advised to include a similar Article 1 in a comprehensive EU private international law regulation. The legislator could hereby provide legal practitioners in Europe with a first general guide and facilitate access to the subject matter and to the solution of the case in question.,1
80,9,"The provision in Article 1(2) of the PIL Act could also serve as a model for a European Union codification in that it would provide judges in Europe with guidance, in particular regarding Hague Conventions that might be in force in their respective Member States and might take precedence over the European PIL regulation.",1
80,10,"It might also be worth considering – both in the Swiss PIL Act (in its next version) and in a comprehensive EU PIL Regulation – adding a further (in fact, a very first) section in Article 1 that gives priority to uniform substantive law where applicable. The reason is that, where uniform substantive law applies, there is no need for PIL rules. This article would apply in particular to international sales scenarios and give priority to the Convention on Contracts for the International Sale of Goods (CISG), provided that the case falls within the CISG’s scope of application, as defined for the relevant EU Member State.",1
80,11,"All the above-mentioned recent national PIL Acts contain a General Part that contains rules that apply to all of the subject matters governed by the Special Part – and so of course does the Swiss PIL Act. Having a General Part avoids the repetition of principles that apply throughout the whole act of legislation and help achieve coherence throughout. As the comparative overview has shown, it is today part of the international acquis when it comes to codifying PIL in a separate statute. Not having a General Part would thus be a step backwards with respect to the national PIL law Acts that have come into force over the past decades.",1
80,12,"The experiences of the Swiss comprehensive PIL Act have been very positive. For one thing, its structure greatly helps to identify the interactions between rules on jurisdiction and on applicable law as it treats both under the same set of rules. The Swiss PIL Act avoids friction, prevents conflicting interpretations, and promotes a uniform view of the whole matter. For example, if a term were to be interpreted differently with respect to jurisdiction on the one hand and applicable law on the other, then such a departure would need to be justified; likewise, the same could be said for terms defined differently for the various topics in the Special Part.",1
80,13,"Last but not least, the qualities of the PIL Act facilitate the teaching of the subject. During the Freiburg conference, the current level of complexity of the EU PIL system gave repeated cause for concern with respect to the teachability of the subject in the EU. In Geneva, where the system of the Swiss PIL Act is taught to approximately 250 students per year, teachability of the PIL system is not an issue. At the end of the three hour per week, one semester course on PIL, almost every student is in a position to solve even complex issues in all core areas of PIL. To be able to efficiently teach the subject, or – from the perspective of students and future legal practitioners – to efficiently learn it, in turn helps future lawyers and judges to reliably handle the matter in their later practical life.",1
80,14,"Swiss students occasionally compare the precision of the PIL Act, the transparency of its structure and rules, the smooth interaction of its Special and its General Part and the coexistence and interaction of international conventions and the national PIL Act to mathematics. Foreign students are reminded of the slick functioning of Swiss watches. They probably do not think of confusion and chaos, but rather the opposite: a well-coordinated, coherent, consistent system of rules smoothly interacting with each other and which often lead to clear and predictable results.",1
80,15,"All the above mentioned comprehensive national PIL codifications contain a General Part. A second lesson from the comparative analysis could therefore be that a modern European Union PIL Act should – obviously, as one is tempted to say from a comparative law perspective – contain a General Part.",1
80,16,"The Swiss example shows that the General Part could – or should, as one is tempted to say against the backdrop of the Swiss experience – first include general rules on jurisdiction, followed by rules on applicable law, and finally by general rules for the recognition and enforcement of foreign judgments. This also promotes uniform interpretation of terms, which in turn helps avoid friction and inconsistencies.",1
81,1,"Comparing the legal systems is a specific method in which due to its important function is considered as a separate branch in law. None of the branches in law can place its knowledge merely on ideas and findings within the national borders. Several basic objections have been given regarding the definition and purpose of comparative study in civil procedure. In addition there are specific problems regarding studying practically the similar systems in a legal system like differences in purpose, definition and concept. In different legal systems like civil law and common law systems in which there is a divergence, even the judicial system`s organs and judges` appointment and judicial formalism are different, which add to the problems of the comparative study. Reviewing these differences could lead to a better understanding of these legal systems and recognizing the common principles in making use of each other`s findings considering these differences and indicate the obstacles of comparative study in this regard.",1
81,2,"Comparative law not only leads to a better recognition of the foreign laws, but also it is consistent with commerce universalization and law unification. Law is not merely the knowledge to interpret the national laws; it rather can provide a wide range of problem solving models whichcould work in solving the national affairs and these models exist within the national borders of the developed countries.",1
81,3,"Although some researchers claim that procedural law is not based upon the comparative studies but there is no difference between civil procedure and other branches of law. They claim that procedural principles represent to predicate on specific rules, namely the Loipolitiqueswhich is not capable of transferring to other countries and societies.",1
81,4,"In fact, recent historical narrations and experimental evidences both reveal that the national legal systems are systematically in accordance with legal traditions or roots in which their countries belong. Specifically procedural and substantive codes in civil law countries differ systematically with common law rules. A wide range of scientific findings as supporting the legal roots theories reveals that legal roots considerably form the society`s characteristic structure including the relationship between state and individuals, therefore it affects the codes, procedures and other rules and a wide range of economic outcomes follows.",1
81,5,"According to this theory, using the civil procedural law models is a misuse of comparative law and has to end in disappointment. If so, civil procedure will merely be a branch of law which is not capable of using the comparative studies. As 12 universal procedure congresses has been held since 1950 which covers almost all essential issues and difficulties in procedure, so we could claim that the opposite viewpoint is correct.",1
81,6,"The main purpose of the civil procedure is to specify the rights and obligations among individuals in accordance with law. Determining the parties` rights and obligations to settle the disputes. In case there is no procedure, the individual might make use of their power in order to realize their rights and settle their disputes and consequently a more powerful result than justice will dominate.",1
81,7,"The basic commitments of civil procedure which are best realized are as follows: exactly determining the right through fair trial process, proceedings without delay, free availability to all, and being precise, fair, fast and efficient. In fact it seems that the civil procedure functions in order to support the individuals` private rights in the world and the rules are codified in order to adjudicate the individuals` private rights.",1
81,8,"While studying the civil procedure rules it is certain that like other laws, civil procedure is capable of being considered as a set of expedients in order to affect, punish, compensate and powerfully clarify the human`s acts. Trial is often defined as a game. The parties to the litigation are like players and judges are like referees. This game is ruthlessly competitive and it is often presumed that it has winner and loser. Realizing its rules like some games is abstractly difficult. These regulations are live and might be meaningful through experience and being played. Consequently, our understanding fromcivillitigation will be much easier than civil procedure.",1
81,9,"According to the above findings, it is concluded that the definition of civil procedure in comparative law is difficult. However, if one is going to define the civil procedure, it seems that the precise definition by J.A Jolowicz is acceptable. He argues that: 1) the civil procedure includes the procedure techniques in courts. 2) The litigation onset is a voluntary act. 3) the plaintiff`s acts are in order to gain benefits. 4) Civil procedure won’t happen without having a defendant.",1
81,10,"The international commerce rules are currently determined by countries with different levels of economic and legal development which leads to a completely different legal framework for international transaction. The variety in concepts, techniques and legal methods among legal systems reflected on the applicable rules in international transactions. This difference in legal systems amounts to obstacles in international commerce and often results in problems in the process of ratifying and implementing the international transactions. In addition, since the judges are instructed within the national systems, therefore they are often totally unfamiliar with the concepts and expressions between the national legal system and the foreign ones",1
81,11,"In addition the comparative studies provides an opportunity to think and modify the national laws for individual systems, through learning and realizing other legal systems, either by means of imports or exports, in order to provide a different method to solve the common issues.",1
81,12,"When the Japanese government decided to adopt the German civil procedural code 1877 in 1889, it was hard to accept that a thorough comparative analysis with the chief laws has been performed, rather they merely intended to adopt a modern model and at that time German was politically and economically successful. After World War II American lawyers insisted on adopting some of the civil procedural models in common law. It doesn’t seem like this accession has been done after a thorough comparative analysis.",1
81,13,"Some jurists consider the civil procedure`s dependency on the national power structure and the efficiency of society`s history and culture as an obstacle to use the comparative studies, on the other hand the proponents render the international trade and globalization alongside with the experience of the European court of justice and human knowledge increase and finally achieving the universal common principles in addition to the model civil procedural law using the collective wisdom as the advantages and needs of comparative study on civil procedure.",1
81,14,"Both systems are different in their capacity to adjust with the modern situation. Common law is more dynamic since its rules gradually and case by case respond to the society`s changing needs and it is less probable that we witness a large gap between the economic needs and law. On the other hand, the French civil law which is born out of a revolution had a fantasy that could achieve the idealistic aim i.e. creating an unchangeable complete law. However, the French law is adjusted with the commercial realities in practice: Germany has based its framework on Savigny`s vision and seeks to establish a dynamic codex; Spain styled the periodic reforms towards the civil law.",1
81,15,"In the first stance, principally the civil courts are competent due to this fact that the courts` competence is general and applies to a wide range of cases like personal status, financial and real state conflicts and verdicts` execution, their local jurisdiction applies to departments in France. A department could have various main civil courts considering the population, the volume of judicial activities and communication network. There are 163 main civil courts in France (for 100 departments). Besides these courts, there are courts with specific competence which deal with the specific cases allocated by the law. Another one is the circuit court that is a substitution to the magistrates’ courts and it is competent to deal with the inconsiderable civil claims (like the conflicts between neighbors, the current cases on landleas and cases regarding the debts less than 10,000 pounds).",1
81,16,The commercial courts are the most ancient courts in the French judicial system that their history dates back to the end of Middle Ages. Today there are 135 courts in France. The commercial court is a syndical court which consists of a set of merchants appointed by peers.,1
81,17,"The competence of commercial court is beyond the commercial cases, and it is competent to the conflicts between merchants and the conflicts on the commercial activities (like bill of exchange) even if they are not used by the businessmen, and also they deal with the conflicts concerning the commercial companies, and bankruptcy process in commercial and industrial enterprises.",1
81,18,"The reforms in the constitutional law in 2005 in the recent 300 years are the sole fundamental in England. This code allocated the judicial function of the Lord Chancellor to the lord chief justice, who serves as the president of English and wales courts. The principle of the independence of the judiciary has been emphasized repeatedly and the United Kingdom Supreme Court has been established. More importantly this law established an independent jury for judges` appointment and besides assigned an ombudsman to deal with the complaints on the process of judges` appointment. Through the wide counsels on the process of appointment, there is a consensus which will eliminate some of the historical standards of judge`s appointment and use the modern employment methods on employing in the judicial positions. In 3 April 2006 this responsibility to employ in most judicial positions transferred to judicial appointments commission which is independent of political support, and functions as a base to appoint the judges merely according to eligibility. In the United States of Americasome of the state judges are chosen by the voters. They can spend their financial aids in the election process like politicians. ",1
82,1,"Components made of multi-materials become more and more important in high-tech applications. Such a component consists of several different homogeneous and/or heterogeneous materials in its different portions to satisfy the critical functional requirements from its applications. Under some working conditions, chemical reactions may be generated and relevant resultants will be produced on the interface between different materials in two adjacent material regions. Since the strength of resultants is usually much smaller than those in the two adjacent material regions, the peeling off is much easier to take place on the interface. Besides, the mismatching of material properties in two adjacent material regions can induce the stress concentration or even stress singularity, which can also cause the failure of components. In order to select suitable or optimal materials for adjacent material regions during the design of such a component, their material compatibility or affinity has to be considered, for which an effective evaluation method of the material affinity is needed. In this paper, the definitions, evaluation criteria, and calculation formula deductions of material affinities including physical and chemical affinities are developed and described in detail. ",1
82,2,"Due to the development and applications of high technologies, there is a need for designing the components made of several different homogeneous and/or heterogeneous materials to satisfy the critical functional requirements from their applications. For such components, materials with different microstructures and/or constituent compositions for required material properties should be connected in the manner of bonding or sintering. Different interfaces are thereby produced between adjacent material regions. If materials in adjacent regions produce chemical reactions, the peeling off is much easier to take place on the interface since the strength of their resultants is usually much smaller than those in the adjacent material regions. For instance, a component is composed of an aluminum core with the high strength and a carbon shield with the low friction factor, thus enduring large load and having high friction-resistance capability. But their resultant named aluminum carbide is a kind of nonmetal material with low strength and cannot endure large load [1].",1
82,3,"Material affinity is the reliable and stable degree of the interface between two different materials connected in the manner of bonding or sintering and includes physical affinity and chemical affinity. Physical affinity is the physically stable degree of the interface under working conditions and the chemical affinity is the chemically stable degree of the interface under working conditions. When determining the material affinity for two different materials, their chemical affinity should be evaluated at first. If their chemical affinity is bad, there is an ardent chemical reaction between them and they cannot be connected together so that there is no need to consider their physical affinity further. If their chemical affinity is good, their physical affinity should then be further judged. If their physical affinity is larger than an allowable value, they can be selected as the suitable materials for two adjacent regions.",1
82,4,"In this paper, a new concept ‘material affinity’ involving chemical affinity and physical affinity is introduced to evaluate the stable degree of bonding strength of the interface between two material regions bonded together. The evaluation criteria of chemical affinity and physical affinity and the examples for mechanical or thermal analyses are also described in detail. According to the evaluation criteria, the material affinities of several material pairs are determined, based on which some guidelines for selecting suitable material pairs are also concluded. With the evaluation criteria of material affinity, it is possible to select suitable or even optimal materials for designing the components made of multi-materials. Besides, although only the mechanical and thermal examples are introduced in this paper, designers can use the evaluation criteria to evaluate the material affinity of two materials for their applications in other fields of high-tech efficiently and conveniently.",1
82,5,"For mechanical analyses, the pair of aluminum and nickel has the best physical affinity among the material pairs studied since they have the similar values of Poisson’s ratios. It further proves that the effect of the difference of Poisson’s ratios on the physical affinity is larger than that of Young’s moduli.",1
82,6,"For mechanical analyses, among the material pairs studied, the maximum peeling stress for the pair of aluminum and copper is minimum due to the similar values of their Young’s moduli, and the maximum shear stress for the pair of aluminum and molybdenum is minimum due to the similar values of their Poisson’s ratios.",1
82,7,"In conclusion, the pair of aluminum and copper has the best physical affinity among the material pairs studied, according to the above-mentioned reasons. Therefore, when selecting materials for adjacent material regions, the pair of materials with similar Poisson’s ratios for the mechanical analysis, or similar thermal expansion coefficients and Poisson’s ratios for the thermal analysis should be preferred.",1
83,1,"The intelligent material is a new marginal subject is developing in the world today, belongs to the frontier research field, it is the intersection of multi subjects. Characteristics and inherent in smart materials, therefore, it has important application value. This paper discusses the concept of intelligent materials, two kinds of new intelligent materials. The basic properties, smart material actuator and its application in intelligent control, compared with the traditional materials compared, smart materials exhibit superior quality.",1
83,2,"Intelligent material is a kind of can “feel” the change of the surrounding environment, and can adopt corresponding countermeasures for the change of material. Smart materials can be divided into two categories according to their functional characteristics: One is the stimulus intensity on the external or internal, such as stress, strain and the physical, chemical, optical, thermal, electrical, magnetic, radiation effects with sensing function material, commonly known as the sensing material, also known as smart sensing materials. Another kind is to respond or driven material on the external environment or internal state changes, also known as intelligent materials, such as: shape memory alloy, piezoelectric materials, electrostrictive materials, magnetostrictive materials, electrorheological fluids, magnetorheological fluids and functional gel etc. These materials can be according to the change of temperature, electric field or magnetic field and automatically change its shape, size, stiffness, vibration frequency, damping, internal friction and other mechanical properties of some materials, and thus may be based on different needs to choose one of the production of various execution or driving element.",1
83,3,"The smart structure is a kind of non biological structure to determine the purpose and will, this field of research began in the last century 80’s, was the radar antenna integrated into a military plane surface, called intelligent cortex, later will expand the concept of intelligent cortex to the entire structure, called intelligent structure. Implementation of smart structure technology including materials design, higher executive and sensing technology, adaptive computer algorithm and energy utilization optimization. Smart structure applications range from the spacecraft and aircraft to large civil structure.",1
83,4,"This paper discusses the concept of intelligent materials, two kinds of new intelligent materials. The basic properties, smart material actuator and its application in intelligent control, compared with the traditional materials compared, smart materials exhibit superior quality.",1
83,5,"System science in such a basic proposition of the premise: System is one of the existence of all things, so it can be used to inspect the system point of view, using system method to describe. Generally speaking, the real world does not exist without any internal relativity thing group, where groups of things must be linked in some way, otherwise not called group, there is no mathematical sense of isolation. A kind of viewpoint beach as non system group, but the famous “self organized criticality” theory to the beach for the important model, found many profound system rules and mechanism, indicates that the beach is a kind of system with abundant dynamics characteristic of nonlinear.",1
1,1," Performance measures are created and applied globally primarily to showcase the effectiveness of a biological, physical, chemical, environmental, economic, or social framework (Jakobsen, 2008). Specifically, an environmental gauge as defined by the United Nations (1997) is ""a data summarization device for complicated environmental topics to exhibit the general status and trends of those topics.""",0
1,2,"The implementation of environmental indicators is crucial to guarantee that routine port operations align with sustainable development. To measure the environmental efficacy of port authorities and to monitor advancements towards sustained enhancement, pertinent Environmental Performance Indicators (EPIs) may be employed, as stated by Donnelly et al. (2007). This strategy allows port authorities to showcase conformity and perpetual growth through scientific verification and measurable benchmarks.",0
1,3,"

Several port organizations worldwide encourage the use of EPIs within their members. Among these, the European Sea Ports Organization (ESPO) emphasized the necessity of identifying EPIs and carrying out environmental monitoring in their Environmental Code of Practice 2003 and the current ESPO Green Guide. Additionally, other organizations like the International Association of Ports and Harbours (IAPH) and the Baltic Ports Organization (BPO) promote the use of indicators.",0
1,4," The port's performance indicators are linked to its environmental aspects. As per the 2015 ISO 14001 guidelines, environmental aspects refer to the elements of the port's activities, products, and services that can have an impact on the environment, such as water discharges, waste generation, noise emissions, and emissions to air. Indicators are essential to monitor the performance of these aspects, especially the significant ones. For instance, the concentration of sulphur oxides (SOx) and nitrogen oxides (NOx) could be indicators associated with emissions to air. Thus, the identification of environmental aspects and performance indicators is interdependent, and EMS requires a set of indicators to measure and improve the performance of the identified aspects over time.",0
1,5,"A tool called TEAP was developed as part of the PERSEUS research project to help ports identify their Significant Environmental Aspects (SEAs). TEAP is available online at www.eports.cat/teap and is linked to TEIP, the Tool for the identification and implementation of Environmental Indicators in Ports presented in this paper. The SEAs obtained in TEAP can be used directly in TEIP to compile indicators, but if a port has already identified its SEAs, it can skip TEAP and go straight to TEIP. (Puig et al, 2015)",0
1,6, The EU-funded project PORTOPIA utilized the TEIP tool from 2013 to 2017 with the objective of creating a Service Cloud for European ports to monitor their performance using designated indicators. The aim is to help port managers identify any changes in performance over the course of a year and compare their results with industry benchmarks.,0
1,7," There is a growing trend of creating and utilizing indicators as a means of managing environmental concerns (Belfiore, 2003). The adoption of indicators is highly encouraged for various reasons.",0
1,8," Indicators have proven to be beneficial in evaluating environmental data and addressing environmental issues, as demonstrated in the aforementioned bullet points. Nevertheless, they may come with certain issues and restrictions, such as the inability of certain indicators to convey the overall state of the environment through a limited number of parameters or the limited availability of data. Moreover, sensitivity is a crucial factor to consider, as some indicators may fluctuate in response to short-term environmental alterations.",0
1,9,"Environmental Management Systems (EMS) rely on indicators as they provide quantitative information necessary for verifying if continual improvement objectives are met. Despite limitations, three widely recognized and implemented standards for implementing EMS are ISO 14001, EMAS Regulation, and PERS. The particular information and requirements concerning indicators for these standards are investigated and given below.",0
1,10," The ISO 14001 standard requires organizations to establish and maintain procedures for monitoring and measuring key environmental impacts and evaluating compliance with legal requirements. Indicators are used for this purpose, but ISO 14001 does not provide specific examples or methodologies. However, the ISO 14031 standard within the ISO 14000 family does offer examples of indicators that can be implemented.",0
1,11,"The PERS protocol, which applies exclusively to ports, places great emphasis on performance indicators and includes a specific clause addressing this issue. As per PERS (ESPO, 2011), ports should identify five to ten environmentally relevant EPIs that align with the port's policies to enable effective monitoring of its environmental performance. The standard also provides approximately 20 examples of environmental indicators that are likely to be monitored in port areas.",0
1,12," The use of environmental indicators is required by all three standards, with some providing examples that could be used by port authorities. However, none of these standards specify how each port should select its indicators. To address this, a research study was conducted in the EU port sector to identify existing methods for indicator selection, which is presented in the following section.",0
1,13,"This section delves into the methods currently utilized for identifying indicators in ports. The identified methods are divided into two groups: one consists of methods developed for the entire port sector, while the other comprises methods employed by individual ports.",0
1,14," A methodology proposed to obtain a system of indicators in the port sector was discovered as part of the INDAPORT research project (2002-2004), which aimed to establish systems of indicators for sustainable environmental port management. The methodology involved identifying 21 applicable port activities at the Port of Valencia, which were analyzed environmentally through a steps-diagram process. Experts were then consulted to determine the most significant impacts, ultimately resulting in 17 port system indicators such as 'Total annual greenhouse gas (GHG) emissions' and 'Total annual water consumption'. This methodology was developed by Peris-Mora et al. in 2005.",0
1,15,"A study was conducted to examine the current methodologies employed in ports for identifying indicators. The study assessed 51 EU ports, 39 ports outside Europe, 13 port operators, and 17 marinas. Among the EU ports sampled, the study found that a large number of them publish a list of indicators they deploy (37 out of 51) but only a few (10 out of 51) explained where these indicators come from. In all of these ten instances, the sources of the indicators were standardised lists of indicators, such as those provided by the Global Reporting Initiative (GRI, 2013) or the EMAS standard (EC, 2009).",0
1,16," In non-EU port authorities, the outcomes were less optimistic. Out of 26 ports that shared the list of indicators, only one port disclosed the source (GRI guidelines) and the resulting indicators. As far as port operators were concerned, only 38.5% of them provided the list of indicators, and 30.8% gave the source, which was the recommended indicator list by GRI and EMAS. Concerning marinas, a higher percentage (47%) of ports published both the indicators and the source, which was the EMAS standard (EC, 2009) for all marinas.",0
1,17, It was not found that either EU or non-EU ports have a methodology for identifying indicators.,0
1,18,"In preceding sections of this article, we have discussed the advantages and significance of recognizing environmental indicators. Various justifications have been given that demonstrate how they are fundamental elements of an overall port environmental management strategy. As previously mentioned, specifications such as ISO 14001, EMAS, and PERS require the use of indicators to evaluate environmental performance. However, since each organization has its unique characteristics and attributes, no common methodology is stated in the standards for identifying and assessing indicators. Although some EPI examples are provided in the standards, the ultimate decision rests with each port, according to their key concerns.",0
1,19," Only one method of creating a system of indicators was discovered during research of existing methodologies in the sector. Moreover, this procedure is no longer used by ports. Findings from individual port research revealed that EPIs are utilized by numerous ports, but only a handful provided an explanation for their use of such indicators.",0
1,20," According to the European Port Industry Sustainability Report 2016, 66% of the surveyed ports have identified environmental indicators to monitor environmental performance. However, when asked about the specific indicators used, nearly 100 different responses were provided, indicating a lack of common approach. This suggests that ports may not be using the most appropriate indicators if they do not have a procedure in place to identify them.",0
1,21," A common method is needed to help ports identify indicators in a more reliable manner. Although each port varies, having a standard methodology that can provide specific results for each port would be beneficial for both the sector and individual ports. Therefore, an interactive tool has been created to provide a set of performance indicators specifically selected for the port user based on the Significant Environmental Aspects (SEAs) of the port, as well as other port characteristics. This method has been developed specifically for the port sector and is valid and publicly available for any port authority, including sea and inland ports. The following section explains the development of the tool.",0
1,22," An in-depth investigation was conducted to compile a comprehensive inventory of Environmental Performance Indicators (EPIs) utilized and reported in the industrial sector, with a particular focus on the port sector. A vast array of references was researched, resulting in the identification of 1279 indicators. However, after thorough scrutiny, a final inventory of 648 unique indicators was obtained. This represents the most extensive collection of port sector environmental indicators known to exist. Eleven sources of information, including research projects and the ESPO Environmental Questionnaire, were consulted, and the results are presented in table 1, ranked by the highest to lowest number of EPIs provided.",0
1,23," The 648 environmental indicators were divided into nine categories based on their characteristics. While seven of the categories matched the environmental aspects identified through research on ports, two sets of indicators did not align with any of the previously defined categories. Hence, two more groups were formed, which are environmental management and port development indicators. Eventually, all the indicators were categorized into the nine groups mentioned in table 2.",0
1,24," 
Due to the acquisition of nearly 650 distinct EPIs, it was essential to condense the list for more efficient application in port regions. A systematic evaluation of each indicator was conducted using specific criteria to filter the list, ultimately selecting indicators that fulfilled the criteria while discarding those that performed poorly.",0
1,25," 
A total of 84 criteria for assessing performance indicators were obtained from 11 sources. Upon analysis, it was found that many of these criteria had similar meanings and were subsequently grouped together. Through this process, the total number of criteria was reduced to 11. These criteria were evaluated in two phases, with the first filter being more general and applicable to all indicators, while the second filter was more specific and required prior research on the indicators' characteristics. Table 3 outlines the criteria used in both filter phases.",0
1,26," The filtering procedure included three phases, which were the initial filter, the reorganization of indicators, and the subsequent filter of indicators.",0
1,27," During the first filtering stage, the comprehensive list of indicators was analyzed. A team of three researchers evaluated the indicators against five criteria, aiming to apply the filter objectively. To ensure consistency, a supervisor coordinated the researchers and held several internal meetings during the process to ensure that the criteria and scoring were consistent.",0
1,28," 

Table 4 exemplifies how indicators were evaluated. A green dot indicated compliance with a criterion, while a red dot indicated non-compliance. An evaluator accepted an indicator if the ratio of accomplished criteria (green dots) to total criteria evaluated was greater than 0.5. Since all five criteria were applied in the initial filter, indicators that met three or more criteria were accepted. A green tick () denoted indicator acceptance, while a red cross () indicated failure to pass the first filter. Indicators accepted by at least two of the three evaluators were deemed acceptable, while those with only one green tick or less were rejected.",0
2,1," Reports have highlighted the lack of emphasis on nuclear chemistry in undergraduate chemistry curricula. It has been suggested that courses on this subject should be introduced globally. The Department of Chemistry at Ege University in Turkey has responded by incorporating a program on nuclear chemistry into their undergraduate curriculum. This program aims to educate students on nuclear chemistry and its applications in various sectors, such as science, industry, and medicine. Further details on the program will be discussed in this contribution.",0
2,2," Reports addressing common educational problems in nuclear chemistry have been disseminated worldwide in both hard copy and electronic form by groups of experts. Two significant reports were published in recent years, one by the International Atomic Energy Agency in 2002 titled “Assessment of the teaching and applications in radiochemistry” and the other by the Presidential office of the International Nuclear Chemistry Society in 2005 titled “Round table discussion panel report” following the 1st International Nuclear Chemistry Congress. These reports and others highlight the systematic issues surrounding the teaching of nuclear chemistry in undergraduate programs worldwide, including those in both developing and developed countries. The round table discussion panel report from the INCS outlined the most essential statements.",0
2,3," The chemistry curriculum for academics must encompass fundamental nuclear chemistry concepts and the principles behind its scientific and industrial applications, particularly those pertaining to medical practice.",0
2,4," ""Undergraduate chemistry curricula in both industrialized and developing countries tend to neglect basic courses and laboratory studies on nuclear chemistry, leading to a lack of interest among graduate students in research areas that require knowledge of nuclear chemistry and its applications. This has caused a significant decline in the number of qualified professionals in the nuclear chemistry field in recent decades.""",0
2,5," It will become increasingly difficult to locate properly trained instructors, including professors, for the necessary chemistry courses in universities across the globe if the current upsetting trend in chemistry curricula persists. This is why revising the current curricula to incorporate fundamental nuclear chemistry courses and lab research in undergraduate chemistry programs should be done as soon as possible in order to reverse the decline.",0
2,6," Based on the significant statements mentioned earlier, a nuclear chemistry education program was suggested and added into the chemistry curriculum of the undergraduate program at the Department of Chemistry in Ege University, Izmir, Turkey. This occurred during a routine update of the chemistry program, resulting in an impressive teaching program in nuclear chemistry and its various applications in scientific, industrial, and medical fields. The fundamental courses that were incorporated into the chemistry curriculum can be found below.",0
2,7,"

This elective course is scheduled for two hours per week during the second semester of the third year. It is designed for students who have a comprehensive understanding of Nuclear Chemistry along with practical laboratory skills and are wishing to acquire further insights on specific Nuclear Chemistry topics. It is worth noting that a considerable number of students have enrolled in this course.",0
2,8," 

It is advisable to incorporate a comparable program that covers nuclear chemistry into all the chemistry curricula offered in various universities globally. This step would undoubtedly incentivize students to explore the intricacies of nuclear chemistry, thus leading to a surge of interest in all fields of nuclear sciences and technology across the next generation.",0
3,1," ""The International Year of Chemistry, celebrated in 2011, coincided with the United Nations' 'Decade of Education for Sustainable Development'. Sustainability is a complex and interconnected set of challenges, including water quality, climate change, renewable energy, national security, food production and safety, disease control, new materials, and more efficient chemical manufacturing. Many of the grand challenges in chemistry are directly linked to sustainability.""",0
3,2," Incorporating sustainability into chemistry education has another dimension. The ACS Guidelines and Evaluation Procedures emphasize the importance of developing students' ethical skills and awareness of chemistry's role in contemporary societal and global issues. This is also reflected in The Chemical Professional's Code of Conduct, which highlights the responsibility of chemical professionals towards the public and the environment.",0
3,3," Chemical experts bear the obligation to prioritize public welfare and safety, in addition to promoting the progress of scientific knowledge.",0
3,4, It is the duty of chemical experts to comprehend and foresee the ecological aftermaths of their actions. They are accountable for reducing contamination and safeguarding the environment.,0
3,5," William M. Sullivan developed a professional education model consisting of three apprenticeships, which are easily related to the aforementioned statements.",0
3,6, Sustainability has the potential to engage students in multiple apprenticeships and connect undergraduate chemistry education to The Chemical Professional's Code of Conduct more effectively than any other context I can think of.,0
3,7," The apprenticeship entails instructing the skills, traits, ethical behavior, and societal obligations that define a professional. Furthermore, the novice is educated on the purpose of a comprehensive practice that covers all aspects of the profession. This practice is based on the fundamental aim of the job.",0
3,8," Incorporating sustainability into chemistry courses has been a desire of many educators, but lack of easily accessible resources has been an obstacle. Few chemistry teachers have time to search through primary literature for relevant examples. However, there are now more resources available, such as environmentally focused articles in this Journal, Science Education for New Civic Engagements and Responsibilities project information online, and a sustainability gateway on the ACS website. In addition, ACS sponsors an award for those who successfully incorporate sustainability into their curriculum, and a forthcoming volume in the ACS Symposium series will address sustainability in chemistry education. The committee on Environmental Improvement selects the award recipients, who give a talk on their work at an ACS national meeting and have links to their work incorporated into the education section of the ACS sustainability gateway.",0
3,9," It is evident that sustainability plays a crucial role in the realm of chemistry and chemistry education. The correlations between the two are both meaningful and substantial, and there exist more resources currently than ever before. The real test lies in discovering methods to incorporate the connection and context of sustainability into our courses as chemistry educators.",0
4,1,"The report title ""Chemistry versus Ecology"" was not chosen randomly. While many people, including scientists, believe that Chemistry and Ecology are diametrically opposed, this is not necessarily accurate. To answer this question thoroughly, it is crucial to provide comprehensive definitions of both terms.",0
4,2," Chemistry is the study of chemical reactions and the composition, structure, and properties of substances. Although it is an important science, with new technologies and methods, it has a negative impact on the environment through pollution. This creates a conflict between chemistry and ecology, as any chemical substance can become an environmental concern when its maximum concentration is reached. The question of how to address this problem remains.",0
4,3," Ecology, the science that studies the interrelationships between living organisms and their natural environment, is the key field dealing with environmental problems. It is widely known that ecology has been warning us about various ecological issues for a long time. Despite the fact that the origins of the term ""ecology"" date back to ancient times, it has developed into a distinct discipline since the 20th century. Justus von Liebig, a German chemist, provided the first explanation of the relationship between living organisms and their environment, with the example of ""plant-soil"" relations, in 1843. Aristotle or his student, Theophrastus, is credited with being the first ""ecologist"" due to Theophrastus's study of the interrelations between animals and their environment in the 4th century BC.",0
4,4," Nowadays, due to the overlap of practically all scientific fields, numerous interdisciplinary areas of ecology have emerged. The current challenging ecological situation has led to the emergence of geographical ecology, physics of the environment, mathematical ecology, genetic ecology, spiritual ecology, and others. Ecology explores the crucial phenomenon of the interaction between living organisms and the environment, which relates to the promotion of healthy lifestyles, friendly relationships, purification processes, and anti-pollution actions. As these issues can have diverse implications, a comprehensive approach is necessary.",0
4,5, The sciences that emerged at the intersection of chemical and ecological studies should be the main focus when considering their apparent opposition.,0
4,6," 
In recent years, there has been significant development in ecological chemistry both in terms of scientific research and education. Esteemed universities and colleges around the world have started establishing departments to train and educate young professionals in ecological chemistry. Chemical knowledge has become a primary scientific focus for many institutions in numerous countries including the USA, Canada, Germany, Sweden, Norway, Poland, Russia, Kazakhstan, Ukraine, Belarus, China, and South Africa, among others, to tackle environmental challenges faced by nations.",0
4,7," Around three decades ago, a significant surge in scientific research in ecological chemistry started. In the 1980s, a new field called ecological chemistry emerged at the intersection of chemistry and ecology. Its main aim was to establish how the environment interacts with living organisms at the chemical level. Ecological chemistry has gained momentum worldwide, leading to the organization of the first International Seminar on ecological chemistry in Chisinau in 1985. In 1992, the Department of Industrial and Ecological Chemistry was established at Moldova State University's Faculty of Chemistry and Chemical Technology, which was the first of its kind in Moldova to specialize in ecological chemistry and environmental protection. As a result, the department began preparing Ph.D. students in the Environmental Protection and Rational Use of Natural Resources area.",0
4,8,"

The editing of the initial textbook on ecological chemistry occurred in 1994, and it was later translated into three languages. In 1991, the Research Centre of Applied and Ecological Chemistry (RCAEC) was founded, which included four scientific labs. Significantly technical developments were made at RCAEC's labs and the department, which dealt with industrial processes' chemistry and water and waste management.",0
4,9,"
This year marks the 20th anniversary of the department's formation. Throughout its growth and development, the staff have encouraged Chemistry students to think ecologically. One of the department's greatest achievements is the significant number of students and publications. Over 20 monographs and manuals, 11 didactic materials, 15 handbooks, and approximately 500 scientific articles relating to ecological chemistry and environmental protection were published. Additionally, 130 patents for inventions were obtained. The scientific monographs have titles that suggest the complexity and actuality of the problems they discuss, such as ""Environmental redox-processes"" (2001), ""Ecological Audit"" (2002), and ""Natural waters' pollution and self-purification processes"" (2002). Other titles include ""Ecologically pure wine industry"" (2004), ""Environmental economy"" (2005), and ""Wastes management"" (2006).",0
4,10," The department has a professional staff of 28 individuals, which includes 1 academician, 6 professors, 8 associate professors, 8 superior lecturers, and 5 assistant lecturers. As for the students, there are 234 license students (enrolled in courses I, II, and III), 69 master students, and 8 doctoral students. Over the course of the department's activity, 120 foreign students have graduated. Additionally, it is worth noting that the Ecological Chemistry and Environmental Protection specialty was added to the department's curriculum for master and doctoral studies during the 2008-2009 academic year at the State University of Moldova.",0
4,11," The department's contribution to ecological chemistry and environmental protection in the Republic of Moldova was significant, resulting in a very respectable standing in this field.",0
4,12," The teaching of Ecological Chemistry in Moldova is not limited to State University of Moldova (SUM) only. Other institutions like the University of the Academy of Sciences of Moldova, “A. Russo” State University, Bălţi, and Tiraspol State University also offer special courses and facilitate research laboratories and centers.",0
4,13, The primary institutions conducting fundamental research in ecological chemistry are the Research Center Applied and Ecological Chemistry of SUM and the Institute of Chemistry of ASM.,0
4,14," ""The state program called ""Water Quality Management and Research"" is a great example of how Ecological Chemistry can be beneficial. It has financed various research projects aimed at studying the ecological and chemical state of water sources.""",0
4,15," ""We will begin with fundamental research in this field and then move on to a project called 'SELF PURIFICATION OF SURFACE WATER', overseen by Dr. Viorica Gladchi. The project focuses on Catalytic redox processes in natural water.""",0
4,16," Reducers, including autochthonous and allochthonous substances, participate in the redox process in water. Autochthonous substances result from the metabolism and decomposition of hydrobionts, while allochthonous substances come from atmospheric precipitates or wastewater. Copper and iron are important metals for redox transformations and can be found in water in catalytic concentrations.",0
4,17," Prof. Maria Gonta conducted a study on nitrogen compounds under the project titled ""NITRATES, NITRITES AND NITROSOAMINES"". The study focused on the oxidation and reduction of nitrites and nitrosoamines in water, food, and living organisms. A proposed mechanism for nitrite reduction in the presence of various antioxidants was found to decrease the risk of oncology maladies in people of different ages. This research was done in collaboration with the Nebraska Cancer Center, led by Dr. Irina Stepanov in the USA.",0
4,18," 

The research project, led by m.c. Ion Geru, investigated the pseudo Jahn-Teller instability of high-symmetry protonated water clusters. Through experiments, they obtained new data on the energy decay of H2n+1On+ systems and the spatial dimensions of non-homogenates in the water hydrogen bonds' network. This research has potential applications in water purification, particularly for removing heavy metals. The most significant finding of this project was the discovery of the 65th water anomaly, which is an increase in diffusion indices with a rise in Ca2+ ion concentration.",0
4,19," 

Although not the primary focus of ecological research in Moldova, some studies have been conducted on radical reactions in the atmosphere. Dr. Natalia Gorincioi's theoretical analysis titled ""RADICAL REACTIONS IN THE ATMOSPHERE"" explored the diversity of hydroxyl radical reactions, the formation of photochemical smog and PAN compounds, which can have a phytotoxic effect and severely irritate eyes. Researchers determined that the presence of reduced carbon (CH4) in a strong high-energy oxidant (such as O3, O2, hν in the stratosphere) increases the concentrations of hydroxyl and water radicals. In addition, the study investigated various ways of decomposing PAN (peroxyacetylnitrates), including reverse processes, photolysis, thermal degradation and reactions with OH-radicals.",0
4,20,"The materials or items that are disposed of by the possessor, planned to be discarded, or required by law to be discarded are considered waste. This involves any unnecessary or extraneous materials. Classification of waste is based on its source, attributes, level of danger, and the methods used to sort, retrieve, or manage it.'",0
5,1,"

It is widely recognized that the concept of click chemistry (CC) is prevalent nowadays, especially among organic chemists. However, many people have lost sight of the original meaning and philosophy behind this term. When discussing click chemistry, some may immediately think of the CuI-catalysed Huisgen cycloaddition, others might consider polymer synthesis or enzyme-catalyzed templated reactions. Therefore, it is necessary to remind everyone of the original definitions, as proposed by Sharpless, Finn, and Kolb. The original philosophy behind click chemistry was driven by the limited number of drug candidates, requiring synthetic approaches that used molecules that were easy to make. Click chemistry is characterized by its modular framework, its wide scope, its high yield, its production of benign, easily separateable byproducts, its stereospecificity, and its simplicity in reaction conditions, starting materials, reagents, solvent use, product isolation, and so on.",0
5,2," The question posed by Barry Sharpless at a conference in Berlin was about the relevance of click chemistry (CC) in medicinal chemistry. CC was originally devised to aid medicinal chemists in tackling combinational chemistry issues, but a significant number of publications related to CC come from the materials science community. These publications advocate the use of CC strategies for synthesizing polymers, dendrimers, and other materials. The attitude behind this is that overcomplication should be avoided. The high success rate of the CuI-catalyzed Huisgen reaction is exploited to overcome low reactivity issues on polymer or dendrimeric scaffolds. Some medicinal chemists continue to use CC for combinational chemistry applications, while others use it for realizing novel ideas that were once deemed infeasible. This review aims to cover both aspects of CC and medicinal chemistry, but it is not a comprehensive account of CC. Readers are referred to related and complementary reviews in the field of CC.",0
5,3," Before discussing the medicinal uses, it is necessary to address the comparison between CC and the CuI-catalysed Huisgen reaction. It should be noted that CC was developed before the CuI modification of the Huisgen reaction and there are other reactions that fulfill CC criteria, particularly those involving olefins. Nevertheless, the CuI Huisgen reaction is currently considered the best, as evidenced by its prevalence in literature, sometimes leading to it being seen as CC in its entirety.",0
5,4," CC was originally created to provide an alternative to solid-phase synthesis, which was popular due to the use of ""click"" reactions as well as the ability to employ reactions that fell short of being classified as such. High yields and easy purification were achieved through the use of excess reagents and washings, as opposed to traditional chromatography. This alternative allowed for the large-scale synthesis of chemical libraries, and various successful examples are highlighted in the paragraph. One such example is the work done by Lexicon Pharmaceuticals, which used CC reactions to create 200,000 different compounds of acceptable purity on a 25-50 mg scale. Noncommercial building blocks, such as epoxides and aziridines, were used to initiate the process, which led to the creation of 1,2-difunctionalized compounds. Imidoesters also provided five-membered aromatic heterocycles through base-catalyzed 1,3-dipolar cycloaddition with b-ketoesters, and nonaromatic heterocyclic libraries were created using 3-aminoazetidines.",0
5,5," Xie and Seto[5] created a collection of inhibitors for protein tyrosine phosphatase (PTP) through a recent synthesis. They began by synthesizing compound 2, an a-ketoester azide, using a brief approach as demonstrated in Scheme 1.",0
5,6," In CC library syntheses, the steps preceding final click reactions, which involve building-block synthesis, are often the slowest. The introduction of the CuI-catalyzed Huisgen reaction has led to improvements in the synthesis of azides, which were previously considered challenging. Recent advancements in azide synthesis have resulted in one-pot procedures that avoid isolation of the azide intermediate, and are coupled with CC. Examples of this include the use of TfN3 as a diazo transfer reagent by Wittmann and co-workers, the use of microwave irradiation for the synthesis of 1,2,3-triazoles via a three-component reaction reported by Van der Eycken and co-workers, and our work on generating aromatic azides and corresponding aniline derivatives. Such in situ protocols may alleviate the ""azido-phobia"" experienced by some.",0
5,7," CC has been utilized to add unnaturally functionalized groups to highly complex natural product frameworks, resulting in an extremely potent ligation tool, as evidenced by the examples mentioned earlier. Figure 4 illustrates a few of the 'click' analogues synthesized from these products. Sun, Wang, and their team have synthesized a few bisdaunorubicins with variously sized connectors by utilizing the CuI-catalyzed Huisgen reaction between complementary alkyne- or azide-functionalized daunorubicins, or bisacetylene- or bisazide-functionalized connectors (phenyl and PEG) to create compounds like 13 (depicted in Figure 5), which exhibit varying anticancer properties toward leukemia K562 cells, depending on the length and flexibility of the connector between both intercalators.",0
5,8," Some researchers did not abandon solid-phase combinatorial synthesis and instead looked at the CC approach to library synthesis in a different way. They used reliable chemistry in developing triazole-containing linkers and as a traditional solid-phase reaction. For example, Gmeiner and colleagues used pyrrole-2-carbaldehyde functionalized with a propargylic handle to 'click' onto an azide-functionalized resin, resulting in a focused library of compounds that displayed high binding affinities to dopamine D3 and D4 receptors. This same research group previously used the Huisgen reaction to design linkers and functionalize solid-phase-bound alkynes, which generated a library of N-benzyltriazole carboxamides that had nanomolar affinities towards G-protein-coupled receptors. (Mask used: paraphrase)",0
5,9," Yao and colleagues created a batch of bidentate inhibitors for protein tyrosine phosphatases by incorporating prior research that peripheral binding to another location could bolster compound potency and selectivity. The team utilized a recognized core binding element and generated a few versions that had alkyne substitutions. They then combined these with various aryl azides to complete the compounds. From their screening process, a specific PTP1B inhibitor was identified that had moderate inhibition, similar to Abbott's initial basis molecule. In addition, the same researchers created a library of matrix metalloprotease inhibitors using the same method. By fusing eight alkyne zinc binding succinyl hydroxamates with 12 azide fragments, the group generated a collection of 96 compounds, some of which displayed adequate potency and mild selectivity for MMP-7 over other metalloproteases.",0
5,10," Yao and colleagues were able to test compounds directly from the reaction mixture without additional purification in their convergent library synthesis. Wong and team used the CuI-catalysed Huisgen reaction in library synthesis, followed by in situ screening of compounds. For their research on inhibitors of Fuc-Ts, they identified the importance of binding energy derived from the GDP-fucose cofactor and synthesized a GDP core with alkyne functionality. This core was then treated with a library of 85 azide molecules in individual wells of a microtiter plate, and the resulting GDP triazole compounds were screened for inhibition against Fuc-T directly in the plates. Compound 16 showed an 800-fold improvement in inhibition over the original alkyne GDP fragment and is the first nanomolar inhibitor of Fuc-Ts. The same research group also used the in situ screening technique in the discovery of HIV-1 protease inhibitors.",0
5,11," Irreversible/kinetic target-guided synthesis (part of in situ combinatorial chemistry) achieves the same result as traditional in vitro combinatorial chemistry, where an enzyme selects its preferred inhibitors from a potential library. However, in the irreversible approach, the potential library is not synthesized by DCC; instead, the enzyme synthesizes its preferred inhibitor through a connecting reaction. Various groups have attempted this approach in the past, utilizing different reactions and strategies. Researchers such as Benkovic, Boger, and colleagues have described the tight binding of a reactive inhibitor to the enzyme active site following an enzyme-templated epoxide opening reaction with a nucleophilic site on the substrate.",0
5,12," The pioneering use of CC for irreversible target-guided synthesis was done by Sharpless and his team. Mock and his colleagues had previously shown that the rate of the Huisgen reaction at room temperature could be increased considerably by sequestering azide and alkyne fragments in a cucurbituril template. An enzyme target is known to stabilize the transition state of a target-accelerated reaction. To be successful inhibitors, accelerated products must possess a product-like transition state. Therefore, cycloaddition reactions that have a transition state reflecting the product structure are ideal. The Huisgen reaction-based strategy that involves azide and alkyne building blocks eludes the use of reacting species that are nucleophilic and electrophilic, hence are prone to undesired reactions with biological molecules. Encouraged by these findings, Sharpless and his colleagues conducted a proof-of-principle experiment utilizing acetylcholinesterase (AChE) as their reaction vessel. AChE was chosen because established inhibitors were available, it binds both the active center and the peripheral site, and inhibitors that span both sites have tighter binding than fragments alone.",0
5,13," Incorporating the existing in situ bCAII library designed by Sharpless et al. into a microfluidic chip device is a technical advance. This was achieved by Kolb, Tseng, and co-workers, decreasing the quantities of reagents required and operating at reaction volumes of approximately 4 mL. With this approach, smaller quantities of enzyme are required, and the microfluidic chip can carry out 32 reactions in parallel. The chip operates with the advantages of low reagent consumption, precise control over reaction conditions, faster reaction kinetics, and cost efficiency, making the process potentially even more efficient. In this application, the microfluidic chip gave a very similar outcome to the original study, demonstrating that the advantages of the in situ approach to lead discovery can be coupled with the use of a microfluidic chip.",0
5,14," The major part of this review has concentrated on showcasing the accomplishments made in line with CC's initial objective of supporting medicinal chemists. Nevertheless, we'll now shift our focus from large libraries and high-throughput screens of combinatorial chemistry to touch briefly on the impact of CC on other areas of medicinal chemistry. While it won't be discussed here, it's worth noting that the CC approach, with the CuI-catalysed Huisgen reaction, has been incredibly beneficial in linking biomolecules together, as seen in the synthesis of glycoconjugates and attaching molecules to other proteins and DNA templates.",0
5,15," The medicinal chemist can benefit greatly from CC as it is becoming an increasingly valuable tool in various fields. One of these areas includes the chemistry discussed in the last section of the review, where the modification of natural products and replacement of functionality in drug targets opens up many opportunities in drug discovery.",0
5,16," The evolution of the application of CC is reviewed, and it is expected that the trend towards increased diversity of application will persist as new applications emerge. Moreover, the discovery of new reactions that satisfy the status of 'click' will further broaden the horizons.",0
6,1,"
Molecular cages having spacious inner spaces are synthesized most effectively by assembling several building blocks under thermodynamic regulation. The common approach to connect these blocks involves utilizing metal-ligand interactions.[1] These coordination cages have assorted uses, such as nanoreactors for chemical reactions, as vehicles for administering anticancer drugs, or to stabilize strongly reactive guest molecules.",0
6,2," Dynamic covalent chemistry has been used to assemble purely organic cages through various reactions such as imine condensations, boronic ester condensations, thiol-disulfide exchange reactions, and olefin metathesis. The combination of metallasupramolecular chemistry and imine condensations has also been successful, resulting in the stabilization of both the metal complex and the imine bond. Some recent noteworthy achievements include the stabilization of molecular P4 within a coordination cage, and the synthesis of a Borromean ring and a Solomon knot.",0
6,3," 

Our group aims to create elaborate molecular structures by merging metallasupramolecular chemistry and dynamic covalent chemistry in a complementary way. A recent breakthrough was achieved when a 52-membered macrocycle was produced by the simultaneous formation of reversible bonds such as imine, boronate ester, and rheniumnitrogen. We expand on this progress by presenting how polycondensation of triamines with metallamacrocyclic building blocks, which contain aldehyde groups, has allowed for the seamless creation of several new small-scale cages.",0
6,4," The researchers wanted to see if they could create a material with permanent porosity due to the high percentage of solvent-accessible volume in crystalline 4a. They performed N2 sorption measurements on a sample of crude amorphous 4a and an X-ray-quality crystalline product after prolonged drying in a vacuum. The surface areas calculated using the Brunauer-Emmett-Teller method were 30 and 15 m2 g-1 for the amorphous and dried crystalline products, respectively, suggesting that larger voids between the cages were eliminated due to a structural collapse during the drying process. This idea was supported by the poor match between the powder X-ray diffraction pattern of dried crystalline 4a and that calculated from single-crystal diffraction data.",0
6,5," 

To sum up, the work outlined in this article demonstrates that by combining metal-ligand bond-forming reactions with imine condensations in a non-overlapping manner (meaning the imine bond is not formed in the metal's coordination sphere), incredibly intricate and large structures can be achieved. Using the dynamic covalent chemistry technique to link metallamacrocycles adds to the current methods for constructing molecular nanostructures, and can be utilized for various other structures.",0
6,6," Et2O vapors diffused into CHCl3/MeOH (95:5) solutions of 4a and 4b, leading to the formation of large, well-shaped single crystals. Although the crystals appeared poor in diffracting X-rays, a satisfactory data set was obtained for a crystal of 4a, whose structure was solved in I2/a, an alternative setting of the monoclinic space group C2/c. Figure 1 displays the solid-state structure of 4a, exhibiting approximate tetrahedral symmetry (T) that is consistent with the simple NMR spectra observed in solution. The trinuclear metallamacrocycles occupy four vertices, and the triphenylmethane units span each of the four faces. Intriguingly, all four metallamacrocycles within a given molecule have an identical relative configuration concerning the rotation about the pseudo threefold axes that connect each vertex with its opposing face (Figure 1a). Nonetheless, the crystal contains an equal number of opposite stereoisomers and is thus racemic.",0
7,1," The Royal Swedish Academy of Science has recognized the outstanding work of various scientists in theoretical and computational chemistry by awarding them Nobel Prizes in Chemistry. Linus Pauling was one of the awardees in 1954 for his research on the chemical bond. Other recipients include Robert S. Mulliken in 1966, Kenichi Fukui and Roald Hoffmann in 1981, Rudolph A. Marcus in 1992, and Walter Kohn and John A. Pople in 1998. Mulliken made contributions to the study of chemical bonds and electronic structures, while Fukui and Hoffmann had significant theories on chemical reactions. Marcus was recognized for his contributions to electron-transfer reactions, while Kohn and Pople were both distinguished for their development of techniques in computational chemistry and density functional theory, respectively.",0
7,2," The Nobel Prize in Chemistry for 2013 has been conferred by the Academy to Martin Karplus, Michael Levitt, and Arieh Warshel for their breakthrough in creating multiscale models for intricate chemical systems. Undoubtedly, the newly acclaimed Nobel laureates may resonate with Newton's famous quote, ""If I have seen further, it is by standing on the shoulders of giants.""",0
7,3," In the molecular dynamics (MD) approach, the time-averaged property is estimated, whereas the Monte Carlo (MC) technique provides ensemble-averaged values. The ergodic hypothesis assumes that any point in configuration space can be reached in a finite number of MC steps from any other point. Under this hypothesis, both averages should be equal and accurately reflect the property being studied.",0
7,4," Simulations, such as the MC method, were born from scientific research conducted during wartime at certain US DOE National Laboratories, where nuclear cross section calculations played a critical role in the development of thermonuclear armaments. These calculations were first published in the 1950s.",0
7,5," ""The issue at hand resembles the one tackled by Laplace in his famous Mécanique Céleste over two hundred years ago. The only variation lies in the fact that electromagnetic forces, which affect the microscopic domain, are substituted for gravitational forces that manage the larger (celestial) universe.""",0
7,6," 

Multiscale modeling employs multiple models at different scales to describe a system. For simulating chemical reactions involving large biological molecules, smaller reactive areas can be treated with more computationally expensive quantum mechanics (QM) while the larger, inert regions are described using less sophisticated classical molecular mechanics (MM) with empirically or semi-empirically parametrized force fields. This hybrid QM/MM approach is a form of multiscale modeling.",0
7,7,"

The original technique of using the QM/MM model for MD simulations in biomolecules was presented in a significant paper by Warshel and Levitt in 1976, where they studied enzymatic reactions. Although they analyzed the entire enzyme-substrate complex, they only utilized quantum mechanics on the atoms directly involved in the reaction while treating the remaining atoms, including the solvent, using classical forces. The same authors also incorporated Shneior Lifson's consistent force field in their computer code, which became the foundation for some of the most well-known computational biology programs in use today, including CHARMM, AMBER, and GROMOS.",0
7,8," Figure 1 depicts how a QM/MM approach was utilized to study a complex consisting of the MMP-2 metalloenzyme (represented by a ribbon model) and a peptide substrate (represented by a ball-and-stick model) containing 2665 atoms. The structure was obtained from an MD simulation that employed QM/MM multiscale modeling. The QM region was comprised of 100 atoms, including the catalytically active MMP-2 residues and the peptide linkage, while the MM region encompassed 1700 water molecules. The figure also features an inset that shows the QM region's charge density embedding, which was determined using DFT.",0
7,9," Equation (3) represents a potential that combines Coulomb and Lennard-Jones forces. The variables qi, Aij, Bij, and rij respectively stand for atomic charges, fitting parameters, and interatomic distances.",0
7,10," Empirical or semiempirical parameters are typically used to define each term in Eq. (2), but first-principles (QM) calculations have also been used for parameterizations. The Matsuoka-Clementi-Yoshimine (MCY) potential for water-water interactions (Vwater term in Eq. (2)) is a notable example, which was developed in the 1970s at the IBM Research Laboratories in San Jose (California).",0
7,11,"

In 1985, Car and Parrinello introduced a different method known as ab initio (first principles) molecular dynamics (MD). This technique involves solving Newton's equations (Eq. (1)) for the movement of nuclei, while using the Schrödinger equation in the DFT format to describe electronic motion [7]. Ab initio MD is a multiscale modeling method that calculates interatomic forces in real-time using DFT, while the nuclei follow classical mechanics. Although it is highly efficient [8], ab initio MD requires significantly more computer time compared to QM/MM methods.",0
7,12,"

Levitt demonstrated the vast benefits of CFF in providing valuable information on biological systems through his publications as early as 1969. One of his contributions involved the first energy minimization of an entire protein structure, namely myoglobin and lysozyme, via a refinement procedure to enhance information from X-ray diffraction measurements. Another breakthrough involved the use of CFF in refining Cartesian coordinates and proposing a model for tRNA that was both energetically stable and stereochemically plausible. Levitt's work in computational biology marked the beginning of substantial research in this field.",0
7,13," Warshel's focus shifted from energy minimization calculations to molecular simulations when he conducted the first MD simulation study on the dynamics of a biological process, specifically the vision process, in 1976. Using a basic model for the protein-chromophore phase, Warshel's MD simulation provided a detailed understanding of the absorption of light by the protonated Schiff base of retinal chromophore bound to the active site of the protein rhodopsin, and explained how the protein facilitated the photoisomerization process even without the structure of the rhodopsin protein.",0
7,14," In the 1980s, Warshel conducted the initial microscopic simulation of ET reactions in condensed phases, which was documented in [13]. Additionally, he carried out the first simulation of an enzymatic reaction, as noted in [14]. The results of molecular dynamics (MD) research proved to be valuable in uncovering the single step versus stepwise mechanistic alternatives involved in bacterial photosynthesis in relation to fundamental processes in photochemistry. As regards enzyme catalysis, MD simulations contributed to comprehending the enzyme's role in decreasing the energy barrier linked with the transition structure (TS) to control the reaction rate. The dynamic data made available by MD computations helped to explain why enzyme-TS binding was more energetically favored compared to the enzyme-substrate connection.",0
7,15," 

In the 1980s, simulated annealing methods were extensively studied. They were often used for X-ray structure refinement [15] and nuclear magnetic resonance (NMR) spectroscopic structure determination [16]. The relevance of MD calculations in interpreting relaxation rates (T1 and T2) and nuclear Overhauser enhancement (NOE) measurements is noteworthy.",0
7,16," 

With the latest massive parallel computers and powerful parallel software, the MD simulation world is expanding to include exciting research fields that can handle increasingly complex biological processes in real-time. The continuous advancement of computational technology (both software and hardware) gives reason for optimism that MD techniques will soon be applied on the cellular scale.",0
7,17," Properly utilizing the computational data libraries containing all recorded parameters and properties of various chemical, biophysical, or biochemical processes along with corresponding mechanistic information can significantly advance bioanalytical chemistry. This can be achieved through the employment of bioinformatics tools.",0
8,1," [1] Fred Basolo (shown in figure 1), who was the Charles E. and Emma H. Morrison Professor Emeritus of Inorganic and Analytical Chemistry at Northwestern University as well as the 1983 President of the American Chemical Society, passed away due to congestive heart failure in Skokie, Illinois at the age of 87 on February 27, 2007. His wife, Mary, had predeceased him, but he is survived by three daughters, a son, and eleven grandchildren.",0
8,2," Fred's achievements were remarkable in the fields of inorganic chemistry, coordination chemistry, chemical education, inorganic reaction kinetics and mechanisms, as well as service to science and society. Following the demise of his mentor, John C. Bailar, Jr. [2], Fred took over as the dean of American coordination chemistry. He recounted his life and career in his autobiography [3] and a collection of his notable papers with annotations [4].",0
8,3," Fred grew up in a mining community where most of the workers were immigrants from the Piedmont region of northern Italy. They spoke the Piemontese peasant dialect, which Fred understood but did not speak well until he started school. His home lacked central heating and plumbing, and he enjoyed watching his mother prepare Italian dishes in their primitive kitchen, which became one of his favorite hobbies. His caring nature towards those around him may be attributed to his upbringing in Coello.",0
8,4," When Fred was approximately ten years old, The Great Depression started. Since he was not old enough to work, he went to elementary school in Coello and then Christopher Community High School. It was during his time in high school that he was first introduced to chemistry. However, his teacher had a negative attitude towards the subject, had limited knowledge about it, and expected the students to learn on their own.",0
8,5," After taking advantage of a college welfare program, Fred successfully got into Southern Illinois Normal School and pursued a chemistry major, graduating with a B.Ed. in 1940. As the sole Coello citizen to obtain higher education, Fred also became the town's solitary Ph.D. While his parents anticipated him following a path towards teaching, the Chairman of the Chemistry Department, James Neckers, encouraged him to enroll in graduate school instead.",0
8,6," Through a teaching assistantship, Fred was able to attend the University of Illinois and chose John C. Bailar as his mentor. Bailar was a proficient professor in organic and inorganic chemistry, which Fred considered a perfect opportunity for him. Fred admired Bailar's caring and compassionate nature and looked up to him as a role model, alongside his parents. Following in Bailar's footsteps, Fred carried on his work with his own students and inherited his position as the leading expert in coordination chemistry in the United States after Bailar's passing in 1991.",0
8,7," 
Bailar's research with octahedral cobalt(III) complexes inspired him to broaden his study to planar platinum(II) and octahedral platinum(IV) coordination compounds. As part of his dissertation, Fred synthesized optically active cis[PtCl2{NH2CH2CH2NH2}2]Cl2 and investigated the stereochemical changes that occur during its ligand substitution reactions. Although his subsequent publication on this topic wasn't of much interest at the time, more than 20 years later, Barnett Rosenberg discovered the anti-tumor properties of the related complex, cis-[PtCl2(NH3)2] (also known as cisplatin), which is now one of the most commonly used anti-cancer drugs.",0
8,8,"The suggestion given by Bailar to Fred was to finish his research within three years to avoid being drafted and to secure his degree from Illinois. Fred managed to complete both his M.S. and Ph.D. degrees in 1942 and 1943 respectively. After that, Fred spent the next three years conducting confidential research, which was sponsored by the government at the Rohm & Haas Co located in Bridesburg, a suburb in Philadelphia.",0
8,9," After obtaining his PhD, Fred joined Northwestern University as an Instructor of Chemistry in 1946. The following year, he got married to Mary Nutely, and their marriage lasted for several decades, bringing four children who all became educators. During his tenure at NU, Fred progressed from Instructor to Professor, achieving the prestigious title of Charles E. and Emma H. Morrison Professor of Chemistry. Additionally, he held the position of Chairman of the Chemistry Department for three years between 1969 and 1972.",0
8,10," The Basolos were granted a sabbatical year through a Guggenheim fellowship in 1954-55, which they spent in Copenhagen. During this time, Fred worked in Jannik Bjerrum's lab, who is known for introducing the term ""ligand."" Additionally, they traveled to other parts of Europe, making a stop in Italy to see Fred's family. As an avid golfer, Fred also made time to play at the Royal and Ancient Golf Course in Scotland, where the sport originated.",0
8,11," In the summer of 1955, Fred and Mary attended the 3rd International Conference on Coordination Chemistry in Amsterdam, where Fred had the chance to hear the plenary lecture by Walter Hieber, referred to as the 'father of metal carbonyl chemistry'. Intrigued by the subject, Fred approached Hieber and asked him about the mechanisms involved in the synthesis and reactions of these compounds. However, Hieber's reply was not very encouraging, as he stated that he preferred to focus on practical chemistry rather than the philosophy behind it. Nevertheless, this incident sparked an interest in Fred, who realized that this area of study was not receiving enough attention and could provide potential research opportunities for him and his students.",0
8,12," While exploring the Rohm and Haas library, Fred developed an interest in substitution reactions on carbon. He realized that similar studies could be conducted on inorganic coordination compounds such as cobalt(III) and platinum(II), which he was already familiar with. However, he lacked expertise in kinetics and mechanisms. Fortunately, Ralph G. Pearson, a fellow instructor and physical organic chemist, was already conducting such studies with carbon compounds. Despite the lack of interest in inorganic chemistry among NU graduate students, Fred managed to persuade Ralph to collaborate on similar studies on coordination compounds. Their joint paper was published in 1952 [16].",0
8,13," Fred and Ralph conducted significant research in various areas of chemistry, including ligand substitution reactions of octahedral cobalt(III) complexes and Pt(II) square planar complexes, acid hydrolysis or aquation of cobalt(III) and chromium(III) metal-ammine complexes, base hydrolysis of metal-ammine complexes, linkage isomers, synthetic oxygen carriers, and organometallic chemistry, such as the indenyl kinetic effect. These studies are regarded as true chemical classics. In addition, Fred explored the field of biological inorganic chemistry.",0
8,14," Fred, like his mentor John Bailar, taught and guided many chemists throughout his career. He supervised 58 doctorates, 66 postdoctoral fellows, and numerous bachelor's and master's degree candidates. A significant proportion of his students were inspired to follow in his footsteps and pursue careers in academia. Many of Fred's former students are noteworthy figures in the fields of inorganic chemistry and chemical education. Similar to John Bailar, Fred's success as a teacher and research supervisor was due not only to his extensive chemical knowledge but also to his enduring personal qualities. In recognition of his contributions to chemical education, Fred received the ACS George C. Pimentel Award in 1992 and the Priestley Medal, the highest honor bestowed by the ACS, in 2001. He was also the recipient of various other awards, medals, and honorary degrees.",0
8,15," 
Fred's involvement in various professional activities included the Gordon Research Conferences, International Conferences on Coordination Chemistry, ACS Petroleum Research Fund Advisory Board, and North Atlantic Treaty Organization. He was also a member of the National Academy of Sciences, and considered his participation in the book 'Opportunities in Chemistry' to be one of his important NAS activities. Along with his more than 380 scientific publications, he also served as an editor for journals or volumes and wrote letters of recommendation, award nominations, or forewords to books or monographs.",0
8,16," 

During Fred's tenure as President, he made efforts to address his long-standing worries. He aimed to combat chemophobia by engaging in discussions about environmental issues with newspaper reporters, radio talk show hosts, and television anchor persons. However, he agreed to such discussions only if he was granted equal time to present the favorable aspects of chemicals. Fred also conveyed his stance on this matter to congressmen and congressional committees. Unfortunately, some of his presidential endeavors did not yield positive results.",0
8,17," 

Fred's globetrotting adventures took him to forty different countries where he immersed himself in diverse cultures and cuisines, relishing every new encounter with childlike wonder. Notably, his frequent trips to Italy, which he affectionately regarded as his second home, afforded him the opportunity to both lecture and familiarize himself with the Italian language. His prolific academic career was duly recognized, as he received numerous honorary doctorates and medals from various Italian universities and organizations. Of special significance was his election as a foreign member of the prestigious Accademia Nazionale dei Lincei, joining the ranks of a select group of scientists including several Nobel laureates.",0
8,18," Regrettably, Mary underwent an emergency quadruple heart bypass in 1991 and was later afflicted by Alzheimer's disease. One day, while Fred was driving her to the daycare facility, he dozed off at the wheel due to a combination of new medications and exhaustion, resulting in a collision with a tree that proved fatal for Mary on February 5, 1997. Fred's back underwent five surgeries that damaged his brain-to-leg nerves, rendering him incapable of walking without two canes. He used a motorized scooter to traverse the NU Chemistry Building (see figure 5). Despite experiencing pain and respiratory difficulties, he still made it a point to arrive at his office in the morning, have lunch with his fellow faculty members, and leave in the early afternoon.",0
9,1," 

The field of green analytical chemistry (GAC) is gaining traction as a research area in chemical analysis that has the potential to challenge current norms. A quick search on the ISI Web of Science database using the keywords ""green analytical"" yields over one hundred results. In addition, there have been two reviews and three books published on this topic in recent years, which is noteworthy. As a subdiscipline of analytical chemistry, bioanalysis cannot overlook this growing trend.",0
9,2,"
Analytical chemistry concerns itself with both quantitative and qualitative data regarding the presence and characteristics of elements and molecules in the surrounding environment. These findings are usually derived from sample solutions, and thus adopting eco-friendly practices, such as decreasing the size, mass, and quantity of materials utilized in information exchange, becomes imperative. Ergo, integrating the concepts of sustainable chemistry within analytical chemistry is both significant and reliable. Furthermore, Namieśnik was the pioneer to demonstrate the applicability of these principles, and how they could define the primary traits of this novel domain.",0
9,3," ""Most spectrometric methods are considered environmentally friendly in terms of solvent consumption, but energy consumption of instruments must also be taken into account for green engineering in analytical chemistry, which aims at economically feasible and low-risk processes. While carbon footprint of manufacturing an instrument is often overlooked, miniaturization plays a key role in greening instrumental methods. Modern bioanalytical instruments are capable of processing small sample sizes.""",0
9,4," 

Both aspects of the analytical process, including sample preparation (solvent usage) and measurement (instrumentation/data processing), can serve as a means of conveying information about the environment. As a result, the principles of green chemistry can be consolidated into a solitary tenet for analytical chemistry, which is to reduce the amount of media employed to transmit information in order to promote eco-friendly analytical chemistry.",0
9,5," 

Recent reviews have thoroughly documented initial efforts to make HPLC more environmentally friendly [2,11–14]. To reduce solvent consumption, one approach is to minimize column dimensions and use smaller particles for packing. Another is to use elevated column temperatures instead of organic solvents for separation. Additionally, alternative, safer organic modifiers to ACN can be used in reversed-phase HPLC. Supercritical fluid chromatography (SFC) is also worth mentioning as a technique that uses carbon dioxide as a mobile phase and has been used for nonpolar, cationic, anionic, chiral, protein, and drug compounds. Solvent recycling is essential in labs but typically requires significant energy.",0
9,6," The greenness of chromatography is ambiguous and should consider the whole analytical process. Energy aspects have been overlooked, except for the research of Van der Vorst et al., who found that preparative SFC consumes about 34% more resources than preparative HPLC. This could have significant implications for other green chromatographic techniques like elevated-temperature HPLC. Thus, the actual greenness of elevated-temperature chromatography requires further life-cycle analysis.",0
9,7," Separation science, including CE, has been impacted by microfluidics, a trend towards miniaturization with volumes measured in nanoliters and picoliters. However, world-to-chip interfacing poses a challenge, as samples and reagents are typically transferred in larger amounts than microfluidic devices can handle. To ensure portability and energy efficiency, all aspects of microfluidic systems must be integrated and supporting instruments miniaturized, including pumps, valves, and mixers.",0
9,8,"

Passive components that function without external power can replace complex analyzers in microfluidic devices, thereby reducing or eliminating the need for supporting instruments. Fluid manipulation can be achieved through gravity, air pressure, or manual actions. The need for simple point-of-care tests in developing countries for medical diagnostics is driving the development of these simple and potentially disposable devices. However, non-instrumental analytical devices can also be useful in developed countries, where home tests and first responder detection for bio-emergencies are necessary. Examples include glucose and pregnancy testing.",0
9,9,"
A researcher in the development of GAC methods can utilize current technology, which has already impacted the environment according to green philosophy, for analyte quantitation. Recent bioanalytical applications demonstrate this, such as Xiang and Lu's use of personal glucose meters for affordable and reliable DNA quantification. Accessible to the public, this method is low-cost and simple to operate. Additionally, Zhu et al. integrated cytometry and fluorescent microscopy on a cell phone with an optofluidic attachment. Another example is Jokerst et al.'s paper-based device that uses a Xerox scanner for colorimetric detection of foodborne pathogens.",0
9,10," The sense of green analytical chemistry is still under debate. It is uncertain whether making analytical chemistry greener would have a substantial effect on the environment, particularly when compared to the chemical industry's impact.",0
9,11," The true environmental impact of green analytical chemistry is a complex issue that requires examination of where the assay chemicals and instrumentation originate and how they are produced. A life-cycle analysis is necessary to fully understand the environmental impact of analytical methods. It is possible that green chromatography may be environmentally acceptable and economically attractive in laboratories, but not benign for society as a whole. The ultimate disposal of the product must also be considered.",0
9,12," 
Analytical chemistry can be seen as an information science that does not require excessive resources to carry out the analysis. To make the field more eco-friendly, miniaturization is a viable solution, but it ultimately depends on the creativity of the analyst to develop greener instruments. One benefit of miniaturizing the process is reduced energy consumption. However, it's important to consider that while lab practices may be environmentally friendly in a local context, the overall concept of ""green analytical chemistry"" might still be viewed with skepticism on a global scale.",0
10,1," The terms ""green"" and ""sustainable"" have become common in various research areas since their introduction to the scientific literature. The Responsible Care® initiative by the American Chemistry Council (ACC) and the Brundtland report are credited with the origin of ""green chemistry."" This concept was later enriched by the Pollution Prevention Act and the Anastas and Warner's 12 principles of green chemistry. Generally, green chemistry aims to create a sustainable society by bringing academia, industry, and government together.",0
10,2," The efficiency of a chemical process is determined by multiple factors, not just the chemical yield. Nowadays, it is crucial to consider the safety of the procedure as well as the selection of solvents, starting materials, and technologies used to control reactive intermediates. Recovery and reuse of materials is important to minimize toxic waste and disposal costs. Additionally, the use of biomass-derived chemicals with lower CO2 consumption should be promoted.",0
10,3," Another important aspect of green chemistry is the technology utilized in the process, which is closely related to chemical and process efficiency. Optimizing energy and time usage is vital, and there is a growing interest in developing innovative heating and mixing technologies, which can aid in controlling chemical process safety and reactivity, as well as facilitating material recovery and reuse. Such technologies reduce energy consumption and improve process efficiency overall. Research into flow chemistry, microwave and ultrasonic irradiation, and mechano-chemistry are just a few examples of independent developmental research platforms that offer innovative tools for achieving chemically and environmentally efficient processes.",0
10,4," ""Various Thematic Series in the Beilstein Journal of Organic Chemistry have highlighted different approaches towards green chemistry and sustainability. Examples of such series include 'Strategies in asymmetric catalysis' by Tehshik P. Yoon, 'Organometallic chemistry' by Bernd F. Straub and Lutz H. Gade, 'C–H functionalization/activation in organic synthesis' by Richmond Sarpong, 'Bifunctional catalysis' by Darren J. Dixon, 'Sustainable catalysis' by Nicholas J. Turner, and 'Organic synthesis using photoredox catalysis' by Axel G. Griesbeck, all of which have provided excellent representative examples of these directions.""",0
10,5," 

The constant evolution of chemical and technological advancements requires the establishment of fresh benchmarks to appraise the efficiency of innovative procedures within the domain of eco-friendly chemistry. An essential component of eco-friendly chemistry is contrasting the multiple methods available by inspecting assorted experimental factors. Obviously, the vital parameter to scrutinize is the precise estimation of the waste generated, which emanates from both the synthetic approach and the technology employed. The principal function of eco-friendly metrics is to assess the latest classification of chemical alterations based on their potential or actual hazardous outputs. In certain circumstances, such as evaluating the waste linked with the mass of the material employed, assessment is effortless to perform.",0
10,6," 
Comparing energy, time, labor costs, and other variables of a process may be challenging. While the primary objective of green chemistry is innovation, it is also the most difficult aspect to assess. Future sustainable chemical production necessitates novel chemistry and innovative technologies. To achieve this objective, it is essential to combine fundamental research with the ability to translate innovation into real-world applications.",0
10,7,"The vast opportunities to advance green chemistry can be found within the multifaceted field of organic chemistry. Scientific contributions towards this goal can be effectively communicated in dedicated journals such as the Beilstein Journal of Organic Chemistry. The compilation of original research and reviews in the Thematic Series ""Green Chemistry"" highlights a representative section of the extensive field of green chemistry.",0
11,1," Heteroatom chemistry has been instrumental in the development of synthetic methodologies for C-C bond formation in organic chemistry. Nobel Prize winners Wittig and Brown pioneered the Wittig reaction and hydroboration respectively, and since then, a plethora of reactions utilizing heteroatoms have been discovered. Heteroatom chemistry has evolved to encompass organic element chemistry, with a focus on the chemical properties of heteroatoms or main group elements, such as bonding modes and structural features. In this article, the author aims to provide a comprehensive overview of heteroatom chemistry through reports on symposiums, research funds, and Asian contributions to international conferences on Heteroatom Chemistry. Additionally, the article discusses the chemistry of compounds bearing low- and high-coordination main group elements, contributions to heteroatom chemistry made by the author's group, and future prospects in the field.",0
11,2," 

The Symposium on Organometallic Chemistry began in 1974 as a conference focused on heteroatom chemistry. It evolved from the Symposium on Organosilicon Chemistry, which was founded by Watase in 1954 as the head of the Organosilicon Chemistry Division of the Kinki Chemistry Society. The event was later joined by Kumada, Sakurai, and Ando. The 58th symposium was held in Nagoya last year, and there has been a growing number of chemists who attend both conferences.",0
11,3," 

Research funds have financially supported heteroatom chemistry through Grants-in-Aid for Scientific Research on Priority Areas by various researchers such as Akiba, Tamao, Tatsumi, and Miyaura during different time periods. Additionally, a Grant-in-Aid for Scientific Research on Innovative Areas was provided by Akasaka. These projects involved more than 100 researchers researching a common theme, and many heteroatom chemists have been able to benefit from these opportunities.",0
11,4," Asia comprises nations like Turkey, Israel, Jordan, Iran, Iraq, Saudi Arabia, Oman, Pakistan, India, Bangladesh, Thailand, Malaysia, Mongolia, China, Taiwan, Hong Kong, Korea, Japan, Australia, and New Zealand, all of which are Asian countries and have presented oral and/or poster presentations multiple times.",0
11,5," Oral presentations can be categorized as plenary lectures, invited or session lectures, and general oral presentations. The continent-wise contribution to oral presentations and poster presentations is displayed in Figure 1 and Figure 2, respectively. It is interesting to note that Japan's contribution has been primarily significant in oral presentations, barring the 7th conference where China took the lead. Asian countries had a comparable or higher contribution to oral presentations, except for the 5th and 6th conferences held in Canada and Poland. The numbers displayed in Figures 1 and 2 indicate Japanese participation in Asia.",0
11,6," It can be noted that the contribution from America to poster presentations is relatively low compared to Asia. Europe's contribution is also lower, except for the conferences held in Italy and Poland. Japan has consistently had the highest contribution to poster presentations from Asia, except for the conferences held in India, Korea, and China. In general, Asia has made a significant contribution to ICHAC conferences, while Japan's contribution can be deemed similarly noteworthy.",0
11,7," 
Double bond compounds between group 14 elements of higher molecular weight, namely disilene 7 [7] and its analogues, digermene 8 [8], distannene 9 [9], and diplumbene 10 [10], were created (Scheme 3). The first Si–Si doubly bonded compound, tetramesityldisilene (7), was synthesized by West et al. It is noteworthy that larger substituents are necessary when progressing from the third to the sixth row.",0
11,8," In 1981, a significant event occurred when the previously established double bond rule was broken with the creation of stable disilene 7 [7] by West et al. in the United States and diphosphene 11 [11] by Yoshifuji and Inamoto et al. in Japan (Schemes 3 and 4). These compounds contained a double bond between heavier elements below the third row, which was previously thought to be impossible.",0
11,9," The introduction of a mesityl group was used as a steric protection group to stabilize the disilene, while a much bulkier 2,4,6-tri-tert-butylphenyl group was needed for the diphosphene because the disilene could accommodate four steric protecting groups, whereas only two were available for the diphosphene. Diplumbene 10 and dibismuthene 12 were successfully synthesized by Weidenbruch et al. and Tokitoh and Okazaki et al., respectively, using much bulkier groups than mesityl and 2,4,6-tri-tert-butylphenyl groups as shown in Schemes 3 and 4. The heavier group 14 series has trans-bent structures, while the heavier group 15 series have planar structures, but the carbon-pnictogen-pnictogen angles are much smaller than 120º, which is a different phenomenon resulting from the difficulty of hybridization between s- and p-orbitals in heavier elements compared to second-row elements.",0
11,10," Okazaki et al. reportedly obtained thiobenzaldehyde 13 and selenobenzaldehyde 14 at an early stage by utilizing the 2,4,6-tri-tert-butylphenyl group's kinetic stabilization. They also obtained telluroketone 15. Silanethione 16, germanethione 17, germaneselone 18, germanetellone 19, and stannaneselone 20 were synthesized by Tokitoh and Okazaki et al. using Tbt and Tip groups or Tbt and Dipt groups or Bbt and Tipt, as steric protecting groups. Stannanetellone 21 stabilized by Bbt and Tipt groups was recently reported by Tokitoh et al. (Scheme 5).",0
11,11," Tamao and Matsuo and their colleagues were able to synthesize the initial stable germanone 22 with the help of effective steric protection of the Eind group, which was initially developed by their group. This trigonal planar structured compound was successfully created through their efforts.",0
11,12," 

Heavier analogues of acetylene have been created and in 2004, independent reports by Sekiguchi et al. and Wiberg et al. announced the first Si-Si triple bond compounds [26,27]. In the production of Sekiguchi's compound 24, tetrabromodisilane was reduced with potassium graphite to produce an emerald green crystal (Scheme 8) [26]. X-ray examination showed that it has a trans-bent structure, diverging from acetylene. Additionally, the bond length is shorter than a double bond length, signifying an authentic Si-Si triple bond.",0
11,13," Aryl-substituted digermylyne with a Ge–Ge triple bond has been synthesized by Tokitoh et al. However, for its lead analogue, Power et al. synthesized a bis-plumbylene (compound 25 in Scheme 9) with a Pb–Pb single bond instead of a triple bond. Hence, the situation changes completely on moving down the periodic table.",0
11,14," The first synthesized among them were heavy metallocyclopentadienides. As the first example, silanole dianions were synthesized and then germanium analogues were also created. Sekiguchi et al. reported on the synthesis of disilagerma and trisila versions. Recently, Saito et al. have succeeded in synthesizing heavier analogues, including stannole dianion and plumbole dianion 26, which they concluded has aromaticity due to the absence of bond alternation between the endocyclic C-C bonds and its negative nucleus-independent chemical shift (NICS) value.",0
11,15," 

Sekiguchi et al. were successful in synthesizing aromatic cation species. They obtained trisilacyclopropenium cation 27, which is the trisila equivalent of the aromatic cyclopropenium cation. This was achieved as a salt with tetrakis(4-tert-butyl-2,3,5,6-tetrafluorophenyl)borate. The X-ray analysis revealed that the silycenium cation is completely free and does not interact with the counter anion.",0
11,16," 

After an unsuccessful attempt at synthesizing a silabenzene by Märkel et al. [40], Tokitoh and Okazaki et al. delved into the neutral aromatic compounds containing heavier group 14 elements. The first example was the synthesis of 2-silanaphthalene 28 (Scheme 10) by employing the kinetic stabilization provided by the Tbt group [41]. This compound's aromaticity was verified by a planar structure with no bond alternation and a negative NICS value akin to naphthalene. Tokitoh et al. continued this chemistry, successfully synthesizing the tin analogue 29 (Scheme 9) [42]. In 2007, Sekiguchi et al. reported the formation of 1,2-disilabenzenes 30 (Scheme 10) through (2 + 2 + 2)-cycloaddition of disilyne 24 with 2 molar equiv of phenylacetylene [43]. Recently, Tokitoh et al. also presented 1,2-disilabenzenes containing aromatic Bbt groups at the 1,2-positions [44].",0
11,17," High-coordination carbon and boron compounds, which were thought to be challenging to produce, are discussed first. Yamamoto and Akiba et al. synthesized and characterized pentacoordinated carbon species 31 [45], pentacoordinated boron compound 32 [46], and hexacoordinated carbon species 33 [47] (Scheme 11). Their structures were identified using X-ray analysis, and Atoms in Molecule calculations revealed bond paths between the central atom and oxygen atoms.",0
11,18," 
Several high-coordination silicon compounds have been reported previously, including four species (34-37) by Japanese scientists, which are illustrated in Scheme 12. The first silylsilicate (34) with tetracoordinated silicon and anionic pentacoordinated silicon was reported by Sakurai and Kira et al., along with the neutral hexacoordinated compound (35). The first pentacoordinated fluorine-bridged compound (36) was reported by Tamao et al. Additionally, 5-Carbasilatrane 37, a neutral silane coordinated with water, is our contribution to high-coordination silicon chemistry. Interestingly, a dimeric structure in the solid state can be recognized as a frozen intermediate of the hydrolysis in a triaryloxysilane.",0
11,19," 
Sato, Furukawa, and Nabeshima and their colleagues have recently accomplished the synthesis of all carbon persulfurane 41 [57] by utilizing the high reactivity of the sulfurane dication. This dication was first synthesized from the corresponding sulfurane (as depicted in Scheme 14). X-ray analysis has revealed that the structure of 41 is octahedral.",0
11,20,"Three areas where we have made contributions to main group element chemistry are outlined, specifically the chemistry of fourmembered ring compounds that include high-coordination main group elements, utilizing photoisomerization of an azobenzene unit for photocontrol of the coordination number of a main group element, and the compound known as the ""Asura"" bond.",0
11,21," To manipulate the coordination number of main group elements through photocontrol, the idea was to add a main group element to the 2-position of azobenzene, a molecule with an available azo group for coordination. This strategy allowed for the control of coordination number through photoirradiation, as the nitrogen coordination could be broken or rebuilt by photoisomerization. This approach also enabled the control of reactivity by irradiation. The authors initially investigated silicon compounds and synthesized 2-trifluorosilylazobenzene (45), which demonstrated pentacoordinated silicon both in solution and in the solid state through variable-temperature NMR and X-ray crystallographic analysis [69].",0
12,1,"

Chemistry teaching has historically not had much connection to everyday life, technology, society, history, and philosophy of science. This article focuses on the knowledge and perspectives that a humanistic and critical-reflexive chemistry teacher needs. The article explores various humanistic approaches to chemistry teaching, highlighting the importance of multifaceted problematization for critical chemistry teaching. This teaching strategy integrates problematized content knowledge in chemistry with knowledge about the nature of chemistry, its role in society, and its communication inside and outside the classroom. The article provides an illustration of different levels of complexity in integrating the human element into chemistry education using different facets of chemistry knowledge for teaching.",0
12,2," There is a common trend in chemistry education to prioritize content comprehension and disciplinary principles. However, there is a lack of attention given to the significant role that science, technology, society, and environment (STSE) concerns play in chemistry knowledge and practices. According to Van Berkel et al., traditional school chemistry activities do not prioritize personal, socio-scientific, and ethical questions that are pertinent to both students' daily lives and society.",0
12,3," 
In order to prepare individuals that are chemically literate and responsible chemical scientists and professionals, it is not sufficient to merely have a grasp on fundamental chemistry principles. Scientific literacy, as defined by Driver et al., encompasses scientific concepts and models, scientific processes, and societal contexts in which science is relevant. Unfortunately, chemistry education has largely focused on the first facet, neglecting to incorporate discussions and activities that facilitate learning about how chemistry can provide solutions to personal, societal, and environmental issues. This one-dimensional view of chemistry by educators hinders their ability to teach the subject in ways that are meaningful and applicable, as pointed out by Talanquer.",0
12,4," ""Hodson's definition of desirable scientific knowledge for citizens involves understanding the nature and methods of science, its history and development, and the interactions between science, technology, society, and environment. In this article, we explore ways to improve chemistry education to align with this goal through humanistic chemistry teaching, which integrates multiple ideas and aligns with humanistic perspectives in science education as outlined by Aikenhead.""",0
12,5,"

The analysis of the human element in Figure 2 can be complex and is related to different strands of STSE education. Pedretti and Nazir23 suggested categorizing these perspectives into different orientations, ranging from problem-solving focused to historical and logical reasoning focused, and finally to sociocultural, value-centered, and socioecojustice-focused. These categories correspond to different levels of complexity in the analysis, with Level 1 being Application/Design-oriented, Level 2 being Historical-and-Logical Reasoning-oriented, and Level 3 being Sociocultural-, Value centered-, and Socioecojustice-oriented.",0
12,6," Hodson proposed a framework with four levels of complexity for issues-based science education. The first level involves understanding the impact of science and technology on society. The second level involves recognizing that scientific decisions are often made based on interests. The third level involves developing one's own values and opinions. Finally, the fourth level involves taking action on socioscientific and environmental issues.",0
12,7," Gilbert suggests that using contexts in chemical education helps students find relevance in the subject and build a comprehensive understanding. He proposes four models of context, with a progression from static illustration to active involvement and critical reflection. Model 1 is just using applications to demonstrate concepts, while Model 2 sees contexts as actively influencing meanings. Model 3 involves the learners in giving meaning to the content, and Models 2 and 3 are at the Sociochemistry level. In Model 4, critical reflection is necessary, and the social dimension of context is paramount. This model is at Level 3 in Figure 2.",0
12,8," The analysis of the human element in Sjöström’s tetrahedron (refer to Figure 2) involves varying levels of complexity, which can be determined by focusing on different aspects of teaching chemistry knowledge. This is outlined in the subsequent paragraphs.",0
12,9," The approaches to teaching and learning chemistry focused on developing fundamental disciplinary knowledge are represented by the triangular base of the tetrahedron in Figure 2. Eilks et al. states that traditional chemical teaching programs belong to this level as they lack technical applications, societal issues, and personal ideas. Science teachers usually prefer abstract ""pure science"" as pointed out by Aikenhead, which explains why decontextualized chemistry courses are still widely used. At this level of complexity, contextual, philosophical, and historical facets of chemistry knowledge and practices are neglected, and chemistry curricula focus on learning core theoretical concepts and basic experimental techniques, such as how chemical bonds form and matter being atomic.",0
12,10," Existing approaches at the Pure Chemistry level typically focus on the manipulation of symbols and formulas, and on the compositional and structural aspects of chemical systems, mostly at the molecular level. These programs often encourage rule-based and case-based reasoning, but initiatives have been implemented to improve chemistry education through model-based reasoning, engaging students in building and connecting explanations at multiple levels of representation.",0
12,11," The teaching approach at the Applied Chemistry level may incorporate relevant social and environmental issues as essential questions and contextualize big ideas. Crosscutting concepts may focus on overarching themes important to modern societies such as human health. However, the chemistry concepts, ideas, and practices are often addressed in a partial and unreflective manner. Examples of this include a lack of discussion on the problems related to energy requirements of modern societies and the failure to analyze the contribution of net emissions of carbon dioxide from fossil fuel consumption to the enhanced greenhouse effect as seen in a thematic chemistry video analyzed by Christensson and Sjöström.",0
12,12," The implementation of applications in Applied Chemistry instruction typically directs the learning towards analyzing and discussing actual experiences in the real world. This results in less emphasis on merely interpreting and manipulating chemical visualizations, and more focus on connecting macroscopic and submicroscopic representations. The relevance of real-world contexts also highlights the importance of energy considerations alongside composition and structure. However, despite the increased attention to practical applications, it does not necessarily lead to a greater emphasis on model-based reasoning over rule or case-based reasoning.",0
12,13," The sociohistorical perspective sees disciplinary chemistry as a human endeavor, with a focus on uncovering the historical development of chemical knowledge. Understanding the genesis of fundamental theories can aid in learning about the nature of chemistry, which is viewed as a cultural product subject to change based on new evidence. One instructional technique used in this approach is Interactive Historical Vignettes, which dramatizes a nature-of-science incident in the life and work of chemists. To improve lesson plans, it is recommended to focus on specific NOS issues rather than general aspects. This approach has been discussed by Wandersee and Griffard and supported by Tolvanen et al.'",0
12,14,"

Sociochemistry has two strands and one of them is referred to as socioscientific. It involves making science-based decisions about the use of chemistry applications in modern societies. This strand also takes into account the ethical and societal values of the use of chemistry and its consequences in society. It specifically emphasizes the practices and products of chemistry in society while highlighting their benefits, costs, and risks. Education for Sustainable Development (ESD) is an important aspect of this strand as it is concerned with democracy and sustainability issues, and the benefit-cost-risk relations of chemical activities and their products. Life-cycle analysis (LCA) is an example of a potential use of this perspective in ESD-driven chemistry education.",0
12,15," 

At a socioscientific level, instruction should revolve around essential questions that address real-world issues, such as determining the quality of drinking water. The curriculum should also emphasize the connection between disciplinary knowledge and its impact, both positive and negative, on modern societies. Crosscutting concepts should be selected with a socioscientific perspective, prioritizing the analysis of chemical knowledge in relation to personal and social relevance, including sustainability issues. Despite the lack of attention to sustainability in many chemistry curricula, some suggest that focusing on possible solutions for a sustainable future should be a central focus of chemistry education.",0
12,16," A proactive educational approach called socioscientific approach involves building chemical models and ideas to prevent problems and find solutions. Students integrate different types of knowledge on various scales while practically addressing relevant issues. The learners are expected to analyze different conceptual dimensions from composition/structure to energy to time issues. Marks and Eilks in their works have designed and discussed various examples of integrative and contextualized perspective. Bulte and his colleagues have built contextualized educational units around structure-property relationships as a crosscutting concept. In recent efforts, educational focuses on producing, using, and disposing of chemicals to minimize their overall environmental impact.",0
12,17," Chemistry is a technoscientific subject that presents diverse opportunities to analyze, discuss, and reflect on the complex interactions between chemistry, technology, society, and environment. The teaching of chemistry involves examining social, historical and philosophical aspects. The top level in the tetrahedron in Figure 2 includes sociocritical reflection about the role of chemistry in society, as well as critical-philosophical reflection about chemistry knowledge production and application. Critical chemistry teaching emphasizes uncertainties in knowledge generation and application, and engages students in critical reflection about the nature of chemistry and of chemistry knowledge. Both content knowledge in chemistry and knowledge about chemistry and chemistry education are questioned. A critical chemistry teacher allows students to express their judgments, interpretations, and arguments which are free yet disciplined. (p 768).",0
12,18," The approach of Critical-Reflexive Chemistry involves questioning and examining chemical ideas, models, and practices through a philosophical lens. This includes determining which concepts are central and why, assessing how different models are selected and used depending on the context and goals, and identifying the key practices involved in the chemical field. The approach requires critical analysis of various ways of generating arguments and explanations in the discipline, considering the advantages and drawbacks of each. It also involves reflecting on how knowledge is represented and communicated, taking into account different dimensional scales and conceptual dimensions. Analyzing content, history, and pedagogy are all important exercises that support Critical-Reflexive Chemistry perspectives.",0
12,19," Teachers and instructors need to have a broad understanding of chemistry and chemistry education with a humanistic perspective in order to design and implement successful chemistry education, as highlighted by our analysis. To develop critical thinking in learners, teachers must become ""critical teachers"" by reflecting on the nature of chemistry knowledge and practices from sociocritical and critical-philosophical perspectives. This requires knowledge of the history and philosophy of chemistry, as well as understanding of the political, ethical, and environmental contexts. Pedagogical content knowledge is also essential to integrate the understanding of chemistry with context. As Thomas suggests, teachers themselves must learn in order to support their students.",0
12,20," According to Van Berkel et al., the traditional approach to teaching chemistry should be replaced with a more fluid, critical, and creative approach that also explores the relationships between chemistry, technology, and society. Chemistry educators should aim to move their courses towards a more empowering and transformative direction by encouraging multifaceted problem-solving, exploring uncertainties in chemistry knowledge, reflecting on the costs and risks of chemistry and its applications, and engaging in critical-democratic action for sustainability. The ultimate goal is to help students build a sense of identity as thoughtful, critical, and active citizens.",0
13,1," 

Active involvement of Ph.D. scholars in global conferences is a vital component of the educational curriculum as it allows them to assess, compare, and deliberate their scientific findings at an international level. The PFC extended financial support to 19 Ph.D. students in 2008 to attend the 2nd EUCHEMS conference (held in Torino, Sept 2008). However, for the year 2009, rather than restricting support to a single event, the PFC has introduced the 'SCNAT Chemistry Travel Award,' which is promoted in CHIMIA and on the PFC portal.",0
13,2," The University of Bern hosted the inaugural 'Young Faculty Meeting' on 28 November 2008, which was jointly organized by Karl Gademann (EPFL), Michele Cascella (University of Bern), and the author of this article. More than 20 professors and group leaders under the age of 40 from all Swiss chemistry departments attended the event. The morning session involved brief presentations of research projects, whereas the afternoon session covered the topics of 'funding opportunities,' 'work/life balance,' 'the cultural heritage of chemistry,' and 'group organization and recruiting.' Due to its success, the event will be repeated this year in a modified format. Andreas Zumbühl (University of Geneva) and Hermann Wegner (University of Basel) are the organizers for 2009 with PFC, and the location remains Bern on 17 June 2009.",0
13,3," The program 'Chemical Landmarks' began in 2009 under the umbrella of the 'Platform Chemistry' organization. Switzerland has greatly benefited from key scientific and technological discoveries in chemistry, and PFC has called for identification of the sites where these discoveries occurred. A commemorative plate and press conference will honor the inventors and preserve their memory. For more information, visit the website chemistry.scnat.ch/chemical_landmarks or refer to CHIMIA.",0
13,4," 

In 2009, preparations for the International Year of Chemistry (IYC) began, which was declared by the United Nations General Assembly to take place in 2011. The Swiss Chemical Society and «Platform Chemistry» will be collaborating to coordinate Switzerland's activities for IYC 2011. This global event will provide a valuable opportunity to showcase the benefits that chemistry can bring to society.",0
13,5," If you want to learn more about the PFC's activities, visit www.chemistry.scnat.ch. For any queries, feedback or eagerness to actively participate, do not hesitate to reach out to the Platform's President or Chief Science Officer.",0
13,6," 
The institution known as ""SCNAT Platform Chemistry"" has been recently making announcements that some of you may have encountered. This brief article aims to provide you with a more detailed introduction to our organization. The ""Platform Chemistry"" is one of six platforms that make up the Swiss Academy of Sciences, a network of over 35,000 scientists from Switzerland founded in 1815 to establish and develop the sciences. The academy's objective is to facilitate the communication and collaboration between science and society, and to achieve it, it has defined different themes and domains. To address these concerns, platforms have been created to group one or more disciplines. Each platform is supervised by an Executive Board-appointed board, with the PFC office overseen by a Chief Science Officer for the management of projects and administrative tasks.",0
13,7," The PFC, through its member associations such as the Swiss Chemical Society (SCS) and the Swiss Society for Food and Environmental Chemistry (SSFEC), encompasses approximately 3,000 scientists and experts. With their collaboration, the platform strives to enhance communications with society, the media, businesses, and politics. The PFC's primary goal is to encourage the study and advancement of chemistry at all educational levels.",0
13,8," It is imperative to enhance the appeal of science, particularly chemistry, among pupils of every academic standard. Similarly, it is essential to augment the count of novice pupils in this field.",0
13,9," The PFC's responsibility is to coordinate efforts in this field by creating a database of public relation activities conducted by chemistry departments and institutes across universities, Swiss Federal Institutes of Technology, and Universities of Applied Sciences. This database acts as a comprehensive guide for future students, current students, teachers, and the general public. The PFC actively contributes to the coordination of these activities.",0
14,1," The study aimed to explore the connection between concepts of learning and methods of learning in the field of chemistry. The researchers developed two questionnaires, COLC and ALC, to evaluate the conceptions of and approaches to learning chemistry of 369 college chemistry-major students, comprising 220 males and 149 females. Results indicated that juniors and seniors were more inclined towards higher-level COLC, like learning chemistry through adapting, than freshmen and sophomores. Regression analyses indicated that students who held lower-level COLC, such as learning chemistry by memorizing or preparing for exams, tended to employ surface learning approaches whereas those with higher-level COLC, such as learning chemistry by transforming, used deep learning approaches. However, contradictory to theoretical views, the study suggested that learning chemistry by memorizing could positively foresee a deep drive to learn chemistry, while learning chemistry by transforming was linked with a surface incentive to learn chemistry. The article discusses how special features of learning chemistry might explain these trends.",0
14,2," There has been a growing research focus on perceptions of learning in recent times, leading education and psychology experts to investigate the learning approaches and perceptions of students. Prior studies have uncovered a correlation between students' learning perceptions, learning approaches, and eventual learning achievements.",0
14,3, Tsai (2004) proposes that the way students perceive learning ought to be seen as academic epistemic beliefs in school since they are associated with students’ beliefs surrounding the character of knowledge and learning within the classroom.,0
14,4,"Moreover, a study conducted by Tsai in 2004 demonstrated that various factors might impact students' academic performance and learning outcomes. Notably, students' approaches and conceptions of learning are considered particularly significant. Therefore, it is imperative for chemistry instructors to scrutinize students' conceptions and approaches to learning, especially in the context of chemistry education. The prime objective of this research is to employ a quantitative methodology to identify the approaches and conceptions of learning chemistry among Taiwanese undergraduates while exploring the connections between the two factors. Additionally, the study investigates the differences among students' grades in their approaches to and conceptions of learning chemistry.",0
14,5," Conceptions of learning are learners' beliefs or interpretations of their learning experiences in school. The first research on this topic was conducted by Sa ̈ljo ̈ in 1979 by interviewing 90 college students and identifying five categories of conceptions: increasing knowledge, memorizing, acquisition of facts or principles, abstraction of meaning, and interpretive process aimed at understanding reality, in hierarchical order. Many subsequent studies followed this line of inquiry, including Marton et al. in Sweden who added a sixth category, 'changing as a person,' and argued that these six categories are representative of most people's conceptions of learning. In the UK, Marshall et al. studied engineering background university students' conceptions of general learning.",0
14,6," Chiou et al. (2012) suggest that further research should focus on exploring learning in specific scientific domains to better understand how students learn. As chemistry is a significant domain in science, this study aimed to investigate college students' understanding of learning in chemistry (COLC).",0
14,7," The ways in which learners approach their academic tasks and how it affects their learning outcomes are referred to as approaches to learning. The majority of educational literature recognizes two modes: a deep approach and a surface approach. Students who choose a deep approach aim to comprehend new information and concepts in a personal context and appreciate the pedagogical significance of the task. On the other hand, students who opt for a surface approach primarily concentrate on fulfilling the obvious task requirements and frequently misinterpret the objective of the task to achieve external objectives. (Bliuc et al., 2011).",0
14,8," Extensive research has been conducted on approaches to learning for various academic tasks and in different domains, as stated by Yang and Tsai (2010). Examples include problem solving in engineering, learning pharmacy, learning through discussion, and learning mathematics. Additionally, Chiou et al. (2012) have studied approaches to learning biology specifically in the field of science.",0
14,9," The variation in the deep and surface approaches to learning differs greatly depending on the subject domain, as noted by Ramsden (1992). For instance, in mathematics, surface learning may entail repeatedly calculating and following an algorithm, while in biology, it may involve matching a species' name with its particular features. Although some scientists, such as Lee et al. (2008) and Liang and Tsai (2010), have begun researching this topic in the field of science education, most of this work has focused broadly on learning approaches in science. Since the discipline of science encompasses several domains, such as physics, chemistry, and biology (Tsai, 2006), investigating students' learning approaches across these different areas may be beneficial.",0
14,10," Further research has explored how grade differences affect students' learning approaches and conceptions. Some studies have compared these differences across grade levels. For instance, Sadler-Smith (1996) discovered that older students tend to take a more profound approach than their younger peers. Similarly, Zeegers (2001) found that more experienced students were apt to use profound approaches to learning science. However, Kember (2000) found the opposite, with juniors and seniors more prone to using surface-level learning strategies. The current research aimed to examine how grade level impacts students' learning approaches and conceptions of chemistry. The study categorized undergraduates as either juniors/seniors (higher grade level) or freshmen/sophomores (lower grade level), as used by Lin et al.",0
14,11," The relationship between students' conceptions of learning and their approaches has been a popular research topic since the 1980s. In the study conducted by van Rossum and Schenk (1984), they used an open-ended questionnaire to investigate 69 undergraduate psychology students' conceptions of learning. They found that lower-level conceptions of learning were linked to surface approaches, while higher-quality learning outcomes were associated with deep approaches. Similar findings were reported in other research studies, where students with sophisticated conceptions of learning tended to employ deep approaches to learning.",0
14,12," According to Kember et al. (2004), students could have varying performances in different learning domains, where they may take on deep learning approaches in science but surface learning approaches in other domains. Furthermore, Tsai (2004) proposed that the concepts of learning are specific to each domain.",0
14,13,"

As a result, the connection between students' perceptions of studying science and their methods for studying science has become a crucial focus for science educators (Chin and Brown, 2000; Tsai, 2004; Tsai and Kuo, 2008). However, only a few research reports have examined this interaction, particularly in the context of learning chemistry.",0
14,14, The objective of this study was to examine how college students majoring in chemistry perceive learning chemistry and how it correlates with their learning approaches. This was achieved through the application of a stepwise regression model.,0
14,15," 
Despite the availability of questionnaires to examine students' learning conceptions and approaches, there is a lack of specifically designed questionnaires to measure college chemistry-major students' COLC and ALC. As a result, this study aimed to validate two instruments modified from previous research to assess these variables. Furthermore, the study investigated whether there was a difference in COLC and ALC among students with different grades. The relationship between students' COLC and ALC was then examined through correlation analysis and stepwise regression methods.",0
14,16," The research was conducted on 369 college students from 6 universities in Taiwan, comprising of 220 males and 149 females.",0
14,17,"All participants in this study were majoring in chemistry and had completed a series of related courses. Their ages varied between 18 and 25 years old with an average age of 20.2. Out of 369 students, 152 were lower grade students (freshman and sophomore), accounting for 41.2% of the total, while 217 were upper grade students (junior and senior), accounting for 58.8% of the total.",0
14,18, The survey used in this study for exploring the students' COLC was adapted from the questionnaire utilized by Lee et al. (2008) and Liang and Tsai (2010).,0
14,19," The questionnaire on conceptions of learning chemistry underwent content examination by both science education and chemistry experts, thus providing expert validation for the survey. Subsequently, the questionnaire was slightly modified in accordance with the aforementioned procedure.",0
14,20," KMO statistics were performed to check if the factor analysis of COLC and ALC questionnaires was appropriate. An overall KMO value greater than 0.50 was required, preferably close to 1, indicating dense correlation patterns that could result in reliable factors from the analysis. To determine a normal distribution of each questionnaire item, the skewness and kurtosis values were measured; skewness absolute values below 3 and kurtosis values below 10 indicate normal states. Noar (2003) suggested keeping the skewness absolute values below 1 and kurtosis absolute values below 2.",0
14,21," The appropriateness of further factor analysis can be inferred from the normal distribution properties of the COLC and ALC questionnaires items, as evidenced by the KMO values of 0.95 and 0.92 respectively and the skewness and kurtosis values that lie within acceptable limits, as depicted in Table 1.",0
14,22," Table 3 displays the results of the exploratory factor analysis for the ALC questionnaire. As recommended in a previous study (Lee et al., 2008), an oblimin rotation was conducted due to the correlation among the ALS factors. This study utilized both principal component analysis and oblimin rotation techniques to establish the factors for the ALC questionnaire items. A factor loading of greater than 0.4 was used to retain the items, resulting in the final version of the ALC questionnaire containing 18 items (a comprehensive list can be found in Appendix 2). The Cronbach's alpha coefficients for the four factors were 0.90, 0.88, 0.92, and 0.74, indicating a desirable level of internal consistency. Furthermore, the total variance accounted for in the ALC was 70.62%. The factor means and standard deviations of the ALC are shown in Table 3. As Table 3 demonstrates, the ""Surface Strategy"" factor received high scores from students (an average of 4.15 per item).",0
14,23," The correlation between ""Memorizing"" and ""Transforming"" COLC factors and two ALC factors of ""Deep Motive"" and ""Deep Strategy"" is deemed statistically significant and positive with a correlation coefficient of 0.26 and 0.58 for ""Deep Motive"" and 0.23 and 0.80 for ""Deep Strategy"", respectively, with a p-value of less than 0.001. Conversely, a negative correlation was observed with ""Testing"" factor and two ""Deep Approach"" factors with a correlation coefficient of -0.30 and -0.24 for ""Deep Motive"" and ""Deep Strategy"", respectively, with a p-value of less than 0.001.",0
14,24," The relationship between the lower-level COLC 'Memorizing' and deep approaches needs further discussion as it contradicts the common result of a negative relationship between lower-level conceptions of learning and deep learning strategies. Chemical representations like formulae, symbols, equations, and structures are extensively used in professional journals and textbooks to describe and explain chemical reactions and phenomena. Thus, students, regardless of their experience, need to memorize some aspects of chemistry to learn it effectively.",0
14,25," Positive relationships were discovered between the ""Memorizing"" and ""Transforming"" aspects of the COLC and the ""Surface Motive"" factor of the ALC, with correlation coefficients of 0.37 and 0.78, respectively, and a statistical significance of p<0.001. Additionally, the ""Surface Strategy"" factor of the ALC was found to have positive correlations with ""Memorizing,"" ""Testing,"" and ""Calculating and Practicing"" of the COLC, with coefficients ranging from 0.31 to 0.44, and p<0.001.",0
14,26," The t-test conducted in this study revealed grade differences in undergraduate students' COLC and ALC, suggesting a positive progression in learning from beginner to advanced levels.",0
14,27," Based on the findings, memorization is a significant factor in predicting surface approaches to learning chemistry. Additionally, testing is another COLC that positively predicts surface strategies for learning chemistry. These results are consistent with previous research on science learning, as demonstrated in studies by Lee et al. (2008), Tsai and Kuo (2008), and Chiou et al. (2012).",0
14,28," It was unexpected to discover that the advanced ideas of learning chemistry, known as ""Transforming,"" could positively forecast ""Surface Motive."" This means that pupils with higher-level COLC are more likely to embrace the surface motive of studying chemistry, which entails learning it only to meet the course requirements and to perform well to obtain a desirable job in the future.",0
14,29," The findings from the regression indicate that the COLC of college chemistry-major students have a significant impact on their ALC. Typically, those with lower-level COLC such as 'Memorizing' and 'Testing' tend to adopt surface learning approaches. However, their surface motivation can also be predicted positively by higher-level COLC such as 'Transforming'. To conclude, COLC plays a crucial role in chemistry learning among college students.",0
15,1," Chemistry core ideas have been a focus of research in science education for the past few decades. The connotation of these core ideas has been explained in theory, and they have been used to organize chemistry curriculums in practice. The Framework for K-12 Science Education and the Next Generation Science Standards organize science content around disciplinary core ideas, crosscutting concepts, and science (and engineering) practices. A similar approach can be seen in the Chinese Chemistry Curriculum Standards, which also emphasize chemistry core ideas.",0
15,2," The analysis of chemistry core ideas in science education standards is of great importance, given the significance of these ideas for learning and the authority of science education standards for teaching. Talanquer and Sevian conducted a comparative analysis of chemistry core ideas between the National Science Education Standards, the Framework for K-12 Science Education, and the Next Generation Science Standards in 2014. It is therefore crucial to examine how chemistry core ideas are presented in the Chinese Chemistry Curriculum Standards and to compare the similarities and differences of these ideas between China and the United States. These questions are both theoretically and practically important as science education is increasingly becoming global, driven by economic globalization.",0
15,3,"Chemistry is often seen as a typical scientific field that explores the qualities, makeup, and arrangement of matter, as well as how these aspects alter and affect energy. Recently, some scholars have emphasized that chemistry should also be viewed as a technoscience. Scientists in this area not only seek to explain and anticipate the characteristics of chemical substances but also endeavor to create new chemicals that may have practical applications. This perspective guided the creation of an analytical framework for the study at hand.",0
15,4,"The core of chemistry revolves around the concepts of ""substances"" and ""processes,"" as these two themes feature prominently in the subject. Thus, the CCCS and NGSS encompassing chemistry focus on these ideas. In our analysis, we emphasize the crucial disciplinary core ideas that shape the fundamental scientific understanding of key principles, concepts, and methods. Students acquire varying levels of comprehension about chemistry concepts during different educational stages, which can have an impact on their grasp and application of chemistry core ideas.",0
15,5," The core ideas of substances and processes in chemistry were analyzed using dimensions such as state of matter, chemical composition, properties, and structure, as well as the relationship between composition, structure, and properties. The macro, molecular, and subatomic levels were also considered. The conceptual framework by Claesgens et al. and the works of Jensen and Talanquer on chemistry knowledge greatly influenced the selection of conceptual dimensions and levels.",0
15,6," In China, chemistry is taught as a separate subject from biology and physics in schools, with its own corresponding standard known as CCCS. CCCS is organized by grade level and divided into three bands for junior high school, compulsory high school, and optional high school chemistry. While high school chemistry in grades 11-12 is optional, it is still mandatory for students to complete at least one level-one module in order to meet graduation requirements. This ""compulsory in optional"" structure is a unique feature of CCCS.",0
15,7," The CCCS presents a comprehensive and diverse range of chemical core ideas in Table 1. The core ideas are categorized into three types, namely Theoretical Concepts, Element and Compound Concepts, and Chemical Terminology and Calculation Concepts. Furthermore, the representation of chemistry core ideas follows the learning progression from macroscopic to molecular to subatomic levels, which is designed to enhance students' cognitive development and facilitate their learning of chemistry. Through analyzing particulate and molecular models, students can describe, explain, and predict the composition-structure-property relationships of different materials and substances.",0
15,8," The NGSS7's system architecture is shown in Figure 2. For the chemistry core ideas, we opted for Disciplinary Core Ideas from the Performance Expectations section, with most of the substances and processes featured in the physical sciences category (highlighted in red). We acknowledge that the NGSS' Performance Expectations offers a unique set of learning objectives that merge science and engineering practices, key disciplinary ideas and crosscutting concepts. However, the primary purpose of the Disciplinary Core Ideas, within the NGSS' context, is to clarify the Performance Expectations and its origin.",0
15,9," The Disciplinary Core Ideas section in the NGSS primarily covers theoretical chemistry concepts such as atoms, molecules, and bond energies, while element and compound concepts and chemical calculations receive less attention. The focus of the NGSS appears to be on modeling and argumentation, and the representation of chemistry core ideas emphasizes the molecular and subatomic levels. This information can be found in Table 2.",0
15,10," The NGSS and CCCS share a common goal of promoting scientific literacy among high school graduates, preparing them to be informed citizens. A comparative analysis of the chemistry core ideas covered in both documents is presented, including content representation, statement forms, conceptual levels, and learning progressions. A summary table is provided to highlight the differences between the two documents.",0
15,11," Chemical terminology concepts and chemical calculation concepts are essential for communication, quantitative research, and understanding core chemistry ideas. These concepts should be highlighted in curriculum standards. However, the CCCS includes more practical and socially relevant chemistry activities than the NGSS, which lacks attention to the transformative and productive nature of chemistry as a technoscience.",0
15,12," The NGSS's Disciplinary Core Ideas section prioritizes theoretical concepts, but it's worth noting that the Performance Expectations section contains some specifics, such as ammonia, methanol, carbon dioxide, synthetic material, mixing zinc with hydrogen chloride, and combustion reactions. These inclusions somewhat make up for the missing concepts emphasized before.",0
15,13," 
Although the CCCS provides a relatively comprehensive and strict representation of chemistry core ideas, the NGSS places more emphasis on other chemistry concepts, such as processes involving molecular collisions, atom rearrangement, attraction and repulsion between electronic charges, as well as nuclear processes. These concepts are centered around the molecular and subatomic levels and aim to explore materials and substances based on their particulate nature. Consequently, the NGSS emphasizes the use of modeling, argumentation, logical thinking, and imagination in chemistry learning.",0
15,14," It is important to consider the merits and inadequacies of the different statement forms for chemistry core ideas in the two documents. While the CCCS provides a clear action verb that defines the fundamental requirement for teaching and evaluation, some verbs may be too implicit and difficult for teachers and students to differentiate. Furthermore, the CCCS only names some core ideas without specifying their meanings, which can lead to varying understandings among teachers and students. In contrast, the NGSS uses specific scientific language to express the meanings and interrelationships among core ideas, making it easier for teachers to understand and teach them with clarity.",0
15,15," The CCCS prioritizes macro level chemistry core ideas for grades 7-9, with a focus on facilitating beginner learning and cultivating an interest in chemistry. Across all grade levels, emphasis is placed on macroscopic ideas about processes, and slightly less on the molecule and subatomic level. In contrast, the NGSS emphasizes the micro level, particularly in grades 9-12, with nearly all ideas about substances and processes focused on the molecule and subatomic level. This suggests that the micro domain of chemistry core ideas should be reinforced in higher grades. Ultimately, the CCCS emphasizes descriptive chemistry while the NGSS prioritizes models and modeling.",0
15,16," We have noticed variations in the portrayal of chemistry core concepts in science education standards between China and the United States, as suggested in our comparative analysis. Examining these divergences is crucial as it can contribute to our comprehension of chemistry core ideas and prompt us to reflect on the objectives of science education. Specifically, we delve into three crucial aspects that significantly impact the representation of chemistry core ideas in both documents being evaluated.",0
15,17," One reason for differences in content representation of chemistry core ideas is the varying research perspectives on science education. In the United States, chemistry curriculum is studied within the larger context of science education, which emphasizes STEM education, cross-cutting concepts, and general concepts. American education standards classify science knowledge into physical sciences, life sciences, and earth and space sciences, with chemistry core ideas primarily presented in the physical sciences. Understanding the interdisciplinary nature of the US chemistry curriculum is important for teachers who may not be chemistry specialists, and can provide context for the area of chemistry, which may be lacking in Chinese and other countries' separate disciplinary curriculum standards.",0
15,18,"
Chinese schools currently use a subject-based curriculum that separates chemistry into its own science discipline. While the CCCS outlines core chemistry ideas, it can lead to a lack of connection between chemistry and other subjects. To improve this, teachers should focus on integrating concepts and showing how chemistry relates to other disciplines. This will help students better understand and apply chemistry in real-world contexts.",0
15,19," The NGSS presents chemistry core ideas without action verbs while Chinese educators focus on students' understanding of chemistry concepts and specific knowledge. CCCS statements take the form of action verbs to provide basic understanding requirements, but some core ideas are presented only by name without their specific content. Further research is needed to explore the meaning of chemistry core ideas from the perspective of discipline ontology.",0
15,20," The difference in teaching approach between China and the United States leads to varying levels of comprehension and learning progressions for core concepts in chemistry. China emphasizes the epistemology of education, which requires a gradual progression from basic to complex and emphasizes student development. As a result, the Chinese Curriculum Standards for Chemistry (CCCS) follow a coherent learning progression from macroscopic to microscopic levels. However, the CCCS lacks comprehensive attention to molecular and subatomic explanations when compared to the Next Generation Science Standards (NGSS) in the United States. Therefore, the CCCS may not fully represent the nature and power of chemical knowledge, and more reflection and discussion is necessary among educators.",0
15,21," 

The curriculum theories in the United States are varied, including subject-based, problem-based, student-centered, and multicultural education. The collision and fusion of these theories affects the selection and presentation of curriculum. Table 2 indicates that recent research results have not fully influenced science education standards. The NGSS has poor representation of chemistry core ideas for grades 9-12, with a focus on molecular and subatomic characterizations. While abstract thinking improves with age, the concentration on the micro level in high school raises questions. Research in science and chemical education shows that students struggle to understand and apply different assumptions of atomic and molecular theories of matter. Some ideas in the micro level of chemistry core, such as molecular collisions, atomic rearrangements, and bond energies, are even hard for high school seniors to grasp.",0
15,22," Upon analyzing and comparing the representation of chemistry core ideas about substances and processes in both CCCS and NGSS, we found that CCCS presents these ideas comprehensively with a good learning progression. However, there are still areas requiring improvement. Specifically, the selection of teaching contents needs to pay more attention to connecting and integrating chemistry core ideas with other disciplinary ideas. Statement forms must explicitly and completely present the specific meanings of core ideas. When considering the macro level, understanding of the micro level should be reinforced as well. Regarding learning progressions, exploring different levels of core ideas among different grades can help improve coherence. Furthermore, US science education standards should emphasize more specific types of substances and chemical processes while also paying attention to the macro level of core ideas, thus facilitating students’ chemistry learning.",0
15,23," 

The distinct variations in the core ideas of chemistry in both documents showcase diverse outlooks on the objectives of science education, the chemistry goals, and the anticipation regarding effective teaching. Our comparison and recommendations have the potential to impact the reforms in chemistry education and science education worldwide, not just for the United States and China. Additionally, we encourage increased attention and interaction between countries concerning the science education standards to prepare for the shared objective of fostering scientifically literate future citizens.",0
16,1," The growing problem of antibiotic resistance on a global level is a grave concern, as it could lead to a post-antibiotic era where common infections no longer respond to treatment. Many antibiotics used in the medical field affect ribosomes, the crucial machines responsible for translating genetic code into proteins. The structures of ribosomes from various pathogens have allowed for a better understanding of how antibiotics work and revealed issues with species-specific susceptibility. Interestingly, the catalytic site of the ribosome is highly conserved and may represent a prebiotic RNA entity that played a role in the origins and evolution of life.",0
16,2," Supramolecular chemistry is currently researching self-organizing systems, which are capable of spontaneously creating specific and functional supramolecular architectures through self-assembly using the molecular information stored within their covalent framework.",0
16,3," Supramolecular chemistry and molecular chemistry are both dynamic due to the ability of their molecular components to form and break reversible interactions and covalent bonds respectively, allowing for a continuous reorganization and exchange of building blocks. This characteristic is described as Constitutional Dynamic Chemistry (CDC) and applies to both levels of chemistry.",0
16,4," CDC utilizes dynamic diversity for the purpose of variation and selection, and responds to internal or external factors by employing dynamic constitutional diversity in order to achieve adaptation.",0
16,5," 

Component selection at both the dynamic molecular and supramolecular levels can be influenced by the creation of an organized phase. This can occur on 2D surfaces, in soft matter such as gels or liquid crystals, and even in 3D solid crystals. The discussion will focus on systems that undergo self-organization-driven adaptation, highlighting the emergence of an adaptive chemistry.",0
17,1,"

This article discusses a type of chemistry education that focuses on Bildung, which involves critical and reflective discourse on chemistry. This is in contrast to the more common form of chemistry education that follows mainstream discourse. Bildung-oriented chemistry education includes knowledge not only about chemistry concepts, but also about the nature and societal role of chemistry. The article also presents Mahaffy's tetrahedron model, which builds upon Johnstone's chemical triangle by adding a human element to represent a more holistic approach. The top of the tetrahedron is further subdivided into applied chemistry, socio-cultural context, and critical-philosophic approach. The professional identity of the Bildung-oriented chemistry teacher is informed by fields such as Philosophy of Chemistry, Science and Technology Studies, and Environmental Education, and emphasizes both the benefits and risks of chemistry and its applications through a socio-critical approach.",0
17,2," It is justifiable to advocate for Bildung-focused chemistry education by using a risk society analysis (Beck 1992; Ekberg 2007). In practicality, this would involve incorporating more ethical and socio-cultural perspectives into teaching. This article introduces a framework for the content and perspectives involved in teaching chemistry in such a way. The intent is to cultivate critical, conscious, and action-capable citizens, also known as 'chemical literacy' (Shwartz et al. 2005). This pertains to the role of chemistry in scientific literacy (Laugksch 2000; Roberts 2007; Holbrook and Rannikmae 2009).",0
17,3," In an earlier publication, Sjo ̈stro ̈m (2007) raised concerns about the conventional approach to chemistry and proposed an alternative discourse that could replace the overly modernistic and reductionistic approach with a more socio-critical and comprehensive framework. Such a discourse would acknowledge chemistry as a cultural phenomenon and examine it within a cultural context. As illustrated in the first and second columns of Table 1, I divided the conventional discourse of chemistry into two categories: disciplinary and societal.",0
17,4," The focus of this paper is on the importance of reflective and critical teaching of chemistry, which is also known as Bildung-oriented chemical education. This approach stands in contrast to the mainstream teaching methods outlined in columns 1 and 2 of Table 1. The paper is grounded in an in-depth analysis of relevant literature, and takes a theoretical and position-based approach to exploring this topic.",0
17,5," 'The German term 'Bildung' is a fundamental concept in Continental education while the Swedish equivalent is 'bildning' and Danish and Norwegian refer to it as 'dannelse'. There is no direct English translation of the term, although it is sometimes interpreted as 'liberal education' and interrelated to the notion of 'citizenship'. According to Vásquez-Levy, Bildung involves the development of critical consciousness, self-discovery, character formation, and an exploration of truth, value, and meaning through contemplation and insight.'",0
17,6," The term Bildung is used in the international educational literature as there is no precise English translation available. A special issue on Bildung was published in the journal Educational Philosophy and Theory in 2003. According to the writer Wimmer (2003, p. 185), Bildung encompasses everything that is not covered by socialization, education, or instruction, while also standing for them all. It is considered the central critical concept of modern pedagogy. Additionally, the concept is utilized in the international environmental and science education research literature as well.",0
17,7," To discuss Bildung-oriented chemistry education, the article utilizes Johnstone's triangle, which outlines the disciplinary content in chemistry education, and Mahaffy's extension of the triangle that incorporates human perspectives. The author proposes breaking down the top of the tetrahedron into three levels: applied chemistry, socio-cultural context, and critical-philosophic approach. However, prior to diving into Bildung-oriented chemistry education, the article first explores and details the conventional discourse in chemistry education.",0
17,8," Chemists' beliefs and values, both explicit and implicit, are referred to as the ""discourse of chemistry"" (Sjo ̈stro ̈m 2007). This term can also encompass dominant societal ideas that influence chemists' practices and conceptions, even if they are not aware of it. Positivism, objectivism, reductionism, rationalism, modernism, and scientism are commonly used labels to describe chemists' views of their science and its role in society, including chemistry teachers and textbook authors. In the following discussion, these labels will be examined, along with the types of knowledge emphasized in most school chemistry courses.",0
17,9,"

In analyzing how chemistry is presented in secondary school textbooks, Östman (1996) classified the discourse using terms like objectivism, atomism, and instrumental rationality. One notable feature that he observed in the textbooks was their emphasis on making human beings the dominant force over nature. Aikenhead (2006) contends that many high school science textbooks attempt to promote a positivistic view of science, consistent with the traditional science curriculum. Moreover, science teachers often prioritize teaching abstract and decontextualized aspects of science. Van Aalsvoort (2004) has corroborated the notion that logical positivism can contribute to students feeling disconnected and disengaged from chemistry lessons that they perceive to be irrelevant.",0
17,10," Objectivism holds that scientific facts remain unaffected by the setting in which they are observed. Scientists, on the whole, perceive nature to be unbiased and authentic, yet post-modernists assert that scientific facts are created, affiliative, and reliant on context. While science is generally presented as unprejudiced knowledge, researchers inevitably make assumptions and value judgements, according to Christensen. Norris, on the other hand, favors an ""epistemic distance"" between realism and relativism, placing equal weight on both aspects.",0
17,11," 

The discourse of chemistry commonly exhibits a strong reductionist approach, as noted by Whitesides (2004, p. 3634). This perspective emphasizes the importance of submicroscopic components and a mechanistic worldview, as described by Early (2004, p. 144), which can sometimes overshadow the significance of the whole. As a result, some students may perceive chemistry as less relevant to their lives and pursue other topics instead.",0
17,12," The perspective of rationalism holds that scientific knowledge and methods are impartial to values. Schummer (1997) points out that the rationalistic stance of numerous chemists hinders communication with the public, as they prioritize rationality as an integral aspect of professional ethics. In addition, the rationalistic view oftentimes implies that it would be desirable for scientific authorities to have greater political power.",0
17,13, The International Year of Chemistry in 2011 focused on showcasing numerous applications of chemistry in society. One of the themed months in Sweden during this year was fashion and its relation to chemistry.,0
17,14," 

The book ""Jakobsson 2003"" discusses the usefulness of TeflonÒ, a polyethen polymer with fluorine atoms instead of hydrogen atoms, in making pans. It is referenced as an excellent material for this purpose. Both TeflonÒ and GoreTexÒ contain chemicals categorized as perfluorinated compounds (PFCs).",0
17,15," Many chemistry teachers and chemists tend to dismiss the public's concerns about chemicals and view them as ""chemophobic."" They often overlook the fact that the public blames chemicals for issues like water quality, air pollution, and herbicides. They fail to recognize that while human life cannot sustain without chemicals, the public is often unaware of their importance. This attitude is demonstrated through a quote from an abstract to an oral presentation held at the 18th International Conference on Chemical Education.",0
17,16," Students often struggle to understand the objectives of chemistry because defining the aims of the field poses philosophical challenges (as noted by Schummer in 1999). Additionally, individual teaching units emphasize various types of knowledge, making it difficult for students to grasp the overarching purpose of the subject (as observed by Van Berkel et al. in 2009). Schummer further explains that traditional concepts for distinguishing between science and technology do not successfully apply to chemistry, making it hard to comprehend the discipline's essence from a philosophical perspective.",0
17,17," According to Van Berkel et al. (2009, pp. 34–35), there are several emphases that should be addressed in chemistry education, including Correct Explanations, Solid Foundation, Structure of Science, Self as Explainer, Scientific Skill Development, Everyday Coping, and Science, Technology and Decisions. However, it is problematic when these emphases are mixed in the same teaching units, as it can lead to confusion about what should be learned and why. In order to avoid this confusion, it is necessary to make clear and consistent decisions about the curriculum emphasis of each unit. When the message about what is to be learned is unclear, teachers and students tend to default to the dominant form of chemistry education, which prioritizes the Solid Foundation emphasis.",0
17,18," Three empirical studies about chemistry teaching in (upper-)secondary schools in Sweden have recently been published. Among them, Maria Kouns (2010) conducted an extensive study where she observed 31 chemistry lessons in an upper-secondary school science class. The teacher was highly experienced and well liked by the students. In addition to classroom observations, the study also included interviews with both the teacher and the students as well as four questionnaires completed by the students. It is therefore interesting to pay attention to the current emphasis in chemistry teaching.",0
18,1," The flow of matter through a living organism is defined by the central feature of metabolism, which involves the transformation of molecules through sequential reactions. These reactions are categorized into pathways that can be cyclic, unidirectional, or branched, and are interconnected at shared intermediates. These highly complex networks of transformations form an organism's metabolome. Manipulating dynamic structural interconversions through external stimuli can help understand the fundamental principles underlying biological processes and aid in the design and construction of biomimetic molecular machines.",0
18,2,"

Various signals have the ability to modify the composition of dynamic systems, resulting in the conversion of one structure into another. These signals encompass light,[4] pH value,[5] chemical templates,[6] temperature,[7] solvent,[8], and concentration fluctuations.[9] The usage of subcomponent self-assembly[10] to form complex metal-organic structures[11] offers the opportunity for these structures to regenerate dynamically by exploiting enthalpic or entropic forces.[2,12] This investigation analyzes how a system consisting of diverse self-assembled cadmium(II) complexes reacts to a range of chemical signals, producing a variety of multinuclear architectures.",0
18,3," Cage 3 has a volume of 196 3, which is 60 3 larger than its FeII analogue made with aniline. In the crystal structure, there is one acetonitrile molecule found inside the cavity and two others in van der Waals contact with the faces of the tetrahedron. According to NMR spectroscopy, 3 binds to triflate ions with an association constant of 43 m1. Despite being a cryptate structure, its affinity for triflate is approximately 103 times weaker than that of the noncryptate cage made from FeII ions and anilines. However, it is similar to the affinity observed for an iron(II) cage assembled from A and aliphatic amines.",0
18,4," Despite multiple unsuccessful attempts to detect the parent ion of hexagonal prism 4 in ESI-MS, other species that are similarly highly charged and held together by weak coordinative interactions are known to be challenging to detect. However, elemental analysis confirms its formulation, and the complex NMR spectra observed in solution are consistent with its solid-state structure.",0
19,1," 

Chemistry is a challenging subject for many students, whether they are in high school or college and non-chemistry majors. One of the main difficulties students face is trying to create a mental model of atomic-level conditions and how it relates to large-scale phenomena. To help with this, chemists have created various computer programs to visualize how atoms interact. Despite the benefits of these tools, they are seldom used to teach introductory chemistry concepts at the secondary or college level, as most studies focus on advanced college classes. Also, few studies have explored how to use these programs as learning aids for high school or non-science majors. Nevertheless, some resources are available for high school-level students.",0
19,2," The development of each activity was guided by collective goals. Firstly, the activity was designed to address common student misconceptions about the topic by utilizing misconceptions from the ChemSource SourceBook and personal experience. A list of these misconceptions can be found in Table 1. Secondly, the student-centered portion of the activity needed to be presented in a manner that is easily accessible to students with limited chemistry knowledge and literacy skills. In order to achieve this, I refrained from incorporating complicated chemical terminology and thoroughly defined and explained any new vocabulary. An excerpt from the introduction of the Atomic Orbitals activity is included below to demonstrate the writing style.",0
19,3," The activities were designed with the principle of dividing them into short segments where students alternate between reading for knowledge and applying that knowledge through exercises. This ensures engagement and promotes learning. Additionally, each activity is self-contained, although previous completion of the Getting Started activity is recommended. Finally, instructor guides are included for each activity, outlining expected student background, major concepts addressed, objectives, typical results, and expected time.",0
19,4," The utilization of Gaussian 09 and GaussView for graphical interface in these activities can be customized to other software like WebMO.21, as the underlying concepts remain the same. By using advanced software, students showed more interest as compared to animations or basic simulations, and were motivated to tackle the challenges that came their way. More information is available in the section regarding pilot programs.",0
19,5," The two activities had both collective and individual design goals. The Getting Started activity had various sections to familiarize students with the software, with stepwise procedures and a parallel worksheet for emphasis. The activity need not be completed in full before using the other activities, and certain sections can be skipped if necessary.",0
19,6," The activity called Shapes of Molecules introduces students to key terminology necessary for comprehending why molecules possess specific shapes, along with the five common molecular shapes including linear, bent, triangular planar, triangular pyramidal, and tetrahedral. As this activity is designed for beginners, I have restricted the shapes to those that are more likely to appear in other scientific courses. The main focus of this activity is to develop the skill of predicting an optimal three-dimensional geometry from a Lewis structure based on the number of lone pairs and atoms connected to a central atom. Due to the target audience, this activity does not touch upon the deviations from ideal geometries. The first section of the activity revolves around teaching essential vocabulary, while the second part requires students to draw Lewis structures, build and measure various molecules, and determine their corresponding shapes with the aid of software.",0
19,7," Students often mistakenly believe that the number of electron pairs around a central atom determines the molecular geometry of the resulting molecule. This leads to a shortcut of just counting the electron pairs and assigning the molecular geometry based on that count, which is incorrect. For example, CH4 and H2O both have four electron pairs around their central atoms, but H2O is actually a bent molecule. To address this, the module teaches students to separately count the number of atoms and lone pairs attached to the central atom and then add them together to identify the correct molecular geometry. The goal is for students to recognize patterns in the relationship between bonding and lone pairs and different molecular geometries.",0
19,8," There are three different groups of molecules included in the activity that can be used to vary the instruction. The first group consists of simple neutral structures with single bonds that follow the octet rule and display four of the five possible shapes. Since no triangular planar structures meet the other criteria in this set, they are omitted. The second set comprises structures with multiple bonds and demonstrates a variety of triangular-planar structures as well as a linear molecule consisting of more than two atoms (CO2). The final set includes molecules with multiple bonds, partial octets, and non-zero charges. Each collection is shown on a separate page for easy combination of the sets.",0
19,9," 
The ability of students to draw correct Lewis structures may vary greatly, so the chemistry activity provides worksheets with pre-filled Lewis structures. These worksheets can be used by the instructor to remove the need for students to create their own. However, students must still be able to understand and interpret them. During data analysis, students search for connections between the three-dimensional shapes and Lewis structures to discover the correlation between the two types of molecular representations.",0
19,10," The Shapes of Molecules activity's Supporting Information includes a teacher's guide, worksheets, and activity. Four versions of worksheets have been given, with one blank all columns, one with only the Lewis structures, one filled with Lewis structures, the number of atoms and lone pairs on a central atom filled in, and one with only the sketch of the molecule column empty.",0
19,11," The activity on Atomic Orbitals teaches the distinctions between orbits and orbitals, then discusses the composition of orbitals and how they relate to waves. Various atomic orbitals (s, p, d, and f) are then examined to reveal the connections between orbital size and energy level, orbital type and the number of orbitals in a subshell, and orbital type and shape. To simplify the fundamental concepts, the use of jargon is kept to a minimum. In addition, a worksheet accompanies the activity, which has questions that pinpoint common student misunderstandings. The answer key for the worksheet is included in the text. Through sketching general shapes and sizes of orbitals, students are better able to grasp the concepts by creating non-linguistic representations. The Gaussian software is used in this section to provide realistic sizes and shapes of orbitals. The Atomic Orbitals activity, teacher's guide, and worksheet can be found in the Supporting Information.",0
19,12, The pilot experiments were conducted in a computer lab situated in a high school library using eight personal computers with settings commonly seen in today's high schools. Supporting Information for this article includes duplicate copies of these exercises.,0
19,13," The pilot involved 95 students, including 24 in an honors-type section of high school chemistry and 71 in three midlevel sections of college preparatory high school chemistry. The students worked in groups of three for three 48-minute sessions, with the first two sessions separated by a week and the final session two days after the second. Each group had a designated ""driver"" who operated the computer and mouse while using the software during the first two sessions. The final session was reserved for analysis and group discussion. Before beginning the Shapes of Molecules activity, the students completed several parts of the Getting Started activity, including building, rotating, and measuring simple molecules.",0
19,14," 

The students demonstrated high levels of engagement when using the Gaussian and GaussView software, with around 90% remaining focused throughout both sessions. Despite their limited chemistry experience, the students were able to effectively utilize the software to construct molecules, showing a willingness to experiment and persevere until achieving their desired results. It should be noted that the software is typically geared towards users with advanced chemistry knowledge and keen chemical intuition.",0
19,15," These findings indicate progress in comparison to my previous classes where ball and spring molecular models were utilized. However, the absence of a control group in this pilot study prevents confirmation. In past classes, around 65% of students at the upper level and 40% at the mid-level could correctly recognize the molecular structure when presented with a Lewis structure. Additionally, approximately 75% of upper-level students and 60% of mid-level students could accurately respond to questions similar to the seven utilized in all the assessments in previous classes. The outcomes suggest a converging performance gap between upper and mid-level students.",0
19,16," The pilot study effectively aided students in comprehending the essential vocabulary and concepts required to determine molecular shape, as indicated by the results. Additionally, the findings also suggest that the students' understanding remained consistent over the course of three weeks. However, while the application questions on the extended post-test yielded slightly less favorable results, it is recommended to provide an extra session to allow students to apply the knowledge gained from this activity for optimal learning outcomes.",0
19,17," The second pilot study had three parts - a pretest, Atomic Orbitals activity, an immediate post-test, and a longer-term final post-test. The first two assessments had the same seven questions, and the final post-test focused on the application of concepts instead of memorized answers. The questions aligned with most learning objectives listed in Table 1 and were all open-ended. Two learning objectives were not evaluated since the questions were difficult to phrase or ended up being omitted. Table 4 provides a description of each question, and the questions themselves are available in Supporting Information.",0
19,18," 

At the high school level, students often only have access to chemistry-related materials in the form of animations and simulations on computers. However, these activities can be mistaken as games by inexperienced students, leading them to approach their learning casually. By utilizing research-quality software, students are more likely to recognize the importance of their learning and take it seriously. Pilot studies have demonstrated that using such software can lead to increased engagement, achievement of learning objectives, and retention of knowledge. Therefore, even students with limited chemistry experience can benefit from the use of research-quality software.",0
19,19, The activities are tailored to cater to the requirements of beginner-level high school and introductory college chemistry students regarding both content and literacy level. Upgrading the complexity level of the questions and the range of molecules used can also allow these activities to be used with students in advanced-level chemistry courses. The incorporation of research-grade software helps students to realize that their instructor holds high expectations for their learning and believes that they have the capability to meet those expectations.,0
19,20," The Supporting Information contains duplicates of the three activities such as student handouts, instructor guides, and standard responses to activity questions. It also includes an unevaluated fourth activity on periodic trends, all inquiries utilized in the evaluations, and a plan file for GaussView. These documents were reprinted with Gaussian, Inc's consent.",0
20,1," 

The focus of this paper is two case studies that demonstrate the incorporation of problem-based learning (PBL) in transportation courses offered by University College Dublin (UCD). These courses are typically taken by civil engineering students during their penultimate and final years, at which point they are expected to be more independent in their learning and begin to transform from passive learners into active researchers. UCD has a learning strategy that encourages their graduates to possess independent learning skills.",0
20,2," The upcoming segment provides a concise explanation of PBL and its applications in engineering programs. Following that, the paper details the case studies, outlining the two courses where PBL was utilized in UCD civil engineering. Lastly, the paper analyzes the achievements and drawbacks of this implementation procedure.",0
20,3," PBL, which stands for problem-based learning, is a widely adopted approach that promotes student-centered learning. Students engage in small groups to identify problems and devise solutions for them. At the beginning of a PBL study, students are given a problem, which they analyze together and establish their learning objectives. Lectures, tutorials, and Q&A sessions follow, providing essential support for the identified problem. PBL teaching prioritizes the student, allowing them to develop critical thinking skills. (Barrett 2005).",0
20,4," PBL has proven successful in engineering courses across multiple countries. Studies by Young and Holgate (1994) and Said et al. (2005) detail the use of PBL in civil and electrical engineering classes, respectively. PBL is more student-centered and increases student participation and motivation, according to Kolmos (1996). Additionally, Veldman et al. (2008) found that PBL helps improve the communication, teamwork, and cooperation skills commonly lacking in engineers. Johnson (1999) supports these findings while highlighting how PBL and cooperative learning enhance writing skills. While introducing PBL may involve challenges, its benefits for student learning and skills development make it worthwhile.",0
20,5," Student evaluation in PBL courses presents a challenge that requires innovative assessment methods (Acar 2004, McDonald 2005, Veldman et al. 2008) since group work may disadvantage stronger students due to group marking (Acar 2004). Reeves and Laffey (1999) state that evaluating PBL work is complicated and comparing student performance is difficult. Enrolling in a PBL course may pose considerable assessment difficulties.",0
20,6,"Provided is a context for the case studies, stating that the civil engineering degree offered at University College Dublin is a four-year program. The final two years of the program are primarily focused on civil engineering topics. Students are given the option to choose elective courses centered around transportation during the third and fourth years.",0
20,7," ""During the fourth year, students delve into modelling and focus on identifying the pros and cons of various transport models. They develop critical thinking skills and assess transport models effectively. The students also learn about traffic engineering, including the role it plays in road safety and factors that can be modified to enhance it, such as driver behavior.""",0
20,8," PBL was implemented in both sections of the course to help fourth year students transition from learning to research, as they are near graduation and will either become engineers or continue their academic careers. As they need to apply the knowledge gained in lectures to solve problems and research, PBL was used to teach them the essential skills necessary for these tasks.",0
20,9," The implementation of PBL was consistent in both academic years. Students received 3 hours of weekly lectures, and a set of tutorials was established to facilitate their engagement in PBL.",0
20,10," In their third year, the students were newly introduced to PBL with the intention of exposing them to the concept and preparing them for utilizing it in their fourth year. A total of 35 students were present in this class.",0
20,11," 

Transport policy can be challenging to grasp, leaving students disengaged. While lectures can introduce different policies and their corresponding theories, the ability to critically analyze and question their implementation is necessary. Research into policy implementation is key in building this capacity, leading to the decision to utilize problem-based learning (PBL) as a solution for tackling transport policy issues.",0
20,12,"During lectures, students were acquainted with various transportation policies and provided with examples of their implementation. In the tutorial during week four, students were divided into groups of 5 and presented with a newspaper headline that addressed the potential introduction of one of the more contentious policies examined in class - the privatisation and deregulation of the public transport system. The Minister for Transport was reportedly exploring the possibility of implementing this policy in Dublin and analyzing global practices to determine its feasibility, according to the headline.",0
20,13," During the lecture, the students were presented with the benefits and drawbacks of the relevant policies, but they didn't analyze them extensively. The intention was to have the students delve into specific examples of these policies in a PBL session.",0
20,14," Each group was assigned a headline and tasked with formulating two policy-related questions within an hour. At the end of the session, each group presented a page outlining their problem definition with the help of available tutors. While some taught knowledge could be used, external research was necessary as the topics had not been fully covered in lectures.",0
20,15," After identifying their issues, the groups were instructed to create a few assignments for evaluation. This included a 10-minute oral presentation where they spoke about the problem's overview, how they defined it, and how they planned to answer their own questions. Additionally, they were to submit a detailed written report and a poster that highlighted the critical aspects of their presentation.",0
20,16," The lecturer graded the first two sections of the project, which included both oral and written presentations. The final portion, a poster, was evaluated by fellow classmates who were asked to provide marks that reflected the additional value they gained from viewing the posters. These posters were an important component of the assignment and groups were only permitted to use an A2 sized poster with minimal writing. This limited the amount of text that could be included and required students to be creative in visually presenting their solutions. The groups had two weeks of collaborative time to organize and showcase their work.",0
20,17," In the fourth year, a class of 50 students was given two problems to solve. The problems followed the same format as the third year, where students were presented with an unclear outline at the beginning and had to define it in small groups of five to seven. Each group then presented their intended approach over the next two weeks. Although it was intended to have groups of only five, some groups had to become larger due to some students being absent during the original grouping process.",0
20,18," 

In the initial task, the learners were given a declaration on the benefits of various techniques used in transport modeling, using terminologies and references that the students have not yet encountered. The objective of this case study was to expose the pupils to the intricacies of transport modeling. While the lectures covered the subject matter, comparing models had not yet been discussed. To resolve this matter, it was necessary to conduct in-depth research on transport modeling, which was not part of the regular classroom activities.",0
20,19," Students were unfamiliar with the concepts of forgiving roads and self-explaining roads, and were required to research the definitions and the methods used to assess them. The expectation was that they would explore the various systems and tools used to audit safe roads and compare the advantages and disadvantages of each method from across the globe.",0
20,20,"

The third and fourth year PBL exercises had several objectives, including encouraging students to engage with challenging topics and promoting independent study skills. Defining problems helped foster innovative thinking and working in teams taught important skills like communication and organization. UCD's civil engineering program strives to offer as much project work and teamwork opportunities as possible to prepare students for working in teams. The team roles of chairperson, timekeeper, and note taker were explained in an introductory session, with the chairperson responsible for facilitating discussions and the note taker ensuring all decisions were noted and agreed upon by the team.",0
20,21, It was anticipated that the students would gain the crucial skill of managing their own education and participating in self-directed learning. The students were provided with minimal instruction on defining problems and conducting research. The intention is for these students to move from being passive listeners and learners to becoming proactive researchers and engaged learners.,0
20,22," The purpose of incorporating PBL into these courses was to promote student engagement and self-directed learning. Hence, it is imperative to evaluate the effectiveness of this approach by posing the question: 'Have students successfully progressed from being passive recipients of information to autonomous, active learners?'""",0
20,23," Students in both classes actively participated in the PBL courses and presented creative solutions to their given problems. Specifically, the third year class tackled transport policy issues with a mature approach, evidenced by their independent research beyond course materials. Many groups explored unconventional case studies related to privatization and deregulation of public transport. The objective was for students to develop informed opinions on the benefits and drawbacks of these policies, which varied among individuals but were supported by the knowledge they had gained.",0
21,1, The participation of numerous factors in civil engineering phenomena makes their analysis a complex problem. Traditional methods often lack physical understanding and rely on simplifying assumptions that can result in significant errors. This paper aims to introduce a new method that utilizes evolutionary polynomial regression (EPR) to capture the nonlinear interactions among various parameters of civil engineering systems.,0
21,2, The EPR approach relies on evolution-based computing and is geared towards identifying polynomial models that describe a given system. This involves utilizing both the genetic algorithm and the least-squares method in tandem to determine viable structures and optimal constants for them.,0
21,3," The EPR methodology's abilities are demonstrated by its use in solving two intricate civil engineering problems that involve assessing the uplift capacity of suction caissons and the shear strength of reinforced concrete deep beams. The outcome demonstrates that the suggested EPR model is substantially more efficient than previous models. The EPR models produce an easy-to-follow and organized portrayal of the system. For design intentions, the EPR models that have been explained in this research are straightforward to use and produce results that are more precise than the current techniques.",0
21,4," A novel data mining approach is introduced in this study to investigate challenging civil engineering issues. Unlike the conventional and artificial neural network-based methods discussed in the literature, the new method triumphs over their drawbacks. It employs EPR as a feasible technique to obtain an organized representation of the system, enabling the user to acquire further insights into its performance.",0
21,5," Despite the extensive development of traditional engineering solutions, many civil engineering issues remain unsolved due to the lack of precise analytical theories and models. This is primarily due to limited and poor quality information, as well as a lack of understanding of the phenomena and factors involved.",0
21,6," The customary practice involves gathering and consolidating the data and afterwards exhibiting it through various methods such as diagrams, illustrations or practical equations.",0
21,7," With the aid of advanced computational software and hardware, new computer-aided data classification techniques have emerged. These approaches involve the use of pattern recognition systems, such as neural networks or fuzzy logic, which can learn from experience and extract discriminants tailored to their respective purposes. Among various techniques, artificial neural networks (ANNs) have gained popularity for their ability to model complex civil engineering problems and detect nonlinear interactions between system parameters.",0
21,8," A group of interconnected neurons called a neural network is made up of two or more layers that interact with each other via weighted connections. An input layer presents the data to the network, while an output layer holds the network's response to the input. By repeatedly showing examples of the input-output datasets and adjusting the model coefficients, or connection weights, the neural network attempts to minimize the error function between the historical outputs and the predicted outputs produced by the model.",0
21,9," ANNs have advantages in civil engineering applications, but also have drawbacks. One disadvantage is that the optimal network structure must be determined in advance, which is typically done through a time-consuming trial-and-error process. Neural network models are also complex and represented by a weight matrix that is not easily accessible to users.",0
21,10,"

A novel technique called evolutionary polynomial regression (EPR) is presented in this study as a means to model civil engineering systems. EPR makes use of evolutionary search to identify polynomial expressions for a given system. Its efficacy has been demonstrated in the past in the realm of environmental modeling (Giustolisi et al., 2007) and water system management (Savic et al., 2006). In this paper, we showcase the prowess of EPR through the application of two real-world examples from civil engineering.",0
21,11," GP and ANN are highly effective nonlinear modelling techniques, however, they both present their own limitations. GP utilizes an evolutionary approach to search for mathematical expressions for F, however, the vector u parameter values that are generated as constants known as ephemeral random constants are non-adjustable, making it challenging to represent optimal values, potentially leading to the skipping of good structures of F during the process. Moreover, the GP-based expression's number of terms can significantly increase, and the evolutionary search within GP can be time-consuming. On the other hand, the preceding section has highlighted some of the shortcomings of the ANN approach.",0
21,12," In EPR, the issue of mathematical expressions becoming excessively lengthy with the passage of time in GP is avoided by conducting the evolutionary procedure in a manner that seeks out the exponents of a polynomial function with a predetermined maximum number of terms, instead of carrying out a common evolutionary search like in GP. Additionally, it produces multiple expressions during one execution, with ascending numbers of terms up to a specified limit selected by the user, enabling the optimal number of terms to be chosen.",0
21,13, The search for the optimal equation form (8) on a worldwide scale is conducted through a conventional GA utilising the exponents user-defined vector (i.e. EX). The GA utilises Darwinian evolution by generating an initial population of solutions at random.,0
21,14," The chromosomes of an individual are represented by the parameter set in the population, and the individual's fitness is determined by its performance in its surroundings.",0
21,15," It is evident that having a zero in EX facilitates exclusion of certain inputs and their combinations from the regression equation. The EPR process terminates based on specific criteria, like the maximum number of generations or allowable error. Figure 1 depicts a standard flow diagram for the EPR mechanism.",0
21,16," The term ""fitness"" in regression-based modelling typically refers to the degree of accuracy with which the regression expression matches the data points. Nevertheless, it is commonly acknowledged that the most effective modelling technique is the one that is uncomplicated while still being appropriate for the intended application.",0
21,17," 

Suction caissons serve as anchor foundations for sizable offshore structures. These caissons are engineered to penetrate the seabed on their own weight initially. However, if they need to reach their full design depth, pumps are used to create a vacuum inside the caisson, lowering the pressure relative to the water pressure outside. Figure 2 depicts a schematic sketch of a standard suction caisson.",0
21,18," 

The reliable evaluation of the inclined uplift capacity of suction caissons is crucial. In the past few years, researchers have utilized artificial neural networks (ANN) to predict the uplift capacity of suction caissons by analyzing experimental data. Although ANN-based models have been effective in capturing the input-output relationship of the data, they lack transparency that can be applied to engineering practices. (Rahman et al., 2001; Vijayalakshmi Pai, 2005).",0
22,1," With an ever-increasing emphasis on sustainable development in civil engineering, it is vital for engineers to share knowledge and information. This article utilized social network analysis to investigate the knowledge and information sharing relationships related to sustainable development. A web survey was conducted within an international civil engineering consultancy, where population members were asked to provide their SD contacts, providing a 76.8% response rate. The data was analyzed with the goal of comprehending cross-boundary connectivity, relationship effectiveness, and key players within the networks. Results showed that cross-functional relationships were widespread, indicating that population members were seeking SD information from other specialized areas. Additionally, population members were more likely to approach co-located peers for knowledge and information and exhibited a lack of inter-office SD relationships, which is a common issue due to the inherent costs of maintaining long-distance relationships.",0
22,2," Social networks are crucial in sharing knowledge and disseminating information, as noted by Wang et al. (2006). Despite the growing popularity of modern communication technology, personal networks remain an important source for seeking knowledge and information, as supported by extensive research. This is particularly significant for knowledge-based organizations, as their personnel rely on personal relationships to access information and solve problems, according to Cross et al. (2001, 2002a).",0
22,3," 

In this article, we focus on the analysis of sustainable development (SD) social networks in an international civil engineering consultancy. The role of civil engineers in creating and maintaining our living environments is significant, and their slow adoption of SD is likely due to the complex nature of their work. Sustainable development aims to balance socioeconomic and technological progress with the preservation of natural systems. However, this process is complex and poses risks and uncertainties. Despite this, stakeholders are emphasizing the importance of SD.",0
22,4," In order to manage this, people heavily depend on exchanging interdisciplinary expertise and information through personal connections to adjust and adapt to changing SD demands and potentials.",0
22,5," The article aims to illustrate how SNA can be beneficial in comprehending SD knowledge and information sharing. While many studies have utilized SNA techniques, there has been no SNA research published in this specific context. The article is part of a research program within an international civil engineering organization, following a previous study where the authors concluded that slow adoption of SD in that organization is due to poor intra-organizational sharing of SD knowledge. The authors identified three fundamental barriers to effective SD KS within the organization: a lack of organizational slack, a silo mentality, and poor ICT systems. The primary objective of this research was to use SNA to confirm if the first two barriers are obstructing SD knowledge and information sharing and four research questions were formulated to support this purpose.",0
22,6," The article commences with a concise introduction to social networks and SNA, followed by the presentation and analysis of the methodology and findings. The ultimate part of the article outlines the conclusions and implications of utilizing SNA to enhance SD performance.",0
22,7,"

Organizational social networks aim to connect a group of individuals, either directly or indirectly, across functional, geographic or organizational boundaries, through established relationships. These networks typically serve two primary purposes, which are to facilitate knowledge search and knowledge transfer. Knowledge search typically involves a group of actors who seek a particular knowledge artifact. To initiate a search, actors use their existing knowledge of what is being sought to guide their interaction with others. Organizational knowledge searching can occur within team networks (business units, project teams) or inter-subsidiary networks (i.e. seeking across functional boundaries). Once the sought or useful knowledge has been identified successfully, it needs to be transferred from the source to the recipient.",0
22,8," 

SNA has been utilized in various fields such as sociology, anthropology, information systems, and organizational behavior (Liebowitz, 2005). It is commonly used to systematically and primarily map and evaluate an individual's or group's potential opportunities in terms of information and knowledge exposure and control (Haythornthwaite, 1996; Cross et al., 2001). Exposing a social network's structure enables the identification of areas for enhancement, such as pockets of intellectual capital, the necessity to socialize actors, and improving organizational learning (Liebowitz, 2005; Chan and Liebowitz, 2006). Nonetheless, SNA techniques have yet to be applied in an SD context within the civil engineering industry, notorious for its slow adoption of SD practices (Boddy et al., 2007) and fragmented nature.",0
22,9," There are numerous factors that contribute to the effectiveness of relationships, and investigating these factors can lead to diverse perspectives of a social network's character and form. Cross and Parker (2004) have identified a set of primary relationship factors that have proved useful in revealing network characteristics. In addition, Cross et al. (2001) have distilled four key factors that distinguish effective from ineffective relationships. These include knowing what another peer knows, being able to gain timely access to the peer, willingness to engage in problem solving, and a degree of safety in the relationship that promoted learning and creativity.",0
22,10," Social network data in SNA are usually stored in a relational data format and displayed through sociograms. In sociograms, actors are represented by shapes, and lines connect shapes where ties exist. Ties can be directed or undirected and binary or valued. Even though directed and valued data are more complicated, they can be simplified into undirected and binary data by setting a cut-off bias or value. SNA software such as UCINET and NetMiner are used to efficiently handle these data structures for mathematical analysis and visualization. Interpretations of data depend on its richness and format, as shown in Fig. 1.",0
22,11," Visualisation methods have a crucial function in aiding the examination of social network data (Moreno and Paton, 1953) and involving stakeholders. Therefore, various visual arrangements and structures can produce diverse analyses and dialogues. This absence of uniformity accentuates the extent of partiality when performing visual analysis (Butts, 2008). Graph theory resolves this subjectivity through the provision of objective network metrics utilising mathematical techniques.",0
22,12," Social networks often have crucial players who are essential to the overall performance of the network. These players fall into different categories such as central connectors, boundary spanners, information brokers, and peripheral people as outlined in Table 2. Identifying such players is one of the primary uses of SNA which enables organizations to improve their effectiveness by working with these individuals. This can help to retain those who make a significant difference in the organization, thus increasing productivity. It should be noted, however, that these players may have different roles and levels of significance in various networks.",0
22,13," 
In the last five years, the organization has become interested in SD. They appointed two sustainability leaders in 2007: one is responsible for internal SD operations, while the other is responsible for strategic development and external communication. These two leaders formed the Sustainability Task Force (STF), which includes SD representatives from every business unit. STF members meet monthly to discuss sustainability initiatives, innovation, market conditions, and client requirements. The STF serves as a platform to disseminate information and launch programs. Additionally, the intranet hosts a sustainability gateway resource tool to encourage group-wide understanding, capabilities, and SD experience.",0
22,14,"

The four relationship factors proposed by Cross et al. (2001) pertain to awareness, access, engagement, and safety. However, while they do not explicitly acknowledge the role of communication frequency in social network collaboration, Cross and Parker (2004) have since recognized its importance as a relationship factor. Given that the authors of the current study sought to explore an open communication culture regarding SD and KS within the organization, they decided to replace Cross et al.'s (2001) safety factor with frequency of communication. This change was expected to yield greater insights on the issue of organizational slack, which is among the research questions addressed in this study. Accordingly, the relationship factors examined were frequency of communication, awareness, access, and engagement.",0
22,15," Social network data can be collected through surveys, interviews or secondary data. In our study, we utilized an electronic web survey as it is a widely used and convenient mode of collecting data with many benefits over conventional survey methods. However, web surveys are prone to nonresponse error, which can lead to missing data, and high response rates are crucial in SNA studies. To address this issue, we employed a personalization strategy and sent two rounds of follow-up reminder emails at fortnightly intervals to increase response rates and reduce survey error.",0
22,16," The survey was divided into four parts. The first section included an introductory page that outlined the study, the confidentiality statement, and the research team's contact information. The second part collected respondent information. The third section was the main body of the survey which contained instructions on how to complete the SNA questions, a description of SD, and contact input boxes. The final part was a completion page that confirmed successful submission of responses. The survey pilot revealed that the survey could be completed in 3-6 minutes, and research has shown that shorter surveys like this one have higher response rates.",0
22,17," Confidentiality protocols are crucial during the collection, examination and disclosure of social network data. The revelation of these intricate structures might jeopardize or impair a person's standing and responsibilities within a network, notwithstanding the fact that the data may not accurately reflect the scrutinized structure. Hence, the security of the data was entirely the responsibility of the research team, who only presented their findings while maintaining anonymity.",0
22,18," During the four-week active period of the survey, responses were imported into Microsoft Excel for further handling. To make data analysis easier, VBA macros were utilized to identify and correct any unclear contact details. Around 24.6% of names did not correspond to the personnel database. Moreover, respondents and contacts were connected to the organisation's personnel database. Using the software package UCINET, directed graph files were generated, which allowed for better analysis. Finally, the macros were also used to extract actors' organisational groups and location data from the personnel database.",0
22,19," Specifying the boundary for collecting and analyzing data can be challenging. The network boundary must not exclude or include irrelevant or relevant actors and their relationships within the population. To focus on knowledge and information sharing in functional business units, the research adopted a positional strategy by defining formal membership boundaries. Three skill groups, SG1, SG2, and SG3 were selected based on their performance in information and knowledge sharing, determined from staff survey results in 2008. SG1 is involved in transportation infrastructure, SG2 provides business management solutions, and SG3 is involved in power station design.",0
22,20," The sociograms of the networks under investigation can be found in Figure 3. The graphs in the left-hand column illustrate all the actors included in the network, which comprises all respondents and their connections. The right-hand column graphs only include population actors, omitting non-population contacts.",0
22,21," The networks' fragility was determined by calculating cut points. Within their networks, SG1, SG2, and SG3 had 14 (16.5%), 47 (18.2%), and 23 (26.4%) cut points, respectively. SG1 was the least fragile since it did not rely on non-population members for SD connectivity. SG3 had only one non-population cut point, which linked a single peripheral actor, while SG2 had four non-population cut points. The degree of intra-population connectivity fragmentation resulting from the removal of non-population members demonstrated these fragility measures. (See Figure 3: intra-population network.)",0
22,22," 

Fig. 4 illustrates the geodesic path lengths for each network, indicating the number of connections required to reach one actor from another. The data reveals that over 80% of actors can be reached in four or fewer links, with a few exceptions. SG2, in particular, has extended paths, with the longest being 12 links. Fig. 5 shows the tightly knit local SD communities present in each population, as indicated by the size and number of weak Scott cliques. Each network comprises many small, cohesive subgroups. The largest clique was found in SG3, consisting of seven actors, followed by SG1 with six actors and SG30 with five members.",0
23,1," In the past twenty years, there have been significant changes in the undergraduate civil engineering curricula. Universities are faced with the challenge of selecting and transferring the appropriate skills and attributes that will enable their students to succeed in the industry. Despite teaching theories advancing, many civil engineering education relies heavily on deductive instruction. The use of case-based teaching is becoming more prevalent, specifically with case-histories and case-studies being the most commonly used. Using the Kansas City Hyatt Regency walkway collapse as an example, this paper explains the differences between the two methods. The benefits of this approach are many, including improved retention of knowledge, better reasoning and analytical skills, development of higher-order skills, greater ability to identify relevant issues, recognize multiple perspectives, along with higher motivation, and awareness of non-technical issues. Professional bodies outline many of these outcomes as expected attributes of civil engineers.",0
23,2," Over the past two decades, undergraduate civil engineering curricula have undergone significant changes in response to the needs of students, industry, society, accrediting bodies, and government organizations. The advancements in computational analysis and design, along with increased recognition of soft skills in the engineering profession, have contributed to these changes. Additionally, there has been a shift towards student-centered teaching and learning approaches based on research by Entwistle, Ramsden, Biggs, and Fry. Consequently, a multitude of new and sometimes conflicting educational theories from other disciplines have entered the field.",0
23,3," University curriculum committees face important challenges in identifying and conveying a specific set of abilities and qualities that they anticipate students to possess upon completing their degree, in order to effectively equip them for their chosen profession. Extensive research and discourse has taken place among both scholars and industry professionals regarding this issue (for example, Williams 1988; Henshaw 1991; Harvey et al. 1997; Yorke 1999; Blum 2000; Mills and Treagust 2003).",0
23,4," Professor Alan Davenport was intrigued by a discussion among his daughter and her peers regarding a case study they were working on at the Ivey Business School in the early 1990s. This inspired him to develop a one-semester undergraduate course in Case Studies in Civil Engineering at the University of Western Ontario, following the Harvard Business School method. This course has evolved over the years and is now an essential part of preparing students for their professional careers, taught by the first author and guest lecturers. Several civil engineering teaching cases have been developed as a result of this course. An overview of some of these cases is presented in Appendix A (Table A1).",0
23,5," Numerous other courses and case studies have been produced in various locations for teaching civil engineering, including works by Bosela (1993), Rendon-Herrero (1993a, 1993b), Baer (1996), Delatte (1997, 2000), Rens and Knott (1997), Pietroforte (1998), Carper (2000), Jennings and Mackinnon (2000), and Rens et al. (2000). Appendix B presents a sizable database of case studies for instructors to employ, though full courses similar to the one provided at the University of Western Ontario are uncommon. Nevertheless, individual cases are more frequently integrated into other courses (Delatte and Rens 2002). In most cases, either the traditional Harvard Business School technique of the ""case study"" or the ""case history"" method is used, both of which can support student-centered teaching, foster deeper learning outcomes for engineering, and cover higher levels of Bloom's revised taxonomy of learning domains (Bloom 1956; Anderson and Krathwohl 2001).",0
23,6," Inductive teaching differs from deductive teaching in that it emphasizes the importance of experiences and interactions in the learning process. The instructor begins by presenting a concrete example that students can observe and interact with. From these observations, students are challenged to make generalizations and draw conclusions, with the guidance and support of the instructor. Inductive teaching is more learner-centered and encourages students to take responsibility for their own learning. There are several different inductive teaching methodologies available, including inquiry learning, problem-based learning, experiential learning, case-based teaching, and discovery learning.",0
23,7," Inductive teaching methods have been previously studied and have shown to encourage deep learning, enhance intellectual development, and align with neurological and psychological studies. Researchers in cognitive psychology emphasize the importance of context and environment in learning, and suggest that social interactions can modify thought processes, present new values, and introduce obligations. Therefore, improving links between academia and industry may benefit teaching by providing appropriate immersion and exposure within engineering communities.",0
23,8," The constructivist approach has evolved to include collaborative learning and group work, with collective construction of knowledge as the basis for problem-based and case-based learning. Instructors may face a challenge in motivating students to acquire the necessary knowledge before engaging in teaching sessions, but students can still be encouraged to explore presented problems as a means of acquiring and retaining knowledge. The aim of learning outcomes is to develop unique and individual ways of understanding, and learning content serves as a means to further knowledge rather than an end in itself. (Mask: Paraphrase)",0
23,9," Perry (1970) devised a scheme of intellectual development that illustrates students' progression to more complex forms of thought during learning. Thompson (1999) highlighted four of the nine stages as significant milestones: dualism, multiplism, contextual relativism, and commitment to relativism. As students develop with time, they embrace the uncertainty and contextual nature of knowledge and recognize their analytical abilities. The model has been discussed in various studies within the context of engineering education by researchers such as Culver and Hackos (1982), Pavelich and Moore (1996), and Palmer and Marra (2004). Unfortunately, engineering students often only reach the lower levels of the Perry scale, indicating the dominance of 'dualistic' forms of teaching in engineering as noted by Wise et al. (2004) and Wankat (2002). Baxter-Magolda (1992) expanded on the Perry model by defining four levels of intellectual development: absolute knowing, transitional knowing, independent knowing, and contextual knowing.",0
23,10," There has been a shift in the way engineering is taught, moving away from laboratory and small group sessions to lecture-based and web-based education due to reasons such as larger class sizes and costly maintenance of laboratories. However, there has been a recent reconsideration of this teaching method as constructivist approaches have become more appealing. The cyclical learning model of Kolb is used to explain the sequence of effective learning activities, including experiencing, reflecting, thinking, and acting. The model categorizes learners into four types and explains experiential learning while also providing an understanding of different learning styles. This model is still an important one in learning theory.",0
23,11," Despite the changes in teaching and learning theories, civil engineering education still relies heavily on deductive instructional methods. However, inductive approaches have gained significant support in other fields. Among them, case-based teaching is popular and has two common types: ‘case-histories’ and ‘case studies’. This paper uses the Kansas City Hyatt Regency walkway collapse as an example to describe these methods and their similarities and differences. Combining deductive and inductive methodologies may provide higher level and broader learning outcomes, considering students' preferred learning styles.",0
23,12," Professor Alan Davenport introduced the casestudy method to civil engineering education at the University of Western Ontario, and it has been a huge success for the past 20 years. Students in their final year have found the course he developed to be the most enjoyable and effective. Despite the importance placed on critical thinking and problem-solving skills, the casestudy method is surprisingly underutilized in civil engineering curricula across North America. The authors are hopeful that civil engineering educators will start using this teaching approach to educate and mentor the next generation of practicing civil engineers.",0
24,1," This article discusses how design skills were taught to civil engineering students at University College Dublin (UCD) using project-based learning (PBL). The article examines the evolution of problem-based learning (PBL) and the factors to consider when designing a PBL module. Based on the literature, it is suggested that a hybrid form of PBL, known as Project-Based Learning should be used in civil engineering education. The article provides a detailed overview of how hybrid PBL was incorporated into the final year of a civil engineering degree at UCD. In conclusion, student perceptions of the PBL process were evaluated and found to be positive. The article also notes that the module developed at UCD helped students develop essential skills required by graduate employers such as problem-solving, innovation, group-working, and presentation skills. The students enjoyed an increased level of interaction with staff and external experts that the problem-solving approach facilitated.",0
24,2," Engineering education is currently undergoing changes as universities are pressured by industries to produce graduates with a wider range of skills. Meanwhile, advancements in technology are transforming the way in which students learn. Experts such as De Bono argue that creativity is necessary for companies to remain competitive in a global market, and that transformative employees who can analyze, critique, and communicate innovative solutions are essential for companies to succeed. Moreover, a report from the American National Science Board has stated that basic engineering skills are becoming commodities that can be easily sourced from low-cost economies.",0
24,3," Various professional engineering and accreditation organizations have formed task forces to enhance engineering program curricula in response to external drivers. According to the ABET guidelines (cited in Prados 1998), one vital suggestion was to incorporate design instruction that covers open-ended questioning, problem formulation, and alternatives assessment to foster innovation in aspiring engineers.",0
24,4," The effectiveness of PBL has been clearly demonstrated, especially in medical education. However, the versions of PBL used in engineering institutions, such as Aalborg in Denmark and the National Technical University in Trondheim, Norway, are typically referred to as Project Based or Hybrid PBL. Mills and Treagust (2003) distinguish Project Based Learning (hybrid) from Problem Based Learning based on certain factors.",0
24,5,"
Educators who want to develop PBL courses face significant challenges, such as determining how to arrange students into groups, finding skilled facilitators, identifying suitable physical space, and formulating problem statements. The availability of resources affects the implementation of questions (i) to (iii), and thus, there is a wide range of PBL approaches used worldwide. Generally, engineering students are accustomed to working in small groups from the beginning of their university studies, making them accustomed to group sizes common in PBL courses (usually fewer than six students).",0
24,6," The Project-Based Learning (PBL) can be hybridized with a floating facilitator, who can provide minimal support to students as they link and apply knowledge. The availability of physical space for projects is an institutional matter, but educators should consider providing project rooms in renovated and new facilities. Overcoming obstacles such as funding can resolve this issue. However, the main challenge that needs addressing is selecting the right type of problems to present for the success of PBL initiatives.",0
24,7," In order to ensure that good problems are prepared, Federau (2006) suggests using the learning climate model. This model is based on a two-axis approach that takes into account assignment freedom, which refers to the openness of the question. For instance, Federau gives the example of a bridge design exercise that says ""design a bridge to span from A to B."" This would be considered a high-assignment freedom problem for a first or second year student who has not studied engineering materials or bridge engineering. In contrast, a final year student who is asked to ""design a concrete bridge to span from A to B"" would receive a lower score on assignment freedom.",0
24,8," The Active Drive, which is the abscissa, indicates a student's motivation in learning and applying the necessary knowledge to solve a problem. In other words, the first or second-year student mentioned earlier is under immense pressure to educate themselves about the fundamental concepts of bridge engineering, such as the maximum allowable spans for various engineering materials, leading to a stronger Active Drive value.",0
24,9," Kolmos et al. (2009) proposed a PBL model that takes into account various elements essential for designing a PBL curriculum. These include objectives, types of problems, progression, size and duration, student learning, academic staff facilitation, space and organization, and assessment and evaluation. The model is a useful tool to consider PBL module case studies in civil engineering, which form part of the first-semester curriculum for the University College Dublin's two-year Master of Engineering (ME) course in Civil Engineering. This program is open to students who have completed a 3-year BSc. in Civil Engineering. During the first semester, students take a series of five ECTS traditional lecture and tutorial-based core Civil Engineering Design courses (CED 1 to 3) that build on the theoretical principles of Structural Engineering and Soil Mechanics developed in the BSc. program. In parallel, they also take a 10-credit PBL (Case Studies) module, which is roughly one-third of the credits available in the first semester. The UCD ME degree is structured over four semesters with students accumulating 30 credits in each semester.",0
24,10," The problems for this type of learning are well-defined according to the usual PBL definition, but they are quite different from the typical problems found in textbooks as they are more open-ended. To create a realistic and diverse learning experience, industry experts provide the majority of the assignments based on current projects. At the beginning of each week, students receive a brief for the assignment and present their solutions to their peers, tutors, and the outside expert on Friday using an ""interruptible"" Q&A format.",0
24,11," It is relatively easy to increase the complexity of problems at the start of the semester. Nonetheless, incorporating external experts (usually experienced engineers from the industry) can sometimes require altering the established timetable. The complexity of the problems can be easily ramped up at the beginning of the semester.",0
24,12," 

The UCD Civil Engineering department relocated to a new structure that features spacious project rooms on the ground floor. These rooms are freely available for project work and studying for students in any stage/year and are enveloped by staff offices, creating an environment ideal for cooperative project work. The UCD campus is located within a convenient 4-mile distance from the city's capital and boasts a positive relationship with industry. Additionally, there is a substantial pool of visiting engineers to serve as tutors in our PBL initiatives.",0
25,1,"The field of civil engineering faces a considerable challenge in the 21st century, as society's perception of problems and their importance directly relates to civil engineers. As a group highly respected for their technical proficiency and rational approach, civil engineers have a significant responsibility to ensure their actions prioritize ""the public good"". To do so, it is necessary to review both professional and educational structures and modernize certain attitudes and approaches. Despite possessing important tools such as new technologies and communication developments, civil engineers must deeply reflect on their essence and take the lead in providing technically-supported and disinterested messages to society.'",0
25,2,"It is widely accepted that society is continuously evolving, which has accelerated historically in recent years. However, despite this change, there are still some outdated structures in both professional and educational fields that are victims of ingrained inertia. Without a decisive push, these structures risk becoming hidebound organizations that are enslaved to the past and lack future effectiveness and efficiency. This article focuses on civil engineering, an essential aspect of city life, which must undergo a major transformation in its professional and educational approaches to deal with the new challenges, attitudes, and implications of the twenty-first century society with the reliability and effectiveness as it has shown in the past.",0
25,3,"

Changes that are intended to have a lasting impact in the future must be carefully planned and implemented from the earliest stages of preparing future professionals. This means that teaching must play a prominent role in shaping the attitudes and skills of twenty-first century engineers. While challenges may arise in designing curricula and implementing new guidelines, these cannot be allowed to undermine the important and desirable goals that we seek to achieve. As Dr. Morales Manceda has pointed out, it is particularly important to include subjects related to ethics and the humanities in university programs, so that students can understand not only the technical aspects of their work, but also the ethical dimension that underpins it. This is because the ultimate aim of technology should always be to advance the common good of humanity.",0
25,4," 
A comprehensive reevaluation of civil engineering must encompass more than just adopting new technologies, altering work practices, or collaborating with engineers from other areas. It necessitates a thorough examination of the field's relationship with society, its active role in addressing the significant issues confronting contemporary citizens, and its capacity to lead and innovate.",0
25,5," It is crucial for a profession that is closely connected to the welfare of the public to possess the capability of spearheading social initiatives and progressions based on thorough technical expertise, ethical values, and a logical and self-governing approach, especially in a world influenced excessively by immediate outcomes, economic performance, political nepotism, and a certain level of moral slackness.",0
25,6,"There is an urgent need for a genuine social structure in society. To achieve this, independent organizations and NGOs must establish themselves as representative bodies with the power to influence decision-making that affects the common interest. In this regard, professional associations, particularly those that encompass civil engineers, have a moral responsibility to take the lead in designing processes to address contemporary societal challenges.",0
25,7," Professor Valero Matas (2009) asserts that intermediate bodies play a crucial role in intricate societies by functioning as a means to protect individual rights and freedoms. By nature, these organizations work to resolve societal issues and fulfill the needs of private life. They additionally serve as a tool for public opinion and political will, promoting critical action.",0
25,8," Professional associations are crucial for civil engineering to play an important role in society's strategic issues. However, their influence is only valid if these associations can reinforce genuine participation, which should not be based on corporatism. In fact, professional associations must focus on seeking optimal solutions through technical approaches that are free of opportunism and pragmatic reflection. They need to have a real capacity to influence decision-making, but only in a manner that is aligned with the social good.",0
25,9," The willingness to take charge and accept responsibility is crucial in the field of civil engineering. From the very beginning of an engineer's educational journey, emphasis should be placed on the significance of the profession in resolving critical issues affecting citizens' daily lives. This includes showing concern for pressing problems such as sustainability, environmental impact, and waste management, all while adhering to ethical and honorable conduct principles.",0
25,10," The longer an organization has been around and the more prestigious it is, the less willing it is to accept change. Civil engineering has a rich history and has produced many talented professionals, which has led to a sense of satisfaction and detachment. In some cases, this can result in a disconnection from the society in which engineers work.",0
25,11," The civil engineer must engage with the social dynamics and the magnitude of the problems threatening future generations. They must be aware of the media's transmission of confusing opinions and the lack of transparency in society's messages. It is crucial for civil engineers to design and build with a broader vision that includes the future, sustainability, the natural environment, and the responsibility to future generations.",0
25,12," The growing awareness implies a significant restructuring of civil engineering, impacting engineering education and professionals, as well as their associations. Rather than dismantling the current structure, it is essential to carefully remodel it while preserving its valuable experiences, responsibility, doctrine, and records. These aspects define the profound values of the profession. The aim is to identify and redefine the parameters of the public interest in the twenty-first century and create a new form of engineering, excitingly standing at a crossroads.",0
25,13," We have at our disposal advanced technologies, improved communication methods, and opportunities for cross-cultural exchange and knowledge-sharing, all of which are valuable assets for modern civil engineering. But first, we must carefully consider our profession's position in society and the priorities that guide our work. With a determined and practical approach, we must address the most pressing issues facing our communities and seek better ways to communicate our solutions to larger audiences.",0
25,14,"

It is widely accepted that civil engineers are highly esteemed by society, though some individuals may not fully comprehend the extent to which their work impacts daily life. Interestingly, society places a great deal of trust in these professionals, occasionally to the point of excess. However, in the event of an accident, this trust may falter, as citizens come to realize the gravity of potential consequences. This pressure from society, which disregards the possibility of statistical failure, greatly influences the decisions and responsibilities of civil engineers, sometimes even hindering their creative capacities. This leads to a curious paradox: a profession that is generally perceived in broad terms is also subject to heightened expectations and demands in comparison to other fields.",0
25,15," There is an author's suggestion to bring back ""classic values"" such as prudence, perseverance, and ethics, combined with clear and effective approaches toward crucial contemporary problems like sustainability, environmental respect, knowledge independence, and closer societal connections. Civil engineering, as it serves the ""public interest,"" should play a more dynamic part in fields beyond its technical capabilities that are influenced by its work and are among the primary concerns of society.",0
25,16," It is undeniable that training is the foundation for the engineer's future professional growth, making teaching crucial in shaping the ideal profile required by society to address its expectations and devise solutions to the most pressing issues of our time.",0
25,17,"According to a team of experts convened by the National Science Foundation in the United States, the National Academy of Engineering (NAE) has identified the primary engineering challenges for the twenty-first century. These challenges, which are crucial for humanity's success, fall under four categories: sustainability, health, reducing vulnerability, and the quality of life. The work of civil engineers plays a significant role in addressing these challenges, and it is crucial for academic institutions to instill awareness and concern for these issues in their training programs. This will shape future engineers' professional work and their perception of the world around them.",0
25,18," The syllabus design is a crucial element, and various authors and scholars concur on the essential principles that should guide the learning system in the future. Kindelán and Martı́n's assessment of the situation is so clear that it is worthwhile to replicate it.",0
25,19," The concept of education in all fields has been redefined by the global communication networks and information technologies. A new educational paradigm has been established in engineering prioritizing the development of generic skills. These skills include effective oral and written communication, multidisciplinary perspective in decision-making and problem-solving, teamwork, and lifelong learning. The interconnection of communication, training, and lifelong learning play a significant role in the engineer's profile in the 21st century.",0
25,20," In addition, we need to address the fundamental question of how to define specific regulated contents for university education once we have determined the overall objectives, basic concepts, attitudes, and skills to be promoted among civil engineers in the next few decades. Trevelyan and Tilli (2007) stress the importance of empirical methods, particularly with respect to technological understanding, but we must also instill in engineers an appreciation for ethical and humanistic principles.",0
25,21," If non-technical studies are disregarded and engineers are only seen as technicians, it questions the significance of such studies. However, these studies are essential in transforming engineers into professionals. It is crucial to discover methods to break this stagnating pattern.",0
25,22," It is important to highlight that there is a need to restore 'classic values', particularly ethical values, in engineering education. Ortega y Gasset's statement about engineers highlights the importance of carrying out engineering under specific conditions, including morality, which should not only be a personal code but subject to rational argument. Therefore, excellence in engineering is closely tied to ethics.",0
26,1," The skills and attributes required for twenty-first century engineers have been extensively discussed, leading to debates on the balance between theoretical understanding and practical application. This paper examines the requirements of UK engineers and evaluates if current civil engineering degrees meet these requirements. Professional body requirements are also critically reviewed, with a consideration of adopting a post-modernist view of engineering. A coastal engineering perspective is presented, drawing parallels to civil engineering. The conclusion is that civil engineering degrees currently adopt a post-modernist approach and are suitable for the future, but further consideration of educational theories may enhance their preparedness.",0
26,2," The UK economy needs to increase the skill level and quantity of engineering graduates to compete globally, as noted in recent reports by Leitch (2006) and the Royal Academy of Engineering (RAE) in 2007 and 2010. Failure to address the shortage of engineers may lead to the UK losing its international industrial competitiveness, according to the RAE. Despite overall university admissions increasing by 40%, the number of students enrolling in engineering courses remained constant at 24,500 annually from 1994 to 2004. In contrast, UCAS data from 2002 to 2007 shows that while all university applicants increased by 12.2%, there was only a 3% increase in applicants in STEM fields from UK students. Furthermore, less than half of engineering graduates entered the profession, as reported by the RAE. It is important to note that the RAE deals with all engineering disciplines.",0
26,3," The main focus of this paper centers on the competence of graduates that higher education institutions are churning out and whether they possess the necessary skills and attributes to participate in the knowledge economy. An examination is conducted on the comprehensive report published by the Royal Academy of Engineering (RAE, 2007) to assess the abilities and traits of future engineers. These characteristics and skills are then juxtaposed with the professional requirements for civil engineering undergraduates. The concept of post-modernism is defined to scrutinize whether it should be incorporated into the education of future engineers. Additionally, theories of education are introduced, along with their relevance for future engineers.",0
26,4," The report Educating Engineers for the 21st Century (RAE, 2007) was published in June 2007 after seeking the opinions of senior staff members in engineering companies and academic institutions. The report collected feedback from 48 universities, the Institutions of Civil Engineers, Structural Engineers and Mechanical Engineers, and the New Engineering Foundation.",0
26,5," Future engineers must have a variety of skills and traits. They should have technical proficiency and comprehension of engineering fundamentals, along with an awareness of how engineering components correspond with other aspects of a project, including business requirements and the broader environment.",0
26,6," Based on the current paper's focus on civil engineering courses, the review centers on whether the professional body requirements align with the desired attributes and skills. In this regard, the professional body for civil engineering courses is the Joint Board of Moderators (JBM), comprising four civilengineering-related bodies, namely, the Institution of Civil Engineers, the Institution of Structural Engineers, the Institution of Highways and Transportation, and the Institute of Highway Engineers. It is the JBM that carries out assessments and accreditations on behalf of the four professional bodies.",0
26,7," Charles Vest spoke extensively about the education of engineers for the future, echoing sentiments from the USA. According to Vest, the specifics of the curriculum itself are less essential than the need to create a stimulating and thrilling educational environment within engineering schools and universities. Engineering coursework should be both challenging and adventurous, in line with Vest's beliefs. In addition, Vest shares the RAE report's perspective that future engineers will require extensive preparation to deal with highly intricate projects that necessitate a comprehensive engineering systems approach. (Vest, 2005).",0
26,8," Vest's perspectives align with those of engineering enterprises (RAE, 2007) that aim for engineers possessing technical expertise and comprehension of the corporate realm, necessitating improved communication and interpersonal skills. It is worth mentioning that, for engineering graduates entering the industry, the most sought-after feature is their capability to use theoretical knowledge for actual industrial difficulties. Other pertinent traits, in order of descending significance, include theoretical comprehension, inventiveness and novelty, teamwork, technical range, and business acumen.",0
26,9," In order to assess the attainment of output standards, they review students' work, such as project reports and examination scripts, and conduct interviews with them.",0
26,10," Civil engineering departments must demonstrate close links with industry, as stated in the JBM guidelines, in addition to meeting required output standards. To establish this connection, civil engineering departments are recommended to create an industrial advisory board (IAB) where members of academic staff meet with practicing civil engineers two or three times a year to receive feedback and support on civil engineering programs. Professor Quentin Leiper provides guidelines on the JBM website to set up an IAB, and tangible benefits at institutions such as the University of Wolverhampton include site visits and guest lectures from industrial practitioners. For example, the head of transportation at Wolverhampton city council is a member of the IAB and has provided traffic data and design project suggestions for the department.",0
26,11," The Oxford encyclopedic dictionary defines 'post-modern' as a movement that reacts against modern tendencies. However, there are various definitions and interpretations of the terms provided by philosophers and artists.",0
26,12," Dr Graham Owens recently wrote an article in The Structural Engineer addressing concerns within the structural community regarding a reduction in understanding of structural behavior. Owens suggests that traditional manual methods of analysis should be reduced unless they enhance students' comprehension of structural behavior. He argues that engineers in the 21st century do not need detailed knowledge of analysis programs but should understand their practical application. Owens believes that part of the syllabus should focus on the approximate nature of engineering activities, including uncertainties in loads, environmental factors, and risk assessments, reflecting a post-modernist viewpoint.",0
26,13," Kamphuis presents a captivating perspective on the evolution of coastal engineering from modernity to postmodernity (Kamphuis, 2006). The relevance of the comparisons with civil engineering is apparent and valuable in the discourse concerning upcoming engineers.",0
26,14," Kamphuis characterizes the years after World War II as the golden era for coastal engineering when people believed that with sufficient funding, research, and effort, anything was achievable - the foundation of present-day thinking. National security drove the expansion of new ports and shoreline protection methods to prevent erosion and flooding. As the century advanced, it was apparent that more advanced numerical or physical models had their restrictions.",0
26,15," 
At the University of Wolverhampton, rather than spending hours on manual calculations for Bishop's slope stability analysis, students are instructed in the fundamental principles and prompted to adjust input parameters and analyze the corresponding outputs. This teaching approach acknowledges the presence of uncertainties and enables students to understand how these uncertainties can impact stability.",0
26,16," The JBM and RAE agree on the necessary attributes and skills for graduate engineers. Accredited civil engineering departments typically meet these requirements, but there is a risk of complacency. Collaboration between universities and industry is encouraged, with examples such as Imperial College's Constructionarium. Part-time students also provide benefits to full-time students, as noted by Davies.",0
26,17," Changes in the education of future civil engineers should be discussed within the framework of educational theories, despite the advocacy for a post-modernist view and approach. Both the JBM and the RAE have no explicit reference to educational theories. The RAE 2010 report, while strongly proposing experience-led engineering, can be viewed as one-dimensional in that it only presents a solution. The issue may stem from engineers' problem-solving nature, which lacks consideration for how students learn. Thus, the logical engineering solution of closer industry involvement fails to address the learning issues confronting graduate engineers.",0
27,1," 

This article introduces preliminary research to pinpoint areas in civil engineering that would benefit from further data sensing and analysis (DSA) studies. The investigation began with an extensive literature review then proceeded to a web survey to gather professional insights across specific civil engineering subfields to determine what challenges could be tackled through civil engineering DSA research. The findings produced ten challenges that this paper portrays through a comprehensive literature review of the economic, environmental, and social impacts of these challenges. The challenges highlighted in the article are high building energy consumption, inaccurate sea level estimation, exacerbating coastal and soil erosion, suboptimal water quality, untapped and waning groundwater, increasing traffic congestion, infrastructure susceptibility to natural disasters, undermaintained and deteriorating infrastructure, improved mining and coal ash waste management, and inadequate construction site safety measures. Ultimately, the article's goal is to empower civil engineering research professionals to prioritize DSA research initiatives to respond to these challenges.",0
27,2," Civil engineering is crucial in enhancing and building societies. The tasks involved are intricate and varied, dealing with unusual difficulties. Civil engineers are responsible for devising, drafting, constructing, and managing facilities that are vital for contemporary living, such as transportation networks, offshore structures, and water systems. With the world evolving rapidly, civil engineers must confront unprecedented predicaments in every subfield. These issues can be multifaceted and interconnected, necessitating an integrated solution.",0
27,3," 

Research in DSA can help reduce the effects of challenges faced in various areas. DSA comprises research in different aspects like data sensing, analysis and fusion, parallel and distributed computing and knowledge discovery among others. This paper explores how civil engineering grand challenges can be tackled through DSA research. A survey was done to determine the most significant challenges, and this paper presents the top ten challenges that emerged from that validation. The paper also highlights the economic, environmental, and societal impacts of these challenges through an extensive literature review.",0
27,4," The main purpose of this article is to review the current state of civil engineering. The research aims to pinpoint the major challenges that the DSA research community should tackle over the next ten years. Ultimately, the objective is to help the DSA community establish a research plan that centers on resolving the pressing challenges identified.",0
27,5," The survey was sent to 850 potential respondents out of the 968 ASCE editorial board members. Incomplete responses were not included in the analysis, leaving 110 complete responses out of 154 received. These respondents gave 124 valid responses for the seven sub-disciplines. The survey results were only used for validation purposes, with the broader review of literature establishing the challenges in civil engineering. Fig. 1 summarizes the 27 challenges in seven sub-disciplines, using box plots to show the distribution of responses on a 1 to 5 scale for each challenge's impact area. The median, interquartile range, and outliers are indicated on the plot. The overall response rate was approximately 18%.",0
27,6,"

The DSA task force reviewed various sources such as journal articles, conference proceedings, and news articles to identify the major challenges faced by the civil engineering community. The task force identified 27 challenges across seven subdisciplines of civil engineering. The 27 challenges were evaluated based on their impacts on economic, environmental, and societal areas. The economic impact was ranked based on its effect on economic growth, direct and indirect costs. The environmental impact was ranked based on negative effects on the environment, natural surroundings, and the ecosystem. For example, pollution and global warming are considered environmental impacts.",0
27,7,"

To confirm the selection of challenges made by the DSA committee report, a subcategory of challenges was chosen based on the challenges that received a median rating of over 4 in two of the three impact areas. When shortlisting the challenges, the median was used instead of the mean as the responses were treated as ordinal and skewed. The resulting list consisted of 16 challenges that had high or very high impacts in two of the three impact areas, marked with an asterisk (*) in Figure 1.",0
27,8, The challenges related to the inherent characteristics or applicability of DSA research were brought together by the authors.,0
27,9," 

After analyzing the survey results, the ASCE DSA report removed the challenge of ""low construction productivity"" from the final list and replaced it with two new challenges: ""need for better mining and coal ash waste disposal"" and ""water pollution and quality."" As a result, this study will focus on investigating a total of 10 challenges. However, the authors did not prioritize these challenges nor did they endorse any specific solution.",0
27,10," Firstly, the survey inquired about the respondents' field of expertise and gave the option of selecting more than one if applicable. Next, the survey presented specific challenges related to the areas of expertise and asked the respondent to assess the challenges' impact on economic, environmental, and societal factors through a discrete five-point Likert visual rating scale (ranging from no impact to very high impact).",0
27,11," Coastal infrastructure needs to be designed with precautions against waves and tides, and to be built above the highest sea level. To balance safety and construction costs, engineers need accurate sea level estimations. Koch (2010) researched the cost of building a mile of sea wall and found it to be over $35 million plus an annual maintenance cost between 5-10% of construction cost. Hurricane Katrina caused approximately $500 billion in damage to the New Orleans area in 2005.",0
27,12,"Unstable sea levels pose a significant problem, particularly during natural disasters like hurricanes and tsunamis where extreme sea levels can occur. Coastal areas have experienced devastating losses of lives and finances due to numerous natural disasters in the past two decades. Various techniques can be utilized to tackle the challenges associated with rising and unstable sea levels. Accurate prediction of the sea level is crucial in the development of an effective prevention system.",0
27,13," The percentage of expenditure spent on fuel is an indicator of the societal impact of energy consumption. The use of energy should benefit all members of society, and if they cannot afford the energy they need, negative impacts on society, such as health issues, can occur. If a household spends over 10% of its total expenditure on fuel, it is considered to be in ""fuel poverty,"" and in the U.S., 15.9 million households fall into this category. Fuel poverty is largely caused by energy inefficiency in buildings, which could be improved to enhance the quality of life of Americans and reduce the nation's dependence on foreign oil, leading to beneficial economic and political implications.",0
27,14," Sea level is expected to increase to dangerous levels due to the continuous emissions of greenhouse gases that result in global warming. If temperatures continue to rise, many coastal cities and small island states in the U.S. are at risk of drowning. An OECD survey revealed that approximately 2 million citizens in Miami and 1.5 million citizens in New YorkNewark were exposed to rising sea levels in 2007. By 2100, about 180 coastal cities in the U.S., including 20 municipalities with populations over 300,000 citizens and 160 municipalities with populations of about 50,000 citizens, would be affected. Over 10% of the land area in Miami, New Orleans, Tampa, Florida, Virginia Beach, and Virginia will be covered under the sea. Therefore, a precise estimate of the increasing sea level is crucial to prevent corresponding consequences. By understanding the long-term dynamic sea level, researchers can protect the affected population and properties in the coastal area. (Molina et al. 2009; Nicholls et al. 2007; Weiss et al. 2011)",0
27,15," Over the past two centuries, approximately 108 hectares of farmland in the US have been abandoned due to soil erosion, causing significant changes to the livelihoods of farmers and the social structure of society. Furthermore, erosion results in increased wind-carried dust that not only acts as an abrasive and air pollutant but also carries human infectious disease organisms, such as anthrax and tuberculosis. In addition, coastal regions heavily rely on marine-related activities that provide numerous benefits to society and natural ecosystems. However, coastal erosion poses a considerable risk to economies derived from marine transportation, offshore energy drilling, resource extraction, fish cultivation, recreation, and tourism. To maintain these societal benefits, there is a need for a more comprehensive understanding of soil conditions, redistribution patterns, and associations with other natural parameters developing effective mitigation plans.",0
27,16," Essential for life, water is necessary for not only human beings, but also plants and animals. Water pollution occurs when injurious and/or toxic substances are introduced, which reduces water quality. The Clean Water Act of 1972 is the cornerstone federal law regulating water quality, while the Safe Drinking Water Act of 1974 ensures the safety of Americans' drinking water. However, despite these acts, over half of assessed rivers and streams and over two-thirds of assessed lakes remain unsafe for various uses. Millions of pounds of toxins are released into U.S. waters each year, impacting both the environment and society, and requiring significant financial investments.",0
28,1," There has been a history of adapting civil engineering developments for military use. This article details ongoing research in the UK on safeguarding structures and toughening civil infrastructure, and how it is being used in present missions and future endeavors. A team comprising military engineers, MoD scientists, and consultants with expertise in civil engineering, defense, security and infrastructure, as well as academic departments from physics and civil engineering from UK universities, worked collaboratively to carry out the research. The program has been driven by innovation and cross-fertilization in civil engineering, and its implementation in current military operations as well as future gear. Striking a balance between the needs of today's missions and the necessity of building a foundation for long-term planning was a vital element of the project. The article describes the program structure, approaches, and successful case studies.",0
28,2," Civil engineering knowledge has often been utilized in military engineering, with examples such as the use of concrete being prominent (Hambly, 2014).",0
28,3," Military engineering in the UK falls primarily under the Corps of Royal Engineers, whose task involves facilitating the military's ability to ""live, fight, and move."" The corps shows a keen interest in technology, being among the first to embrace inventions like balloons and manned flight, and more recently, utilizing ground robots for disposing of explosive ordnance.",0
28,4," 
The current force protection engineering research and its application in recent conflicts are outlined in this paper. This serves as a model for transitioning civil engineering research into practical applications and showcases the exchange of concepts between military and civil engineering.",0
28,5," The programme, which commenced in 2012, is a 3-year research project being carried out. It is based on a set of criteria provided by the Ministry of Defence (MoD), generated by military officers currently serving in the capability directorate combat support branch and Defence Science and Technology Laboratory civilian scientists, forming the foundation of the study.",0
28,6,"Requirements for 2020 focus on military capability rather than engineering performance levels. They are influenced by government defense and security policies, as well as military concepts and doctrine.",0
28,7,"A research contest was held by the Defence Science and Technology Laboratory, won by a team of industry and academia led by QinetiQ, according to the specified requirements. General requirements for a more diverse range of research programs were also established, such as a greater level of innovation, the utilization of research in practice, a powerful system approach, elevated knowledge pull-through from civil engineering systems and technology, and a higher level of scientific rigor.",0
28,8," The program will be managed for three years with annual revisions based on progress and changing requirements. The time-based view of the program is not practical, but Figure 1 depicts the program content and associated performance drivers, including performance measures and development lines that must be addressed in the acquisition of defense capability. It is important to note that the work addresses both specific capability needs and enabling work, which aims to provide methods and data for improved systems and solutions in the future.",0
28,9,"Equipment capability is a crucial component of combat effectiveness, along with morale, leadership, and training. This paper focuses on the field of force protection engineering and its associated programme, which aims to develop solutions based on military requirements and research, with the ultimate goal of application in military operations. The programme incorporates several themes to streamline this process.",0
28,10," The initial step of the research programme involved examining current analysis tools that are software-based, including those developed by international collaborators. Additionally, the programme utilized a formal requirements capture process. Basically, the objective was to create a user-friendly and fast computer-based system by gathering various datasets and design guidance already accessible, enabling options to be generated and compared swiftly. The current analysis programmes had a research-oriented approach, rather than catering to the guidance requirements of in-theatre users.",0
28,11," The development of the program involved creating multiple prototypes with increasing functionality. The user group was regularly consulted and each iteration was tested by them. Changes and improvements were implemented in subsequent phases. The latest version, called the 'force protection engineering tool', is now being used by the user group for current operations. It features a user-friendly interface to model a base and place people and infrastructure assets within it. The process of transitioning from research to practical application has commenced.",0
28,12," The software has databases featuring possible harmful weapons and materials used in their production, along with all the relevant traits. Furthermore, the software offers pre-designed encampment models, while allowing the user to generate their own unique layouts and simply structured buildings. The program computes statistics by using data interpolation, experimental data-based computer algorithms, or published solutions (as evidenced by the US DoD in 2002). Following this analysis, the program generates color-coded zones, which where overlaid onto a base model, provide an indication of the potential severity and quantity of injuries.",0
28,13,"The base incorporates various engineering measures for force protection, and their impact on injuries is assessed. ""What-if"" scenarios are created quickly, and a clear and concise representation of the protective measures and resource needs is provided to commanders to facilitate decision-making.",0
28,14," Combat is inherently dynamic, unpredictable, and takes place in constantly evolving environments. Thus, personnel and equipment must possess the ability to be versatile and adaptable. Modularity has been acknowledged as a key factor in providing equipment with the necessary flexibility. This attribute can be seen in the popular Bailey bridge and its variations.",0
28,15," In the field of force protection engineering, the concept of modularity has been explored in two ways: through the use of modular structural solutions and modular levels of protection. This approach allows for flexibility in adjusting the size, logistical considerations, and level of protection based on the operational phase and location. An illustration of this concept is the modular ""sangar,"" which provides a secure position for firing and observation and can be either ground-based or tower-mounted.",0
28,16,"

The sangar underwent extensive testing, including ballistic, fragment, and blast effects, as well as timed construction trials. Troops and user representatives were present during weapon effects trials. The lightweight frame is made of glass fiber-reinforced plastic I sections with bolted joints, while walls consist of three layers for primary protection. An outer layer of overlapping steel armor plate panels, inner E-glass panels, and an intermediate gap that can be filled with sand or crushed stone offer maximum protection. Optional ballistically protected glazing can be added. In summary, the resulting sangar design is ready for practical use.",0
28,17," The military's focus in the future will be on contingency operations; however, their recent operations have been of an enduring nature. During these operations, soldiers may be stationed at various tactical bases of different sizes, ranging from main bases with thousands of occupants to forward operating bases with around 100 soldiers. These bases may remain in a fixed location for months and are often targeted by enemies.",0
28,18," Indirect fire, including rockets and mortars, is a major concern among the various threats faced. Insurgent forces have frequently used these weapons against UK forces. The research programme has focused on determining the ideal thickness of construction materials, such as concrete slabs and gabions filled with sand or crushed rock, to protect against these weapons.",0
28,19," ""There is a problem with protecting gabion structures from residual kinetic energy effects caused by indirect fire. While protection against rocket blast and fragment threats is established, the rocket's motor can remain intact and carry enough energy to pierce through the protection after detonation. Adding more thickness to overcome this issue is not practical. To address this, a program was initiated with input from users, academia, and industry during a brainstorming meeting.""",0
29,1," 

The implementation of coal bottom ash in civil engineering is a highly promising solution for mitigating the environmental and social issues that arise from bottom ash disposal. This review examines both traditional and cutting-edge technologies for the utilization of bottom ash in civil engineering, encompassing bottom ash production and properties, examples of its conventional utilization as a replacement for natural resources, and advanced utilization for specialized purposes, as well as environmental considerations for both raw bottom ash and its applications. The aim of this review is to encourage and facilitate the efficient recycling of coal bottom ash in civil engineering applications.",0
29,2,"Thermal power generation is a widely used energy generation method worldwide in modern civilization, and while biomass has gained attention as a potential substitute to conventional fuels, fossil fuels such as coal, natural gas, and petroleum are still the predominant source for thermal power generation. Thermal coal, in particular, is preferred due to its technical and economic advantages, and is used in many countries for power generation more often than oil or gas. However, during the process of electricity production from thermal coal, Coal Combustion Products (CCPs) are produced, as indicated by Feuerborn and Eck (2010).",0
29,3," CCPs refer to the remains of combustion, namely fly ash, bottom ash, Flue Gas Desulfurization (FGD) gypsum, and others. While some CCPs are reused efficiently in advanced nations, significant amounts of them are disposed of in developing countries as it is less expensive than utilizing them (Jang, 2010). Yet, the need to tackle the CCPs disposal issue has become critical for various reasons.",0
29,4," Leachate from CCPs can cause environmental contamination, leading to incidents such as the death of fish and birds due to toxic leachate from an ash pond in South Korea in 2009. As a result, researchers have focused on ways to increase the use of CCPs to minimize disposal and reclamation. (Carpenter et al., 2007; Han and Min, 2009).",0
29,5," Most research and evaluations on the usage of CCPs have centered on fly ash, which makes up nearly 80% of total CCP output and is suitable for application in various industries. On the other hand, since bottom ash accounts for a smaller fraction of CCP output (less than 20%), there have been fewer instances of its utilization, particularly in developing nations where eco-concerns are usually given less importance (Jang, 2010).",0
29,6,"""If the drawbacks of bottom ash were transformed into benefits, its application potential could be expanded, leading to an increase in its consumption. Its advantages include a higher hydraulic conductivity and lower density compared to natural soils, as well as higher strength in comparison to artificial lightweight aggregates. Natural construction materials such as sand, gravel, silt and clay are becoming scarce in developed nations due to environmental conservation movements. Therefore, bottom ash could be considered as a cost-effective and low CO2 raw material, supporting the global movement to conserve natural resources.""",0
29,7," The article discussed the traditional and modern ways of using coal bottom ash in civil engineering. It included information on the properties and production of bottom ash, examples of its use as a natural resource replacement or for special applications, and environmental concerns related to both raw bottom ash and its uses. The review aimed to encourage the effective recycling of coal bottom ash in civil engineering to address environmental and social issues related to its disposal. It should be noted that the term ""bottom ash"" refers specifically to coal bottom ash and not MSWI bottom ash.",0
29,8," Bottom ash that is dry is more easily recycled than wet bottom ash, leading to potential cost savings (Oh, 2004; 2005). Recently, a new management system has been introduced to transform bottom ash into fly ash by returning the dry bottom ash to the combustion chamber (Kochert et al., 2009). The process involves milling the bottom ash, conveying it back to the coal feeder, and reintroducing it into the furnace with coal (Kochert et al., 2009). This allows most of the bottom ash to be converted into saleable fly ash, and reduces the cost of disposal for the remaining bottom ash.",0
29,9," Boiler slag is a byproduct of wet bottom boilers that operate at very high temperatures. The ash is drawn from the bottom of the boiler and flown into a water-filled hopper where it is quenched and crystallized to form pellets. This material is known as boiler slag and is characterized by its coarse, angular, glassy appearance. In some countries, bottom ash and boiler slag are grouped together as bottom ash or bed ash. The production of bottom ash, including boiler slag, typically accounts for 5 ~ 20% of total ash production and varies depending on the type and combustion efficiency of the boiler system and the coal source in use.",0
29,10," Other byproducts that are extracted from thermal power plants include FGD gypsum, FBC ash, cinder ash, and cenospheres. FGD gypsum is derived from flue gas desulfurization, FBC ash is produced by boilers with an FBC system, cinder ash falls on the bottom of air heaters and ducts, while cenospheres are lightweight, hollow spheres primarily made up of silica and alumina, floating on the surface of ash slurry.",0
29,11," Bottom ash displays varying physical characteristics that depend on several factors such as the type and quality of coal source, pulverized fineness, and operating conditions of the power plant (RMRC, 2008). Generally, bottom ash particles possess dark, angular shapes with porous textures, as depicted in Fig. 2 (Kim and Lee, 2011). Coarse bottom ash has several millimeter-sized craters and pores while fine bottom ash has very few craters on its surface. Bottom ash develops micrometer-sized pores on its surface (Fig. 3) (Kim and Lee, 2011). The porosity of bottom ash is nearly half of that of quartz sand within the radius range of 1.7 nm to 300 nm (Fig. 4) (Kim et al., 2011). This implies that the nanostructure of bottom ash is denser than natural sands or gravels.",0
29,12," The impact of particle shapes, surface textures, and gradations on mechanical properties have been recorded in Table 1. Bottom ash has a rough surface texture, which results in a higher angle of shearing resistance and California Bearing Ratio (CBR) compared to normal aggregates (Ghazavi et al., 2008). Its porous structure contributes to a higher optimum moisture content, Los Angeles abrasion loss, and water permeability. However, the chemical soundness of bottom ash is similar to that of normal aggregates.",0
29,13," 

Bottom ash can be utilized in various fields apart from civil engineering. It can be applied in agriculture as soil amendment, providing nutrients to plants and crops, or as a growth medium in horticulture. Bottom ash can also be used for ice and snow control on roads and as blasting grit and roofing granules. Additionally, fine bottom ash with similar particle sizes to clay and silt can be added to ceramics and porcelains to introduce unique colors and texture.",0
29,14,"

The use of CCPs as geotechnical fill is widely practiced, with bottom ash or mixtures of bottom ash and low-quality fly ash being commonly used in construction for various purposes such as stabilized bases, granular bases, embankments, structural fills, backfills, and mine fills. Unlike fly ash, which requires complex treatments and screening processes, bottom ash can be easily handled using similar methods and processes as natural soils due to its similarities in physical behaviors, engineering properties, and particle size gradations. Additionally, bottom ash has excellent hydraulic conductivity, providing ""free-drain characteristics"" to foundations that are not susceptible to frost heave. With a higher friction angle, the shear strength of bottom ash is comparable to that of most natural soils. (Sources: Parker, 2002; Koehler, 2002; Karim et al., 1997; RMRC, 2008; Lovell et al., 1991).",0
29,15," Kumar and Stewart (2003) conducted a laboratory experiment on the geotechnical engineering properties of dry bottom ash from Illinois, US, which included varying amounts of sodium bentonite. The study revealed that the unconfined compression strength and cohesion of bottom ash-bentonite mixtures increased linearly as the bentonite content increased, while permeability decreased. In another study, Kumar and Vaddu (2004a) investigated the changes in strength and stiffness over time of bottom ash-bentonite mixtures, using the same type of bottom ash. Although bottom ash has physical characteristics similar to those of natural soils, differences in chemical characteristics resulted in variances of engineering properties of mixtures of bottom ash and admixtures with time.",0
30,1," 

Construction rehabilitation has not been extensively studied in Civil Engineering Schools around the world. This article suggests an international guideline course for Civil Engineering students at the bachelor's level, in order to introduce them to basic concepts related to rehabilitation of constructions. The course content and focus is designed to be common across all Civil Engineering programs globally, given our increasingly globalized world. However, the course should only be viewed as a general guideline, with universities expected to pay closer attention to topics that are most relevant in their respective regions or countries, including construction practices, preservation laws, and legal jurisdiction. Additionally, the authors suggest that the course should prioritize existing building types, including significant historic structures and commonplace buildings that require rehabilitation.",0
30,2," 

To accomplish this, the first phase in the process involved analyzing and incorporating the findings from a survey sent to professors at 89 universities in 30 different nations worldwide. Subsequently, topics that could be incorporated into the course were tentatively grouped, with an assigned teaching time for each. Afterward, distinguished specialists were consulted to audit the initial course outline. Finally, we refined the course based on their feedback and comments to create the ultimate guide.",0
30,3,"
The cultural significance of conserving old buildings is a central principle in modern societies. Over the years, researchers have delved into inspecting, testing, monitoring, and analyzing the structures, but there hasn't been a similar emphasis on teaching the subject. The designing of older constructions is a complicated process due to their intricate geometry, the variations in traditional material properties, diverse construction techniques, elusive knowledge of existing damages, and the impact of different design choices throughout their lifespan (Roca 2007). These hurdles create unique issues in diagnosing and intervening, which can at times restrain the adherence to regulatory requirements and the existing construction guidelines. As a result, comprehending, analyzing, and repairing old buildings is one of the most significant challenges that current engineers face.",0
30,4," 

The market for building rehabilitation and maintenance is a crucial aspect of construction, especially in developed societies. In Europe, this sector accounted for 28% of construction output, amounting to 332∙106 € in 2010, and in the USA, it also holds a significant share of the construction market. Furthermore, several factors indicate that the rehabilitation market has high growth potential in many countries, such as the increasing social awareness of the significance of preserving heritage buildings, favorable prospects offered by the cultural sector, and the aging of existing housing. Additionally, the rehabilitation market plays a vital role in sustainable urban growth by promoting lower energy consumption and using fewer materials than new construction work.",0
30,5,"There are various policies in construction rehabilitation that deal with extreme situations. The laws and regulations for preservation vary greatly from one country to another. In some European countries, the laws are quite strict, but in others, rehabilitation policies are not directly addressed. The legal jurisdiction for the scope of practice also follows a similar pattern.",0
30,6," When developing a guideline course, it is crucial to begin by asking some fundamental questions such as when to renovate a structure, what inspection procedure to follow, and whether students have any background knowledge on traditional and modern materials. Additionally, it is essential to include the question, ""Why?"" in all of these inquiries. A civil engineer must have the ability to adopt an approach while responding to these queries at the design level. (Dally et al. 2012).",0
30,7," 

It is important to focus on preserving historic buildings that have been highlighted for rehabilitation and maintenance, as their potential failure can have significant technical, cultural, and economic consequences. The rehabilitation protocols for these buildings must be carefully considered. Additionally, while less culturally unique buildings may still need rehabilitation due to changes in functionality or habitability, they too require thorough analysis. The rehabilitation market for these types of buildings also contributes significantly to the construction sector's economy. In conclusion, both types of buildings should be included in the educational proposal.",0
30,8," Engineers, particularly Civil Engineers, require specialized training due to the various factors involved in construction rehabilitation. Lombillo et al. (2013) conducted a study on the global commitment of Faculties or Schools of Civil Engineering towards construction rehabilitation.",0
30,9," Based on the previously mentioned research, and as a consequence of the growing demand for the rehabilitation of existing buildings, we believe that studying a course in construction rehabilitation should be considered optional for Civil Engineering students pursuing a bachelor degree. In light of diverse practices across countries, this article suggests the creation of an international guideline course in construction rehabilitation to facilitate collaboration, joint strategies, and relationships among colleagues in universities.",0
30,10," The article concludes by selecting topics that integrate the gathered information. To provide justification, the subsequent section introduces some essential topics for completing the construction rehabilitation guideline course.",0
30,11," As a result of the aforementioned difficulties in analyzing pre-existing structures, we must employ a comprehensive approach based on agreement. A rational analysis procedure is depicted in Figure 1 as an illustration.",0
30,12," In selecting appropriate techniques and materials in subsequent stages of Design/Project and Work (Binda et al. 2009), previous knowledge is critical within these phases. Additionally, conducting these preliminary studies can reduce intervention costs and working times as the preliminary study phases (phases 1-3) can minimize uncertainty in the intervention (Lourenco et al. 2008).",0
30,13,"

Hence, a precise preliminary investigation (Binda et al. 2008) should be the basis of the rehabilitation process to determine the current state of the building. The rehabilitation process must be approached from a multidisciplinary approach, taking into account various complementary aspects such as the historical evolution of the construction, geometry, cracking patterns, material characteristics, construction technology, potential failure mechanisms, etc. (Penazzi et al. 2000). It is crucial to have collaboration among professionals such as architects, engineers, chemists, restorers, historians, archaeologists, etc. Binda et al. (2000) suggest that the multidisciplinary working method is key to a successful investigation, which is evident in the Torrazzo of Cremona (Italy) rehabilitation study.",0
30,14," The question we now have enough motivation to ask is what construction types we should teach Civil Engineers. The subsequent paragraphs will provide details on this matter. The vast majority of historical monuments are masonry buildings, as are numerous residential structures. In addition, there are a significant number of civil engineering structures like bridges, retaining walls, and highway reinforcements. In Europe alone, 500,000 monuments are registered with the International Council on Monuments and Sites, and 20% of them have structural issues. Of those issues, 40% refer to masonry constructions and buildings. This implies there could be around 40,000 necessary interventions on existing buildings, not to mention civil engineering structures such as infrastructures and bridges. Consequently, we need to create a teaching module that focuses on the rehabilitation of masonry structures in Civil Engineering degree programs.",0
30,15," Earthen buildings are widely used throughout the world, particularly in developing countries where traditional construction methods are still prevalent. Approximately 17% of cultural heritage sites are built of earth, emphasizing the need for effective diagnostic techniques to assess the condition of earthen architecture and preserve it from external threats.",0
30,16," The majority of houses in the US are made of wood, but only a small amount of graduate students in structural engineering and materials science specialize in timber. In contrast, Germany only has 14% of single family houses built with timber and China has almost completely replaced the use of timber with concrete, despite it being commonly used in traditional buildings. Timber was extensively used for floor and roof trusses in both common and historic structures.",0
30,17, There is a requirement to offer fundamental knowledge about how existing buildings react to seismic activity to reduce the destructive impacts of earthquakes on buildings.,0
30,18," It is a challenge to establish standardized criteria for an elective course that has a significant societal impact and provides our students with fundamental knowledge. The proposal is to create a universally recognized course for all Civil Engineering degrees that emphasizes common topics. However, it is crucial to tailor the course to the specific region and country since each university must focus on the most common construction practices in that area, considering the local context.",0
31,1," The objective of the study detailed in this article was to create and evaluate a collaborative mobile augmented reality tool (CAM-ART) that is contextually aware and beneficial in construction and civil engineering education. The study utilized an augmented reality-based information delivery system called CAM-ART that was tested in a classroom setting to augment conventional lecture-centered teaching and learning methods. The curriculum materials of a regular textbook were supplemented with computer-generated three-dimensional (3D) objects and other digital multimedia, including sound, video, and graphs. Using the CAM-ART application on their tablets or smartphones, the study comprised civil engineering and construction students who were divided into Group A (the control group) and Group B (the test group) through random selection. The composed learning tool was evaluated in a collaborative and interactive environment, with pre-performance and post-performance data collection, and student perception of using the AR-based tool was assessed through a feedback questionnaire. Data analysis revealed that CAM-ART positively contributed to students' learning in both the short and long term.",0
31,2," Despite recognition of the value of technology in improving learning quality, higher education institutions are slow to adopt technology advancements on a large scale, and have much to learn about the implementation of educational technology. Scholars argue that blended learning environments, which combine traditional classroom practices with technology solutions, are the way forward (D'Souza et al., 2013). However, current teaching paradigms and methods are often outdated and do not take into account the fact that the new generation of students are immersed in information and communication technology (ICT) from a young age, handling digital information daily, and working collaboratively and competitively in interactive environments (Beck and Wade, 2006; Klopfer, 2008; Prensky, 2001).",0
31,3," The effectiveness of instrumental aids in controlling human learning has been suggested by researchers such as Skinner (1954). An examination conducted by Virginia Tech and the University of Georgia on approximately 1,400 university instructors revealed that the majority of instructors believed that classroom technologies had a positive impact on their teaching and students' learning, according to respondents (Brill and Galloway 2007). In another research, teachers demonstrated a favorable attitude toward ICT since it helped enhance students' integration (Gülbahar 2008). As a result, delivering a supplementary pedagogical tool in combination with teachers' guidance is an excellent method to promote successful learning. When a new technology is introduced in the classroom, the primary question that must be addressed is whether students can potentially accomplish the same tasks using the new technology (such as smartphones or tablet devices). Does this also translate to better and more engaging learning with extra-lasting outcomes? As a result, it is critical to use technology correctly and effectively.",0
31,4," The paper discusses the use of mobile technologies to promote interactive learning and enhance student engagement. To this end, the authors created a context-aware mobile augmented reality tool (CAM-ART) and applied it in an undergraduate engineering course, with the aim of transitioning from traditional, teacher-centered instruction to a more student-centered approach. The study sought to improve students' visual and conceptual understanding of classroom technology and lay the groundwork for future research in STEM disciplines.",0
31,5," Metacognition is a crucial factor in the learning process according to various learning theories. It involves learners being aware of the best way they learn and how to control their learning. A presurvey test was conducted on 166 undergraduate students regarding their awareness of their learning style, and feedback was obtained on the use of technology and mobile devices in the classroom. The results showed that visual information and technologies were perceived as effective aids for learning, but motivation could not be stimulated by just adding visual presentations. To combine traditional and technology-based course delivery techniques, mobile AR was chosen as an innovative approach due to the critical role of motivation in learning.",0
31,6,"

Technology, if properly used, has the potential to enhance student achievement and teacher learning, according to various researchers who reviewed the literature on technology and learning. Interactive simulations are believed to be more effective for cognitive gain outcomes, as per studies done by Dede in 1998, Vye et al. in 1998, and Yoon et al. in 2012. With the accessibility and ease of creating and displaying virtual objects and environments, the authors of a study were motivated to investigate its potential in real classrooms. They aimed to test if students can learn better by using their mobile devices to access contextual visual information related to the course material. The study focused on four types of virtual-real environments, namely pure virtual reality, augmented virtuality, AR visualization, and reality, each with distinct characteristics described by Milgram and Kishino in 1994 and Azuma in 1997. AR visualization supplements reality rather than replacing it, as it overlays 3D computer-generated objects and text on top of the real-world environment.",0
31,7," The increasing use of AR in education is due to its ability to facilitate situated learning, where hands-on experiments are more applicable to real-world situations. By combining the real world with the learning process, AR creates interactive and engaging learning experiences, leading to more participation and collaboration. The CAM-ART mobile context-aware AR tool was designed and tested in an undergraduate course, allowing students to receive virtual information about course materials through their handheld devices while working collaboratively. This eliminates the need for bulky AR head-mounted displays.",0
31,8," According to the survey responses, nearly 80% of students were confident in using mobile applications on their devices and almost 50% expressed comfort in working in a group where each member could use their own mobile device. These findings, along with other academic research, suggest that utilizing interactive and collaborative pedagogical tools can improve learning quality, enhance students' practical knowledge, and help them apply course concepts to real-world problems. The rest of the paper will provide a detailed description of the mobile AR learning system design, assessment strategies, and results and discussion.",0
31,9,"

Researchers have outlined seven key principles for designing a good educational system: interaction, empowerment, awareness, flexibility, accessibility, immediacy, and minimalism. To create an effective design, these principles should be incorporated through a participatory process with teachers and tested in the classroom. CAM-ART was designed to incorporate these principles, specifically through the use of a context-aware mobile AR application that displays visual information on top of textbook pages, coupled with teacher knowledge to provide empowerment and awareness. Additionally, the tool can be used individually or collaboratively, allowing for interaction and flexibility in accommodating varying levels of knowledge within and between groups.",0
31,10," The AR platform utilized in the study described here employs AREL, an augmented reality experience language. An AREL experience encompasses both static and dynamic components; the former being the AREL extensible markup language (XML) which defines all of the content and links, and the latter being the AREL JavaScript that specifies the interactions and behaviors of individual objects or the entire scene. AREL is featured in Junaio and is compatible with both Android and iOS operating systems. An AREL package comes equipped with three distinct elements: (1) static XML to define content, (2) Javascript logic to specify interactions, and (3) multimedia content (examples of which include 3D objects, images, movies, and other types of multimedia). Via a wireless internet connection (Wi-Fi or 3G-4G), end-users and servers establish communication by exchanging data over hypertext transfer protocol (HTTP).",0
31,11,"

As handheld devices are moved over book images, multimedia elements, including 3D computer-generated graphics, videos, and sounds, appear on top of the textbook visuals. This allows for interactive learning experiences, such as watching a real video of a split spoon sampler in action. Two-dimensional images of different drill bits and hand-operated augers, as well as 3D models, can also be displayed. Students can collaborate with peers and use multiple devices simultaneously, enhancing participation and encouraging interaction. Teachers can easily implement this tool by having students use their own mobile devices at no extra cost.",0
31,12," The 88% male and 12% female students were randomly divided into two groups, with Group A acting as the control group attending the first mystery lecture and Group B acting as the test group attending the second. Both lectures had identical learning objectives and material, but only one allowed the use of CAM-ART. Students were not informed ahead of time to prevent bias, but were given a presurvey questionnaire a week prior to the lectures to collect basic information on their gender, program of study, familiarity with technical terms, and possession of certain tools. Each student was assigned an ID number and assigned to a group accordingly. The topic of the lecture was on construction site investigation.",0
31,13," The experiments required appropriate techniques and guidelines to assess the benefits and impacts of the new tool on the learning process. The authors chose nine different classroom assessment techniques (CATs) as introduced by Angelo and Cross (1988) and used them systematically to evaluate the tool's practical benefits in classroom settings. The nine selected CATs were background knowledge probe, memory matrix, categorizing grid, defining features matrix, approximate analogies, course-related self-confidence surveys, punctuated lectures, teacher-designed feedback forms, and group-work evaluations. Detailed descriptions of these CATs can be found in Angelo and Cross' work.",0
32,1," The precise monitoring of civil engineering structures necessitates techniques that deliver accurate and reliable measurements with fast processing speeds. With the advent of microprocessor controllers and communication systems, monitoring systems have been developed to ensure reliability of civil engineering constructions. This paper presents a detailed overview of the design and architecture of the Civil Engineering Structures Reliability Monitoring (CERM) system, developed exclusively for the Technical Mechanics and Theory of Constructions Department at the Faculty of Civil Engineering and Architecture, University of Nis. Unlike generic monitoring systems, CERM is designed to provide accurate reliability monitoring, and this paper explores its full potential. The system is based on the use of Integraf 10X series universal microprocessor controllers and a custom software package. CERM provides real-time data acquisition and analysis of measured values using developed mathematical models.",0
32,2,"

The development of low cost sensors that can be charged with solar power and communicate wirelessly has provided new opportunities for designing systems and applications to monitor various parameters of structures, particularly in civil engineering. In civil engineering, monitoring structures and constructions is crucial, as it ensures their stability and reliability. Engineering structures may experience alterations in stability over time due to functional deficiencies, material and property changes, fluctuating load levels, human errors, and neglectful maintenance. During the design process, engineers calculate the essential quantities for a structure's lifetime and reliability, such as material properties, geometry, load, and environmental effects. However, during their lifespan, external influences alter these values, which can result in a shorter lifespan, impaired function, or even structure failure.",0
32,3," Reliability of a structure can be assessed in the design or operation phase. The factor of safety (FoS) is calculated as the ratio of structural capacity to actual load and is often referred to as the realized FoS. Other types of FoS include technical, social, and design. Variables N and L influence the technical FoS, while the social FoS considers the structure's impact on people. The design FoS is a constant value prescribed by law or custom. FoS is complex and should be analyzed from different perspectives. Structural resistance also affects reliability, particularly when dynamic influences are considered. Technological constraints, such as maximum deflection angle and vertical acceleration, are used to ensure structure safety.",0
32,4,"

Structures in use gradually deteriorate due to various factors such as load, environment, and human error. Predicting the exact deterioration processes and the lifespan of long-life structures is impossible. However, there are methods available to anticipate the impact of environmental and human factors on structures. In literature and practice, two methods are used to enhance structure reliability during the operational stage: computer-supported monitoring of load effects and fuzzy methods for technical condition evaluation. Computer-supported monitoring is applied for simulating and monitoring stress parameters. The mathematical model specially designed to monitor the stability of the construction and its parts includes deformations, stretching, and structural resistance.",0
32,5," The ideal method for monitoring structures' reliability could be a fusion of the two methods. This would involve a computer system with the capacity to keep track of particular structure parameters, simulate environmental and human factors, anticipate potential behavior of the structure, and offer recommendations for improving the structure at the operational stage. These computer systems are useful for monitoring river water quality [5], production monitoring in plants [6], and monitoring structures in civil engineering.",0
32,6," We will introduce the architecture of a computer-based system, known as Civil Engineering Structures Reliability Monitoring (CERM), in this research paper. CERM aims to guarantee the dependability and steadiness of observed structures through precise measurements and risk assessment using prediction models and expert knowledge. CERM has the potential to calculate crucial structure parameters, such as deformations, stretching, and structural resistance, in real-time. The system can predict structure behavior for future periods of time from the calculated parameters. The software, which is still in progress, will be tested in laboratory settings to optimize stable structures and constructions. The system not only monitors the structure's parameters but also evaluates the mathematical structure model, a projection of the constructional set and distinct parts of the structure, to establish correlation. The system will be useful in both the building design and operation phase since it can anticipate the behavior and simulate the impact of dynamic environmental parameters. Consequently, it can aid in determining the stability of building designs for the planned lifetime of the structure.",0
32,7," The CERM system, designed to monitor the reliability of civil engineering structures and constructions, is illustrated in Fig. 1. The system operates using a client-server architecture with the client responsible for collecting structure parameters through various sensors while the server analyses the gathered measurements with specialized software to assess reliability. CERM's unique software package, including communication software and application software for both client and server, automates the gathering, processing, and supervision of data to improve the reliability of structures.",0
32,8," The INTEGRAF 10X is a microcontroller-based universal regulator that provides multiple functions such as acquisition, regulation, automatization, supervision, and control of processes and production systems. It is a high-performance microcontroller compatible with instrumentation and automation of industrial and agricultural equipment, waterworks, and other similar systems. With eight analog and eight digital inputs, it can receive signals from various sensors and measuring devices. The software of Integraf 10X can process and scale technical values of input signals and control the outputs independently, eliminating the need for human intervention. Additionally, it maintains a real-time connection with CERM clients through various interfaces such as GPRS modem, Ethernet cable, 485 communication interface, or PLC.",0
32,9," The CERM system utilizes various types of connections to establish its communication infrastructure. One such connection is based on GPRS modem, which provides a solution to communication issues between the central computer/server and microprocessor regulators INTEGRAF 10X/clients within any area covered by the local mobile network. However, to prevent data loss in cases of traffic blockage or inability to ensure constant connection, data buffering must be implemented. Fortunately, the CERM system has a client-side buffering function that ensures the security of data in cases of technical errors. Although GPRS offers network flexibility, it is not without drawbacks such as being functionally dependent on the quality of mobile service provided by the local operator of the digital GSM network. Additionally, the response time using GPRS modems is longer compared to wire connections, and the load of the mobile network can significantly impact the response time as well.",0
32,10," Due to the potential for the GSM service provider to be unreliable and traffic blockages, it could reflect poorly on the reliability of the CERM system. To address this issue, three additional types of connections have been provided for the CERM real-time system, including GPRS modems, Ethernet cable, and RS 485 communication interfaces or PLC. With the ability to connect to multiple measuring points on one or more structures, the CERM system creates a unified information system for conjoint control of the structures' reliability.",0
32,11," 

The CERM system is versatile in measuring the reliability of various structures and constructions, and serves as a centralized information system for monitoring structure reliability in different locations and types. It calculates reliability using structure parameters, which differ depending on the type of structure being tested. Strain and temperature are the most common parameters of interest, as they have a significant impact on a structure's reliability during operation. To measure these parameters, resistant strain gauges and thermoelectrical sensors can be used with the Integraf 10X device. The CERM system software continuously compares real-time measured parameters with design-phase parameters or measurements from a database. If there is a deviation from expected values, the system will suggest optimized changes to ensure the structure is safe.",0
32,12," The software will define mathematical models of bridge and roof constructions for testing purposes. Temperature, wind speed, frequency, strain, slope, and deflection will be used to monitor the reliability of the structures. Simulated input parameters will be entered in Integraf 10X and sent to the server for reliability testing. If there is a deviation from the nominal value, the system will alert the user and provide reliability optimization steps. The results of reliability calculation and structure behavior prediction will be evaluated before using CERM appliance for real structure reliability measurements.",0
32,13," 
In recent years, the assessment and mitigation of risk have become crucial research areas in civil engineering. If a structure's properties do not match its expected values, its reliability, safety, and performance are compromised. Continuous monitoring of structural features is required to ensure their reliability, which involves measuring essential parameters and noting any alterations in the building or material. This is essential for prompt and effective maintenance of structures. While there are several approaches to monitor a structure's reliability, computer-based methods are the most effective.",0
32,14, A computer system called CERM was introduced in this article for monitoring the reliability of civil engineering structures. The aim of the system is to identify and suggest corrective action to reduce the difference between actual measurement values and predefined limits.,0
33,1, The utilization of digital models to convey civil engineering designs is still a topic of discussion. This preliminary study explores the adoption of technology in repurposing data and evaluates the time and cost of digital (as opposed to traditional) design preparation for infrastructure projects.,0
33,2," The study explores the impact of building-information-modelling (BIM) on quality-management, technical-applications and contractual-liability. It involves creating project scenarios and analyzing the timeline and fees of the resulting modelling application. Furthermore, it includes conducting qualitative interviews with eleven significant stakeholder companies to validate the findings.",0
33,3," The investigation into digital-model data distribution and usage revealed that there was an 8% increase in time and efficiency during the design phase and an overall cost-saving of 0.7%. However, the use of modelling is not universally accepted across supply chains due to concerns about liability, quality management, and the lack of Australian-Standard contract clauses that address the hierarchy, clarification, and reusability of digital-model documents.",0
33,4," The results of a limited industrial study indicate that quality systems should focus on quality control procedures and ensure that dimensioned documentation is given priority. Additionally, training on digital model formatting, CAD file continuity and digital visualization software can improve model dissemination and reuse. Using digital model data distribution in civil engineering contracts can result in time and cost savings, and enhance infrastructure provision for society.",0
33,5," 
This study enhances our understanding of the distribution of 3D-models in the areas of roads, earthworks, and drainage. It also provides proof that, with the right attention given to the conditions of contracts and training to maintain continuity in revising documents, the civil engineering industry can gain significant advantages from digital-model data in communicating design concepts.",0
33,6," The means of communication for engineering design documentation have progressed from hard-copy blueprints to integrated digital-models, but some in the industry still prefer hard-copy drawings. Contractual obligations related to hard-copy dissemination are well-known, but there is less understanding when it comes to digital-model data-distribution. The civil-engineering industry is uncertain about the risks and benefits of digital-model data for design and asset-management. There is a need for more information to determine if benefits outweigh the risks of implementing digital-model data-distribution in civil-engineering contracts. (Steel 2012)",0
33,7," 

Building information modelling/BIM-Infrastructure civil-engineering data-modelling creates digital models that convey construction and engineering design details. However, there are differences in user-disciplines when it comes to repurposing these models over a built asset’s life-cycle. BIM software is useful in retrofitting a building during its maintenance phase, while civil-engineering modelling software is more tied to site-establishment and the corresponding site environment. We need to enhance existing theory and link it to both design-stage application and asset-management. (Sources: Li et-al 2009; Li et-al 2012; Hughes, 2000; Cai, 2006; Azhar, 2011; Becerik 2012; Tran, 2011; Cheung 2012)",0
33,8," BIM and earthworks/drainage-activities data-modelling differ in the potential for model reuse or repurposing. Civil-engineering infrastructure activities often require resurveying, whereas asset-management for substructure/sub-element establishment limits the potential of civil-engineering digital-data-models to assist in retrofitting upgrades. Design-model aspects, including architectural/structural superstructure and mechanical and electrical fittings and fixtures, offer more potential for facilities managers in retrofitting upgrades.",0
33,9," The examination of major concerns with regards to transportation, drainage and earthworks data modeling in the 'civil' sector can be tackled by referring to studies related to 'BIM'. This is valid because the construction industry frequently considers BIM as an all-inclusive term and both building and civil engineering endeavors necessitate the dissemination of pertinent information to multiple inter-disciplinary groups.",0
33,10," The major concerns relating to data distribution in data modelling are discussed below. These concerns include quality control and preparation, liability and agreements, and intellectual property and compensation. They are examined progressively in light of key factors. Through the evaluation of these essential factors, the research objectives specified in the methodology section are devised with the overall aim of assessing significant advantages that have been identified in prior research on digital data model distribution in civil engineering contracts carried out by Sas (2008) and Arayici (2011).",0
33,11,"

A digital model for civil engineering, along with related BIM execution plans and quality assurance procedures, can replace traditional manual methods and has the potential to reduce the amount of hard-copy set-out point information and road cross-section illustrations. It also allows for simplified drawings of longitudinal sections on a smaller scale. However, this reduction in drawing-form information can only be achieved if certain requirements are met, such as providing native format digital versions of design drawings and models to the relevant parties and ensuring they have software capable of reading all the supplied data. If these requirements are not met or only partially met, the designers resort to including all the traditionally required information on their drawings, regardless of potential duplication or irrelevance. The discussion of ""eastings"" and ""northings"" below serves as a case-in-point.",0
33,12," In order to expand a mine, a project for access roads, infrastructure, and facilities must produce many drawings, including a site-plan for an unsealed heavy-vehicle access-road which requires the identification and siting of up to thirty equating-elevation-level easting and northing set-out points. By implementing digital-model data-distribution early on, unnecessary set-out points for easting/northing/levels across many design drawings can be eliminated, resulting in multiple-party verification and reduction of duplication. After the certificate of practical completion, these set-out points are irrelevant. (Donaldson, 2013).",0
33,13," Set-out points indicated on design drawings can be a time-consuming task for designers and recipients due to the need for processing and re-digitisation. In some cases, surveyors might receive hard-copy versions of several hundred eastings, northings, and levels, requiring them to create their own digital copies. Senior drafts-people often carry out extensive checks to ensure each supplied coordinate matches the corresponding digitised or re-digitised equivalent. While disclaimers are widely used by the industry to dilute contractual obligations and responsibilities, surveyors still check document-consistency to ensure supplied design-data matches the construction or as-built versions. Even when data is supplied merely for information purposes, vigilance and checking for errors and mismatches between contracted hardcopy documents and digital-information is essential.",0
33,14," The best approach for civil engineering set-out points can be found, but there is a need for providing an integrated geometric design information to the construction team beyond laser-scanning products like Trimble. This can be achieved through a digital model of strings rather than points in order to extend the traditional hard-copy set-out points. The ideal solution for surveyors would be to receive a reliable native-format digital model as part of the contract documents without the need to navigate ""disclaimer-stamps"".",0
33,15,"

Although advanced equipment is becoming more widely available, it is not always clear how BIM balances technology application with contractual obligations and responsibilities. BIM requires well-developed management procedures during the construction phase, but theory often conflicts with practice. For example, in traditional hard-copy drawings, senior staff usually check them before issuing them as tender or contract documents. However, digital model data also needs to undergo the same checks, but senior staff may be less comfortable checking three-dimensional models than hard copies. It is a platitude that the industry needs to address quality control and liability as design data moves down the supply chain and extends into the asset's usable lifespan. (Source: Arensman, 2012)",0
33,16," Requisite checks are necessary at different project stages and must be clearly stated in standard forms of contract as part of quality systems. Australian Standards AS-4000 clause 8 specifies general conditions of contract for defining responsibility for correct information and clause 29 outlines the need to establish and adhere to a conforming quality system, however, these clauses do not explicitly provide for digital models. This lack of standard contract clauses for risk allocation of model content and perceived liability of stakeholders (discussed below) is a concern highlighted by Foster (2008).",0
33,17," Design-models are more flexible than hard-copy drawings and can be edited easily after distribution, but this presents potential liability issues. The party providing the model may be concerned about unauthorized changes or software incompatibility, which could pose a serious risk. To address this, many designers use disclaimers to protect themselves from any claims arising from erroneous edits made to the digital model. The purpose of the disclaimer is to indemnify the supplier/source of information and distance designers from liability.",0
33,18,"

Recipients express concerns about digital-model liability, while nominated and domestic suppliers/subcontractors are unsure if digital-models alone are contractually binding. Despite routine checks against hard-copies for discrepancies, minor errors in the model are simply corrected by parties further down the supply-chain or recreated from scratch. Arensman's findings suggest that stakeholders remain wary of relying solely upon digital-models, despite industry desires.",0
33,19,"

Liability and disclaimer concerns are further complicated by uncertainties regarding intellectual property rights for BIM models. Designers' digital models can be reused, which raises questions about ownership and potential lost revenue. In-house innovative designs may be open to interpretation by others seeking to use similar innovations for independent projects. Softcopy models contain significant libraries of standard specification entities, and digital models have high usability if repurposed. Ownership of the completed building model remains an ongoing issue due to the collaborative nature of BIM. Clarifying patents within a design model and identifying individual innovations may ensure legal protection for patented designs. (Foster 2008; Larson 2008)",0
33,20," Project procurement presents an opportunity for clients to purchase or donate towards a completed design-model. Successful bidders are given the chance to bring the design to life and unsuccessful ones release the rights to the submitted model for appropriate compensation. An example of this process is demonstrated in the bus-station redevelopment project in Perth WA. A multi-stage tendering process was initiated to seek expressions of interest from design-and-construct companies. This resulted in an invitation to supply a digital-model of the design proposal for a fee, which allowed subsequent tenderer review and the award of the contract to the winning consortium. The losers were also suitably compensated for their submitted models. This approach can invite further discussion of fee structures for digital-model procurement as part of the tendering process.",0
33,21," The calculations and validations were made under the assumption that the estimated hours to complete a digital model include error checks before issuing. Even if not explicitly stated in the contract, a significant amount of digital modeling is assumed to be carried out as per current industry practices, whether for information or not. Furthermore, the industry is assumed to spend more time on modeling and less time on hardcopy drawings. This assumption was verified anecdotally and through interviews, indicating that more hours are spent modeling than are recorded for hardcopy drawing timesheets.",0
34,1,"

This research examines the link between individual motivation levels and the decision-making and overall performance of civil engineers in construction projects. The study focuses on Turkish civil engineers, as Turkish contractors have a significant presence in international markets. A questionnaire survey was conducted to collect data on personal demographics and perceived motivators. The findings show that personal demographics play a crucial role in determining what motivates individuals, and executives in the construction industry can leverage this connection to motivate engineers more effectively.",0
34,2," The significance of employee motivation is a topic that has gained interest among employers and researchers across various fields. The construction industry has recognized the importance of motivation, as it has the potential to improve project performance and deliver high-quality outcomes within a shorter time and at reduced costs. This aligns with the ultimate objective of construction projects, as completing projects within budget, schedule, and quality standards can increase the likelihood of securing new contracts. (Oyedele, 2010).",0
34,3,"

Improving the performance of construction workers is believed to enhance the overall performance of a construction project (Uwakweh 2006). Consequently, researchers have dedicated significant attention to the motivation of construction workers. However, there has been a lack of research regarding the motivation of professionals in the field such as architects and civil engineers. It is important to motivate professionals as much as construction workers for a successful project completion. If a civil engineer lacks motivation, it can lead to inadequacies in decision-making, problem-solving, and change management which can negatively impact the project's success (Pheng & Chuan 2006; Seiler et al. 2012). In other words, the success of a construction project is highly dependent on the professionals involved, who come from various design and management positions.",0
34,4,"

There is a question regarding how to motivate professionals in the construction industry. While some studies have been conducted to identify motivators, they often fail to account for the fact that professionals have unique characteristics that can influence their motivation. Demographic variables, such as age, marital status, education, and work experience, play a significant role in how professionals perceive motivation. To address this gap in research, this study aims to explore the motivators of Turkish civil engineers while also analyzing the relationship between motivation and demographics. Specifically, the study seeks to collect and analyze data to understand what motivates civil engineers in Turkey and examine how motivators vary based on demographic factors.",0
34,5," Employing a comprehension of the correlation linking civil engineers' motivators and their demographics can prove to be advantageous for the upper-level management of construction organizations. It is projected that, with this comprehension, senior officials can stimulate their employees more efficiently through the implementation of various motivators that cater to individual civil engineers.",0
34,6,"

Although the main focus of this study is not cultural examination, a better understanding of the factors that influence the motivation of Turkish civil engineers can be achieved by considering the local national culture. To provide insight into the national culture of Turkey, Hofstede's (1980) study was chosen among others, such as Trompenaars (1993) and Schwartz (1994). Hofstede (1980) explored national culture in different countries through four dimensions: power distance, individualism, masculinity, and uncertainty avoidance. This model has been utilized by numerous researchers.",0
34,7," Turkey ranks high in power distance, indicating a culture that accepts inequalities within organizations (Hofstede 1980). With a centralized power structure and a clear hierarchy, Turkish employees expect close supervision and direction from their managers. Superiors and subordinates view each other differently. However, a high score in power distance can also make it challenging to obtain cooperation from subordinates.",0
34,8," According to Hofstede's (1980) research, Turkey has a low score in individualism, indicating that it is a collectivistic society with a strong focus on group harmony. Individuals value the group over themselves and avoid open conflicts. Communication and feedback are indirect and emotional dependence on the organization exists. The relationship between individuals prioritizes moral values over task completion.",0
34,9,"
Hofstede's (1980) research focused on the masculinity dimension, which explores whether individuals prioritize excelling in their profession or finding enjoyment in their work. According to Turkey's low masculinity score, socializing with family and friends holds greater significance than work for Turkish people. This implies that they work to live rather than live to work. Moreover, a low masculinity score indicates a tendency to avoid conflicts in both personal and professional settings, and to prioritize achieving consensus.",0
34,10," Hofstede (1980) delved into the notion of how societies cope with ambiguous and unknown scenarios by outlining an uncertainty avoidance dimension. Turkey was awarded a high score on this parameter, highlighting the desire for written laws and regulations. Furthermore, individuals resort to numerous rituals to assuage anxiety and stress. A high score on uncertainty avoidance also indicates significant anxiety about keeping one's job secure. Dissenting individuals and inventive concepts are frequently viewed as hazardous until they gain acceptance.",0
34,11,"

The motivation of engineers and architects has been studied using various motivation theories, but most studies have failed to consider individuals with unique personal characteristics. While Oyedele's (2013) study explored the link between demographics and motivation in the construction industry, it only focused on the demotivating factors for architects and considered work experience and firm type as personal factors. To fill the gap in research, this study aims to investigate the motivators of civil engineers based on their personal characteristics (such as age, experience, education, and company type) to enable executives to tailor motivators to individual engineers.",0
34,12," The study aims to investigate the impact of personal demographics on the motivators of civil engineers. The methodology included a thorough literature review to identify the most commonly cited motivators, designing a questionnaire based on the literature review and surveying civil engineers in Turkey. The collected data was subjected to statistical analysis to determine whether there is a significant relationship between personal characteristics and motivators among Turkish civil engineers.",0
34,13," A questionnaire comprising seven questions was created, with the initial section consisting of six questions that gathered data on the personal characteristics of the respondents, such as age, marital status, education, work experience, type of company, and the maximum project value. These personal characteristics have been investigated in studies conducted in various industries, including construction (Oyedele 2013) and others (Kukanja 2013; Amankwah et al. 2013; Linz 2004; Huddleston et al. 2002; Wong et al. 1999; Gaki et al. 2013; Urosevic and Milijic 2012), except for the maximum project value, which is crucial for civil engineers.",0
34,14," The determination of a questionnaire's internal consistency when using a Likert scale is commonly advised to be done by calculating a Cronbach's alpha coefficient of reliability, as suggested by Oyedele (2013). Additionally, nonparametric tests are recommended for analyzing Likert data by Carfio and Perla (2008) and Jamieson (2004). Thus, for this study, the IBM SPSS Version 21 program was utilized to perform the Mann-Whitney U test.",0
34,15," 

To verify if the motivators and their corresponding Likert scale truly assess the motivation of civil engineers, the Cronbach’s alpha coefficient is computed. A value greater than 0.8 is recommended by George and Mallery (2003) to ensure satisfactory internal consistency. The study's overall Cronbach’s alpha coefficient yielded a value of 0.855, indicating strong reliability and internal consistency. It is also important to evaluate the Cronbach’s alpha values of each item when excluded, to confirm that all criteria contribute to the internal consistency. If the Cronbach’s alpha value is higher without including the criterion (i.e., motivator), it implies that the overall Cronbach’s alpha coefficient value would be greater without it (Field 2005). The findings from Table 2 indicate that none of the motivators need to be excluded since all Cronbach’s alpha values for excluded items are lower than the study's overall Cronbach’s alpha coefficient of 0.855.",0
34,16," 

The assumption that there are no variations in the average scores of the incentives as observed by civil engineers in two categories (10+ years of work experience vs. less than 10 years of work experience) is known as the null hypothesis. If the null hypothesis is discarded, it indicates that the discrepancy between the average scores of the incentives is statistically substantial at α ¼ 0.05, and it is represented by an asterisk (*) beside the average scores provided in Table 3.",0
34,17," 

Table 3 illustrates that the age factor plays a significant role in motivation studies for civil engineers. Younger civil engineers (below 35 years) emphasize on gaining knowledge, ability, and confidence, as well as opportunities for advancement and promotion compared to older engineers. This outcome is consistent with Schein's (1990) career anchor categories, where technical/functional-motivated individuals such as civil engineers need such motivators. The result is meaningful because young engineers possess limited experience in the construction industry compared to older engineers, thus requiring promotion opportunities. This finding aligns with previous studies conducted by Wong et al. (1999) and Linz (2004), stating that younger employees show an inclination towards career motivators associated with skills development and career progression.",0
34,18," It was discovered that single and married civil engineers have similar views on motivators, except for the importance they attach to ""gaining knowledge, ability, and confidence"" and a ""comfortable physical work environment."" Single civil engineers place more importance on these motivators than those who are married, which could be attributed to their desire for career advancement and gaining more experience. This finding is similar to a study conducted in Hong Kong's hospitality industry by Wong et al. (1999). However, Gaki et al. (2013) found no significant difference in the perception of motivators between single and married nurses in Greece. Although the findings on the relationship between marital status and motivators vary, this study suggests that marital status does have an impact on some motivators.",0
34,19," Table 3 reveals that there are notable discrepancies in the attitudes towards three different motivators when examining the educational backgrounds of the participants. The motivators in question are ""gaining knowledge, ability and confidence,"" ""impacting my subordinates positively,"" and ""working on projects of my choice."" Individuals with a bachelor's degree prioritized these motivators more than those with a higher degree. This result is in line with earlier studies conducted by Gaki et al. (2013), Huddleston (2002), Kukanja (2013), and Wong et al. (1999) that also identified a similar correlation between the educational background of employees and their perception of motivators.",0
34,20," The respondents' perceptions of motivators such as ""gaining knowledge, ability and confidence,"" ""rise in salary,"" ""impacting subordinates positively,"" and ""opportunity for advancement and promotion"" were found to differ based on their work experience in the construction industry. Those with less than 10 years of experience placed more importance on gaining knowledge, improving their abilities and career advancement. This aligns with Schein's career anchor categories for technical/functional individuals. Meanwhile, those with over 10 years of experience prioritized impacting subordinates positively. Similar findings were reported by Wong et al. (1999) in a study conducted in Hong Kong hotels.",0
34,21," The agreement between the respondents regarding motivators, with the exception of job security, holds true for both those who worked on small projects and those who worked on large projects. The study suggests that civil engineers who have only worked on small projects feel less secure in their jobs, possibly due to a higher rate of layoffs and therefore insecure employment, or a lack of qualifications for larger projects. However, the study also indicates that job security can have an impact on the perceptions of motivators for civil engineers. Executives should be aware that civil engineers with a history of small projects in their past highly value motivators that ensure job security, a criterion overlooked in previous motivation studies.",0
34,22," Two civil engineers with different personal characteristics were randomly selected to represent different demographics in order to better explain the results of the study. One was younger than 35, single, had an advanced degree, had over 10 years of work experience, worked for a contractor, and had worked on projects over $50 million, while the other was older than 35, married, had a higher degree, had less than 10 years of work experience, worked for a consultant/public owner, and had worked on smaller projects under $50 million. The Mann-Whitney test showed a statistically significant difference in the way these two individuals perceived motivators, indicating that different sets of motivators are needed for different individuals.",0
35,1," The article delves into the obstacles faced by civil engineering consulting firms when applying Systems Engineering (SE) in their projects and suggests areas of improvement for these firms to focus on. To gather data, the methodology of Eisenhardt for building theory from case studies was utilized in six civil engineering projects. The authors developed a framework comprising a detailed list of queries on the implementation and reasoning behind SE. Results revealed that there are three primary obstacles in applying SE completely, including a lack of clearly defined procedures and responsibilities, team members being in the learning process, and the absence of a demanding client to enforce SE's use. The article closes with recommendations for enhancing SE implementation and states that future research should explore different companies in the civil engineering industry.",0
35,2,"
The International Council on Systems Engineering (INCOSE) defines SE as an interdisciplinary approach that enables successful system realization. SE considers both technical and business needs of customers, aiming to provide quality products that meet user needs. SE implies that contractors' responsibilities transform from carrying out a predefined structured assignment to solving ill-defined, ill-structured, and complex problems in the project's early stage. Integrated contracts like DesignBuild and Design-Build-Finance-Maintain are increasingly becoming standard practice in the civil engineering industry.",0
35,3," 

In the shift from conventional methods of work to SE work, engineering consulting firms play a crucial role. They not only assist in the implementation of SE in civil and construction engineering projects but also need to apply SE themselves, especially if they have design or project management departments. Nonetheless, certain firms encounter obstacles when utilizing SE in construction projects.",0
35,4," The aim of this study is to examine the obstacles faced by engineering consulting firms while implementing SE in civil engineering projects, identify the reasons behind these challenges, and offer suggestions for enhancing SE practices. The research question addressed in this paper is the extent to which civil engineering consulting firms utilize SE in construction projects and the areas in which they should concentrate their efforts to enhance the use of SE. This investigation provides readers with comprehensive insights into the application of SE in the civil engineering sector from the perspective of an engineering consulting enterprise.",0
35,5," The studied engineering consulting firm is a global organization that offers a diverse range of consultancy, design, engineering, and management services in various market sectors relating to the built and natural environment, including civil engineering. The firm's consulting services have been accredited with ISO 9001 quality management and ISO 14001 environmental management standards. The firm has identified the growing importance of systems engineering (SE) and has been implementing it more prominently since 2010. SE's objective is twofold: to enhance the firm's working method to improve the quality of its services and products and to reduce failure costs by improving the transparency, traceability, and demonstrability of its processes. To encourage SE usage within the firm, they have developed an in-house SE handbook.",0
35,6," The focus of this research is on the civil engineering industry and its characteristics that affect the role of consultancy firms in projects and their ability to apply SE. The role of engineering consultancy firms varies based on the project, as the client determines when to involve them. The stage in which the firm is involved influences their freedom in carrying out the assignment. For instance, if the firm is only responsible for producing detailed designs, many design options have already been selected, leaving little room for exploring alternate solutions.",0
35,7," It is a common practice in civil engineering industry to divide projects into separate segments, often contracting different consulting firms for various phases. However, this approach hinders the application of SE as each firm may focus solely on their own part of the project, losing sight of the bigger picture and the overall success of the project. This disjointedness results in the loss of top-down approach of SE, ultimately affecting the overview of the entire project. [Farnham and Aslaksen, 2009].",0
35,8," The civil engineering industry is characterized by one-off projects, which results in the dismantling of the project organization and companies going their separate ways once the project is completed. Due to this lack of continuity, SE is not consistently used and there are additional costs for setting it up on each new project that need to be recouped through the project's amortization.",0
35,9," The significance of this research lies in the fact that no previous investigation has scrutinized the implementation of Systems Engineering (SE) within a consulting engineering company in the civil engineering sector in such an extensive manner. The existing literature only covers some aspects of SE, such as requirement engineering, verification, team communication, stakeholder engagement, and traceability. Additionally, previous research has examined the impact of SE on construction safety and information flows but in other industries than civil engineering.",0
35,10," The paper is arranged in the following manner: Section 2 outlines the conceptual SE framework. Section 3 subsequently discusses the scoring method and research design for the in-depth case study, drawing on the elements of the aforementioned framework. The paper concludes with Sections 4, 5, and 6, which respectively present the results, discussion, and conclusion.",0
35,11," The purpose of SE is to provide guidance for the engineering of complex systems, as mentioned by Kossiakoff et al. (2011). Based on the Systems Engineering Fundamentals of the Department of Defense (2001) and relevant SE handbooks and guidelines from the Civil Engineering industry in the Netherlands (ProRail et al., 2008), Figure 1 illustrates the different elements of the SE process, with nine elements forming the main SE process (elements 1-9). The other three elements are the process input (element 10), process output (element 11), and systems analysis and control element (element 12). The nine main elements were analyzed in detail, using decomposition to reach a level of concreteness suitable for specific yes or no questions, in accordance with the method proposed by Farnham and Aslaksen (2009). The results of interviews, documents analysis, and observations were used to answer these questions and provide insights into the SE process.",0
35,12," A case study approach was employed to investigate the difficulties faced by engineering consulting firms in implementing SE in their projects. This research methodology was deemed suitable as it allows for an understanding of the complex interactions in a real-world setting, particularly in the realm of civil engineering projects [Eisenhardt, 1989; Yin, 2009]. Furthermore, Eisenhardt [1989] notes that a case study investigation provides an avenue for iteratively testing and refining theories with empirical data, facilitating a connection between theory and practice. Our research methodology is presented in this section, outlining the three key stages of the study: commencement, data collection, and data analysis.",0
35,13," The initial stage involved defining the research inquiry, the setting, and determining the constructs. Our research inquiry was identified as: What is the scope of SE utilization by engineering consulting companies in civil engineering projects, and what areas require attention for enhancing SE application?'",0
35,14,"

The civil engineering industry in the Netherlands was the context of our research. This is significant because the two main clients, Rijkswaterstaat and ProRail, require the use of SE in all their projects. Rijkswaterstaat is responsible for the development and maintenance of safe highways and waterways, while ProRail maintains and manages the railway network and related facilities. The fact that SE has been mandated by both clients for some years now presents two advantages for our study. First, we have access to many cases where SE has been utilized, which allows us to choose our cases strategically. Second, despite being applied in the country's civil industry for some time, SE is still new enough for us to examine the challenges associated with implementing it in engineering projects.",0
35,15," The SE process model discussed in section 2 is an essential component in our research, as it operationalizes the construct of ""Systems Engineering."" Another crucial construct is ""improvement,"" which refers to enhancing the application of the SE process model and is evaluated using a yes/no questioning system clarified later.",0
35,16," The case study utilized the same protocol for examining all six cases, which was designed to improve its reliability. The protocol consisted of two steps: first, a framework for analysis was created using an SE framework that contained a comprehensive list of questions based on the elements of SE, which could be answered with a yes or no. Each yes received five points, while no received zero points, and answers in between were allocated 2.5 points. (Yin, 2009)",0
35,17," The second step involved creating a method to assess the fulfillment of each SE element in the SE framework by assigning a score of up to 100%. This allowed for mutual comparison between the elements. An example of calculating the score for the RA is provided in Table II, based on four questions for readability purposes. A score of 0% indicates no implementation of the framework, while a score of 100% indicates full implementation. The score is determined by answering yes or no questions for each SE element and summing them up, then dividing by the maximum score possible. In the example from Table II, the four questions had a score of 10 out of 20, resulting in an application score of 50% for the SE element.",0
35,18," The absence of clear internal procedures and responsibilities for SE prior to project implementation is a significant reason why SE tasks have not been fully employed, as demonstrated by the projects. Specifically, this pertains to the absence of standard V&V forms and procedures.",0
35,19," In one project, there was confusion about how to handle design changes which led to undocumented new requirements and designs not meeting agreed-on requirements. However, in four other projects, requirements were structured in greater detail using information software programs which facilitated change management and system engineering (SE) application, ultimately improving the V&V process.",0
35,20," Employees were not fully implementing SE activities due to a lack of SE knowledge and skills. This was evident in a project where work routines were not adjusted to accommodate SE elements, resulting in their partial or unintended execution. The learning process was impeded by insufficient training opportunities due to time constraints.",0
35,21," Employees lack familiarity with the application of SE feedback elements, as evidenced by anecdotes. For example, only one of six projects had a verification plan due to the project leader's emphasis on SE. However, the plan did not provide specific guidance for verifying each requirement, and employees struggled to compose it. As a result, additional project team time was spent on figuring out verification methods.",0
35,22," The fact that employees from different disciplines made changes to the design without reporting to the SE controller or documenting them is a clear example of their learning process. However, this led to a loss of control over design changes and required rework and additional meetings. This situation highlights the employees' lack of awareness of the importance of documenting changes, which is a crucial aspect of SE.",0
35,23," The feedback elements in SE are not as well-executed as the core elements, which include RA, FA, and Synthesis. This is because the firm already had experience in performing the SE process before implementing it. Therefore, the core elements only require improved documentation and organization of activities that were already being carried out. On the other hand, the SE feedback activities are more complex and require more planning and structure, which are not typical activities for employees in an engineering consulting firm.",0
35,24,"

Enhancing employees' knowledge and skills in SE is a vital recommendation for improvement. The feedback elements of SE, such as validation, verification, and loops, are unfamiliar to most employees, unlike the usual SE elements like RA, FA, and design synthesis. Therefore, offering training to apply those feedback elements is crucial. Furthermore, the presence of experienced SE employees in a project could positively impact SE application via transfer of their knowledge and experience to other team members. Hence, it's advisable to involve experienced SE employees more often. SE education and training have been recognized as significant in literature. [Bonnema, Lutters-Weustink, and Van Houten, 2005; Bhasin et al., 2010; Godfrey, Crick, and Huang, 2014]",0
36,1,"

Humans are social creatures because of their ability to learn, which varies among individuals. Civil engineering instructors can improve their students' academic success by identifying their learning styles. This study aims to explore the learning styles of civil engineering students in Turkey and determine their correlation with success in construction management courses, gender, age, type of university, and year of engineering study. Data was collected from undergraduate students at four universities using the Kolb Learning Style Inventory II. The results indicate a correlation between learning styles and management success, age, year of education, and type of university but not gender.",0
36,2,"

Learning is a crucial aspect of human beings, and everyone has their unique characteristics, abilities, preferences, and ways of thinking and acting that make them different from each other. Each learner has their own preferred methods of perceiving, organizing, and retaining new information, which is known as their learning style. Different learning styles are reflected in various academic strengths, weaknesses, skills, and interests. As there is a vast array of job descriptions within engineering, it is reasonable to assume that there is potential for all students, no matter their learning style, to be successful as engineers.",0
36,3," 

The relevant literature contains multiple reports on the utilization of learning styles in engineering education that demonstrate the substantial advantages of implementing it. Some scholars have even revised their fields to encompass the full range of learning styles, while others have succeeded through the use of diverse techniques and educational activities, including project-based learning, group problem-solving, and exercises. Thus, comprehending the dissimilarities in learning styles plays a crucial role in constructing well-rounded instruction that satisfies all students (Felder et al. 2002). In light of this, syllabi for civil engineering and other disciplines should accommodate varying learning styles.",0
36,4," The objective of this paper's research is to examine learning in civil engineering education and construction management by utilizing Kolb's learning styles. The study investigates the correlation between students' learning styles, construction management success, gender, age, year of engineering study, and university type. Data was gathered through survey forms from civil engineering students from four different universities in Turkey. The data was analyzed using SPSS 18 software, which included reliability analyses, frequency and percentage distribution analysis, correlation analysis, and ANOVA. Furthermore, the paper puts forth some proposals.",0
36,5,"Learning is a personalized internal process that has gained great recognition among educational leaders. The way individuals learn plays a critical role in educational improvement. Each person has their own preferred method of receiving information, which is known as their learning style. Several well-known learning style models exist, such as Myers-Briggs-type Indicator, Hermann Brain Dominance Instrument, Felder-Silverman Learning Style Model, and Kolb's Learning Style Inventory. Despite their varied methods of classifying learning types, all models have similar aims and approaches. This paper's research uses LSI II, a revised version of Kolb's Learning Styles Inventory.",0
36,6," The mode of concrete experience pertains to individuals who prioritize their feelings over their thoughts. They are generally skilled in social interactions and have a tendency for intuitive decision-making. On the other hand, the reflective observation mode pertains to individuals preferring to observe others than partake in activities. They appreciate diversity of opinions. The abstract conceptualization mode pertains to people that prioritize thinking over emotions. Their problem-solving approach is scientific rather than artistic. Finally, the active experimentation mode pertains to individuals who aggressively shape situations and people around them. They value practical application over observation or reflection.",0
36,7, Assimilators combine AC and RO as learners. They excel at comprehending a vast amount of information and presenting it in a clear and coherent manner. Abstract ideas and concepts pique their curiosity more than individuals. They place more significance on a theory's rationality than its applicability (Kolb and Kolb 2005).,0
36,8," Accommodating learners merge the learning approaches of CE and AE, comprehending their surroundings through a concrete lens of emotions and using actions to translate the knowledge they acquire. They primarily learn through practical experience and operate based on intuition, rather than rational analysis. Accommodators tend to rely more on others for information, rather than their own technical expertise, when resolving issues (Hsu, 1999; Kolb and Kolb, 2005).",0
36,9," The test for learning style inventory consists of 12 open-ended questions that offer four alternative responses for each question. The respondents should rank-order the four sentence endings that best describe their learning style. Based on their responses, four scores are calculated according to the test's key and then clustered under four modes of the learning cycle, namely concrete experience, reflective observation, abstract conceptualization, and active experimentation (Kolb 1984). Finally, these four scores are plotted on the learning cycle graph (Figure 2).",0
36,10,"

Due to the close relationship between the civil engineering industry and business, students studying in this field are required to obtain fundamental skills in various areas, including law, management science, planning and coordination, as well as team collaboration, all of which fall within the realm of construction management (Sears and Clough 1991; Gürer and Koç 1996). The efficacy of the industry heavily relies on the quality of education that employees receive. Additionally, the level of education of the employees will ultimately impact their career success (Sertyeşilışık et al. 2012).",0
36,11," Civil engineers anticipate securing a managerial position in the constantly evolving construction industry. As per Russell and Yao's observation in 1996, an engineer's recruitment is based on technical expertise, termination arises from poor interpersonal abilities, while leadership and management aptitude lead to promotion. Warszawski in 1984 asserts that owing to the project-based function of the construction sector, distinctive skills and attributes are necessary.",0
36,12," It is undeniable that the expertise of civil engineers in certain fields directly impacts the excellence and expenses of construction work. As a result, it is imperative for civil engineers engaged in these projects to possess a comprehensive understanding of management and its subcategories, including planning, organization, coordination, direction, and control. Hence, similar to other subjects, teaching construction management to students in accordance with their learning preferences is vital for their future success in this field.",0
36,13," Data was gathered from civil engineering students at four Turkish universities to assess their learning styles using a questionnaire consisting of 12 questions from Kolb's LSI II. The research resulted in 227 data points, which were analyzed using SPSS 18. The analysis included assessing reliability, calculating percentage frequency distributions, conducting Pearson's coefficient correlation analysis, chi-square, ANOVA, and Tukey's honestly significant difference (HSD) posthoc test.",0
36,14,"Construction management courses are mandatory for students enrolled in the Departments of Civil Engineering at Çukurova University, Gaziantep University, Zirve University, and Hasan Kalyoncu University. The curriculum includes additional managerial courses related to construction such as law for engineers, project management, and more.",0
36,15,"Construction management courses lay the foundation for understanding essential principles of construction management, including but not limited to cost analysis and pricing techniques, bidding processes, organization of construction sites, scheduling, occupational safety, and more.",0
36,16," The sample group consisted of 227 individuals, aged between 19-27. The majority of the group (120 participants, which is 69%), fell in the age group of 22-24 years. The average age of the participants was 22.26 years, with a standard deviation (SD) of 4.059. Out of all the participants, 185 were males (81.5%) and 42 were females (18.5%). More than half of the participants (127 individuals, which is 55.9%) had received their education from state universities. Also, 41.9% of the participants (95 individuals) belonged to the fourth year, but students from all years took part in the study. All the relevant statistics have been tabulated in Table 1.",0
36,17," Table 2 displays how grades for construction management among civil engineering students are distributed in Turkey. Since the construction management course is typically taken during the third or fourth year of the civil engineering curriculum, only data from third- and fourth-year students were included in this analysis, totaling 134 participants. The findings indicate that 67.9% of these students received grades of 70 or above in the construction management course.",0
37,1," 

The combination of process automation and quality assurance is a crucial advancement in the field of civil engineering. Geometry is a crucial aspect of quality assurance, and in order to measure and control geometric elements, engineering geodesy measurement and evaluation processes need to be integrated with construction processes. Quality assurance is a multifaceted and complex area, and a new model has been introduced to describe quality based on characteristics and parameters. This model has been applied to engineering geodesy processes in civil engineering to assess the quality of building geometry.",0
37,2,"Quality concerns have gained significant attention in various professional domains due to the rise in product complexity and customer expectations. This trend can be observed in fields like machine construction, transportation, civil aviation, information technology, plant engineering, civil engineering, and geodesy. The tactics employed to address quality issues may vary, but a shared focus on safety underpins most approaches.",0
37,3," A new quality model has been developed in the project 'Efficiency optimization and quality control of engineering geodesy processes in civil engineering', supported by the German Research Foundation. It considers the complexity of product and process quality, especially in civil engineering. The model describes quality based on characteristics substantiated by parameters.",0
37,4," ""Unlike typical quality models that focus solely on products, this model places equal emphasis on both products and processes. It consists of two levels and incorporates accuracy, correctness, completeness, reliability, timeliness, and specialized application-specific parameters. This article discusses the fundamentals of the model, its creation process, and partially covers the spread of the quality parameters. Finally, the paper concludes with a sample problem and some concluding statements.""",0
37,5," A conceptual framework is a quality model that breaks down the abstract concept of quality into specific aspects for a thorough description and comparison. While there is no complete quality model in engineering geodesy, examining related fields such as civil engineering software development, data management, and transport telematics can provide insight into potential models. In the realm of software quality, a three-tier model consisting of characteristics, sub-characteristics, and metrics (or parameters) is commonly used. The sub-characteristics serve as the intermediary layer between the parameters and the overall characteristics.",0
37,6," Well-known models for quality include FURPS and ISO 9126 for software development, and a three-tiered model for geographic data management. However, the Institute of Engineering Geodesy has developed two-tiered models for transport telematics and civil engineering, which will be described further in the paper.",0
37,7," A complete quality model should consider the actual products or processes it applies to, representing all requirements through independent characteristics and parameters that do not influence each other. The model should be applicable to both products and processes, at both characteristic and parameter levels, with quality described through various parameter types as presented in Table 2 via ISO/TS 19138 (ISO 2006).",0
37,8, A comprehensive quality model for civil engineering geodesy processes can now be constructed by considering the overall structure of the quality model and the different types of parameters that may be involved.,0
37,9," The quality characteristics related to the process, such as expense, timeliness, correctness of the process, resources, and synchronization, and their parameters are established with regard to the building plan and the agreement. The initial four qualities relate to the overall process and its sub-processes, while the fifth quality of synchronization pertains to the interplay of the sub-processes. It explains how much the sub-processes that are reliant on one another operate in synchronization.",0
37,10," The quality attribute related to product availability is the all-encompassing characteristic that considers all other attributes. The quality attributes linked to product accuracy and correctness, as well as the process accuracy, can be determined and evaluated using standardized parameters, generally accepted codes of conduct, and technical specifications detailed in the contract.",0
37,11," The quality model in question is designed for small and medium enterprises and does not incorporate the specific requirements of engineering geodesy. Furthermore, it lacks the capability to factor in parameters and their impact on processes. It is best suited for quality assurance in residential housing construction. These shortcomings point to the need for a more comprehensive quality model at the parameter level.",0
37,12," Engineering geodesy is responsible for converting the intended building shape into tangible reality, with a significant emphasis on ensuring the accuracy of the geometry in high-rise structures. To determine the quality of a building's geometry, specific requirements must first be established, which will then be used to derive quality parameters and characteristics.",0
37,13," The requirements for the geometry of a building can be defined by using standards like DIN standard 18202 (DIN 2005), which outlines the limit deviations for geometric building components including walls, foundations and floors. Building components are represented in plans by nominal sizes and their location in a coordinate system, while their real size is the actual size. Figure 3 illustrates the relationship between nominal size, actual size, actual deviation, limit deviation and tolerance.",0
37,14,"

Unlike the residential house quality model in Section 2.2, which distinguishes between product and process quality based on characteristics, this model differentiates between them based on parameters. The parameters 'Adherence to the Plan', 'Vulnerability to Failures', and 'Time Delay' are exclusively process-oriented, whereas the others are primarily product-oriented. However, a product parameter can also be used to evaluate a process if it is the outcome of a single sub-process. The following section elaborates on four key parameters.",0
37,15," The quality parameters mentioned earlier are specific to individual products or processes. To assess the quality of multiple processes or finished products, it is necessary to define a suitable computational technique to propagate each of the quality parameters through the process. The process for two crucial parameters, namely the standard deviation and tolerance correctness, is described below.",0
37,16, The method to compute the impact of different parameters' measured values on the final outcome through a process may be done by either the law of propagation of variances (also known as propagation of errors) (Teunissen 2003) or Monte Carlo Simulation (Binder 1979) to propagate the standard deviation. The normal distribution is usually used to assign the stochastic variables.,0
37,17," An engineering geodesy process, along with the quality parameters it produces, is demonstrated in this section through an example integrated into the construction process. The example illustrated in Figure 5 involves using a total station to stake out the corner marks of a formwork on the floor foundations.",0
38,1," The development of expert systems has been viewed as a challenging and knowledge-intensive process. This study suggests a metaheuristic regression system inspired by nature that is capable of discovering viable solutions. The system employs a user-friendly interface that doesn't require mathematical software installation. The MATLAB graphical user interface design environment (GUIDE) was used to design the intuitive interface, which was then implemented by the MATLAB compiler. The standalone system is user-friendly and provides a range of features, including evaluation, data file selection, test set selection, hold-out, cross-validation, and prediction, making it simple to use in solving several civil engineering challenges by manipulating the interface. The optimization module's effectiveness was evaluated using five benchmark functions. The performance of the proposed regression system was subsequently verified through a comparison of its civil engineering problem solutions with those obtained from empirical methods previously reported. As case studies, five actual datasets, including energy-efficient buildings, construction material strength, concrete structure shear strength, bridge scour depth, and subbase soil modulus, were used. The accuracy of the predictions was between 8.24% and 91.76% superior to those of previously reported models.",0
38,2," 

AI has been a field of research since the 1950s and has been extensively used in civil engineering in the last decade. It is utilized to model complex behavior of engineering applications by using methods like predictive modeling, clustering and association, evolution, pattern matching, data visualization, and metarule guided mining. (Liao et al. 2012).",0
38,3," Prediction is the most widely used data mining function, and conventional methods have been outperformed by AI in terms of predictive ability according to research by Chou and Pham (2013), Mousavi et al. (2012), and Platon et al. (2015). Ville (2001) notes that numerous AI researchers have attempted to create computer algorithms for executing data mining tasks.",0
38,4," Support vector machine (SVM) is a widely used AI methodology in the field of artificial intelligence. It involves analyzing a small amount of data based on the principle of structural risk minimization in statistical learning theory. The objective of SVM is to obtain the global optimum and to avoid the local optima. To accomplish this, nonlinear problems are solved linearly in a higher-dimensional space than the original feature space.",0
38,5," The application of this solution has undergone extensive examination due to its thriving implementation in classification tasks, as well as its proficiency in regression tasks, notably in support vector regression (SVR) utilized by SVMs (Vapnik 1995). SVR is commonly employed to tackle nonlinear regression issues by creating the input-output model and has displayed remarkable performance in numerous prognosis domains (Mohammadi et al. 2015; PengandLing2015; Suykens et al. 2002). Furthermore, it has been extensively researched for its efficacy in time series prediction (Quan et al. 2010).",0
38,6," 

SVR is known for its high computational burden due to the required constrained optimization programming (Wang and Hu 2005). However, a proposed solution to this problem is the least squares SVR (LSSVR) algorithm (Suykens et al. 2002). LSSVR utilizes equality constraints and a cost function similar to that of a classical artificial neural network, which substantially simplifies the problem since its solution can be attained through linearization. As a result, training SVR becomes more efficient and simpler.",0
38,7," 

Recent studies have shown that the implementation of the smart firefly algorithm-based LSSVR has been successful in various civil engineering fields. This model combines several techniques including firefly algorithm, chaos theory, adaptive inertia weight, Lévy flights, and LSSVR to create an artificial firefly colony algorithm-based LSSVR model. This innovative approach has significantly improved the operational effectiveness and quality of solutions in forecasting problems within civil engineering. (Chou et al. 2015; Chou and Pham 2015).",0
38,8," The vast potential applications of AI techniques in civil engineering and construction management may be limited due to their complexity. Skilled individuals are necessary to carry out the model’s operations, which can be labor-intensive. Reasoning systems must have the ability to recognize and execute the appropriate actions to be successful in real-world scenarios. Some related software can be used to apply AI techniques, but it can be expensive and challenging to use. Furthermore, most software programs only provide rudimentary AI techniques without optimization capabilities.",0
38,9," The research aims to create a user-friendly interface that utilizes data analytics loop to address previous issues with the proposed nature-inspired metaheuristic regression system. The system includes an upgraded smart firefly algorithm (SFA) – based least squares SVR (SFA-LSSVR) model, which was optimized for better computing efficiency. Validation of the optimization approach was performed using various classic benchmark functions. Chou et al. (2015) and Chou and Pham (2015) have reported excellent performance of the optimized regression algorithm in various CE fields.",0
38,10," 
In the system interface, the two primary user functions are evaluation and prediction. The evaluation function offers the user four alternatives for testing data, including using the opened data file for testing, selecting a different test set for testing, dividing the opened data into learning data and test data, and dividing the opened data via the k-fold cross-validation method. Moreover, the system contains the baseline least squares SVR minus the smart firefly optimization algorithm. The efficiency of the proposed system is validated via performance comparisons with preceding works and empirical methods using hypothesis testing and cross-validation algorithms. Experiment results reveal the system's potential in solving numerous predictive problems in CE with high efficiency.",0
38,11,"
The structure of this paper is as follows. After an introduction, the subsequent section examines the related literature to establish the study context. The third section goes into detail on the techniques that were employed to create, deploy, and verify the efficacy of the system. The fourth section discusses the creation of the nature-inspired metaheuristic regression system, including the system's specifications, implementation, architecture, and interface design. The fifth section includes the validation of the system via benchmark functions and five case studies. The final section contains concluding thoughts and research contributions.",0
38,12," The application of AI techniques is commonly used to tackle classification and prediction challenges. These techniques, which have been developed extensively in recent years, can give businesses an edge over traditional approaches (Mousavi et al. 2012; Platon et al. 2015). There have been various instances of deploying AI techniques to energy management and construction engineering (Coelho and Mariani 2013; Mosa et al. 2013).",0
38,13," 

In recent years, numerous metaheuristic optimization algorithms inspired by nature have been developed. Some examples include the genetic algorithm (Goldberg 1989), particle swarm optimization (Kennedy and Eberhart 1995), differential evolution (Storn and Price 1997), artificial bee colony (Karaboga and Basturk 2007), teaching-learning based optimization (Rao et al. 2011), and symbiotic organisms search (Cheng and Prayogo 2014), which have all been introduced as novel approaches to efficiently solve optimization problems.",0
38,14," Support vector machine (SVM) has been widely used in forecasting and regression. Recently, SVR, a variation of SVM, has gained popularity in these areas, as demonstrated by studies such as Cherkassky and Ma (2004), Cheng et al. (2010), Li et al. (2009), and Pal et al. (2011). For example, Cheng et al. (2010) used a fast messy genetic algorithm to tune an SVR model for estimating the final cost of two construction projects, while Li et al. (2009) found that an SVR for predicting the hourly cooling load of a building outperformed an artificial neural network model. Even for modeling pier scour, Pal et al. (2011) showed that SVR was superior to other models such as a four-empirical-relation model, a back propagation neural network model, and a generalized regression neural network model.",0
38,15," An alternative approach known as LSSVR, which aims to minimize the sum of squared errors in training data sets and margin error simultaneously, has been utilized (Van Gestel et al., 2001). Li et al. (2008) employed LSSVR to predict the weight of injection-molded parts, revealing that it is a highly efficient forecasting method compared to the SVR and radial basis function neural network techniques.",0
38,16," The SVR model has demonstrated significant success in predicting problems, but its accuracy is reliant on pre-determined parameters (Min and Lee 2005). Unfortunately, there are no universal guidelines for selecting appropriate parameters (Cristianini and Shawe-Taylor 2000). Thus, identifying optimal parameters is a crucial aspect of researching SVR.",0
38,17," Several studies have utilized optimization techniques to determine the optimal SVR parameters and have highlighted their benefits (Gilan et al. 2012; Hong 2009; Yang et al. 2011). For example, Gilan et al. (2012) created a hybrid model that combined SVR and particle swarm optimization for predicting compressive strength in concrete containing metakaolin. Li et al. (2013) applied learning-based optimization to adjust hyperparameters of a least squares support vector machine and built a NOx emissions model for a 330-MW coal-fired boiler.",0
38,18," According to recent research, the firefly algorithm (FA) has proven to be highly efficient and has outperformed other metaheuristic algorithms like PSO and GA (Pal et al. 2012). Furthermore, in a comparison of performance in feature selection, Banati and Bajaj (2011) found that FA was faster and had a better solution quality compared to algorithms like GAs, ant colony optimization, PSO, and bee colony algorithms. Additionally, for solving civil engineering problems, the smart FA based least squares SVR model has shown superior computational efficiency and solution quality (Chou and Pham 2015).",0
38,19," Despite the recognized benefits of AI techniques, effectively implementing them remains a challenge. Thus, having an expert system with a user-friendly window or browser interface is essential for real-world application, according to Leung (2009). As a result, several user interfaces specifically tailored for civil engineering have been created.",0
38,20," ""Examples of interfaces designed for different purposes have been proposed by Zapata et al. (2013), Lin (2013), and Senthilkumar et al. (2010). However, for the proposed SFA-LSSVR, a user interface for regression prediction needs to be developed. Therefore, this work aims to design a user-friendly interface for this advanced method.""",0
38,21,"The section focuses on the methodologies employed in creating the nature-inspired metaheuristic regression system, encompassing hybrid artificial intelligence models, design and implementation tools, and validation techniques for assessing system performance.",0
38,22," The SVMs, introduced by Vapnik in 1995, are commonly applied in both classification and regression tasks. An abundance of research in civil engineering has revealed the remarkable learning capacities of SVMs. The SVR, which is the regression model of SVMs, is widely adopted for addressing nonlinear regression problems and constructing input-output models.",0
39,1," In order for undergraduate civil and construction engineering students to tackle the challenges of a rapidly changing world, it is essential to cultivate their professional abilities. This paper thoroughly investigates the implementation of practical training in the field of civil and construction engineering, drawing upon a literature review of practical training worldwide and a survey of educators, students, and contractors in Taiwan to assess problems with traditional summer practical training courses. While the initial hypothesis was that a lack of job opportunities contributed to the issue, the study revealed a much more complex set of concerns, such as worries about the liability of students working on construction sites and the cultural question of whether apprentices should receive compensation. To address these issues, the study utilized the Delphi method to examine and improve upon existing practical training programs.",0
39,2," Engineering educators face a significant challenge in cultivating professional ability, according to Belcher (1995). To meet this goal, civil and construction engineering education should incorporate theoretical and professional knowledge, practical skill training, and macroscopic experience (Hulse et al., 1985). Therefore, curriculum planning must encompass both theoretical and practical skills to ensure success.",0
39,3," Practical training serves as a vital link between students in the classroom and the industry, allowing them to gain first-hand experience and exposure to the challenges of construction engineering. Through practical training, students can integrate their theoretical knowledge with practical skills, shortening the gap between their undergraduate education and professional practice. As such, this research aims to examine the modes and processes of practical training for undergraduate civil and construction engineering students. The paper reviews the current state of practical training programs and presents questionnaires completed by contractors, educators, and students. Using the Delphi technique, this paper proposes an improved practical training program based on the research findings.",0
39,4," In this study, it is proposed that the practical training undertaken by civil and construction engineering undergraduates during summers is imperative. The hypothesis is supported by questionnaires developed after an extensive literature review of the practical training curriculum worldwide. To validate the hypothesis, the Delphi Technique was implemented, and the researchers assessed the appropriateness of the methodology. The paper presents and discusses the significant outcomes of the study.",0
39,5," 

The initial segment of the paper provides an overview of the existing summer training programs in civil and construction engineering education in Taiwan. Following this, the project's questionnaires are introduced. The second portion of the paper delves into the research methodology of the Delphi Technique, as well as the results of the research. Based on the findings, a more polished and bettered summer practical training curriculum is suggested for civil and construction engineering education in Taiwan.",0
39,6," To tackle the issues in existing summer training schemes for civil and construction engineers, it was imperative to rank and recognize them by conducting several practical surveys and gathering feedback from contractors, educators, students, and professionals. These surveys were designed after a comprehensive review of the current state of engineering education and practical training across the globe.",0
39,7," The questionnaire was answered by only 25 out of 200 first-class contractors selected from different regions of Taiwan, resulting in a 12.5% retrieval rate. This low response rate could be attributed to the sluggish economy of the country and the contractors' lack of interest in practical training for undergraduates due to the limited availability of construction work.",0
39,8,"Invitations to complete the questionnaire were sent out to department heads and professors from 25 departments specializing in Construction or Civil Engineering. A total of 19 responses were received from universities and institutes of technology in these fields, resulting in a retrieval percentage of 76%. The findings revealed that heads and professors of Civil Engineering departments were particularly keen on practical training.",0
39,9," The students were given two sets of questionnaires. The initial questionnaire was administered to 75 students before they started their summer practical training, while the second questionnaire was given to 69 students after they had completed their summer practical training.",0
39,10," In Table 2, the opinions of heads and professors of civil engineering departments are listed. The majority of professors believe that practical training is essential for students, but only 5% of departments provide such programs. Practical training aids students in comprehending the application of theory to practice, increases their interest in civil engineering, and helps them secure future employment. However, civil and construction engineering departments are concerned about the safety of students on construction sites due to potential hazards.",0
39,11,"presents the survey summary provided by contractors who expressed their agreement towards the necessity of practical training and having insurance for students. Their constructive suggestions were also acknowledged. Summer practical training was deemed important and necessary by the contractors, but they expressed concerns about their profits as extra resources were scarce in light of the economic crisis.",0
39,12," The Delphi group discussed several questions regarding practical training implementation, and Table 5 lists the answers. It is strongly recommended that students have injury insurance during their practical training and submit reports on their learning experiences. Although buying insurance is not common in Taiwan, Delphi group stresses the importance of protecting students through insurance coverage. As a result, students' performance outcome can be better assessed by school through their submitted reports.",0
39,13,"

The problems with practical training were discussed and the corresponding solutions were listed in Table 7. It was agreed that summer practical training should be mandatory for all construction engineering departments in our country to help students apply theory to practical engineering. The Ministry of Education in Taiwan encourages practical training and it will be used as an index for academic accreditation. Universities with good practical training will get financial support from the Ministry of Education.",0
40,1," The field of structure dynamic research is currently popular within the realm of civil engineering. It encompasses various complex topics, including dynamic analysis and testing in response to natural phenomena like earthquakes, wind, and other dynamic forces. The main objective of this paper is to outline the major dynamic research conducted in civil engineering over the past few years, categorizing these into five main areas. These are primarily based on research published in the Science in China Series.",0
40,2,"The rapid economic development has resulted in the quick development of civil engineering structures such as high-rise buildings, long-span reticulated structures, bridges, and dams. However, recent years have also seen an increase in natural disasters like strong earthquakes such as the Wenchuan earthquake and Haidi earthquake in China and extreme climate events like hurricanes and tsunamis. These disasters have become typical dynamic excitations for civil engineering structures and have led to a rise in research topics related to dynamic problems. China has established a significant research program for these topics under the National Natural Science Fund.",0
40,3," ""Civil engineering structures face various dynamic problems. Researchers need to actively explore issues like dynamic excitation field, numerical models, dynamic response analysis, structural health monitoring, vibration resistance measures, and vibration tests.""",0
40,4,"

This paragraph provides an overview of recent research in the field of structural health monitoring and related topics. Li et al. conducted a study on modeling for benchmark structures and recommended the use of a more advanced 3-dimensional structure model for accurate detection of local member damages. Xu et al. explored the dynamic behavior of multi-span bridges under moving loads, focusing on the impact of coupling conditions between spans. They found that deflection strongly depends on local coupling, particularly near critical stiffness values. Xu et al. also proposed an intelligent control strategy for building structures equipped with magnetorheological dampers and subjected to earthquake excitation, using a neural network and fuzzy controller to solve time-delay problems and quickly determine control currents.",0
41,1," The field of civil engineering is experiencing rapid growth due to the complex, global problems that require a diverse pool of engineers with a range of skills, views, and leadership styles. Despite the predicted increase in job opportunities, women currently constitute a small proportion of the civil engineering workforce, and the number of women graduating from undergraduate civil engineering programs across the US has stagnated. This paper presents recent data to provide an overall picture of the national participation of women in civil engineering, which shows that while ASCE membership reflects the national percentages of women in B.S. civil engineering programs and in CE practice, senior membership, including the rank of Fellow, shows very low representation of women and is not reflective of the percentage of women in the society. The paper suggests recommendations for ASCE to lead the way in increasing the percentage and standing of women in ASCE and the CE profession.",0
41,2," Civil engineers play a crucial role in addressing the challenges posed by deteriorating infrastructure, the impact of climate change, urbanization, the depletion of natural resources, and the need for access to safe drinking water. They are required to utilize innovative solutions to solve these problems.",0
41,3," The CE workforce is comprised of only 9.7% women, as reported by the Bureau of Labor Statistics (2012). Although progress has been made since the 1970s when there were no women in CE, the current statistics are still far from satisfactory.",0
41,4," 

The paper presents updated information regarding the representation of women in civil engineering programs, practice, and ASCE membership at the national level. ASCE can play a crucial role in promoting gender diversity by encouraging more women to join ASCE and the civil engineering profession in general.",0
41,5,"

There are numerous explanations in the literature as to why women are underrepresented in engineering degrees and professions. The engineering career may be suffering from an image problem, according to several authors (Johnson et al. 1992; Hersh 2000; Isaacs 2001; May and Chubin 2003; Extraordinary Women Engineers Coalition 2005; Tietjen 2004; Widnall 2006; National Academy of Engineering 2008). Few girls in precollege are aware of what engineering involves or what engineers do. Tietjen (2004) points out that this issue can be partly attributed to the fact that people tend to have more contact with doctors, dentists, and other professionals than with engineers. Moreover, most TV programs and movies are centered around legal, medical and other careers, leaving little representation for engineers.",0
41,6," Hatch (2008) devised recommendations aimed at resolving the lack of diversity in the CE workforce by recognizing the significance of diversity and creating favorable conditions in the workplace that promote diversity recruitment and retention. Hatch's work acknowledges the challenges that come with a diverse workforce, such as communication, work/life balance, retirement, telecommuting, and religious demands, and emphasizes the benefits of developing an inclusive work environment. Additionally, Hatch's recommendations align with the workplace issues identified in the study by Rayman and Stewart (1999) and a subsequent study.",0
41,7," There is concern about the disparity between the number of women receiving engineering degrees and the smaller percentage of women in engineering jobs. The US Bureau of Labor Statistics reports that women make up only a small portion of the engineering workforce, with percentages varying by discipline. Some experts attribute this gap to the work environment, particularly in regards to hiring practices. Companies may subconsciously base their idea of an ideal candidate on their current pool of employees, which could contribute to the lack of female representation. A study by the National Society of Professional Engineers found that some CEOs and human resource professionals in smaller engineering firms believed that women were less likely to advance in the field because of family responsibilities, but statistics from the study showed little difference in the number of years worked by males and females.",0
41,8," The Extraordinary Women Engineers Coalition (2005) conducted a study involving 85 high school girls, which revealed a disparity between factors that motivate girls to choose a career and the message conveyed by the engineering community. The girls were primarily focused on aspects such as enjoying their work, a productive environment, making a difference, earning a reputable income, and having a work-life balance. Conversely, the engineering community emphasizes the challenges, complexity and computational skills required to solve problems, which did not resonate with the girls' interests. Tietjen (2004) asserts that women are inclined to pursue careers that they perceive as valuable; hence, the lack of knowledge about engineering led to inadequate assessment of its significance. Additionally, engineering professions are often blamed for environmental degradation, which deters women from engaging in engineering (Hersh 2000). To address this phenomenon, ASCE, American Association of Engineering Societies, and WGBH Educational Foundation established the Extraordinary Women Engineers Project in 2004 to encourage women's participation in engineering.",0
41,9," According to a survey conducted by Servon and Visser in 2011, 2,500 executive women in science, engineering, and technology fields were found to experience a hostile workplace environment. Women in engineering fields, who constituted approximately 28% of the respondents, reported they were sexually harassed (69%), perceived as less capable (26%), met bias in performance evaluations (44%), and received unwanted attention due to their feminine appearances (32%). Moreover, a third of the women felt extremely isolated. The study suggested that family-friendly policies should be adopted, the organizational culture should be revamped, and promoting women in higher positions could help build a more supportive environment.",0
41,10,"In Central Europe, there was a significant increase in the percentage of women enrolled in universities and pursuing careers in civil engineering during the 1980s. In the 1970s, the percentage of women earning CE degrees grew from negligible to over 1% of the total. In the United States, the percentage of women earning B.S. degrees in CE more than doubled between 1970 and 1973. This trend can be seen in the rising number of women receiving B.S. degrees in CE from Penn State, as shown in Figure 1.",0
41,11," Private schools do not have a strong correlation with high percentages of women in all programs (correlation coefficient is approximately 0.31). However, Table 3 summarizes some general characteristics of schools that have 35% or more women. Fig.3 displays the distribution of the 28 schools with at least 35% women in the B.S. degree pool. These schools have smaller graduating classes, with a median size of 19.5, compared to the median class size of 43 for all programs. The majority of these schools (79%) are private and 86% are in or near urban areas. More than half (57%) of the programs also have Ph.D. programs in CE, with six of those programs being at least 50% as large as the B.S. program in the same school. By comparison, the largest programs have Ph.D. programs that range from 4 to 14% of the number of B.S. graduates in the same year.",0
41,12,"There are certain traits that can be taken into account by universities, corporations, and professional associations while encouraging women to participate in demanding research and other continuing education problem-solving activities. Additionally, the creation of more personalized settings within larger programs or organizations might be beneficial.",0
41,13," ASCE policy aims to promote Section activity in professional and paraprofessional job training, counseling, and education for women. Additionally, they plan to collaborate with other engineering organizations, industry, private philanthropy, and the government to enhance the number of women graduates from engineering schools. Furthermore, ASCE will provide its support for legal and moral requirements that prohibit any forms of employment discrimination while encouraging the adoption of affirmative action programs by engineering employers and administrators. Lastly, they will invite women engineers to join ASCE and participate in policy-making positions to address exclusion problems and other national concerns.",0
41,14, The committee concluded that male and female civil engineers should be held to the same rigorous standards to ensure that women in this field are respected and held in equal regard to their male colleagues (Keith 1978).,0
41,15," Since 1976, the number of female members in ASCE has increased to 16,265 including students. However, the June 2012 membership data revealed some areas for improvement. Female student membership in ASCE constitutes 19.5% of the total membership, and nonstudent population has 9.4% women, which is less skewed than in the national workforce data. But, women's representation in the Member category is only 6.7%, while men dominate Membership and Fellow categories. Presently, only 1% of ASCE Fellows are women, whereas 99% are men.",0
41,16,"The demand for civil engineers is increasing swiftly, and the field requires not only more proficient professionals, but a varied set of engineers to tackle the intricate, worldwide challenges that humanity confronts currently and in the future. ASCE stands in an ideal position to advocate for promoting diversity, with a blend of students, scholars, and experts from private and governmental organizations.",0
42,1," ""The ""Civil Engineering Design Project"" is a capstone senior design course at Purdue University for all seniors before graduation. According to the course catalog, it involves planning, designing, and analyzing civil projects with an integrated and realistic group project covering all major aspects of the profession. It is a popular course with high enrollment and has been team-taught since the 1960s. From 2001, the course has focused on the design-build method of project delivery, with student teams responding to requests for proposals for local projects. The proposals entail two stages - the conceptual designs and alternatives analyses and the design-build project proposal, with an oral presentation for both phases. The culminating activity in the course is the design-build proposal. Students are assigned to teams based on criteria such as overall grade point average, grades in key courses, work experience, computer software skills, and Meyers-Briggs typology.""",0
42,2," The Civil Engineering Design Project is a capstone course offered by Purdue University for senior students in their last semester. The course aims to provide an integrated and practical experience of the various aspects of civil engineering. The class typically has a high enrollment of 30-120 students and has been taught in several ways since the 1960s. The current iteration involves three credits and mandatory attendance of 50-minute briefing sessions on Tuesdays and Thursdays, followed by a 2-hour office session for teams. An engineering manager is present in the shared classroom office space, which is used by five teams.",0
42,3," The TA positions for engineering managers are typically filled by graduate students in civil engineering, although sometimes community volunteers may take on the role. The course director, who is usually a senior faculty member, is responsible for planning the agenda and recruiting speakers for each briefing session. Instructional team members facilitate these sessions and offer advice during office hours. The teams also have access to a design lab that is fully equipped with modern technology and reference materials to aid in project development.",0
42,4," The course has utilized the design-build method of project delivery since 2001, with student teams responding to a collective request for proposals (RFP) for local projects. The RFP is prepared prior to the start of the course by the course director, instructors, teaching assistants, and the project owner. Drnevich (2005) outlined the history and development of the course up until 2004, including the people involved and the completed projects. Students are placed into teams based on various factors to ensure balance, with the process described by Drnevich and Norris (2007) and utilizing an optimization model developed by Norris (2007) for forming MBA teams at Purdue's Krannert School of Management. Civil engineering design project team sizes range from 5-8 students, with a limit of 15 teams due to facilities and scheduling constraints.",0
42,5," Once teams have been established, they are given the task of creating a unique identity by designing logos, letterheads, drawing sheet title blocks, transmittal forms, and any other materials deemed necessary. The teams have no specific requirements regarding their structure, but it is essential that they collaborate to ensure that the end products have a consistent and professional appearance and content.",0
42,6,"

In 2007, the university introduced a module focusing on project planning and management. This module involves a lecture and an assignment where teams study a Request for Proposal (RFP) and create a written plan, complete with a Gantt chart, to meet the requirements and deadlines of the RFP. Upon completing Phase 1 submissions and presentations in the second month of the semester, teams must then evaluate and revise their plans and Gantt charts for Phase 2 submissions and presentations. The revision process involves reviewing detailed weekly time sheets that include individual and team hours. Project expenses are calculated based on invoiced hours and associated billing rates and are used in the final evaluation of the deliverables.",0
42,7," The course integrates individuals associated with the projects, including the owner, practitioners, and retired local engineers as volunteers. The Purdue Architect's office presents an overall master plan for the campus and the athletics director, director of athletic facilities, and coaches provide briefings. The Purdue physical facilities' design and construction group and local engineering firms provide briefings on various topics during biweekly morning sessions on Tuesdays and Thursdays, including civil site development, LEED case studies, and methods of project delivery.",0
42,8," All calculations must be checked and signed-off by another team member before submission, which is a firm and realistic deadline. Late submissions are not accepted. All information should be submitted electronically, except for presentations, and multiple hard copies of the proposal with drawings and calculations are required for efficient grading and team member retention. All submissions are due at 12:00 p.m. EST on mm/dd/yy in room G175 Civil Engineering.",0
42,9," Grading rubrics are created by the instructional team and at least three members review all deliverables. These rubrics provide a detailed description of requirements for formatting, grammar, and writing style in proposal deliverables. Comments are given on hard-copy products and the instructional team discusses every team's product to reach an agreement on a suitable grade. All deliverables are considered a group effort and each member gets the same grade. The written proposal grades are adjusted based on peer evaluations, and rubrics are used for both team and individual presentations to establish presentation grades. A comprehensive feedback report is produced for each phase to address things done well and things that need to improve to reach professional quality. All teams receive feedback as a collective summary.",0
42,10," Peer evaluations are conducted twice at an individual level - once after Phase 1 and again after Phase 2. The process is anonymous and includes a self-assessment and assessment of team member performance. Group grades are adjusted based on the average peer evaluation, resulting in individual grades being adjusted too. Drnevich and Norris (2007) discuss the effectiveness of the peer evaluation process in promoting teamwork and identifying collaboration challenges or issues within teams.",0
42,11," The course evaluation by students usually takes place twice per semester, once after Phase 1 and again after the course completion. These evaluations occur via anonymous online surveys. Besides, the School of Civil Engineering carries out exit surveys and post-graduation assessments.",0
42,12, The civil engineering capstone design course offered at Purdue University is detailed in this document. It is mandatory for all senior civil engineering students and takes place in their final semester before graduation. The course is based on RFPs and closely resembles the tasks carried out in the field of civil engineering. The participation of engineering professionals and experts from the local community affirms the maintenance of realistic practice conditions.,0
42,13," The success of this course has been made possible by numerous contributors, including colleagues, practitioners, teaching assistants, and staff members, to whom the authors express their gratitude. The students who took the course and offered feedback to enhance it are deserving of special recognition.",0
43,1,"Growing interest in sustainable civil engineering has been sparked by recent natural events, such as the earthquakes in Japan and storm surge effects in New York. While sustainability topics are usually part of civil engineering programs at the baccalaureate or graduate levels, they can also be adapted for secondary school students. Engineering camps targeted at secondary school students have been created to attract diverse and quality students into civil engineering. This research aims to explore civil engineering sustainable module topics suitable for secondary school students through content development and two case studies. The instructional content includes lesson objectives, key concepts, activities, experiments, and other pedagogical techniques. Two modules have been implemented at the Bucknell Engineering Summer Camp program for secondary school students. The developed module topics and case study results can serve as examples nationwide on how to introduce sustainable civil engineering to encourage future civil engineering students.'",0
43,2," The civil engineering curriculum is seeing a rise in sustainability topics due to recent natural events and global awareness. Earthquakes in New Zealand and Japan, storm surge effects in New York and New Orleans, and the ongoing issue of global warming have led to new developments in topics such as earthquake engineering, soil liquefaction, and green building. Introducing secondary school students to these new concepts can attract and engage diverse students into civil engineering. Hands-on, real-world, problem-based lessons can increase awareness and interest in the field among high school students.",0
43,3," Bucknell University currently provides a summer engineering camp that lasts for a week and is aimed at students in secondary school. The camp educates students on various aspects of engineering through practical exercises and lessons taught by an array of engineering faculty members. Furthermore, the camp allows for the creation, execution and assessment of fresh civil engineering modules by secondary school attendees every year.",0
43,4," 

This study examines the ability to create, execute, and assess topics related to sustainable engineering, including water preservation, environmental impact evaluation, and eco-friendly construction across all subfields of civil engineering. These module topics can serve as a blueprint for teaching sustainability in secondary schools, motivating and inspiring future engineering students. To verify the feasibility and efficiency of these topics, two case study modules have been fully established (Introduction to Sustainability, and Introduction to Earthquake and Liquefaction) and executed in a camp setting. The findings of the case studies, as well as the list of sustainable module topics and teaching content, may provide the groundwork for engineering educators looking to incorporate sustainability into high school curricula.",0
43,5," 
With the understanding that incorporating sustainable topics in engineering modules can invite students to study engineering, sustainability modules were created and evaluated utilizing distinct learning goals. These objectives, described in detail later, are the foundation for the module's arrangement and execution. Upon finishing the sustainability module, students should possess fundamental principles and be able to demonstrate their knowledge through hands-on experiments and activities, as well as understand the real-world application context.",0
43,6," Active learning, a pedagogical technique that engages students in meaningful learning activities, is widely acknowledged for its benefits. Studies show that active learning improves information recall, clarifies misconceptions, and enhances student attitudes and academic achievement. Collaboration further improves student retention and comprehension. Therefore, the sustainability modules in this study incorporate both active and collaborative learning techniques, as well as traditional instructional methods.",0
43,7," This portion encompasses an examination of prior literature regarding the correlation between civil engineering and sustainability, alongside instructional methods suitable for secondary school education. Furthermore, a concise introduction to the participation of secondary school students is presented, with particular emphasis on engineering camp programs.",0
43,8," The issue of human impact on the natural environment is gaining attention at local, national, and global levels due to various events such as storm surges, rising sea levels, depletion of natural resources, and population growth (Litman 2006). Consequently, there is a growing need for a sustainability movement focused on reducing the anthropogenic influence. Sustainability is defined as meeting present needs without compromising the ability of future generations to meet their own needs (WCED 1987). Therefore, secondary school students are expected to develop innovative plans to reduce negative impacts on the environment, society, and the economy.",0
43,9," 

Sustainability encompasses more than merely safeguarding the environment. Today's civil engineers, and those in the future, must develop and construct projects that consider all three pillars of sustainability: the economy, environment, and society (ASCE 2012). This approach, titled the triple bottom line of sustainability, recommends an equitable balance of all three aspects by lessening environmental, economic, and social impacts. Therefore, involving upcoming engineers in this mission and drawing them to the civil engineering field is crucial, as they will serve as the next designers, contractors, and workers.",0
43,10," Active learning techniques have been extensively researched and are widely accepted as beneficial. Essentially, active learning involves engaging students in learning tasks that are meaningful instead of simply having them listen to lectures. Studies support the use of active learning as it aids in memory retention, clarifies misunderstandings, and improves student attitudes. Collaborative learning has also been found to be effective in enhancing academic achievement, retention, and attitudes. With this in mind, the sustainability modules developed in this study incorporate both active and collaborative learning processes in addition to traditional instructional methods.",0
43,11,"

Engineering-focused summer education programs have been found to impact high school students' interest in pursuing engineering degrees later in higher education, according to Qiao et al. (2012). By providing hands-on experiences with design challenges, experiments, and teamwork, engineering camp programs can help motivate and cultivate the next generation of engineers. Although there isn't much data on how many K-12 students are being exposed to engineering curricula, studies suggest that early exposure can increase interest in the field, as stated in Katehi et al. (2009). These programs are popular across the country and attract a diverse range of interested students, including women and underrepresented minority students.",0
43,12," Bucknell University hosts a one-week summer program every year that concentrates on engineering education for high school students. The program accommodates around 100 students annually, who receive instruction from Bucknell faculty on a range of engineering subjects, including mechanical, civil, chemical, electrical, biomedical, and computer science. The faculty members each teach a module based on their area of expertise, with approximately 25 students attending each 90-minute class. Each module employs active learning techniques to enhance students' learning and engagement. The engineering camp not only exposes students to engineering but also employs sustainability modules to spark their interest in civil engineering.",0
43,13,"To evaluate the relevance and applicability of sustainable module topics and instructional content, two specific topics (#1: Sustainability Introduction and #2: Earthquake and Liquefaction Introduction) are selected as case studies and fully integrated into Bucknell University's Summer Camp. The effectiveness and relevance of this curriculum for high school students is assessed through indirect evaluation methods.",0
43,14," Two modules were chosen, Introduction to Sustainability (#1) and Introduction to Earthquakes and Liquefaction (#2), to evaluate their relevance for secondary school students. These case studies were designed as 90-minute lessons for roughly 25 students and were fully implemented during the Bucknell Univ. Engineering Summer Camp program. The lesson materials, objectives, implementation techniques, and activities were developed and evaluated in-depth during the process.",0
43,15," 
The next section outlines the creation and execution of the Introduction to Sustainability module, which was integrated into the Bucknell Engineering Summer Camp. The module was developed in 2011 and was utilized three times during the 2011, 2012, and 2013 camp sessions, with an average of 50 students participating each year. The objective of the module was to introduce concepts and practical applications of sustainability to secondary school students with an interest in engineering. As concerns regarding human-caused environmental impacts continue to escalate, future engineers will face increasing pressure to preserve, safeguard, and renew natural and constructed ecosystems.",0
43,16," During the introductory section of the lesson, the pupils worked in teams of five and engaged in a warm-up activity. Each group was provided with one of six unrelated items, including a wooden spoon, cloth bag, shoe, belt, plastic cup, and a dishtowel. The pupils were given five minutes to brainstorm and create five original uses for the assigned item, aside from its original purpose, to encourage innovative and sustainable systems thinking. Following this exercise, the students shared their top three concepts with the class and explained their thought processes.",0
43,17, The objective of Step 2 was to create practical and interactive problem-solving exercises that would challenge students to exhibit their ability to think critically and communicate effectively. Tasks such as determining their ecological impact and constructing concept maps of green design initiatives were designed and modified for a 90-minute class with around 25 participants.,0
43,18," The module ends by exploring how engineering design principles can be applied to achieve sustainability, with a focus on green design. The LEED rating system, created by the USGBC, is discussed as a viable tool for reducing environmental, economic, and societal impacts. The certification process for LEED projects is also explained, after which the students are divided into teams to study six exemplary projects that vary in type and were identified by USGBC (2013) as profile projects. The projects include the Exelon Building, Nationals Park Stadium, Chipotle Restaurant, Vista Dunes Development, Clearview Elementary, and Twinbrook Station.",0
43,19," The students were allotted 30 minutes to peruse the materials and pinpoint the primary design aspects employed in the project. They were instructed to categorize those aspects as either economic, environmental or societal benefits, or a blend of the three. Using Venn diagrams, the students separated the design components into the three components of the triple bottom line. Later, they conveyed their findings to the class and provided context as to why the project is a model example.",0
43,20," The module for Introduction to Earthquakes and Liquefaction is discussed in the upcoming section which covers its development and implementation at the Bucknell Engineering Summer Camp. During the camp programs of 2011, 2012, and 2013, the module was used thrice with the same instructor, having initially been created in 2011.",0
43,21," Bucknell Univ., along with Stanford Univ. and Arizona State Univ., is researching the post-liquefaction shear strength and structure of sands. The researchers believe that the soil structure resulting from the liquefaction and resedimentation process may be prone to reliquefaction during subsequent earthquakes. They sought funding from the National Science Foundation to develop learning modules for two different groups, with the work for secondary students included in this research. The second group, consisting of upper level undergraduates and graduate students, will be studied in future research efforts. While the module centers on small-scale shake table and liquefaction, other instructional components were developed and used to explain the principles.",0
43,22,"
During this section of the module, the discussion focused on soil properties such as density, porosity, and void ratio. The particulate nature of granular soil was also introduced to aid students in understanding porosity and void ratio concepts. Before the experiment, students were asked to define porosity and void ratio, and the fluidized bed was employed to demonstrate porosity with expert guidance from the instructor. The experiment also required students to explain the reasons for the increase in volume once the sample was permeated upward with air. Additionally, students were prompted to identify soil density methods such as blowing air in a different direction, creating a vacuum through the bottom of the cylinder, applying stress to the surface of the specimen, and shaking the soil specimen. Discussions during the experiment encouraged questions and answers that assisted students in comprehending the concepts better.",0
43,23," 

After conducting the fluidized bed experiment, the students delved into the concept of effective stress. Through the use of an analogy that involved a person standing in water of different depths, the students were able to grasp the impact of pore pressure (whether from air or water) on effective stress. Additionally, the students were educated on the fact that the effective stress in a dry soil sample is equivalent to the total stress, while there is no intergranular stress during liquefaction which renders the effective stress equal to zero. The session also focused on why the soil becomes denser post-liquefaction and why ponded water accumulates on top of the liquefied soil surface.",0
43,24," During the final phase of the module, students partook in a gauntlet experiment aimed at enhancing their comprehension of individual sand grains' movements and miniature penetration test performance. The exercise entailed simulating soil particles in various densities and arrangements in a corridor and requesting a student to navigate through a crowd of their peers. Afterwards, the student had to connect the resistance felt while moving through the group to the relationship between soil density and liquefaction. The experiment was enjoyable for the students and helped them understand its objective.",0
44,1," After scrutinizing the authorship of journal papers listed in the ISI Web of Science from departments and institutes related to chemical engineering, civil engineering, and mechanical engineering in Taiwan during 2008, this report has concluded that the scientific productivity of professionals in all three disciplines still adheres to the general trend previously studied.",0
44,2," According to Fronczak et al. (2007), the productivity of over three million authors listed in the INSPEC database from 1969 to 2004 followed a power-law distribution, specifically the Pareto distribution. The researchers identified two different exponents for junior and senior scientists, with g = 1.67 ± 0.01 for those with less than 20 publications and g = 2.87 ± 0.03 for those with more than 100 publications. The lognormal distribution also partly fit the data, accounting for long-life scientists. Fronczak et al. (2007) concluded that the degree of scientific productivity remains relatively constant across generations for a given seniority level.",0
44,3," Cheng and Chen (2007) conducted an analysis on the scientific productivity of chemical engineering professionals in Taiwan in the year 2006 using data obtained from ISI Web of Science. They found that the number of authors with x publications, N(x), followed a distribution of N(x) = 1320x^2.22. Additionally, the correlation between the number of publication x and the number of faculty authors F(x) was found to be F(x) = 257.5x^1.64. The researchers noted that the smaller exponent of 1.64 suggests that the correlation between scientific productivity and faculty authors behaves more like that observed among junior scientists, as reported by Fronczak et al. (2007).",0
44,4," The scientific productivity of professionals in chemical engineering, civil engineering, and mechanical engineering in Taiwan was analyzed in 2008 by scrutinizing authorship in all journal papers present in the ISI Web of Science.",0
44,5," The scientific productivity of chemical engineering, civil engineering, and mechanical engineering professionals in Taiwan in the year 2006 was determined through a comprehensive search of the ISI Web of Science database. The search criteria utilized were 'AD = (Taiwan AND (Chem Engn))' and 'Pub Yr = 2008', 'AD = (Taiwan AND (Mech Engn))' and 'Pub Yr = 2008', and 'AD = (Taiwan AND (Civil Engn))' and 'Pub Yr = 2008'. Each paper retrieved from the database was then carefully examined on a per-paper basis to ensure that it contained information contributed by at least one domestic chemical engineering professional. Papers that were not authored by a domestic chemical engineer were excluded from the data.",0
44,6," Upon further examination of the authorship of articles 237, 433, and 163, it was found that 237 articles had corresponding authors from domestic chemical, civil, or mechanical engineering institutes, and 256, 253, and 144 had corresponding authors from foreign institutions.",0
44,7," The study analyzed papers from 2008, written by chemical engineering, civil engineering, and mechanical engineering experts in Taiwan and cited in the ISI Web of Science database. The papers were authored by 237, 163, and 433 corresponding authors from domestic institutes in those respective fields, resulting in 802, 278, and 968 papers. The majority of publications came from a small number of leading domestic organizations. The study determined that the number of corresponding authors with x publications could be accurately modeled by a power-law function with an exponent of 2.16 ± 0.08.",0
45,1," The past 30 years have seen a transfer of cultural work from humans to computers, resulting in what is known as 'algorithmic culture', which has reshuffled the meanings of words like information, crowd, and algorithm. This essay aims to explore the emergence of algorithmic culture and provide an initial understanding of it. Although primarily a historical analysis, it concludes by highlighting the critical implications of this shift in today's world.",0
45,2," Author Mark R Probst noticed that several gay romance books had lost their Amazon sales rankings, including his own novel, The Filly, and brought the issue to widespread attention. He contacted Amazon customer service, hoping it was a mistake, but was informed that Amazon filtered 'adult' material out of most product listings. Probst posted about the incident on his blog, highlighting inconsistencies in the policy, leading to major news outlets picking up the story. It was discovered that gay and lesbian titles disappeared from Amazon's main product list as early as February 2009.",0
45,3," Amazon cited a cataloging error as the cause of the issue in a press release on Monday. Over 57,000 books were impacted, including those with LGBTQ+ themes as well as titles categorized under ""Health, Mind, Body, Reproductive and Sexual Medicine, and Erotica."" A technician in France reportedly made a mistake by changing the ""adult"" attribute in the database from ""false"" to ""true,"" resulting in the de-listing of books with such metadata. Amazon claimed the mistake was not driven by homophobia but was a genuine human error exacerbated by technological affordances. (James, 2009a; see also Rich, 2009).",0
45,4," In the aftermath of the scandal, Larry Kramer, an LGBT activist and author, remarked that Amazon's handling of the world's cultural heritage should be closely monitored (as cited in Rich, 2009). Although Amazon initially started as a retail company, it has evolved into a prime example of how people delegate the classification and ranking of objects, ideas, and more to data-driven computational processes. The scale of Amazon's back-end data architecture is so significant that it began offering surplus capacity to clients in 2006 under the Amazon Web Services moniker. Furthermore, Amazon collects sensitive information on users' reading habits through its Kindle e-book devices, and this is just the beginning of how it profiles and markets products based on browsing and buying trends (Striphas, 2010).  Amazon, Google, Twitter, Facebook, Netflix, and other companies are transforming human thought, behavior, organization, and expression into the framework of large-scale data and computation. This change alters how culture has traditionally been practiced, perceived, and comprehended; I refer to it as ""algorithmic culture,"" following Alexander R Galloway's phrase (2006).",0
45,5," This essay takes inspiration from Raymond Williams' work on keywords and focuses on moments of catachresis that create an alternate meaning for specific words and phrases. By utilizing these moments, the essay proposes new ways of understanding reality using language, such as incorporating culture into computational data processing. The essay argues that while the technological aspects of algorithmic culture tend to receive more attention, the semantic dimensions are of equal importance. According to Williams, language plays a crucial role in shaping social and historical processes, giving rise to new territories that may only later be occupied by technological advancements.",0
45,6,"
A keywords approach allows for the identification of enduring senses and meanings, referred to as 'traces without ... an inventory' (Gramsci, 1971: 324; Seigworth, 2000: 237). By cataloging this inventory, one can contextualize algorithmic culture within a broader historical context and critically evaluate its claim to impartiality and egalitarianism. The decline of cultural publicness and the emergence of an elitist culture purporting to be its antithesis are significant consequences of algorithmic culture.",0
45,7," Gary Hall poses the question in Culture in Bits about what cultural studies' classical names would have produced had they had access to modern digital computational technologies. To be specific, he asks how Richard Hoggart's work would have looked like with email. Similarly, the question is posed about Raymond Williams and how he would have tackled the AmazonFail dilemma while trying to comprehend the intertwining of culture as a ""court of human appeal"" and computational decision-making. (Williams, 1958: viii). Hallinan and Striphas (2014) also consider this.",0
45,8,"

The book Culture and Society covers the time period from 1780 to 1950, encompassing the industrial revolution and the end of World War II. The latter event, according to Beniger (1986), marked the beginning of new revolutions such as the computer and communications. Williams (1958) may have chosen the year 1950 because it represented a midpoint where past, present and future met. In the conclusion of Culture and Society, Williams examines how communication has evolved alongside new technologies. Later on, in The Sociology of Culture (1981), Williams briefly addresses the relationship between culture, information and digital technologies. While he did not develop a holistic theory on the subject, his work laid a crucial foundation for understanding how cultural coordinates have shifted since 1950.",0
45,9," When the English language first incorporated information in the 12th or 13th century CE, mostly from Latin, the word revealed the tension it would carry. Initially, it held two significant semantic registers: law and religion. While the religious definition, which the OED now identifies as rare, could be more accurately described as spiritual or even deific. Significantly, information connoted the act of imbuing something with a specific quality, animation or character, as shown by its definition as ""the giving of form or essential character to something"" (‘Information’, n., n.d.). This meaning signifies an intrinsic connection between this act of shaping and endowing something with life, substance or character.",0
45,10," The word information was heavily influenced by early modern empiricism and idealism, which shifted its meaning from an intrinsic quality to extrinsic sense data. The definition referred to as ""knowledge communicated concerning some particular fact, subject, or event"" reflects this change. It highlights how the locus of information has shifted from pre-modern times through early modernity and beyond. Although it originally referred to existential work, divine or worldly, the focus shifted to a more object-oriented definition over time.",0
45,11,"
The word crowd has a history of polarity reversal in its etymology, which began when it was adapted from Dutch, German, and Frisian verbs in the 15th century, denoting pressure or pushing. The English verb 'to crowd' retains this early meaning, although it can be figurative in some contexts. According to the OED, the rise of the word's usage coincided with early modernity, and it has often been used interchangeably with mass, mob, multitude, and throng to refer to large gatherings of people, generally in public, especially in urban settings. The word is often associated with impedance, inefficiency, and frustration, as well as individual anonymity and engaged inaction. Previously, the word ""crowd"" carried mostly negative connotations.",0
45,12," Mackay not only adheres to the conventional wisdom but also manipulates it to some extent. He makes a slight shift in terminology by referring to the 'popular mind' before talking about 'thinking in herds.' While the latter suggests an active process of group thinking, the former is a more passive concept that refers to a generalization of everyone's mindset. This semantic maneuver is comparable to how the term 'information' has transformed from a physical entity to a non-material object that can be dispersed into the world.",0
45,13,"

The invisible hand is a mysterious force in economic activity, similar to the spiritual sense of information. Friedrich A Hayek made a more explicit connection between the two, supporting the positive view of crowds in both Adam Smith and Gustave le Bon's work. Hayek's book, ""Road to Serfdom,"" published in 1944, argued for a force – the economic sphere – to keep the state in check. He believed in stripping the state of economic planning responsibilities and leaving coordination up to individual actors. Hayek emphasized information's critical role in coordinating economic activities, particularly through the price system, rather than relying on the invisible hand's arcane workings. (Hayek, 2007 [1944]: 232, 95)",0
45,14," The contemporary terms such as 'crowdsourcing', 'crowd wisdom' and similar phrases have been established due to the positive connotations associated with crowds. These terms have become popular in the last two decades or so, including 'hive mind', 'collective intelligence', 'smart mobs', 'group genius' and more. The diverse traditions and technological advancements have resulted in imperfect translations of these phrases. Williams' (1958) conception of 'solidarity' required for sustaining a 'common culture' did not anticipate the computational solidarity present today. The redemption of crowds is striking given the major computer platforms are now central to online interaction.",0
45,15," The importance lies in obtaining information, which is highlighted by two influential papers from Bell Laboratories engineers. Ralph Hartley's 'Transmission of Information' from 1928 was significant for technical reasons, but he also boldy sought to categorize communication as a form of information. Hartley's conceptualization of communication involved a procedural game of chance where the goal was to achieve identity of message in a given context by mentally selecting symbols. Shannon built on Hartley's work and intensified the focus on information.",0
45,16,"

Shannon's expertise went far beyond electrical engineering. He was also an exceptional cryptographer and had contributed to various government-sponsored secrecy projects at Bell Labs during the Second World War. One of his lesser-known papers, ""A Mathematical Theory of Cryptography,"" was initially classified. Shannon's work revolved around the intersection of algorithms and algorisms, and he acknowledged that communication and cryptography were so closely linked that they couldn't be separated. He believed that communication was merely a simpler form of cryptography that consisted of signals, noise, and redundancies that could be used to reduce disruption and promote order. Therefore, Shannon proposed using algorithms to mitigate algorisms.",0
46,1," 
Blood culture bottles have been found to be more effective than traditional media for vitreous culture in cases of suspected infectious endophthalmitis. Therefore, vitreous culture with blood culture bottles should be given priority for microbiological diagnosis. Furthermore, using both methods in conjunction has shown to increase the probability of a positive culture yield.",0
46,2," The study was conducted in accordance with the Declaration of Helsinki, approved by the Khon Kaen University Ethics Committee for Human Research (HE551093). Patients diagnosed with clinically suspected endophthalmitis at KKU Eye Center from 2008 to 2014 were enrolled. Inclusion criteria included patients with best-corrected visual acuity of 6/15 or worse, clinical findings of endophthalmitis no longer than 3 weeks, and a history of intraocular injury or surgery no longer than 6 weeks. Exclusion criteria included patients with a history of uveitis or the use of eyedrops that could interfere with culture results within 1 week.",0
46,3," The undiluted vitreous specimens were extracted from all patients by aspiration through a 23-gauge needle during vitrectomy. The vitreous specimens were then cultured using both BCB (VersaTrekREDOX1) and CCM (blood agar, MacConkey agar, chocolate agar, Sabouraud dextrose agar, and thioglycolate broth). Both BCB and CCM were sent to the Clinical Microbiology Laboratory within 30 minutes and further inoculated, incubated, and examined for growth. Any organisms were then identified.",0
46,4," The researchers focused on the number of positive culture yields in different media methods as their primary outcome, specifically comparing BCB and CCM. They also examined the types of infectious endophthalmitis and causative organisms as secondary outcomes. The statistical analysis was performed using SPSS for Windows version 16.0, and McNemar χ2-test and an odds ratio with 95% confidence intervals were used to analyze the collected data. A difference was deemed significant at a P value of <0.05.",0
46,5," The vitreous samples underwent microbiological testing by inoculating them in both BCB and CCM. Of the 305 eyes tested, 151 (49.5%) were found to have positive cultures in either one or both of the methods.",0
46,6," The positive culture results differed significantly between the two methods, with 136 eyes (90.1% of 151 eyes) showing positive cultures in BCB and 99 eyes (65.56% of 151 eyes) showing positive cultures in CCM. The odds ratio was 3.47 and the 95% confidence interval was 1.92, 6.63. These results were statistically significant with a P value of <0.00001. BCB method had a higher rate of positive cultures compared to CCM method as shown in Table 1.",0
46,7," 

Despite Tan et al.'s examination of 85 vitreous specimens from 85 eyes, they found no significant difference between BCB and CCM with regards to growth, as BCB yielded 69% and CCM yielded 72%. Although they concluded that BCB was not superior to CCM, they found that employing both culture methods led to a significant increase in culture yield. In contrast, the current study examined a larger series and validates the KKU report, with BCB manifesting a higher number of positive cultures than CCM, signalling a statistically significant difference. Moreover, the combination of both methods led to better positive results when compared to relying solely on BCB or CCM.",0
46,8," BCB may be superior to CCM for vitreous culture due to a potential inhibitory effect of purulent fluid on organisms. It is suggested that dilution of this fluid in a larger volume of BCB may increase recovery of organisms. BCB contains nutrients that promote organism growth and only one medium is needed for inoculation, making it time-saving and requiring only a small volume of specimen. Additionally, transportation to the laboratory is simpler as immediate incubation is not necessary, making it suitable for office settings and hospitals without adequate microbiology laboratory facilities.",0
46,9,"Although this study has the advantage of being the largest series of patients reported, there is a drawback. The rate of positive cultures was only 49.5%, which is relatively low compared to previous studies. This may be due to the study's retrospective nature, as it only included patients who underwent vitreous culture using both methods, and excluded those whose cultures were positive using only one method. It is possible that some patients received antimicrobial treatment prior to vitreous cultures, causing some microorganisms to go undetected. Moreover, some patients may have endophthalmitis caused by non-infectious reasons.",0
46,10," The conventional media was found to be inferior to BCB in vitreous culture for infectious endophthalmitis, making BCB the recommended primary method for microbiological diagnosis. Positive yields can be further improved by using a combination of both culture methods.",0
46,11," 
The statistical analysis was done by Dr. Kaewjai Thepsuthammarat from the Clinical Epidemiology Unit, Faculty of Medicine, Khon Kaen University, and the English language presentation of the manuscript was assisted by Professor James A Will from the University of Wisconsin, for which the authors express their gratitude.",0
47,1," The author of this article discusses the concept of ""body culture"" and its significance in both theory and practice of human movement activities related to sports and physical culture. Through a historical and contemporary perspective, the author explores various theories by Norbert Elias, Frankfurt School, phenomenology, Michael Foucault, and Pierre Bourdieu to provide context for the topic. The author examines the expression ""body culture"" in relation to fields such as philosophy, sociology, anthropology, ethnology, psychology, education, linguistics, theology, politics, and democratic assumptions.",0
47,2," 

In the early 20th century, the Mentawai people living in clans along the rivers in equatorial rainforest, were introduced to the Dutch colonial power for the first time. The Mentawaians, who had lived according to their 'Stone-Age' culture, were termed as 'mild savages' by the westerners. The colonial authorities were amazed by their rich traditions and shamanic rituals, and this encounter marked the beginning of cultural learning and eventual transformation.",0
47,3," The plot revolves around a misinterpretation. The Dutch had the notion to engage the Mentawaians, who were renowned for their adeptness in shooting, in a celebration to pay tribute to the Dutch royalty. Through physical involvement, they aimed to establish a connection between their respective cultures. Similarly, it is frequently contended today that sports embody a fundamental, unbiased, and all-encompassing bodily language, which, despite diverging linguistic languages, can be a perfect conduit for mutual understanding and bridging gaps between nations.",0
47,4," The encounter played out differently in reality, as recalled by the old Mentawaian. The initial meeting was friendly and festive, with decorations and a meal, but it soon turned absurd when the Dutch cheered incomprehensibly about a coconut being hit by an arrow. The event ended with an insult when the Dutch officer distributed sports rewards based on achievement, which conflicted with the Mentawaian social structure of maintaining balance between clans. The act of giving unequal rewards based on shooting abilities went against the egalitarian nature of the stateless society and complicated relationships between clans living under the same longhouse. It became clear that bow-and-arrow shooting was a Mentawaian art of hunting and a Western sport, making them fundamentally different activities.",0
47,5," The complexity of bodily activity, body language, and body culture is highlighted by the case. It also emphasizes the significance of body culture in comprehending society and cultural diversity.",0
47,6,"Moreover, it elucidates the connection between the history of sport in the Western world and that of non-Western cultures. History is not restricted to the development and evolution of mainstream ""sport"" as commonly understood. Guttmann's (2004) seminal work on this subject highlights this perspective. Rather, it encompasses the histories of diverse physical activities in numerous Asian, African, Indigenous American, and Pacific societies. These non-sporting practices (Sonderwege) reveal distinct approaches that contrast with Western sports. The involvement of body culture, particularly in instances of cultural confrontation, reveals the cultural diversity of different societies.",0
47,7," In the 1970s, there was a sudden surge in attention towards ""the body"" amongst cultural and social studies scholars. This interdisciplinary conversation included sociologists, historians, philosophers, anthropologists, sport studies scholars, and medical studies scholars. They discussed ""the return of the body"" or its ""reappearance"" with the most popular term being ""Die Wiederkehr des Körpers"" coined by Kamper/Wulf in 1982. Soon after, the term ""body culture"" emerged to encapsulate the newfound fascination with the body.",0
47,8," The history of this term and the related field of knowledge can be divided into three distinct lines of development. These include the line of classical theories on the culture of the body, the history of the term ""body culture"" itself, and the recent profile of discourse and changes in social practices that led to increased attention. Each of these lines leads to different historical phases.",0
47,9," ""After the term ""body culture"" was coined, academics redirected their focus to earlier studies on the subject by sociologists and philosophers such as Norbert Elias, the Frankfurt School, and some phenomenologists dating back to the 1920s and 1930s. Michel Foucault and Pierre Bourdieu later connected these earlier studies to the new studies on body culture.""",0
47,10," Michel Foucault (1975), a French philosopher who followed phenomenological traditions, conducted in-depth research on the knowledge configurations during the Renaissance and Baroque periods to understand modern society's post-1800 ""development"" and panoptical control. Foucault's approach involved analyzing the history of military discipline, and he considered the panopticon as a control mechanism. The contemporary body is subjected to the biopolitics of power and moves within a network of prisons, as per Foucault's interpretation. This approach has notably influenced the study of body, space, and architecture within sports (Vertinsky/Bale 2004) and motivated critical examination of the disciplined body in gymnastics and sports (Vigarello 1978, Barreau/Morne 1984, Vertinsky/McKay 2004).",0
47,11," Pierre Bourdieu focused on bottom-up social-bodily practices, studying the Kabyl Berber people in Algeria before examining different social classes in Paris and France. He coined the concept of habitus, which is an incorporated pattern that becomes social practice through diverse forms of taste, distinction, display of the body, and sports. The social habitus can be understood as a form of cultural capital alongside economic capital. Jacques Defrance applied Bourdieu's concepts to the history of sports and gymnastics.",0
47,12,"Recently, other pioneers of modern social thinking have unveiled the recognition of 'the body' as a subterranean category. This can be seen in Karl Marx's contemplations on the ""foundation"" of human behavior and communal connections, Max Weber's evaluation of the Protestant and capitalist ""worldly asceticism"", and Marcel Mauss' scrutiny of ""corporeal techniques"".",0
47,13," German Socialist workers' emphasis was on Körperkultur, while Nazi sport gave priority to Leib and Leibesübungen and abhorred Körperkultur, considering it materialistic, decadent, and Jewish. Russian Socialist adopted the concept under the name fiskultura via German Socialist ""body culture"" after the revolution of 1917. Fiskultura became an alternative to bourgeois sport, uniting Proletkult and hygienists under Stalinism's dominance; the contradictory terms were combined under the phrase “sport and body culture.” After 1945, this continued in the Soviet bloc. Körperkultur was reintroduced into the German Democratic Republic, where the review of sport sciences was titled Theorie und Praxis der Körperkultur, and the sports university in Leipzig was called “German High School of Body Culture” (DHfK).",0
47,14," The notion of body culture was consistently referred to in the singular form throughout all of these alterations. Despite the fact that a closer examination revealed both cultural diversification and historical evolution, the concept of body cultures in multiple forms was not yet discussed.",0
47,15," ""The term 'body anthropology' was coined by some European scholars, who worked within the framework of the French-Danish-German Institut International d’Anthropologie Corporelle (IIAC 1987 ff; Barreau/Morne 1984, Dietrich 2001 and 2002). The publication Stadion, Journal of the History of Sport and Physical Education (Cologne 1975 ff) used the terms 'Sport und Körperkultur' in German and 'Sport et culture physique' in French as its title. In Japan, Satoshi Shimizu, a sociologist, founded a Centre for the Study of Body Culture at the University of Tsukuba.""",0
47,16, The scholarly attention to the human body through the concept of body culture emerged in the 1970s as a result of a cross-disciplinary process.,0
47,17," During the 1970s, there was a surge of interest in the anthropology of the body, triggered by Clifford Geertz's famous article on Balinese cockfighting. This article gained worldwide attention and is still frequently cited in discussions of the intersection of culture and sport. Other anthropologists, such as Susan Brownell and G. Whitney Azoy, continued this trend by examining the body in the context of different cultural practices, like Afghan Buzkashi and Chinese sports. Their work demonstrated how power dynamics and cultural values could be embodied and reproduced through physical activity.",0
47,18," The Tübingen School in Germany, led by Hermann Bausinger, conducted research on upright posture in ethnology, while Danish ethnologists explored the bodynear concept of life-form analysis and Swedish ""cultural analysis"" viewed modernity as a change in bodily practice. The Centre for Contemporary Cultural Studies' (CCCS) Birmingham school garnered widespread global recognition for its analysis of youth cultures, sport and rock music.",0
47,19," Psychology initially struggled with expanding its focus beyond the soul or psyche to include the body. However, Wilhelm Reich, a German Communist psychiatrist, revolutionized therapeutic practice and psychoanalytic theory in the 1920s and 1930s by emphasizing the importance of the body, particularly in regards to ""body armour"" and orgasm. Reich's work also allowed for a critique of Fascism through a body-political lens. In the late 1960s, there was renewed interest in Reich's work that led to new forms of therapy and the emergence of Somatics. Finland and the UK approached the body and its role in subjectivity and culture through narrative and autobiographic methods. David B. Morris's 1991 study on the ""culture of pain"" was also a significant contribution.",0
47,20," 

""Changes in the education field were impacted by these developments. Educational experts from France, Germany, and Denmark collaborated under the umbrella of ""body anthropology"" (IIAC 1987 ff) to investigate traditional games and new urban body cultures (Barreau/Jaouen 1998, Dietrich 2001 and 2002). The term ""movement culture"" gained prominence in German pedagogical thinking (Moegling 2001/2). Play, games, and various forms of ""Sport for All"" were seen as educational opportunities in a culture that emphasized sports.""",0
48,1, The comparison of the usefulness between bone marrow culture and blood culture in evaluating FUO was conducted to determine which one is superior.,0
48,2," During a one-year study, the usefulness of bone marrow culture and blood culture in diagnosing FUO was examined using a cross-sectional approach. Marrow aspirates from each case were analyzed for bacterial, mycobacterial, and fungal culture. Similarly, venous blood was sent for bacterial culture. The BMC and BC results were then compared.",0
48,3,"

The study included 57 cases of fever of unknown origin (FUO), with a male-to-female ratio of 1.22:1. The age range of patients was five to 83 years, with a median of 30 years. The duration of fever ranged from 21 to 365 days. Bacterial growth was observed in 15.78% of bone marrow cultures (BMCs) and 5.26% of corresponding blood cultures (BCs), while no fungal or mycobacterial growth was detected. The most commonly isolated organism in BMCs was Salmonella typhi (three cases), followed by Staphylococcus aureus (two cases), Escherichia coli, non-fermenting Gram-negative bacilli, Enterococcus species, and Salmonella paratyphi–A (one case each). BCs yielded two cases of Salmonella typhi and one case of Salmonella paratyphi–A.",0
48,4," BMCs are more beneficial than BCs for assessing patients with FUO, particularly in instances of salmonella infection and become crucial when the patient has been administered antibiotics. However, conducting BMCs for mycobacteria or fungi is improbable to produce any growth in immuno-competent patients presenting with FUO.",0
48,5," The study was conducted for one year and was cross-sectional in nature. It consisted of all cases of FUO referred to the department of pathology at Manipal Teaching Hospital. The criteria for FUO were based on Petersdorf and Beeson, which required a temperature of 38.3oC (101oF) or higher persisting for at least two weeks and a seven-day investigation in the hospital, or if three out-patient visits did not result in a diagnosis. Patients who did not meet these criteria were not included in the study.",0
48,6," The clinical findings were documented and patients were informed of the procedure. Venous blood was taken for bacterial culture. Bone marrow aspirations were carried out with a Salah needle attached to a 20 cc syringe using local anesthesia from the posterior superior iliac crest after taking aseptic precautions. About 10 ml of bone marrow was aspirated for bacterial, mycobacterial and fungal cultures. For bacterial cultures, the aspirate was inoculated into biphasic brain heart infusion medium and biphasic MacConkey medium and incubated at 37°C for seven days, with regular subculture on the third and sixth days until the growth was observed. Subcultures were performed and incubated at 37°C for 18-24 hours. The growths in the slants were Gram-stained, and the isolates were identified by biochemical and serological tests. For Mycobacteria, the aspirates were inoculated into Lowenstein-Jensen medium and incubated at 37°C until growth appeared, maximum for eight weeks. For fungi, the aspirates were inoculated into Sabouraud dextrose agar medium and incubated at room temperature until growth appeared, maximum for four weeks.",0
48,7," Out of 57 patients, bacterial growth was observed in BMCs in nine cases (15.78%), and in three cases (5.26%) corresponding BCs also exhibited bacterial growth (as mentioned in Table 3 and 4). None of the BMCs showed growth of mycobacteria or fungi. The commonest bacterium isolated from BMCs was found to be Salmonella typhi (33.5%), which is shown in Table 4. In two cases, the bacterial growth observed in BMCs and BCs were found to be similar (as mentioned in Table 3).",0
48,8," According to Haq et al's study, infectious diseases made up the majority (63.21%) of cases of FUO. The most common infectious diseases were tuberculosis (24.53%), followed by enteric fever (12.74%) and visceral leishmaniasis (9.43%). In Jung et al's study, the most common cause of FUO was also infections (46.4%), with enteric fever being the most prevalent (29.6%), followed by malaria (9%) and tuberculosis (5.2%). However, these studies did not solely focus on BMCs and BCs like the present study. Despite this difference, the present study found enteric fever to be the most common cause of infection-related FUO.",0
48,9," 
A bone marrow examination, which includes BMCs, plays a crucial role in the investigation of FUO. However, it may not be adequate in identifying a specific cause in all cases. To achieve a high diagnostic yield, it is important to combine the examination with a comprehensive clinical history, hematological and radiological assessment, as well as BMC and serology tests. In cases of suspected salmonella infection or patients under antibiotic treatment, BMCs are more effective, as demonstrated in the present study. However, in immuno-competent patients, BMCs are not efficient in isolating mycobacteria or fungi.",0
49,1," The use of synovial tissue from the same joint as the chondrocyte nutritive supply source was investigated as a possible alternative to conventional culture methods that require four to five weeks to prepare layered chondrocyte sheets for articular cartilage repair and regeneration. The study involved co-culturing synoviocytes and chondrocytes on temperature-responsive inserts to assess chondrocyte growth and perform a molecular analysis of the chondrocyte sheets. This method produced transplantable tissue in an average of 10.5 days and confirmed the expression of genes critical to cartilage maintenance while suppressing genes detrimental to repair. Additionally, the adhesive factor fibronectin-1 was observed in all sheet layers using this method, whereas conventional preparation methods only showed positive FN1 immunostaining on the sheet surface.",0
49,2," Articular cartilage, which is crucial in maintaining joint function, has limited self-propagation due to several reasons, such as the absence of blood vessels, chondrocyte immobility within the extracellular matrix, and age-induced decrease in their proliferative ability. In case of damage, fibrous tissue takes over and surrounding cartilage degenerates, leading to osteoarthritis. Both aging and joint overuse result in cartilage defects, and treatment methods are available to address full-thickness injuries. Unfortunately, regeneration of hyaline cartilage is not possible regardless of the type of defect.",0
49,3," Alternative techniques for autologous periosteal implantation have been employed in recent years, including the use of type I/III porcine collagen for concealment (Gomoll et al., 2009). Matrix-induced autologous chondrocyte transplantation is commonly done by seeding multilayered collagen with chondrocytes (Bartlett et al., 2005). However, there is still room for improvement such as lowering cytotoxicity, increasing biocompatibility, and treatment efficacy.",0
49,4,"
Various strategies have been devised to enhance the growth of cells in vitro, such as utilizing feeder cells or incorporating growth factors into the culture medium (Fujisato et al., 1996; Wakitani et al., 1997; van Osch et al., 1998). Nonetheless, only a small number of these agents can be administered clinically, and their effects are transitory. In vivo, the primary source of nutrition for articular cartilage is the synovial fluid produced by the synovial membranes within the same joint (Hodge and McKibbin, 1969). Synovial tissue is believed to aid in repairing damaged cartilage (Hunziker and Rosenberg, 1996) and exhibits remarkable ability for regeneration, repair, and growth. A vast number of cells can be extracted from synovial tissue, and MSCs differentiated musculoskeletally with synovium origin demonstrate excellent potential (Fan et al., 2009). We have previously explored whether stratified sheets of chondrocytes co-cultured with synovial cells could be transplanted into a full-thickness cartilage defect model in pigs, and we discovered that the repair was more advantageous than the control group (Ebihara et al., 2012).",0
49,5," The researchers used simple techniques to enhance the growth of chondrocytes. One of the methods was co-culturing them with synoviocytes to simulate the provision of nutrients in synovial fluid. They also prepared three-layered chondrocyte sheets using a combined culture method and compared their ability to encourage cartilage repair with single-layered sheets. Additionally, they conducted a preliminary investigation using porcine cells and found that co-cultures resulted in a higher increase in chondrocyte numbers than single cultures.",0
49,6," 

Ten patients (six men and four women) who underwent surgery to reconstruct the anterior cruciate ligament at Tokai University Hospital provided cartilage and synovium samples. Their median age was 29 years (age range 20-42 years). Separation of cells was done enzymatically, following the methods reported in Sato et al. (2003). All patients willingly participated in the study, and the Tokai University Ethics Committee approved the research.",0
49,7," The study utilized cell cultures of different generations (P0,P1,P2) that were either cultured alone (S group) or in combination with synoviocytes (C group). The cultures were grown in a six-well dish with inserts that had a 0.4 mm pore size. Additionally, a layered chondrocyte group was grown with heat-sensitive inserts. The same culture medium protocol was used for chondrocyte maintenance throughout the study.",0
49,8," Cell proliferation ability was assessed in both 24-well and plate culture dishes by seeding 1 × 104 cells/cm2 into chondrocyte and synoviocyte cultures to prepare the S group and C group. Proliferation was evaluated on culture days 3, 5, 7, 9, 11, and 14 using a 3-(4,5-dimethyl-2-thiazolyl)-2,5-diphenyl-2H-tetrazolium bromide (MTT; Dojindo, Kumamoto, Japan) assay with six replicates per experimental condition.",0
49,9," The mean and standard error of the mean (SEM) were used to present the data. Differences between single chondrocyte sheets and layered chondrocyte sheets were examined through analysis of variance (ANOVA). When p was less than 0.05, we conducted multiple paired comparisons using the Student–Newman–Keuls test.",0
49,10," The CL group consistently expressed higher levels of genes such as COL2, ITGa10, TIMP1, and SOX9 important for maintaining articular joint characteristics compared to the S group. This difference was observed in P0 and P1, with significantly higher expression of COL2, ITGa10, and TIMP1 in the CL group. MMP3, MMP13, and ADAMTS5 were significantly inhibited until P1 in all groups, with no significant differences in gene expression during P2. High expression of COL2 and low expression of COL1 – markers of articular cartilage – were observed in every successive generation of layered chondrocyte sheets. The AGC1 and FN1 genes did not differ significantly between treatment groups. (Figure 4A–G, I).",0
49,11," This study received funding from the Japanese Ministry of Health, Labour and Welfare for Health Labour Sciences Research Grant and the Ministry of Education, Culture, Sports, Science and Technology for Grant-in-aid for Young Scientists (B). We express our appreciation to CellSeed, Inc. for providing the temperature-responsive culture inserts used in this investigation, as well as to the Education and Research Support Center at Tokai University.",0
49,12," 
A new approach has been developed to co-culture chondrocytes and synoviocytes with temperature-responsive culture inserts. Expression of essential genes for cartilaginous differentiation, maintenance of cartilaginous features, and adhesion factors were detected in layered chondrocyte sheets created by this method. It demands significantly lesser culture time in comparison to conventional methods. However, it still takes up to 21 days to make transplantable P0 cell sheets. Consequently, a further reduction in the culture period may be required for actual clinical usage.",0
50,1," The article investigates the correlation between learning culture and safety culture in organizations and proposes the hypothesis that factors indicative of a good learning culture might also indicate good safety culture and vice versa. After conducting an extensive literature review, six components were identified that can be measured by the same instrument, forming guiding principles for measuring safety and learning culture. Eight other areas saw partial alignment between the two, while four other components were found to be relevant to only safety culture or learning culture. The overall conclusion was that though there is a relationship between learning culture and safety culture, it is not reliable to gauge one as a measure of the other.",0
50,2," The emphasis on culture in the domains of learning and safety stems from the recent trend in organizations to examine the social and environmental factors that affect work. While the terms culture and climate are sometimes used interchangeably when discussing workplace safety and learning, there are distinct differences between the two. Culture refers to the values, beliefs, and assumptions underlying an organization, whereas climate describes the workforce's perceptions of the overall ambiance. Culture is a relatively stable feature of an organization, whereas climate can evolve and change over time. Culture is typically measured through observable indicators, although these indicators can be complex and difficult to interpret. Despite this, analyzing an organization's culture can provide valuable insight into workplace safety and learning.",0
50,3," Safety perception has transformed to support employee well-being and develop safer work environments, according to Dedobbeleer and Béland (1991), Cooper (2000), and Glendon and Stanton (2000). Initially, safety was approached through technical solutions, but as better mechanical systems were invented, attention shifted to addressing human error and operational issues. Despite this, unsafe practices and decisions remain a significant cause of system failure alongside socio-technical aspects, which consider the interaction between humans and technology. Recently, culture has become an essential focus in safety and organizational psychology research to comprehend incidents and safety in organizations.",0
50,4," It could be beneficial to identify common factors to enhance the measurement of safety and learning culture. Positive factors indicating a learning culture may indicate good safety, while positive factors denoting safety culture may indicate good learning. Establishing a relationship between safety culture and learning culture measurement could benefit organizations. However, interdisciplinary research investigating the relationship between safety culture and learning culture is scarce. With the aim to improve measurement methods, this study aimed to determine whether safety and learning cultures are interrelated and to what extent they occupy the same conceptual space. By drawing on literature from various disciplines, the study sought to identify how to use learning culture measures to assess safety culture and vice versa.",0
50,5," The study aims to determine the correlation between learning culture and safety culture factors, and how they can be used interchangeably to promote good safety practices. This will aid organisations in streamlining their workflows by identifying key principles that could help foster a positive learning culture that contributes to safety. Furthermore, the research aims to advance the theoretical understanding of both learning culture and safety culture by establishing a relationship between the two disciplines, which could be further explored through empirical studies.",0
50,6," The article provides an overview of safety culture and learning culture literature, describing the process of selecting and summarizing relevant papers from both fields. It identifies and categorizes key indicators for safety culture and learning culture derived from the literature, and explains the method used to synthesize them into overarching themes. The article then compares and aligns these themes within the safety culture-learning culture nexus, ultimately concluding with a set of principles for effective safety and learning culture.",0
50,7," The papers chosen for inclusion were required to have indicators of safety or learning culture, with empirical and review papers only being considered if they included relevant indicators. After an initial list, a shortlist was created through a two-stage filtering process, starting with the elimination of non-relevant papers based on abstracts. The remaining papers were assessed to identify and abstract key indicators, with some articles discarded if they did not meet the criteria for safety or learning culture or lacked the required indicators.",0
50,8," The indicators for learning culture and safety culture were analyzed and categorized into themes, such as commitment, collaboration, and workplace conditions. Two separate thematic analyses were conducted for each culture. The indicators were color-coded based on the article source, the construct, and the type. Emergent themes were identified, and the results were transferred to a database. (Table 2 illustrates these themes.)",0
50,9," The safety culture and learning culture were compared in the final phase of the study using thematic alignment. The themes of learning culture were reviewed and compared to those of safety culture, and synthesised summary statements were used to determine the level of alignment between the themes. Thematic alignment was undertaken by three researchers independently, with any discrepancies resolved through discussion. The output was the aligned themes presented in Table 2 and discussed in the following section.",0
50,10," The safety culture and learning culture exhibit some level of correlation as evident from the six recurrent themes, including open communication, employee empowerment, collaboration, alignment of espoused and enacted priorities, internal systemic alignment, and management. Table 2 offers a summary of these themes and indicates the number of articles that represent every theme out of the overall papers reviewed.",0
50,11," Collaboration is a recurring theme in the literature, where safety and learning are emphasized to be the responsibility of all employees in an organization (Lähteenmäki et al, 2001; France et al, 2010). Teamwork and effective work practices are vital for safe and productive operations within and between teams. Collaboration promotes learning by providing opportunities for individuals to develop team and group work skills both within and outside the organization. Trust in colleagues' expertise is crucial for successful collaboration, and mutual support is essential for fostering a positive safety and learning culture (Grote, 2008; Westerberg and Hauer, 2009).",0
50,12," The critical theme connecting safety culture and learning culture is the alignment of enacted and espoused priorities. This means that employees' actions should align with their intentions. If an employee's intention is to achieve accreditation rather than to learn, the result can be shallow learning. Likewise, if an employee reports a colleague's unsafe behavior with malicious intent instead of aiming to improve safety, the outcome may be detrimental. Therefore, individual and organizational values must be synchronized with professional practice. This concept has been discussed by Argyris and Schon (1978), Wiegmann et al. (2004), Leung (2006), and Zohar (2010).",0
50,13," Upon reviewing the literature, we discovered that particular competencies pertaining to the job and meta-cognition were crucial for employment, as noted by Clarke in 2005. The meta-cognitive competencies identified in organizational learning literature were comparable to those outlined in security literature. These competencies include an employee's capability to assess their abilities relative to others and their confidence in participating in learning or safety manners. Nevertheless, there are dissimilarities as safety competencies are learned and trained within organizations. It's thought that employees may not even possess basic safety competencies, such as knowing how to evacuate a building in case of a fire. On the other hand, personnel are frequently assumed to have knowledge of how to learn, even though that may not always be the case. There are sparse initiatives in place to encourage employees to develop their learning competencies and learn how to learn.",0
51,1," 

An immunomagnetic separation coupled with selective agar culture (IMS/culture) was optimized to detect Salmonella in food samples. The study compared the effectiveness of direct culture, IMS/culture, and multiplex PCR (mPCR) and found that IMS/culture had a higher detection rate among the three methods. After selective enrichment, 83, 95, and 104 samples were identified as positive for Salmonella by direct culture, IMS/culture, and mPCR, respectively. The study recommended using mPCR for pre-screening and IMS/culture for further identification to enhance positive identification and increase the number of Salmonella isolates.",0
51,2," 

Outbreaks of foodborne salmonellosis have caused serious concern regarding the quick and accurate diagnosis of pathogens. While conventional culture methods for detecting Salmonella are commonly used and considered the ""gold standard,"" they are also slow, demanding, and not highly sensitive. To address these challenges, various methods have been developed to detect Salmonella in food - such as immunoassays and nucleic acid-based approaches. Immunomagnetic separation (IMS) and polymerase chain reaction (PCR) have been selected as promising methods to increase sensitivity and reduce detection time.",0
51,3," PCR techniques have been described as rapid alternatives to culture for detecting Salmonella in food and allow highly sensitive detection in just a few hours. PCR methods targeting Salmonella virulence genes like fimA, invA, and hilA have been developed. Multiplex PCR (mPCR) targeting two or more genes has also been widely used to increase specificity in Salmonella detection. Studies by Glynn et al. (2006), Moganedi et al. (2007), Moreira et al. (2008), Rahn et al. (1992), Upadhyay et al. (2010), Guo et al. (2000), Fach et al. (2009), Kim et al. (2006), and Woods et al. (2008) support these findings.",0
51,4," IMS uses anti-Salmonella polystyrene beads to capture and concentrate specific bacteria from food samples, enhancing the precision and accuracy of detection. Additionally, culture, ELISA, or molecular techniques can be employed to identify isolated cells (Cudjoe et al., 1995; Hagren et al., 2008; Jordan et al., 2004; Lynch et al., 2004).",0
51,5," 

Different methods have individual characteristics and applications. However, there has been limited research on comparing the effectiveness of different Salmonella detection methods on various types of food. While some methods have shown success, a quick and simple procedure is still necessary to improve sensitivity and efficiency, especially when analyzing large numbers of food samples. Thus, the objective of this study is to assess and compare three methods, conventional direct culture, IMS/culture, and mPCR analysis, for the identification of Salmonella in food samples.",0
51,6," In total, 700 food samples were analyzed in China after being bought from retail markets. These samples included chicken (104), pork (117), duck (41), beef (17), mutton (15), fish (109), shrimp (29), milk (36), vegetables (84), mushroom (70), and ready-to-eat food (78). All these samples were delivered to the laboratory in a chilled container and stored at 4°C before being examined within 24 hours of purchase.",0
51,7," Samples were prepared according to the Chinese National Food Safety Standards (document GB 4789.4-2010) by enriching a 25 g sample in 225 mL of buffered peptone broth (Huankai, Guangzhou, China). One mL of the cultures was then incubated in 10 mL of selenite cystine broth (SC) (Huankai) at 37°C and 10 mL of tetrathionate brilliant green broth (TTB) at 42°C for 24 h. Loopfuls of SC and TTB cultures were streaked onto xylose-lysine-tergitol 4 (XLT4) selective agar plates (Difco, Detroit, MI, USA) and incubated at 37°C for 24 h.",0
51,8,"

Table 1 outlines the results of the food samples collected. Out of the 700 samples, 110 were positive for Salmonella. Three different testing methods were used and yielded varying numbers of positive samples. Direct culture detected 83 positive samples, IMS/culture detected 95, and mPCR detected 104. Overall, 122 strains of Salmonella were isolated from 103 culture-positive samples. Of these, 115 were from IMS/culture and 104 were from direct culture. The isolated strains represented 9 serogroups and 32 serotypes, all of which were detected through IMS/culture, as shown in Table 2.",0
51,9," 

After performing selective enrichment, both SC broths and TTB broths were subjected to IMS simultaneously. To do this, 1 mL aliquots of each broth were added to an Eppendorf tube together with 5 μL of immunomagnetic beads (prepared at a concentration of 10 mg/mL). The tubes were then incubated at room temperature for 10 minutes with slight agitation. Following this, 50 μL of a solution containing 1% Tween-20 in PBS was added to the tubes and mixed well, before separating with Dynal MPC-S. The beads were washed twice with PBST and resuspended in 100 μL of PBST, before being transferred onto XLT4 plates for incubation at 37°C for 24 hours.",0
51,10," The data from Table 1 shows that out of 700 food samples tested, 110 showed positive results for Salmonella. The methods used to detect the positive results were direct culture, IMS/culture, and mPCR, with IMS/culture detecting the highest number of positive samples. Strains of Salmonella were isolated from 103 of the culture-positive samples, with a total of 122 strains isolated. The isolated strains were found to belong to 9 serogroups and 32 different serotypes, which were all detected by IMS/culture. Table 2 further elaborates on the distribution of isolated serotypes.",0
51,11," In a sample size of 103 positive cultures, 20 were detected only by IMS/culture and not by direct culture, and out of those 20, 18 were also identified through mPCR. The reason for the two samples that tested negative with mPCR could be the low number of Salmonella colonies present on the XLT4 agar plates. IMS/culture was found to be more effective in detecting a smaller number of food-borne pathogens than direct culture. These findings are significant for identifying cases where only a few Salmonella organisms are present in a sample and might be missed by direct culture.",0
51,12,"

The samples that tested negative with mPCR had positive results with SC broth but not with TTB broth through direct culture. The positive isolates were all identified as S. Enteritidis. SC broth is less selective than TTB broth and is suitable for low Salmonella samples. The negative mPCR results suggest the presence of low-level Salmonella in broths. This finding highlights that the IMS/culture method may yield false-negative outcomes for detecting S. Enteritidis at a low level.",0
51,13," The eight false-negative results of IMS/culture could be due to matrix effects that affected the IMS process, causing immunomagnetic beads to be lost due to extremely high fat contents in the meat, according to Skjerve and Olsvik (1991). Additionally, heavy growths of other Enterobacteriaceae organisms on the culture plates from the eight samples could have interfered with the growth of isolated Salmonella colonies. Non-specific adherence to the beads of organisms other than Salmonella is a known issue when using IMS, especially with samples containing mucoid colonies of Proteus spp. and coliforms such as Escherichia coli, Klebsiella aerogenes, and Enterobacter spp., as reported by Cudjoe and Krona (1997).",0
51,14," The detection rate of mPCR was high, identifying 97 of the 103 culture-positive samples. For the six samples not detected by mPCR, four were S. Enteritidis, one was S. Heidelberg, and one was S. Typhimurium, all of which were positive in the Salmonella test after mPCR analysis. Additionally, seven other Salmonella-positive results were detected only by mPCR, and the presence of the target gene was confirmed by DNA sequencing. The mPCR method showed higher sensitivity and faster results than traditional culture methods, making early intervention and preventive measures possible. However, positive results generated by mPCR require further confirmation by culture. This method could be useful as a screening or evaluation tool for virulence genes.",0
51,15," According to the study, mPCR is both faster and more sensitive than direct culture and IMS/culture methods. While IMS/culture is more effective than direct culture for Salmonella isolation, it also allows for viable organism isolation, making it valuable for future epidemiological research. For the screening of large amounts of food samples, a combination of mPCR and IMS/culture is recommended for easy, rapid, and efficient results.",0
52,1," Firms need to constantly innovate to competitive advantage and this requires a high level of absorptive capacity (ACAP) - the ability to absorb and apply external knowledge. A study using data from 592 CEOs and managers from six countries reveals how corporate culture affects potential and realized ACAP, and how national culture dimensions moderate these relationships. The adhocracy culture supports ACAP, while market and hierarchy cultures hinder it. Additionally, some national and corporate cultures are more effective in fostering realized ACAP than others. These findings could guide researchers and firms in improving their knowledge management processes.",0
52,2," With higher innovation speed, increased competition, and radical technological changes, innovation is becoming more critical for the success of companies. Therefore, firms must continually acquire and process new information and exploit this knowledge in the innovation process to remain competitive. To achieve this, they need to ensure that knowledge management processes are adequately supported and fostered within their organizations.",0
52,3," Absorptive capacity (ACAP) refers to a firm's ability to obtain, analyze, and apply external knowledge, and it plays a critical role in knowledge management. ACAP has been extensively explored in management research, particularly in terms of its positive impact on innovation processes. Researchers have shown that ACAP promotes innovation, interorganizational knowledge transfer, and overall performance across national borders. Although there have been studies on ACAP as a dependent variable, they have been limited and mostly focused on knowledge-based antecedents. Interestingly, intraorganizational antecedents, including corporate culture, have been largely ignored in previous research, despite the fact that corporate culture significantly impacts individual behavior in organizations.",0
52,4,"

When investigating how corporate culture affects ACAP, it is important not to overlook the broader cultural impact of national culture on people's thoughts, emotions, and behaviors (Kluckhohn, 1951). Studies have confirmed that national culture can influence the effectiveness of organizational value systems (Hofstede, 1985), which raises the question of how corporate and national cultures interact to affect ACAP. Thus, the present study must include national culture dimensions, in line with research calling for cross-cultural studies on ACAP (Flatten, Greve et al., 2011). As a result, the present study is comparative in nature, focusing on a comparison of national cultural contexts of domestic companies.",0
52,5," 
The research holds weight in terms of management as it identifies the kind of corporate culture that companies should promote to facilitate knowledge management in their entities. Furthermore, it recognizes the difficulties that companies face with rising multiculturalism (Schoemaker, 2008) by clarifying how national culture impacts their efforts to explore and exploit knowledge.",0
52,6," Absorptive capacity refers to a company's ability to recognize, assimilate, and effectively use new external information for commercial purposes. This term is closely related to several areas of research, including innovation, learning, and dynamic capabilities. Overall, ACAP can be viewed as an important dynamic capability that plays a critical role in knowledge creation and utilization.",0
52,7,"

ACAP has garnered much attention since its creation two decades ago and has been subjected to various reviews and expansions. The reconceptualization of ACAP as a four-step process by Zahra and George (2002) has been supported by multiple empirical studies. The first step involves the identification of relevant knowledge, while the second step entails the analysis and interpretation of the acquired information. The third step, transformation, integrates the new knowledge with existing processes, and the final step, exploitation, pertains to the commercial utilization of the information.",0
52,8,"

Research indicates that while each dimension of ACAP has individual importance for firms, a parallel implementation of both dimensions produces even greater benefits. This is because pieces of knowledge migrate between the assimilation and transformation stages before they can be exploited. However, the dimensions cannot be considered mutually independent, as each has particular shortcomings that can only be overcome by the complementary use of all process dimensions. For example, if a firm focuses solely on realized ACAP, it may achieve short-term profits but won't develop a new and innovative knowledge base necessary for recognizing strategically important opportunities and securing a first-mover advantage in the market.",0
52,9," Firms need to encourage and promote the values and behaviors that support all aspects of ACAP. For this purpose, corporate culture can be used as a tool to foster ACAP. Cultural values play a crucial role in knowledge management processes and innovation. However, previous studies have been insufficient in assessing the role of corporate culture in managing ACAP, due to the utilization of simplified constructs or a narrow focus on a single industry. Therefore, further research is required to understand the relationship between corporate culture and ACAP.",0
52,10,"
A clan culture places an emphasis on consensus and values personal relationships, loyalty, and tradition. Cohesiveness, participation, teamwork, and a sense of family are dominant attributes of this culture. A mentor or facilitator is the typical leadership style, whose strategic goal is to develop human resources and achieve high employee commitment. 

An adhocracy culture is focused on an entrepreneurial spirit, creativity, and adaptability. The typical leadership style calls for an entrepreneurial innovator and risk taker with strategic emphasis on innovations, growth, and the acquisition of new resources. Entrepreneurship, flexibility, and risk-taking are key organizational bonding mechanisms. 

A market culture is characterized by an orientation toward market superiority and clear goal orientation. Competitiveness and goal achievement are characteristic attributes of this corporate culture.",0
52,11," The four types of corporate culture, as described by Deshpandé et al. (1993), are not completely separate from one another, as organizations typically exhibit a dominant culture while also displaying characteristics of the other types. Employees within an organization tend to adopt the values of the dominant culture over time, affecting their behavior accordingly (Cameron & Quinn, 2006). Previous research has demonstrated that corporate culture is linked to innovation strategies and that this relationship varies depending on national culture settings (Engelen, Flatten, Thalmann, & Brettel, 2014). Therefore, Deshpandé et al.'s (1993) concept provides a useful framework for addressing the research questions of this study.",0
52,12,"

A cultural concept at an all-encompassing level can have a greater impact than corporate culture. Corporate culture is a collection of shared values and norms within an organization (Deshpandé & Webster Jr., 1989); in comparison, national culture comprises the ""organized modes of thought, feeling and reaction [ . . . ] and particularly their attached values"" (Kluckhohn, 1951, 86) among members of a particular culture. Both corporate and national cultures are acquired from other members of the culture over time (Hofstede & Bond, 1988). Whereas corporate culture centers on ""the way things get done"" in a company (Deal & Kennedy, 1982, 4), national culture represents the general behavioral patterns of people within a culture, whether in professional, social, or private settings. Consequently, firms can shape their corporate culture, while national culture must be viewed as an unalterable aspect (Hofstede, 1994).",0
52,13,"

In the current study, we utilized Hofstede's (1980) cultural dimensions to capture national culture. Specifically, we incorporated the Hofstede scores for power distance, individualism, and uncertainty avoidance in each of the six countries in our sample. Power distance refers to the acceptance of unequal power distribution within institutions and organizations, while individualism looks at whether individuals prioritize their own needs over the group's interests. Lastly, uncertainty avoidance measures a society's aversion to uncertain and ambiguous situations. These dimensions were chosen as they are crucial in the innovation research field and impact factors related to innovation, such as the nature of innovations. (Shane, Venkataraman, & MacMillan, 1995).",0
52,14," Based on the high variation among the selected nations in power distance, individualism, and uncertainty avoidance, we excluded the dimensions of masculinity, long-term orientation, and indulgence from our analysis. We also considered the criticism surrounding the specificity of masculinity. Therefore, we believe that focusing on the three dimensions mentioned above is reasonable while balancing the need for a parsimonious research model with the need to cover the most relevant cultural dimensions. Our analysis revolves around the interplay of corporate culture, ACAP, and national culture, as depicted in Fig. 2.",0
52,15," We base our research model on the idea of strategic fit. For a long time, the concept of fit or congruence has played a crucial role in organizational behavior (Nadler & Tushman, 1980). Researchers have explored how fit applies to different internal and external factors, such as innovation strategy, organizational structure, technology, and management style, and how it impacts organizational effectiveness, efficiency, and viability (Burton, Lauridsen, & Obel, 2002). The strategic fit perspective is relevant to our study because organizations must adapt to their environment to survive (Aldrich, 1979), and it has been studied in terms of organizational culture (O'Reilly et al., 1991).",0
52,16," To formulate hypotheses regarding the direct influence of corporate culture, we rely on Deshpandé et al.'s (1993) organizational culture types model illustrated in Fig. 1. This model merges two principal areas of study, namely, the systems-structural outlook (Van de Ven, 1976) and the transaction cost outlook (Williamson, 1975, 1981), to describe each of the four corporate culture types included in our research model on four dimensions: dominant organizational attributes, leadership styles, organizational bonding mechanisms, and overall strategic emphases. We implement these four dimensions to build our hypotheses for (1) the possible effects on ACAP before (2) establishing our hypotheses for the realized ACAP effects.",0
52,17,"

Regarding clan culture, cohesive, participative, teamwork-oriented, and family-like attributes foster extensive and free knowledge sharing among members and departments, which is crucial for knowledge assimilation. A clan culture's leadership style is characterized by a mentor or facilitator who encourages creativity and innovation by clearly stating their visions. Facilitative leaders create a nurturing environment that allows members to take risks and explore new opportunities, creating a fruitful environment for gathering knowledge that requires openness to identify external knowledge from various sources and the ability to solve complex problems.",0
52,18,"

In terms of market culture, the key characteristics are competitiveness and achieving objectives (Deshpande et al., 1993). To stay ahead of the game, businesses need to constantly update their knowledge base through knowledge acquisition and assimilation (Flatten, Engelen et al., 2011). However, this culture heavily prioritizes achieving objectives, which could impede a company's potential for ACAP for a number of reasons. Firstly, it's difficult to quantify the exploratory nature of knowledge acquisition and assimilation as measurable objectives. Instead, openness to a range of formal and informal activities (Auster & Choo, 1993) and constant knowledge sharing (Cohen & Levinthal, 1990) are crucial for potential ACAP. As such, it's questionable if this corporate culture is well-suited to promoting knowledge acquisition and assimilation. Secondly, the typical leadership style in a market culture is highly decisive and goal-focused (Deshpandé et al., 1993), which can lead to slower innovation exploitation times. On the other hand, exploratory knowledge acquisition requires an open mind and flexible procedures (Auster & Choo, 1993).",0
52,19," In hierarchy culture, the dominant attributes are order, rules, and regulations, focusing on mechanistic processes for high efficiency. These organizations operate through formalized and structured procedures governed by rules and policies, hindering the development of new intellectual approaches. This negatively affects the potential ACAP. The dominant leadership style involves a strong coordinator and administrator, but the strictly implemented hierarchical structures make it difficult for subordinates to present novel ideas, impeding the acquisition and assimilation of knowledge. The focus on formalization and orders in organizational bonding also limits a company's flexibility.",0
52,20,"

Regarding the achievement of ACAP, we maintain that the predominant characteristics of a clan culture have a positive impact. Firstly, ACAP requires creativity (Kotler & Armstrong, 1991), the ability to turn knowledge into products, processes, and systems (Lawson & Samson, 2001), and the capability to commercialize (Liu, 2006). The attribute of participation ensures the commitment of members of the organization (Deshpandé et al., 1993), and because of the high degree of teamwork, knowledge can be effectively utilized in the pursuit of opportunity exploitation (Zahra & George, 2002). Secondly, a company with a clan culture is mainly crafted by its strong leaders who act as mentors and facilitators (Deshpandé et al., 1993). Such leaders are usually role models for their employees and can themselves exhibit how essential the transformation and utilization of knowledge are for the company. If effectively demonstrated by the company's top management, subordinates will adopt their actions, values, and beliefs (Hambrick & Mason, 1984). Consequently, employees in such a culture will make significant efforts to realize ACAP. Finally, a clan culture is bonded through values like loyalty, tradition, and interpersonal coherence (Deshpandé et al., 1993).",0
52,21," According to Deshpandé et al. (1993), an adhocracy culture is characterized by entrepreneurship and creativity, making it ideal for combining new knowledge with existing organizational knowledge in the transformation phase of realized ACAP (Zahra & George, 2002). In addition, leaders in adhocracy cultures are typically entrepreneurial innovators and risk-takers who encourage members to act independently, facilitating effective implementation of opportunities at all hierarchical levels (Shane, 1994). Lastly, organizational bonding mechanisms in adhocracy cultures are based on an entrepreneurial mindset as well as flexibility and creativity, leading to a risk-taking attitude among members of the organization. Hiring entrepreneurial leaders further promotes this attitude, leading to quick updates to organizational processes, commercializing new knowledge, and establishing new competencies; all of which are vital elements of realized ACAP (Brettel et al., 2011).",0
52,22,"

Market culture is distinguished by competitiveness, goal achievement, external focus, and mechanistic processes. This orientation may facilitate the integration of acquired knowledge into organizational processes, thereby supporting the transformational and exploitative components of realized ACAP. The leadership style associated with this culture is decisive and achievement-oriented, which can accelerate decision-making and enhance the efficiency of innovation exploitation. Goal and production orientation are bonding mechanisms that promote adherence to schedules and enable prompt exploitation of opportunities, while also fostering technological and process innovations. By emphasizing competitive advantage and market superiority, firms are motivated to effectively adopt new technologies or processes based on effective commercialization capabilities.",0
52,23," It is necessary to assess the moderating influence of power distance on the relationship between corporate culture and potential as well as realized ACAP, using Venkatraman's (1989) framework for fit-as-moderation. This emphasizes the importance of internal factors, such as corporate culture, fitting with external contingencies like national culture in order to achieve a positive outcome in terms of potential and realized ACAP.",0
52,24," An organizational culture that encourages innovation among workers and fosters individual autonomy is known as an adhocracy culture. However, this type of culture cannot be maintained in high power distance countries where there is a focus on inequality among employees and strong dependency on leaders. This results in a misfit between the external and internal conditions, causing a weaker relationship between adhocracy culture and potential ACAP (Absorptive Capacity). This is because the adhocracy culture cannot motivate employees to generate new knowledge creatively or innovatively. The same is true for the relationship between adhocracy culture and realized ACAP. (Based on Cameron & Quinn, 2006; Hofstede, 1980; Demir et al., 2011)",0
52,25," In a market culture, leaders are known for their decisive leadership style and are categorized as ""hard-drivers"". However, subordinates should only follow this style if they accept a high power distance culture. In a market culture, competition is highly valued, which can lead to lower levels of trust and cooperation among employees. This lack of trust can negatively impact potential ACAP, which relies on communication and trust, but may not have as great of an impact on realized ACAP.",0
52,26,"
An organization adopting a hierarchy culture tends to be highly formalized and depends on rules and policies. To follow these regulations, employees must recognize the privileged role of their superiors and accept the unequal power distribution. Such organizations are often found in high power distance cultures, where leaders act as coordinators or administrators, displaying their superiority over employees. This behavior is generally accepted in such cultures. However, this combination of internal and external conditions might impede organizations from transforming and exploiting assimilated knowledge. Hence, we can expect a stronger negative effect of hierarchy culture on realized ACAP in a cultural setting characterized by high power distance.",0
52,27," The focus in an adhocracy culture is on differentiation and competition, with an emphasis on individual achievement rather than group cohesion. This type of culture is more common in individualistic national cultures where flexibility is valued, as members are often more autonomous and less emotionally dependent. Adhocracy culture may support creative and explorative thinking, making it the appropriate culture for individuals to pursue their personal projects in terms of both new knowledge acquisition and assimilation, and knowledge exploitation. We expect high levels of individualism to intensify the positive relationships between adhocracy culture and both potential and realized ACAP.",0
52,28," A focus on differentiation characterizes a market culture, which involves pursuing competitiveness rather than promoting harmony or integration. Internal competition is favored in such organizations, appealing to individualistic national cultures that emphasize the individual over the group. The market mechanisms that govern transactions within a market culture align with individualistic national cultures that prioritize the involvement of individuals with organizations as a calculative process. Based on this, we predict that high levels of individualism in a culture will strengthen the expected negative association between a market culture and potential ACAP, while also amplifying the anticipated positive link with realized ACAP.",0
52,29," Hierarchy culture, also known as bureaucratic culture, is characterized by strict adherence to rules and regulations. This culture may align with collectivist national cultures that value order and security. Hierarchy culture strives for stability and predictability, which is desirable in collectivist cultures that seek stable relationships. However, the combination of hierarchy culture and high levels of individualism may lead to a misfit, resulting in the expected negative relationship between hierarchy culture and potential and realized ACAP. Therefore, we anticipate that high levels of individualism will intensify the hypothesized negative relationships between hierarchy culture and both potential and realized ACAP.",0
52,30," We evaluate how uncertainty avoidance moderates the correlation between corporate culture and ACAP. People from countries with high uncertainty avoidance feel uneasy in uncertain circumstances, prompting them to steer clear of such occasions (Hofstede, 1984).",0
52,31," Clan culture values interpersonal cohesion, integration, and morale (Cameron & Freeman, 1991). It has been referred to as ""consensual culture"" due to its emphasis on consensus and avoidance of disagreements (Deshpande & Farley, 2004, 5), which aligns with national cultures high in uncertainty avoidance (Hofstede, 1980). Clan culture's focus on tradition (Deshpande et al., 1993) also corresponds to high uncertainty avoidance cultures that resist change (Hofstede, 1983). High uncertainty avoidance cultures are also characterized by emotional expression (Hofstede, 1983), which supports the sharing and caring nature of clan culture (Cameron & Freeman, 1991). These factors suggest that high uncertainty avoidance cultures facilitate potential ACAP by fostering knowledge sharing (Flatten, Engelen et al., 2011). Therefore, the relationship between clan culture and potential or realized ACAP is likely strengthened in high uncertainty avoidance contexts.",0
52,32," In adhocracy cultures, leaders are viewed as entrepreneurs and innovators who embrace uncertainty as an opportunity to exploit. They are associated with low uncertainty avoidance countries where taking risks is common. However, high uncertainty avoidance and adhocracy cultures are not compatible as employees in a high uncertainty avoidance culture tend to avoid acquiring new knowledge and prefer relying on existing products or processes. Consequently, the relationship between adhocracy culture and potential and realized ACAP is weakened in a high uncertainty avoidance culture.",0
52,33," In market culture, competitiveness is encouraged through determined leadership, as opposed to high uncertainty avoidance national cultures that prioritize consensus and avoiding competition. Market culture is production-oriented and lacks personal involvement, which fits better with low uncertainty avoidance national cultures. However, when uncertainty avoidance is high, the misfit between internal and external conditions weakens the relationship between market culture and potential and realized ACAP. This can impact communication, trust dimensions, and the implementation of newly gathered knowledge, which are essential for developing potential ACAP and realizing ACAP.",0
52,34," A hierarchy culture relies heavily on formal guidelines, rules, and procedures, and this is particularly appealing to high uncertainty avoidance countries whose members prefer clear policies and regulations. Additionally, a hierarchy culture's emphasis on uniformity aligns with the values of high uncertainty national cultures whose members perceive diverging views and people as threats. Given this compatibility, it can be theorized that high levels of uncertainty avoidance reinforce the already negative association between hierarchy culture and potential ACAP since it suppresses creative, controversial, and open-minded thinking, making it challenging to acquire and assimilate new knowledge. Furthermore, this link also strengthens the already negative relationship between hierarchy culture and realized ACAP since uncertainty avoidance further exacerbates the negative effect stemming from the strong emphasis on formalization, impairing an organization's ability to adapt processes flexibly.",0
52,35," The natural logarithm of firm age and firm size, which respectively indicate the years since foundation and number of employees, were included in the model (Danneels, 2008; Engelen & Brettel, 2011). Moreover, we controlled for 15 primary sectors where the firms operate as well as the Human Development Index and logarithm of gross domestic product per capita as country-specific effects (Flatten et al., 2015). To account for industry-specific effects within each country, we also added a measure on technological dynamism based on respondents' ratings of constant change in product technology in their industry (adapted from Homburg, Jensen, & Krohmer, 2008).",0
53,1," ""A novel technique called adaptive culture structuration is introduced in this paper to explain and evaluate cultural shifts, as well as to construct an adaptable cultural structure learning environment.""",0
53,2," The study delves into the experiences of 12 financial sector employees who underwent a culture change initiative through a case study. The research used qualitative methodology following grounded theory principles with a constructivist and interpretive approach. Secondary data from organizational documentation was used in addition to semi-structured interview data, which was analyzed through content analysis, constant comparison, and theoretical sensitivity with the assistance of ATLAS.ti software.",0
53,3," Respondents displayed a dedication to investing their time and effort into embracing the culture change initiative and its associated principles. Additionally, employees' analytical assessment of the embedded value promises included experiencing a significant event that disrupted the manager's demonstration of the values. Consequently, the ""received practice"" of the workers demonstrated the implemented values rather than the proposed ones, which managers could not observe.",0
53,4," An adaptable learning environment cultivated with cultural values promotes a collaborative practice between managers and employees, rather than a hierarchical practice. This approach enables employees to express their interpretations and assessments, which are often concealed from managers, and helps to facilitate shared understanding and resolve issues related to psychological contracts at the workplace.",0
53,5," In the era of economic instability and societal transformation, the concept of global competitiveness becomes crucial (Rugman et al., 2012). With the existing uncertainty in the present-day changes, businesses must leverage as many human resources as possible to enhance their competitiveness, as pointed out by Albert et al. (2000, p. 13). It implies that the conventional approaches of structural and institutional organization are no longer dependable, and more focus should be given to the motivation and commitment of the members.",0
53,6," 

The concept of adaptive culture structuration views employees' experiences during a culture change, emphasizing the importance of this initiative in a way that aligns with Giddens' (1984) structuration theory. In our case study, employees' ability to reconstitute their activities became particularly apparent when a new and unanticipated change occurred during an existing culture change program.",0
53,7," Based on our research, the way employees perceived a current organizational culture change program is revealed by their accounts. It appears that employees evaluated cultural speeches made by managers based on whether or not the expressed values were in harmony with the managers' actions. As a result, whether managers practiced what they preached in their behaviors was a crucial factor for employees. Moreover, employees conducted epistemic analyses of cultural discourses as their ""received practice.""",0
53,8," Organizations may use corporate culture as a hidden control method, preventing employees' ability to utilize their knowledge. Similarly, employees' interpretations and evaluations may be hidden from managers, inhibiting workplace learning opportunities. To address this issue and meet employees' need for validation, a new theoretical approach called ""adaptive culture structuration"" is proposed, drawing on Giddens, Poole, McPhee, and DeSanctis.",0
53,9," The ability of employees to take initiative and act independently is acknowledged in various studies (Billett and Pavlova, 2005; Campbell, 2009), which facilitates a setting where managers and employees can collaborate to give meaning to their work (Billett, 2001, 2008; Gergen, 1994), altering the activity of ""received practice"" into a ""negotiated"" one.",0
53,10," The paper's structure revolves around the sequence of events in the case study depicted in Figure 1, starting from the cultural change initiative and its accompanying persuasive dialogues to the supposed implicit assurances of the received psychological contract. During this time, workers were actively engaged in identity work to demonstrate their commitment to the organization, with some even exhibiting deep structural identification. However, managers seemed disconnected from the impact of their actions on employees, leading to mistrust and negative consequences. In this context, the study follows the culture program's progress, considering unexpected changes, epistemic activities of employees, and creating adaptive culture through negotiated practices, as shown in Figure 2.",0
53,11," In order to contemplate a negotiated practice environment, we must take into account three pertinent concepts from the literature, including corporate culture, psychological contract, and identity. Afterwards, we will conclude with a fourth theme, which is a novel concept of adaptive culture structuration.",0
53,12,"When individuals identify strongly with the culture and identity of an organization, it is assumed that their connection is lasting like that of a community. Yet, organizations that are susceptible to external and internal shifts may lose the enthusiasm and dedication of workers who previously aligned with its values and principles, leading to disengagement. Therefore, we suggest that values shared by all members of an organization serve as profound commitments and psychological agreements.",0
53,13," Dick and Nadin (2011, p. 294) suggest that the concept of the psychological contract, which embodies managerial understandings of the employment relationship, significantly shapes workplace identities. They argue that managers view themselves as legitimate power holders and believe that they will succeed if they manage properly and their employees respond in a certain way. However, this perspective fails to consider the active role and power of employees, who may have their own interpretations of what it means to be effectively managed.",0
53,14," According to Hamel (2009), employees' intentions and strategies are affected by the impact of psychological contract violation, which is supported by Dulac et al. (2008) and Turnley and Feldman (1999). However, a review of the literature indicates that organizational shared values have not been thoroughly investigated as deep promises and psychological contracts. Richard et al. (2009) conducted one of the few studies that linked psychological contract and organizational culture, and identified psychological contract as a mediator between organizational culture and employee commitment. They concluded that managers can leverage psychological contracts beneficially by comprehending how they are formed and maintained to avoid negative effects of violation.",0
53,15," Workplace identities are constructed through social and psychological interactions between employees and managers, who represent the organization. This construction is legitimized through institutional arrangements such as culture, which shapes employees' sense of belonging and identification with the organization. Rousseau proposes that this can take the form of a situated identity, focused on situational cues, tasks, and teams, or a deep structure organizational identity, created through exchange relationships and a shift in control from the individual to the firm. While this process may thrive in strong corporate cultures, some may view it as a further attempt to control employees' organizational identification. (Hatch and Schultz, 2004; Alvesson and Willmott, 2002; Rousseau, 1998)",0
53,16," In her work, Driver (2009, p.55) notes the ongoing discussion on organizational identity and proposes a less definable understanding of identity through psychoanalytic theory, adopting Lacanian viewpoints. Harding (2007, p.1763), also using Lacan as a reference, challenges the notion of self as an imagined object or void that is filled with recognition from others.",0
53,17," Organizational identities are created through stories and conversations that represent the long-lasting character of both the organization and its members. According to Dutton et al., employees react to the organization's image, which boosts their self-esteem and encourages them to be active members of the symbolic community. Tracy and Trethewey's crystal metaphor aligns with the intricate and diverse nature of individual identity.",0
53,18," Belonging to a symbolic order can pose difficulties when the order is disrupted, as stated by Brown (2006). Driver (2009) acknowledges that identity crises can be beneficial for personal growth, but notes that such disturbances are often viewed in a negative light, as an indication of failure rather than a chance to connect with one's core identity. Rousseau (1998, p. 231) also highlights the problematic nature of identification, cautioning that while it can enhance employee retention and adaptability, it may not be suitable for all employment relationships.",0
53,19," The way a company is managed influences its culture, whereas the psychological contract represents how employees perceive and invest in the organization. As employees structure formal rules and resources, these perspectives work together in a flexible manner. This co-production of meaning is possible through negotiation among employees.",0
53,20," Giddens' structuration theory, as described by Poole and McPhee, presents an alternative understanding of negotiated practice by bringing together members' perspectives. This inter-subjective construct is defined by Giddens as having a duality in structuration that governs the continuity or transformation of structures and systems through the application of rules and resources.",0
53,21," 

Structuration is presented as an organizational theory by Poole and McPhee (1983) and Poole et al. (1985), who argue that formal structures and agents influence each other in a mutually constitutive way. Bastien et al. (1995) similarly support the idea that individuals are not simply free or solely controlled by social structural forces in organizational climate. They use structuration theory to identify ""kernels"" of structure and agency duality. Whittington (1992) contributes to this discussion by theorizing manager agency, suggesting that managers adopt an agency role through their own ideologies. In Festing and Maletzky's (2011) study on cross-cultural leadership adjustment as a reciprocal process, they also employ structuration theory. Finally, Leydesdorff's (2010) analysis emphasizes communication and expectations, highlighting how organizations engage in structured structures and structuring structures as mutually reconstructive.",0
53,22," According to DeSanctis and Poole (1994, p. 12), adaptive structuration theory (AST) expands structuration theory to include technological application. Their comment emphasizes that technology is not the sole determinant of behavior; instead, people generate their own interpretations of technology using embedded resources, interpretive schemes, and norms. This relationship between formal institutional structures and human interaction enables constitutive adaptation, a recurring theme in literature on structuration (Festing and Maletzky, 2011). Witmer (1997) links structuration theory to organizational culture, arguing that the theory provides a fuller understanding of organizational phenomena. This study builds on that thinking by introducing adaptive culture structuration.",0
53,23,"

Adaptive culture structuration (ACS) refers to the interaction between values expressed by managers, the analysis of employees, and the engagement of managers in a negotiated process. Unlike DeSanctis and Poole's (1994) AST, ACS recognizes the dynamic relationship between managers and employees as holders of power. The assumption of ACS is that both parties are free to express their interpretations and assess each other's perspectives. It is also assumed that the organizational environment facilitates learning from and with each other, achieved through a ""negotiated space"" in the form of an ACS environment. Additionally, managers must address changes in values to maintain generative ""values-promises.""",0
53,24," We carried out research in an 800-member segment of a prominent financial organization that had been recently acquired by a significantly larger financial entity. During the implementation of a fresh culture transformation initiative, senior managers and the human resources department led a minor exploratory inquiry.",0
53,25," Managers initiated discourses and utilized both formal and informal communication methods to persuade individuals. Activities emphasizing values occurred frequently, during which required values-based practices were transmitted. Values were further discussed and practiced in team meetings and interactive workshops. A three-day live-in retreat, focused on vital values, was expected for all employees to attend within the calendar year.",0
53,26," The researchers aimed to qualitatively explore how employees interpreted and attributed meaning to the values the organization espoused and how they perceived cultural change. It was unexpected that the data revealed employees' beliefs about values being deeply shared promises and organizations representing structures for identification, alongside their ability to assess and judge the validity of the messages received from managers. These issues were highlighted by negative experiences that some participants faced. Their reported evaluations revealed these issues.",0
53,27," During our exploratory investigation, we conducted interviews with twelve employees who were experiencing a culture change initiative led by management. We were open to unexpected findings, and our research questions aimed to uncover how personal and work values intersect with organizational values. We also used organizational documentation to support our interview data.",0
53,28," The study incorporated employees' personal experiences with the culture initiative as described by Fenton and Langley (2011) during the design stage. A semi-structured interview approach was used to allow participants to express their subjective understandings of events and experiences. The interpretive epistemology gave priority to participants' stories and interpretations, and the researcher-participant relationship was established through interactive and one-on-one conversations.",0
53,29," The research design comprised of six stages which were a literature review, preliminary fieldwork, data collection, data analysis, and management, results, further literature review with a focus on structuration theory(Giddens,1976,1984), and discussions. The rationality and course of action taken for data collection, analysis, management, and the audit trail element of rigor have been highlighted in Table II.",0
53,30," The process of developing themes started with selecting the unit of analysis, which was a respondent's statement related to the cultural project. Next, a decision was made on whether to begin with open coding or invivo coding, and invivo coding was chosen with the use of authentic responses as labels wherever possible. The constant comparative method was then used to identify incidents or comments and assign them to meaningful categories, each containing codes that were related to each other, including subcategories such as positive or negative cases, and those linked to other categories. (Refer to Figure 3 for more information.)",0
53,31," During the initial stage, categories were established with a wide range of meanings to ensure varying degrees of classification. As the examination progressed, categories were evaluated in connection with larger themes, which is consistent with Cortazzi's (1994, p.160) methodology of studying cultural attitudes towards a particular subject through a group's collective stories.",0
53,32," ""Literature was utilized to enhance theoretical sensitivity while exploring the chosen theme. This involved expanding existing corporate culture and identity literature to include more critical and Lacanian theories. The concept of psychological contracts was incorporated as unmet expectations arose, particularly with regards to organizational identity structures. Additionally, the literature on agency was used to develop ideas around employees' active and creative reconstitution of cultural messages and promises.""",0
53,33," At the beginning, the participants were in agreement with the declared values that were being implemented (none of them had anything negative to say about them). They believed that these values were in line with their own and they were eager to share stories about how their personal goals and productivity had improved.",0
53,34," It is crucial for an organization's change process to have clear and transparent interpretations, that can be openly discussed by all members. Organizations must find ways to facilitate such discussions and incorporate them into the workplace learning opportunities for both employees and managers. The focus should be on the practicality of negotiated practices, rather than just relying on traditional received practices. This will ultimately determine the success and longevity of the change process.",0
53,35," The second aspect of the discussion centers on the concept of an ""epistemic lens"" that employees use to perceive and evaluate the credibility of formal organizational structures as manifested in actions. The third aspect proposes strategies for building a flexible and structured learning environment where managers and employees can collaborate, share their perceptions and evaluations, and tackle challenges and hindrances that could impede the fulfillment of commitments.",0
53,36, The corporate culture cycle in this study stands out because the management change initiative and cultural conversation emphasized the shared values that were expected and promoted. Figure 6 demonstrates how the employees interpreted and approved the validity of the message conveyed by the management in the corporate culture change effort.,0
54,1, I examine Raymond Williams's analysis of the idea of culture and its origins from a contemporary perspective. I contend that a contextual approach is required to understand the evolution of the concept and how it has been utilized in various historical periods.,0
54,2," Writing about ""culture"" as a ""keyword"" is both ironic and iconic, as it was the starting point for the genre. Raymond Williams famously called it ""one of the two or three most complicated words in the English language,"" and later admitted to regretting ever hearing it. However, he continually returned to it in his work. This could be seen as a call to more rigorous conceptual work, or an acknowledgment that the ambiguities of the term serve to naturalize contingent articulations. Étienne Balibar has recently described culture as ""the most confusing of all.""",0
54,3," Culture becomes a relevant concept when it represents tangible issues and conflicts. In order to comprehend its meaning, we should analyze its particular shape and substance in a given moment, and evaluate its functions and positioning within society. We should also consider the extent to which culture operates independently or is integrated into the broader social fabric.",0
54,4," Williams recounts a tale set during the emergence of a self-aware European modernity in the late 18th and early 19th century. However, he overlooks the moment of telling and its own decisive effects when retelling the story. Williams is constructing a history of culture because he is writing at a time when the category itself has once again begun to represent a set of historical issues. At the moment, his efforts were determined by the intersection of two historical sets of problems concerning culture. Williams tells the story of the rift between culture and society, but his own project, cultural studies, aims to break away from this tradition and reconstruct a social totality that has been disrupted, at least in part, by the discourses he unites.",0
54,5," Williams's account depicts the moment when the contrast between civilization and barbarism no longer suffices for the self-perception of an emerging Euromodernity. This differentiation, regardless of whether it is conceived in static or dynamic terms, was inadequate for a world that placed the human at its core - not only as the site of rationality but also as the creator of worlds. The standard of ""civilization"" was simultaneously too rigid, too shallow (focused solely on matters of decorum and civility), and too materialistic (focused purely on demonstrations of wealth and accomplishment). Instead, contemporary critics with diverse ethical, political, and aesthetic placements looked (somewhat paradoxically) to the domain where nature and human agency intersect - culture as the cultivation of organic growth - in order to establish more human-centered, compassionate, and ""interior"" standards of distinction, variation, and judgment. In so doing, modernity as culture established itself not only against both civilization and barbarism, but also against (pure) nature - as unattended and untamed - and against tradition.",0
54,6,"

Euromodernity has a constructionist ontology that involves cultural mediation as the third term, serving as the repository of contradictions in human reality. This means that culture defines human existence, encompassing all human activities but favoring a subset of them as the concrete existence of the universal. The definition and boundaries of this subset are constantly debated in terms of historical change. Culture provides a problematic answer to a normative question due to the contradiction between the universalism of mediation and the necessary relativism inherent in the concept of culture as the creation of a second reality. Therefore, culture is a search for a position and standard to describe and judge the recursive fabrication of the modern.",0
54,7,"
The specificity of culture is determined not only by the privileged activities within a geohistorical context, but also by the culture as a whole way of life. This defines both the existence of humans and the diversity among them. Mediation is the impossible logic of reconciling this contradiction, with culture as both the subject and object of mediation. It serves as the benchmark for evaluating social change, making culture the foundation for reconciling the universality of human culture and the specificity of various cultural identities.",0
54,8," Marx's role in the discussion of culture may seem insignificant in some ways, but it was actually quite important. He challenged the prevailing idealistic view of culture by emphasizing the practical processes through which people create their own history and make the things they need to survive. This emphasis on social constructionism displaced the earlier focus on cultural constructionism. Marx didn't deny that humans are intelligent and creative, and he acknowledged that language often plays a role in this process. However, he tended to downplay cultural elements and instead prioritized the primary role of economic and social structures in shaping society. Nonetheless, some scholars have pointed out that Marx did have some writings on art and aesthetics that suggest a more nuanced view of culture's place in society.",0
54,9,"
The concept of culture was simplified into the base and superstructure model, where economics represented the material dimensions and culture was reduced to mostly idealist understandings. This led to two consequences. Firstly, the recovery of the social totality's centrality in history, which was not strongly felt until the mid-twentieth century. Secondly, Marx's theory of ideology helped expand earlier arguments about the constitutive emergence of new forms of power in Euromodernity, which included the belief that force and coercion were being replaced by other forms of power such as ideological consent, consensus, bureaucracy, and discipline.",0
54,10," Following the Russian Revolution and the subsequent decline into Stalinism, the role of culture in Marxist theory underwent significant changes. While the successes of the Russian Revolution had to be acknowledged, it became clear that the rest of Europe was experiencing revolutionary failures and a culture of defeat. This led to the rise of Western Marxism, represented by thinkers such as Lukács, Adorno, Brecht, and Gramsci. They analyzed not only art but also language and ideology, as well as the culture of consumption and capitalist culture more generally. Through their analyses, they sought to explain why capitalism continued to win despite conditions that seemed ripe for revolutionary change, and why revolutions took the form of fascism. Perry Anderson coined the term ""Western Marxism"" to describe this approach.",0
54,11," Williams' work established the basis for the use of the culture category post World War II, which dealt with existing and new issues associated with it. As a result, culture became a central focus across various intellectual models. The narrative William presented discussed the problematics of culture in this context and its emergence 150 years ago. Denning suggested two new challenges as the Cold War's tripartite worldview was largely understood in cultural and ideological terms, while the culture industries expanded to become the most visible part of the consumer economy. Additionally, the diminishing sense of privilege and universality of working-class politics led to the disappearance of a taken-for-granted working-class culture.",0
54,12," The way in which culture is expected to play a crucial role in society has shifted notably since the 1970s. However, in the present day, we are grappling with a set of challenges that are still evolving and undefined, making it less straightforward to describe the current context. Despite this, culture maintains its relevance across different domains, whether it be in theory, practical application, or economic value.",0
54,13," Bennett (2005) has observed that the use of culture has increased tremendously in the contemporary context. Culture is not only used as a noun but also as an adjective to describe various aspects of social life, social activities, lifestyles, and sensuous pursuits. Culture is also used to describe forms of politics and the increasing dominance of culture as a source of power. The use of culture has become as important in political terms as economic and ideological struggles. Some critics have even talked about the ""culturalization"" of society and economies.",0
54,14," It is clear that the category of culture is struggling to address social and political issues, despite its efforts to simplify and express them. Although it still pertains to familiar problems like navigating change and identity constructions, it also deals with the challenge of determining values and making judgments in a constantly evolving and subjective society. Additionally, it must consider the relationship between individual parts and the larger whole.",0
54,15,"Although it is evident that we are currently experiencing an organic crisis, the inability to fully grasp the present context as a whole and the lack of a unified defining moment may indicate deeper challenges to the dominance of various Euromodernities. These challenges can be traced back to the movements of the 1960s, which marked the first visible forms of resistance against privilege and domination.",0
54,16," The exploration of new ways of being modern has led to cultural inquiries into ontological depths. Where culture used to see identity instability in relation to practices, it now concerns itself with the instability of practices in the face of processes. Cultural attitudes have also shifted from negative differences to positive multiplicities. Some intellectuals and critics reject fragmentation they feel culture produces and offer ""affect"" as a challenge to cultural weight. ""Affect"" describes the connection between imagination, bodies, and expression that makes visible the multiplicity of cultural apparatuses and effectivities. (see Grossberg 2010).",0
54,17,"

Affect challenges the idea of culture being the necessary third term in a dialectic and proposes mediation without such a term. This political transformation of Williams's question of culture changes the focus to the relation between change and imagination, between actual and virtual realities.",0
55,1," The essay argues that Zygmunt Bauman highlights the hesitation between intellectuals as saviors or oppressors in the left-critical movement but doesn't resolve it. The essay shows how human nature and culture are constitutive of human culture, leading to reciprocal hierarchies of social division. This pattern of vertical reciprocity is excluded in capitalist-bureaucratic liberalism, collapsing the hierarchical axis into the false-binary of 'left' versus 'right.' The essay suggests that authentic resistance to this system involves retrieving the dynamic paradox of the hierarchical communion of guiding excellence fused with popular spontaneity, which is the organic root of human culture and the means of the authentic practice of human justice.",0
55,2,"

Bauman's contradictory perspective on the modernity and primordiality of intellectual dominance creates uncertainty, which is further emphasized by the idea that the divide between intellectuals and non-intellectuals is the primary social and economic division. This notion has been proposed by the American anthropologist Paul Rabin, who highlighted the role of shamans in solving current and new problems by claiming to be in contact with the spirit world. Both Rabin and Bauman consider this to be a tactic of power. Therefore, original social oppression involves a combination of monopolizing expertise and creating a false expertise through the invention of religious illusions that exploit people's vulnerabilities and uncertainties.",0
55,3,"

Bauman's take on the European Enlightenment is plagued by several paradoxes due to his primary socio-historical analysis. He describes the philosophes as a group of anti-priests who seized a unique opportunity during the era of absolute kingly rule, wherein a centralized system of surveillance and regulation was required to supplant the decaying socio-economic-juridical function of the feudal nobility. They functioned as a new 'fourth estate' by utilizing advancements like printing, faster travel and urbanization for networking purposes (anticipated for today). Initially disdaining school and university education for being too closely tied to clerical contemplation and otherworldliness, they opted instead for a novel educational approach that would integrate with their reforming political agenda.",0
55,4," The importance of a purely secular thrust before the French revolution may have been exaggerated by Bauman. There were larger numbers of Jesuits supporting royal absolutism and Jansenists calling for more constitutional reform. The Enlightenment did not only focus on secularity but rather an experimentalist approach to reform that remained in continuity with reform efforts since the Middle Ages. These efforts sought to eradicate superstitions and ritual obsessions of popular religiosity. They all composed a counter-priesthood that opposed a new rule through reason to an older priestly rule of encouraging superstition. (Source: Barnett, 2003: 130^67 and Taylor, 2007)",0
55,5," Bauman emphasizes the importance of the intelligentsia in leading the way towards restored and enhanced freedom, which aligns with another aspect of Rousseau's political perspective. He believes that true freedom is not just the absence of restrictions, but the fulfillment of one's creative potential. Therefore, an educative program that frees individuals from the influence of unquestioning belief and unfair authority is necessary to encourage people to be truly free.",0
55,6," Bauman’s argument in favor of enlightenment is unconvincing and seems like an afterthought at the end of his books. His best work focuses on the dialectic of enlightenment, which shows how intentions to emancipate often lead to the opposite. The rise of mass democratic culture resulted in the destruction of local political participation and folkways that were immune to control. Furthermore, Bauman heavily relies on Foucauldian ideas to unmask enlightenment purposes as a will to power through the acquisition of social information and proposal of remedies.",0
55,7,"

Bauman notes that 'ideology' transformed into 'sociology', which led to government experiments in re-education. However, Bauman's approach as a 'sociologist' allows him to be wary of the rationalism of the philosophes while continuing a reform program based on insights. His criticism of Comte raises the question of whether his non-positivist sociology suggests suspicion of all clerisies and redundancy of an intellectual elite. The challenge for Bauman is to choose between populism or elitism in pursuit of the ideal of 'emancipation', which has only existed in Western intellectuals' minds. Nonetheless, Bauman's metanarrative work casts doubt on whether this ideal can be realized.",0
55,8,"

One could contend that the freedom to consume is essentially a widespread manifestation of the enlightenment principle of liberty. This transcription has made the role of ""legislators"" redundant, as noted by Bauman, leaving public intellectuals with a more modest function of interpretation. The acceptance of autonomy as the norm means that market mechanisms can nearly extract a public order from it indirectly. However, Bauman overlooks the doubling of every transaction by a record, which is a present surveillance mechanism. As a result, the economy is monitored by a bureaucracy that retains dispersed monitoring of the increasing risks of a deregulated marketplace.",0
55,9," In agreement with Bauman, postmodern government regulators only follow procedures instead of adhering to ideals or theories. However, the author questions Bauman's call for the restoration of the legislative role, as it appears unattainable given the current circumstances. The author argues that Bauman lacks a proper metaphysical basis for his appeal to ""genuine"" freedom and can only point to the need for a debate on the common good. The author suggests that a thicker sense of fulfilment requires norms and roles ascribed to us by tradition, assuming it discloses something objectively good beyond human election.",0
55,10," Bauman's lack of a clear stance on the relationship between the masses and intellectual elites leads him to an aporetic trap that is common among the contemporary liberal left. He runs the risk of being accused of elitism if he scorns the masses and their religiosity or compromise the advancement of progress by scorning intellectual elites. Although emancipation is aimed at overcoming unequal power that inhibits freedom, the power to liberate is still derived from knowledge, and therefore learning is necessary to free ourselves from our natural condition and the uncertainties and fears it generates. However, the concept of ""equal learning"" is problematic because learning inherently creates a divide between those who have learned and those who have not.",0
55,11," Bauman's inability to determine whether the clerisy is good or bad leads to his inability to determine whether culture or nature is the liberator. As a result, he cannot assign a just position to culture over nature or intellectuals over the folk-mass of people. He fails to recognize that the nature/culture divide is constitutive for culture and reproduces itself within society, often as a social division. This division is a type of experiment that society performs upon itself to constitute society and always involves a division between the experimenters and the experimented upon, which may not necessarily be unjust. Boltanski and Thévenot (2006) have also noted this phenomenon.",0
55,12," Bauman views human society as a self-governing entity governed by cultural or social norms without considering any metaphysical beliefs. Habermas, who shares this perspective and seeks to eliminate metaphysical claims from public discourse, believes that only pragmatic-normative terminology should be used. Through democratic consensus, it is assumed that if everyone can contribute, a pragmatic ""truth"" will emerge. However, this does not guarantee the universal victory of reason, unless we believe that truth is simply what is popularly accepted.",0
55,13," The cultural self-referentiality of the 20th century can be attributed to the aftermath of religion, which created a humanistic consensus that is now fading away. Habermas' suggestion that evolution has created an intentional referentiality for human survival is flawed, as it would imply a utilitarian use of this sphere. This implies a naturalistic metaphysics, which denies the existence of a spiritual realm. If we want to accept the existence of human ends beyond the utilitarian, we need to consider a spiritual ontology.",0
55,14," It is necessary to find a metacritical discourse that can bring about a resolution to the problems faced by the clerisy. The key issue is to establish a ""just"" and ""justifiable"" position for the clerisy, in order to avoid the conflicting opinions about them as either malevolent witch-doctors or benevolent saviours. The solution lies in Plato's ideology, where intellectual rulers, although they might be serving their own interests, can still pursue the transcendent Good through the right metaphysics. This view supports the idea that people who possess the ability to judge should be granted their rightful place, ensuring justice in terms of positioning of individuals and objects. Essentially, this means that there can be no fair distribution of labor and sharing of skills and resources unless there is a clear distinction between the wise and the other societal actors.",0
55,15," The idea that some people 'know better' than others about values is widely considered unacceptable today. However, Zygmunt Bauman, a modern sociologist, demonstrates a suspicious rejection of this idea, followed by an extravagant embrace. Instead, we require a more modest concept of 'organic intellectuals' whose knowledge is distanced from immediate exercise of power and whose social experiments are more subject to populist feedback. Additionally, intellectuals must respect the folk-wisdom of ages that has stood the test of time, rather than being contemptuous of it. Bruno Latour advises that we should not underestimate the naivety of learned and iconoclastic beliefs. (Bauman, 1999: 266-92).",0
55,16," Bauman acknowledges the concept of 'just balance' among the roles of elites, which existed in medieval times where noble rulers and landowners interacted with popular participation. However, Bauman overlooks the significance of having an 'organic' intelligentsia for effective popular participation. The absence of such an intelligentsia could lead to the dominance of a hidden monied and technocratic elite, as seen in modern times. The question of whether a different development from the Middle Ages was possible remains, as proposed by 'guild theorists' like Bodin and Althusius in the early modern period.",0
55,17," The condition of human beings, where education plays a role in creating a division between the informed and less informed, highlights the importance of choosing between a religious or secular clergy. It is evident that a religious clergy is more connected to traditional wisdom, as the shaman's prestige is based on their ability to articulate myths and perform rituals while retaining their connection to infancy and mystery. Thus, the mystery is a shared property among all.",0
55,18,"

Perhaps modern, critical, secular thought presents the incorrect choices. It aims to eliminate religion but may unintentionally abolish common culture and the knowledgeable elite who support it. This group's duty of advising is vital to popular culture, which, since ancient times, has always been marked by folk tales about royalty. Although we see our current political divide as high versus low, right versus left, it could be that the real issue is the dominance of the middle. Only the authentic combination of high and low can challenge this dominance. When a popular left lacks an aristocratic right, it often encourages the aspiring lower class to adopt the middle's ways. Meanwhile, an aristocratic right without a popular left usually resorts to nostalgia or kitsch. It is apparent that resisting the capitalist-bureaucratic centre requires a continuously dynamic and paradoxical blue/red fusion of guiding excellence with populist spontaneity, as John Ruskin long argued.",0
55,19," ""It is overly simplistic to believe that Bauman only sees the negative side of enlightenment and that we should reject its legacy. As we continue the ongoing experiment of humanity, we cannot forget that we have the capability to radically transform ourselves. This was not fully recognized in pre-modern times and we must acknowledge its truth now.""",0
55,20," It is erroneous to interpret the insight as allowing us to remake ourselves now when we couldn't before, as it leads to a mistaken perception. Acknowledging that we can experimentally transform ourselves and our environment highlights that we have always possessed this ability, disproving the idea of our past naivety. This echoes Latour's argument that we were never really modern. We realize that experimentation is integral to human society and although it is now more widespread and significant, it has always been a defining characteristic.",0
55,21, Humans transition from the non-referential play of signs to semantic consciousness through constructing rituals with archetypal actions. These actions provide recognizable patterns and curves that induce wonder and allow for introspection. Ritual is an experiment that tests if certain patterns will hold and if they can be used to manipulate natural forces.,0
55,22," Latour suggests using the term 'faitiche' instead of 'facts' or 'fetishes'. Scientific facts are not natural realities, but rather co-produced by us and nature. Like rituals, they are not planned and occur as surprises. We, along with nature, are jointly caught up in the arrival of an event.",0
55,23,"

Since the ritual-experiment that shapes humanity is the work of nature, it is impossible to exclude metaphysical considerations or determine that invisible entities like motions, genies, or genes are not real. Only Bentham's utilitarianism views such entities as convenient fictions because it considers only physical or sensory stimuli as socially real. However, if our world consists of faitiches, then we cannot know what is really at work. Nevertheless, we are obligated to speculate about this to have social order and meaning. Latour suggests that once one has rejected the idea of the space of the mind being inside the brain, it becomes possible to think of imaginary entities as being both 'out there' and 'in here.'",0
55,24," If the tension between nature and culture is inherent in culture, then a metacritique cannot critically determine whether meanings, imaginings, spontaneities, or purposes are purely cultural or natural. Similarly, cultural norms cannot necessarily be exempt from physical habits.",0
55,25,"

Humans establish culture through rituals, which are experimental risks that become habits. These rituals are both aristocratic and democratic as they are initiated and received by the populace. However, societies that prioritize experimentation are susceptible to an elitist scientific aristocracy dominating the masses. This leads to the illusion of representation and the control of society itself. Rituals become an imposed law or contract without variation, rather than an authentic habit that imparts artistic or craft skills.",0
55,26," Money plays a role in measuring the relative socio-ethical value, as suggested by Aristotle. Cohen's attempt to evade comparison aligns with communistic socialists such as Boris Groys and Alain Badiou. However, all subjective judgments are entangled in numeration, making it impossible to avoid. Refusing comparison is only an election of endless ""number ones,"" reducing essential content to abstract identity. This refusal rejects justice and cooperative labor, ultimately leading to a dominant hierarchy based solely on numbers. Bauman analyzes and attacks this hierarchy.",0
55,27, It is not feasible to assume that everyone has the same capability and resources because of the reasons discussed previously. Human civilization operates in a structured and continuously learning environment where there are initiators and learners. This concept is always present in every society as humans interact with each other and the environment around them. It is because we are part of nature ourselves.,0
55,28," 

Perhaps human transcendence is merely an illusion and all that is happening is the manipulation of one unifying process that ultimately victimizes humanity. Alternatively, if that is not the case, we can still recognize the importance of ritual-experimental outcomes without reducing them to a single manipulative force. Instead, these revelations can only make sense as a unified whole if they point towards a transcendent reality that draws them together analogically.",0
56,1," The last few decades have seen a significant expansion in literature regarding cross-cultural negotiation, which can be sometimes unclear and inconsistent. The introduction focuses on the crucial arguments raised about the importance of national culture, the practicality of categorizing cultures as fixed, and the confusion caused by vague terminology. Given the impreciseness of the national cultural concept and the variations in negotiating circumstances, it is unsurprising that studies can conflict. Nonetheless, the articles in this edition advance our comprehension of cross-cultural negotiation procedures.",0
56,2," Intercultural negotiations have significant advantages for both practitioners and researchers. Practitioners can benefit from predicting the behavior of their counterparts from different cultures, enabling them to develop strategies that align better with their negotiating style. To achieve this, they prefer examining the impact of dominant cultural traits on negotiation processes. Meanwhile, researchers can benefit from testing their assumptions and gaining new insights into intercultural negotiation processes. Rather than questioning the characteristics of a specific culture, researchers can query the salient traits and values of a group in various circumstances, compare results between different groups, and examine what happens to salient features when representatives of two groups interact.",0
56,3," In the realm of cultural psychology, cross-cultural and intercultural negotiation studies, experimental methods are commonly employed. There is a vast and intricate body of literature in this area, which is frequently updated with new editions of textbooks and survey articles. Examples of such publications include the Handbook of Negotiation and Culture and Negotiating Globally. Authors such as Adair and Brett, Cai and Drake, Gelfand and Dyer, Ghauri and Usunier, and Weiss have also contributed to the field with various anthologies and overviews. Researchers have conducted numerous cross-cultural comparisons, examining the impact of communication traits on the negotiation process. Although there are nearly 500,000 published works related to negotiation, culture, and communication, the majority of these concentrate on cross-cultural comparisons rather than intercultural interaction. Nevertheless, recent studies directly addressing this issue include those by Fisher, Leung and Bhagat, Buchan, Erez and Gibson, Leung and van de Vijver, and Tsui, Nifadkar, and Ou.",0
56,4,"
It is not surprising that many studies yield ambiguous results. We must acknowledge that making sweeping generalizations about cultures is difficult, and instead of pretending to have final answers, we ought to rise to the challenge. While generalizations can be useful, they also have limitations. Finding a balance between them and situational specificity could enhance our understanding of negotiating across cultures. This article will address objections to culturally-based negotiation studies and explore how the studies in this special issue mitigate those concerns, deepening our knowledge about culture and negotiation.",0
56,5," No cultural group can be defined solely by their individual experiences and surroundings. The size of a nation does not necessarily dictate the extent of its cultural identity, and even within a homogeneous cultural group, individuals may not share the same level of identification with their national culture. This makes it difficult to understand the relationship between culture and negotiation practice. The article by Gelfand, Lun, Lyons and Shteynberg proposes a descriptive norm approach to address this challenge.",0
56,6," The significance of national affiliation in predicting negotiating choices may be overshadowed by professional culture and corporate culture. Salacuse's survey (1998) showed that respondents from various countries and professions had differing preferences for negotiation outcomes and processes, while diplomats and military personnel displayed similar choices despite their nationality. The role or status of negotiators may also have greater influence than national culture. Brett and Okumura (1998) and Drake (2001) found that culture was not a major factor compared to other roles, such as buyer/seller.",0
56,7,"

The study of culture and negotiations is heavily influenced by context, which has numerous consequences. One of the significant contexts is experimental studies, which highlight that the behavior exhibited during the experiments may not be the same as when actual contracts are at stake. There is also a difference in the negotiation style between intracultural and intercultural negotiations. Graham (1990) utilizes 'acculturation theory' to describe the process of adaptation for a weaker national group to the more potent culture of the host group in an experiment.",0
56,8," The interaction between culture and context becomes increasingly crucial in situations with high power differences and uncertainty, as pointed out by Leung et al. (2005). Kumar and Patriotta's article in this issue proposes that a third person, or ""tertius iungens,"" may assist in reconciling task- and culture-related ambiguity during cross-cultural negotiations.",0
56,9,"

Many studies utilize data from one or multiple nations to illustrate a larger cultural region such as ""Arabic culture,"" ""Latino culture,"" or ""East Asian culture."" This issue contains two articles that explore the concept of cultural characteristics that apply to an extensive group of people. Ramirez-Marin and Brett propose that a cultural construal can overturn the accepted sequence of cause and effect. The relationship itself may be the center of attention for relationship-oriented cultures, such as the Latino culture, and business may stem from that connection. In the other article, Ott examines bundles of characteristics as a foundation for predictions. She examines the possible conflicts that may arise during negotiations among three substantial negotiation styles (linear-active, multi-active, and reactive), which are derived from regional characteristics such as level of agency, time sensitivity, and use of information. While the concept of regions and cultural grouping is more imprecise than nations, it is easier to handle in terms of broad expectations and conflict predictors.",0
56,10," We must also take into account the challenge associated with cultural typologies, such as those proposed by Hofstede, Hofstede, and Minkov (2010), as these frameworks often provide conflicting information when assessing the influence of culture.",0
56,11," The article by Maddux, Kim, Okumura and Brett raises questions about the extent of agency, suggesting that Americans view the individual as the responsible entity, while the Japanese express regret on behalf of the system or organization with agency. These findings contradict the previous assertion that individualism is solely an American value.",0
56,12,"

Stereotypes based on surveys and anecdotal evidence from negotiation experts can lead to different conclusions. The idea that relationships are important for some cultural groups is highlighted in two articles in this issue. Ramirez-Marin and Brett assume that Latinos, who are believed to focus on relationships, make low initial demands and aim for integrative deals. However, in Ott's article, the assumption is that relationship-focused Latinos make inflated initial demands and large concessions, based on Lewis's (2006) research. Other cultures, such as Russia, also prioritize relationships in negotiations but are reported to disclose minimal information and, therefore, opt for distributive deals.",0
56,13," 

Studies show that Americans may be viewed as either having a fixed-pie bias or seeking creative solutions during negotiations. One study suggests that Americans aim for fair solutions, while another argues that Americans have more freedom to seek creative outcomes because of their desire for equality. In contrast, Indian negotiators may be seen as stubborn and reluctant to make concessions, but some experts note that their offers can be heavily padded, and concessions can be significant.",0
56,14," It is vital to acknowledge that there is sufficient proof for each of these generalizations, despite their conflicting nature. To comprehend the fundamental cultural presumptions of the examination, it is imperative to understand the specific research question behind each of the studies.",0
56,15," Collectivism has been studied extensively and often compared with individualism in North America, China, and Japan. However, the definition of collectivism itself varies depending on the scope of the in-group, which can range from immediate family to nation. Therefore, it's important for studies to have similar definitions in order to accurately compare findings. Brewer and Chen's review in 2007 highlights this variability in definition and shows how in-group favoritism can exist in even highly individualistic cultures. Similarly, intense group competition can occur in highly collectivistic communities.",0
56,16," The acceptance of hierarchy or egalitarianism within a national culture is dependent on context, as evidenced by various studies (Chen, Leung and Chen 2009; Gelfand et al. 2007; Tsui et al. 2007). While it is commonly assumed in interaction studies that harmony is achieved through a consensus process among equals, it is not necessarily contradictory to find that groups with steep hierarchies can also reach consensus decisions. In such cases, lower-ranking members may seek to anticipate the desires of those in higher positions, while egalitarian groups may be more prone to conflict. This kind of hierarchy-based harmony may be increasingly common in Western organizations, where staff are hired for their alignment with the company's structure, discouraging dissent and requiring everyone to understand their place in the hierarchy for effective negotiation. The role of corporate culture in this phenomenon may be influenced by the organization's country of origin.",0
56,17," Semnani-Azad and Adair address the challenge of distinguishing various elements of dominance in this issue. By highlighting non-verbal power moves, they demonstrate how the apparently harmless and relaxed posture characteristic of the Canadian group (especially men) can indicate a negotiator who does not need to try too hard and might not honor their opponent's face. Meanwhile, the Chinese group adopts a forward-leaning, paperspreading space occupancy. Hence, identifying dominant features removes the need to debate which side exhibits more dominance based on a mutual criterion.",0
56,18," The final aspect of worry pertains to cross-cultural studies being criticized for essentialism. Given that intercultural bargaining frequently occurs within multinational corporations encompassing a diverse, international workforce, it is reasonable to question the extent to which a specific standard can be distinguished as an authentic cultural agreement.",0
56,19," Bi-cultural individuals are difficult to categorize because they can adapt to either of their cultural backgrounds, which is influenced by cultural artifacts (Oyserman et al. 2002). While it may seem sensible to search for shared norms, scripts, and values in cross-cultural comparisons, this assumes that fundamental norms change slowly, if at all. However, each negotiation creates a temporary mini-culture, or transaction culture, that is shaped by the communication and behavior of the participants. Changes in cultural values can still be compared, as shown by examples such as generational differences in views on justice in Germany. In emerging economies, there are noticeable shifts in business values across generations, although these differences may not always be reflected in national surveys.",0
56,20, Surveys can help create a depiction of shared norms through aggregated individual self-reports or reference-shifted surveys where respondents report on their perception of the norms of others. Chan (1998) and Fisher (2009) offer a review of methods and results.,0
56,21," The inclusion of an individual's evaluation of the norms and prejudices that were examined is an intriguing case (""but I myself am not like that""). The dissonance is often strong, as evidenced by surveys conducted in 1995 on whether British citizens believed that Prince Charles, then a bachelor, could marry a Catholic. Although the vast majority of respondents claimed to be indifferent to the matter, they thought others would be opposed. It is unclear whether this reference-shifted consensus reflects a current cultural norm or an outdated one after an actual shift.",0
56,22," The article by Tinsley, Turan, Weingart and Aslani in this issue examines how mental models can affect attitudes towards a standard buyer/seller dispute in both America and the Middle East. By surveying respondents in the US, Turkey and Qatar, the study reveals that young Qataris tend to prefer a compromise where the Western buyer saves face and the Middle Eastern seller is protected, while American and Turkish respondents focus more on protecting the buyer and their shared gains. The article also highlights how comparing mental models can provide valuable insights into attitudes and beliefs.",0
56,23," The special issue contains empirical studies that investigate previously neglected areas like Europe, Latin America, and the Middle East. Both these empirical studies and theoretical contributions should hold significance, not just for cross-cultural and intercultural negotiation experts but also for other academic audience members exploring the role of cultural nuances in negotiation processes.",0
57,1," Culture has gained recognition as an important factor in contemporary organization theory. This article traces the evolving significance of culture in organization theory, beginning with the lack of consideration for cultural aspects in the early 1900s, the emergence of shop floor culture in the 1920s, exploration of informal and institutional relations in the mid-1900s, and current approaches that integrate concepts from various fields. This historical context raises pertinent research questions on organizational change, boundaries, and deviance. The author concludes that culture, power, and agency are converging, potentially leading to a theory of society.",0
57,2," In the 1980s, ideas from previous institutional and ethnographic studies of organizations led to two significant developments. The first was the emergence of organizational culture frameworks, which emphasized the importance of meaning and symbols in organizations. The second development combined aspects of early institutionalism, symbolic interactionism, and ethnomethodology to create neoinstitutional theories of organizations that focused on the cultural-cognitive construction of organizational structures and practices. Today, cultural arguments and questions in organization theory explore the constitutive effects of culture on organizational members’ inner lives, their interpretations of organizational life, and the construction and maintenance of social structures. The study of culture in organizations has become the study of cultural organization. (Van Maanen and Barley 1985; Dobbin 1994a).",0
57,3,"Through the next few pages, I document the rise and fall of cultural debates in organization theory throughout the last hundred years, incorporating this as a foundation for addressing significant culturally influenced inquiries about organizational deviation, boundaries, and changes.",0
57,4," Early in the nineteenth and early twentieth centuries, there was a project to create self-regulating markets in Europe and globally. As free markets and capitalist gain became the motivations behind most social institutions, the rational organization was seen as the means to realize and sustain the market society, despite being separated from local customs (Polanyi 1944/1957).",0
57,5," Early organizational researchers viewed culture as unnecessary and even hostile to rational organizations, but ironically, culture played important but unacknowledged roles in their work. Applied theorists recognized the value of workers' knowledge of factory operations but also saw their traditions and practices as disruptive. As a result, they developed strategies to disrupt and replace those traditions, effectively incorporating culture into their work without acknowledging it.",0
57,6,"

Scientific management, created by Frederick Taylor in the early twentieth century, was the most famous representation of applied organization theory. Taylor's goal was to improve the efficiency of workers' tasks, which he achieved by studying traditional work practices through time and motion analyses. The resulting restructured tasks were simpler and easier for supervisors and owners to manage. Taylor also believed in incentive wages coupled with piece rates, and thought that unions and traditional compensation and production methods were unnecessary. Unfortunately, this approach removed workers' collective knowledge, but brought it back repackaged as ""scientific"" procedures. Taylor intended his system to improve labor relations and create objectivity, but in reality, it had a different outcome.",0
57,7," Academic theorists aimed to devise general laws and abstract descriptions of formal organization while Taylor and Fayol endeavored to develop universal principles for managing work. Weber's notion of ""ideal-typical"" rational-legal bureaucracies as hierarchical systems governed by rules, merit-based career paths, and rational accounting methods exemplifies this type of theoretical approach (Weber 1978, 956-63).",0
57,8," The distinction between cultural action and rational organization has been a central topic in organization theory throughout the twentieth century, as argued by Dobbin (1994a, 119). Parsons (1956) elaborated on Weber's concept of cultural and instrumental action and suggested that the operational functions of organizations could be separated from the less rational human element in order to address integrative problems effectively. Barnard (1938) indirectly addressed cultural factors and subtly emphasized rationality by defining organizations as cooperative systems in which members voluntarily commit to goals. Executives are vital to this process by creating a moral atmosphere that fosters members' optimal performance for achieving collective goals. By investing organizations with morality, Barnard argued that rational organization developed through members' commitment to morally infused objectives.",0
57,9,"

The differentiation between culture and rationality resulted in the separation of organizational research into two groups: one primarily investigating instrumental action, independent of cultural factors, and another group studying the more ""soft"" aspects of organizations, such as norms, symbols, and legitimacy. This distinction had implications beyond organization theory and impacted wider disciplinary and institutional boundaries. Disciplines such as economics and some areas of political science tended to focus on frameworks based on ""asocial, acultural, universal economic laws,"" whereas sociology, anthropology, and applied psychology placed greater emphasis on the nonrational elements of social practice and historical contexts. This same division was evident in business schools, where streams of economics, finance, accounting, and psychology existed alongside sociology and other social sciences.",0
57,10," Researchers conducted observational experiments and an extensive interviewing program to investigate workers’ experiences and emotions towards work. Despite AT&T's presumed progressiveness, the manufacturing jobs were still dull. The researchers found that the managerial attention given to workers in the illumination experiments made them feel important, motivating them to work harder irrespective of physical conditions. This dynamic was later generalized as the ""Hawthorne Effect."" Roethlisberger and Dickson argued that collective beliefs and nonrational values also influence productivity. These insights became the bedrock for the human relations school, which elevated the importance of workplace norms and sentiments in organization theory.",0
57,11,"

Researchers in HR spent several decades looking at workers' attitudes and values using Hawthorne's qualitative observation and unstructured questionnaires. Researchers from sociology, labor economics, and applied psychology used quantitative methods to study data from structured surveys and field experiments. From those studies, different organizations started implementing various approaches ranging from employee interviews to internal media campaigns and sensitivity training, with the goal of altering the work culture according to the managers' standards. HR helped to reduce the harshness of scientific management, and its traces are visible in modern organizations, thanks to departments dealing with employee relations. However, criticism of its techniques and evidence base reduced the impact of the HR movement in the 1950s (Perrow 1986,83).",0
57,12," Selznick's case study of the Tennessee Valley Authority, documented in TVA and the Grassroots, presented the idea that both formal and informal structures played a role in achieving organizational goals. Rather than solely focusing on how informal structures hindered formal structure, Selznick explored how the informal could expand executive control to reach objectives. Selznick used terms such as ""law"" and ""association"" to describe these informal relations, adding a sense of permanence to them. His treatise, Leadership in Administration, expanded on this idea, stating that leadership should guide the transition from organization to institution to meet desired aims and standards. Organizations start as technical, instrumental building blocks.",0
57,13," Sociologists at the University of Chicago explored the informal aspects of bureaucracies by immersing themselves in the daily lives of various communities and occupations through ethnographic research. Their objective was to observe and comprehend behavior in specific situations, inspired by the teachings of Everett Hughes, a faculty member at Chicago. This approach differed from Selznick's functionalist institutionalism. The Chicago fieldworkers aimed to map out the actual operations of occupations by analyzing behavior in a particular and situated context.",0
57,14," Chicago-style fieldwork challenged the notion of organizations as static and uniformly rational entities, rather highlighting their instability. This approach is exemplified by Strauss and colleagues' psychiatric hospital study, which drew from symbolic interactionism to explore the negotiation of meaning in organizations through social interaction. This work formed the basis for the ""negotiated order"" approach. Howard Becker's Boys in White similarly examined paradoxes in student socialization and survival within conflicting expectations at a medical school. (Fine 1984, 243)",0
57,15," Erving Goffman did not explicitly identify as a negotiated order theorist, but he implemented a dramaturgical approach to organizations rooted in Chicago symbolic interactionism. He investigated how people navigate the less visible elements of formal organizations. Goffman considered Presentation of Self in Everyday Life, his now-classic work, to be a guide for comprehending how organizations endure via individual and collective role and identity ""performances"" within a physical structure. In a similar vein, his celebrated Asylums explores the challenges of organizational underlives and posits that maintaining the self is crucial to organizational functioning. Morrill and Fine (1997) support this theoretical framework.",0
57,16," Despite gaining popularity among organization theorists in the mid-twentieth century, approaches such as institutional analysis, negotiated order, and dramaturgy, along with culturally-inflected works, did not replace the dominant rationalist organization theory. Nevertheless, these frameworks inspired future generations of researchers to explore the informal aspects of organizations and their negotiated orders across various institutional settings. As history shows, organization theory oscillates between purely rationalist eras and those where cultural aspects seep into prevailing frameworks. This pendulum swing is evident in the rise of scientific management during the first two decades of the twentieth century and the emergence of HR, institutionalism, and the Chicago-style fieldwork/negotiated order approaches during the 1930s-1950s.",0
57,17," As the research on organizational culture gained popularity in the 1980s and 1990s, the newer generations of scholars began to shift away from the initial focus. Some researchers utilized survey techniques similar to those used in cross-cultural attitudinal research, while others experimented with mathematical techniques to analyze cultural artifacts and practices. Additionally, some scholars drew inspiration from the humanities and adapted textual deconstruction, narrative analysis, and critical hermeneutics to explore gender inequality, organizational change, and emancipatory organizational practice, respectively. This expansion of organizational culture research provided an opportunity for collaboration between organizational studies and the humanities, but it also sparked conflicts over theoretical and methodological differences, as well as debates on cultural interventions into managerial practices. As a result, what began as a small coalition grew into a turbulent collection of ""warring"" factions.",0
57,18," Business consultants recognized the potential of organizational culture to shape individuals and collaborative relationships for management purposes. Developing organizational cultures was compared to building communities and tight-knit ""clans,"" emphasizing mutual support, solidarity, and commitment. Unlike HR or early institutionalism, applied organizational culture proponents aimed to embed culture more deeply into individuals and groups' psyches by transforming their identities and selves, restructuring their inner and interactional lives. This way, the language of commitment and cooperation in applied organizational culture work echoes Barnard's arguments on the moral dimensions of organizational membership.",0
57,19," Business consultants recognized the potential of organizational culture to shape individuals and collaborative relationships for management's benefit. Creating organizational cultures became similar to creating communities and tight-knit groups, emphasizing mutual support, solidarity, and commitment. Unlike HR or early institutionalism, which focused on normative commitment, applied organizational culture advocates sought to delve deeper into individual and group psyches by transforming identities and inner lives. This approach evokes Barnard's arguments about the moral dimensions of organizational membership.",0
57,20," At around the same time that academic articles addressing organizational culture emerged, the neoinstitutional framework was introduced through initial statements. This framework, much like the perspective of organizational culture, concentrated on the non-rational facets of organizations like symbols, rituals and myths. However, instead of using such concepts to investigate the cultural shaping of organizational personnel, neoinstitutionalists relied on them to understand the cultural establishment of organizational rationality and structure. Drawing inspiration from symbolic interactionism and cognitive-behavioral decision-making theories, alongside early institutional theory, John Meyer and Brian Rowan argued that organizations symbolize wide-ranging cultural myths about rationality. According to them, such myths have come to be believed as objective truths. They also claimed that organizations reflect their agreement with these concepts by getting specific structures and strategies. Consequently, it is not rationality that is technically better but rather rationality that implies suitability, resulting in understandings of legitimacy and the resources essential for survival.",0
57,21," Neoinstitutional theory extends its scope beyond organizations and specific sectors, investigating the historical roots of modernity, such as rationality and instrumental social organization. The key inquiry driving this research is how did instrumental rational organizations become dominant? Using the diffusion of cultural-cognitive models as evidence, neoinstitutionalists argue that Western European cultural shifts surrounding the Enlightenment, Industrial and French Revolutions, and “market” endeavors in centuries past pervaded the world. Their models prioritized Western rationalist, means-end assumptions about reality and social organization universally. This ultimately resulted in a “Western cultural account” world culture according to Meyer et al. (1997). DiMaggio and Powell (1983) further explicate the mechanisms responsible for this diffusion via institutional “isomorphism,” specifically mimesis, normative (professional), and coercive pressures. These factors ensured that organizations, especially those related in fields of producers, clients, relations to governments, and rules of the game, became institutionally consistent.",0
57,22," At the micro level, the performance of organizational routines can lead to incremental change over time by introducing variation in patterns of action and practice. This approach highlights the relational nature of power in organizations, involving multiple lines of interaction up, down, and across hierarchies. Examples from Hallett's ethnography of deference and leadership during change in an elementary school and Ewick and Silbey's narrative analysis of how powerless individuals use their working knowledge of institutionalized authority to resist it illustrate this broad tack. Feldman and Pentland (2003) theorize a cultural-political theory of change that challenges the notion of routines as sources of stability or organizational inertia.",0
58,1," The debate over the meanings and implications of cultural relativism has spanned several decades. Roger Sandall critiques the anthropological concept of culture and identifies relativism as an obstacle to open society. However, I challenge this perspective by drawing on the works of Franz Boas and Johann Gottfried Herder to argue that the social science concept of culture should not be associated with notions of rejecting standards of truth, beauty, and morality, or the idea that all cultural practices are equally true or untrue. Furthermore, I examine how culture is used in the philosophy of primitivism, multiculturalism, and identity politics, and contend that many ostensibly relativist claims are actually used to serve non-relativist agendas. Rather than overvaluing cultural differences, our problem lies in underestimating them. Even in multicultural societies, we tend to project our own outlook and aspirations onto others.",0
58,2," Roger Sandall explains that the West once had a structured and hierarchical approach to cultural evolution, with universal principles guiding the progression from tribalism to advanced civilization. But then, an anthropological concept of culture influenced by Johann Gottfried Herder emerged in America, emphasizing cultural distinctiveness and rejecting hierarchical order and moral judgments. This relativistic view of culture has been wielded by a contemporary ""Culture Cult"" that is motivated by resentment against Western civilization and has worked to erase meaningful distinctions and universal standards, like a ""moral acid.""",0
58,3," Anthropologists and other social scientists used the concept of culture to discredit linear notions of cultural evolution and the idea that so-called ""primitives"" were inferior. 19th century schemes of cultural evolution were hierarchical, with societies ranked on a Eurocentric scale and based on biological assumptions about race. Franz Boas and his followers rejected these ethnocentric and racist schemes, emphasizing common humanity and cultural relativism as a way to approach cultures historically and scientifically.",0
58,4," Clifford Geertz stated in his essay ""Anti Anti-Relativism"" that it is not anthropological theory, but data collected from the field that stimulates concerns about relativism. The vast array of human practices such as customs, beliefs, and aesthetics across different cultures challenges our previously held assumptions about the world. Geertz argued that exposure to cultural diversity can lead to a ""relativist bent"" or an appreciation of the possibility that ""what is truth on one side of the Pyrenees is error on the other."" The debate over cultural relativism is not about the implications of anthropological research; rather, it is about how to navigate and coexist with cultural diversity. While cultural pluralism may cause discomfort, Geertz suggested that genuine nihilism is rare. (Geertz 1984/2000).",0
58,5," Sandall attributes the culture doctrine he is concerned with to Herder and contemporary multiculturalists as his ""romantic heirs"". He believes Herder brings together all the strands of his critique including the culture concept, Romanticism's reaction to Western civilization, multiculturalism, and the moral psychology of resentment. However, Sandall is only familiar with Herder's ideas through Isaiah Berlin's book Vico and Herder. This interpretation is uninformed by the available historical literature on Herder and the origins of the human sciences, making his claims questionable. Although Berlin's contribution to Herder's ideas was noteworthy, Sandall's emphasis on it seems outsized. The important claim is about the relationship between Herder and the anthropological concept of culture, whether his ideas contaminated it right from the start as Sandall suggests.",0
58,6,"

Sandall's claims lack evidence and it is unclear if any exists. Instead, I will present two objections to his position. The first pertains to Herder's views and whether he truly represents the Counter-Enlightenment as argued by some, such as Berlin. However, recent literature challenges this oversimplification and recontextualizes Herder's thinking within the Enlightenment, as demonstrated in John Zammito's Kant, Herder, and the Birth of Anthropology published in 2002.",0
58,7," Denby challenges the common perception of Herder as an opponent of Enlightenment ideas by highlighting how Herder's approach to history and anthropology actually aligns with Enlightenment ideals. Denby suggests that Herder's concept of culture is more in line with a unitary Enlightenment model of civilization than previously assumed, and that Herder's relativism is not absolute because he maintains an ethical universalism. Additionally, Herder's notion of progress includes the idea that civilizations build upon one another and that the desire to improve our lives is a universal human trait. Ultimately, Denby suggests that Herder's ideas should not be dismissed as an opposition to the Enlightenment.",0
58,8,"

Sandall's claims against Herder's influence on anthropology are subject to my second general objection. While Herder's influence on the discipline is undeniable, some historians argue that it runs through a tradition from Herder to Wilhelm Humboldt, Heymann Steinthal, Franz Boas, and others. The view that Herder originated the notion of ""cultures"" in the plural has been challenged by new scholarship on the subject. Furthermore, George Stocking and others have argued that Boas inherited a singular notion of culture from the nineteenth century and only gradually changed its meaning.",0
58,9," Boas replaced cultural stages with the concept of multiple cultures, each with a distinct history and developed through borrowing from other cultures. He viewed each people as having their own ""genius"" or unique cultural expression, similar to Herder's idea of the human spirit being embodied in ethnic or national forms. This was also influenced by later thinkers, such as Steinthal and Bastian, and had roots in racialist thought traced back to Herder, against which Boas explicitly opposed. However, Boas accounted for ethnic diversity through cultural traditions, rather than racial heredity.",0
58,10," The trivializing dynamic that affects multiculturalism stems from the belief that all cultures are equal and deserve equal respect. Multiculturalism aims to empower minority or ""subaltern"" groups and cultures, which has become a common goal. Multiculturalism is rooted in a history of assimilation and national identity in the United States, evolving from interculturalism movements that existed in public schools during the inter-war years. Multiculturalism emphasizes the preservation of difference and identity, and some, especially in more extreme forms, propose deep cultural determinism. Despite these differences from interculturalism, multiculturalism shares many of the same ideals, such as the celebration of difference and tolerance and the condemnation of ethnocentrism and parochialism.",0
58,11,"

The idea that all cultures are equal is problematic, according to Taylor. While it makes sense to approach the study of cultures with an assumption of their value, it is not just to demand that all cultures are inherently valuable or equal. Defenders of this principle often use neo-Nietzschean theories that equate all standards with power, but this approach does not actually respect other cultures as it does not involve studying them and applying objective and non-subjective standards of value. Instead, it is better seen as condescending and a form of praising the other culture for being similar to ourselves, rather than a genuine appreciation of the culture itself.",0
58,12,"

The principle that all cultures are equal stems from the emphasis on acknowledging identities. Charles Taylor, in his renowned piece ""The Politics of Recognition"" links this principle (Taylor 1994). He identifies a particular understanding of authenticity, along with a democratic urge for equality that results in universalistic demands for public recognition of two types. The first is the recognition of the equal status of every citizen, which takes a tangible shape in the legal equalization of political rights and claims. The second, and more contentious demand is the recognition of difference. This claim implies that individuals and groups have separate and exceptional identities they are expected to adhere to. A failure to follow this originality due to a lack of recognition or misidentification by others results in psychological distress. Dominant groups often consolidate their supremacy by imposing a sense of inferiority on minority individuals and cultural groups, resulting in injury or harm to these groups. Therefore, public recognition must extend beyond equal dignity and encompass individual identity variations (gender, sexual orientation, etc.) and equal appreciation of various cultures.",0
58,13,"

Multiculturalism takes on many forms, each with its own level of depth and recognition of cultural differences. While some versions may be considered ""culture lite,"" others emphasize the incommensurability of cultures and the significance of group differences. However, much of this discourse emerges from the combination of multiculturalism and identity politics, which centers on highlighting the discrete cultural memberships of marginalized groups and advocating for recognition and legitimacy in wider society. Women, LGBTQ+, African-Americans, and other constituencies all make moral and political claims on the state to address issues of equality and oppression.",0
58,14," Some claims made by relativists about the good, the true, and the beautiful are contradictory, lacking substance, or used to enforce norms. Additionally, some claims are not straightforwardly relativistic, as they have concealed premises that rest on universalism. While some genuinely relativistic claims do exist, many supposed relativists have an ulterior motive or tacitly accept cross-cultural standards/values. Robin Fox, an anthropologist, argued that post-colonialists don't fully respect indigenous cultures because they assume that everyone desires liberal democratic rights. This assumption is based on the belief that given the choice, individuals will choose forms of freedom that we recognize and endorse.",0
58,15,"

The belief in universal sameness that disregards cultural differences is widespread. As an illustration, I would like to refer to a research article I authored back in 1996 (Davis 1996). The focus of my analysis was on the public outcry trigged by the Programme of Action, adopted during the UN Population Conference in Cairo in September 1994. The preceding two decennial population conferences had centered on making birth control technology available, advocating family planning, and encouraging governments to establish objectives aimed at reducing birthrates. The suggested plans aimed to provide people with the power to choose family planning methods. However, these programs alone did not necessarily shift people's attitudes toward family size. Some used birth control not to limit the number of children but rather to space out births. From the perspective of population control, they were making the wrong selection. The secretary-general of the Cairo conference claimed that the existing programs had not created an environment conducive to people making sound decisions (emphasis added). This novel idea of an ""enabling environment"" emerged in Cairo. The Programme of Action designated the primary components of this environment and outlined measures to implement them.",0
58,16," There is a large amount of trafficking in universal values happening, with various groups and organizations spreading their beliefs. Economic globalizers are pushing capitalist production and consumption while NGOs and moral entrepreneurs aim to evangelize the underdeveloped. There are also efforts to ground universal values in evolutionary psychology, creating a ""human nature industry."" This is not a world dominated by relativism, but rather one where we may underestimate cultural differences. Our multiculturalism often assumes a sameness of outlook and aspiration, projecting ourselves onto others.",0
58,17,"

Recently, the Anglican Archbishop of Canterbury, Rowan Williams, sparked controversy for suggesting ""constructive accommodation"" with certain aspects of Muslim religious law (sharia) and the likely integration of sharia into the British legal system. This has led to a strong reaction from many. Such moments remind us that there are diverse cultures and normative systems, and that we are increasingly living together. We should not exaggerate differences but cannot ignore them either. Looking ahead, there will undoubtedly be challenges, and relying on ethnocentric viewpoints or empty rhetoric about tolerance will not help us navigate through difficult waters.",0
59,1," Nonmaleficence, the principle of doing no harm, is a crucial ethical principle in nursing care. However, health care errors still occur despite this principle. The Institute of Medicine's report, To Err is Human, made it clear that health care error was responsible for numerous deaths annually in the U.S. The report recommended a shift to a system-focused approach rather than an individual blame response. It suggested that the culture of safety should be adopted, and that errors and near misses should be viewed as opportunities for learning and improvement. There have been many efforts to decrease the incidence of health care error since the report was published, but health care has not yet reached the success of other high-risk industries such as aviation or the nuclear industry. Chassin and Loeb have observed that no hospitals or health care systems have achieved consistent excellence throughout their institutions, and the rate of health care error may be higher than originally estimated.",0
59,2," The concept of a culture of safety was first introduced by high-reliability organizations (HROs), according to the Agency for Healthcare Research and Quality (AHRQ). HROs are organizations that have a high risk of error but very few negative outcomes, such as the nuclear and aviation industries. The comparison between these industries and healthcare highlights the discrepancy in their safety standards. Hospital-associated preventable harm is estimated to cause up to 400,000 deaths annually in the US, equivalent to two full jumbo jets crashing every day. While this would be unacceptable in aviation, it's a regular occurrence in healthcare.",0
59,3," According to the Joint Commission, a safety culture is characterized by trust and empowerment of staff to report errors, near misses, and risks. In the healthcare industry, the Joint Commission defines safety culture as the collective knowledge, attitudes, behaviors, and beliefs of staff regarding the importance of patient well-being and care, which is reinforced by systems and structures supporting patient safety. It is worth noting that emphasis is placed on systems rather than individual healthcare workers, although the latter's attitudes, knowledge, and behaviors can impact the safety culture.",0
59,4," The key focus in safety culture is the system because safety issues often originate from the system itself. According to Reason9, individual errors are referred to as active errors, while system errors are latent errors. Active errors occur at the frontline of healthcare and have immediate consequences, such as when a nurse administers medication to the wrong patient. Latent errors, on the other hand, may not be evident until they combine with other factors, such as faulty barcode scanning processes. Reason9 states that latent errors pose the greatest risk to complex systems and are the primary cause of most errors. Reason's model for error, commonly known as the Swiss cheese model, depicts potential errors as holes that can be offset by other defenses until they align, leading to patient harm.",0
59,5," Accountability is a crucial aspect of safety culture, as highlighted by Frankel and colleagues. Workers need to be willing to acknowledge their concerns and ensure that their colleagues maintain standards. Hand hygiene compliance is a prime example of how accountability can be improved, as it is the most effective way to prevent hospital-associated infections. Unfortunately, compliance rates are only at 40%, leading to an estimated 75,000 preventable deaths a year. To address this, the Joint Commission Center for Transforming Healthcare recommends making every employee accountable for performing hand hygiene and monitoring others. Just in time coaching and You Tube videos can help to increase accountability.",0
59,6," Trust is crucial in a safety culture, but fairness for workers is necessary to develop trust. If frontline workers are solely held responsible for latent errors, a just culture is prevented. Just culture means responding to errors reasonably and fairly, without punishing the worker. The ANA recommends the concept of just culture in health care, and direct-care nurses should support its implementation in their institutions.",0
59,7," argues that unintentional errors do not warrant punishment according to Marxist philosophy. In healthcare, the current disciplinary system tends to focus more on the outcome rather than the action itself. This means that a healthcare provider who causes harm due to a simple mistake may face stricter disciplinary action than someone who intentionally disregarded safety procedures but did not cause harm. For instance, a nurse who administers harmful medication due to a lapse in concentration may be punished more harshly than someone who deliberately fails to follow safety protocols by giving aspirin instead of acetaminophen.",0
59,8," 

A culture that is considered to be just is one that encourages trust and increases reporting. Instead of looking solely at the outcome, a just culture examines the actions taken and also explores any underlying or systemic causes of the mistake. This creates an environment where workers feel secure in sharing problems they encounter. Without a just culture, a safety culture cannot be established. If the culture is excessively severe or punitive, errors will be concealed and underreported. In the realm of safety, ""no news is good news"" does not hold true.",0
59,9," A patient transition happens when a patient changes from one care setting to another or switches from one healthcare worker to another. Handoffs refer to the communication between healthcare workers during these transitions. Studies have shown that the period of handoffs and transitions can be a risky time for patients. According to estimates, up to 80% of serious medical errors may be linked to miscommunication during healthcare provider handoffs.",0
59,10," Workers' best efforts and intentions cannot prevent errors and near misses from happening. Therefore, it is crucial for frontline nurses to know the best practices for managing error. This section covers two practices - root-cause analysis (RCA) and supporting the second victim.",0
59,11, Nurses who participate in RCA must be ready to examine mistakes and close calls from the perspective of the mentioned factors instead of simply pinpointing the immediate cause of an error.,0
60,1," Microfluidic devices for cell culture enable 3D tissue culture with perfusion, mimicking the blood flow in our body. A microfluidic device, made of a detachably assembled microfluidic chamber chip and multi-microwell array chip, allows for spheroid perfusion culture in a microarray format, with the advantage of uniform formation, growth analysis, proliferation control, and post-culture analysis of the collected spheroids. Human hepatocellular carcinoma (HepG2) cells were cultured in this device under two perfusion flow rates, resulting in different cell growth, metabolic activity, mRNA, and protein expression compared to static culture. This demonstrates the potential of microfluidic perfusion culture in precisely controlling the culture environment. The detachably assembled microfluidic device enables convenient post-culture analysis.",0
60,2," Three-dimensional cell clusters imitate natural environments more accurately than traditional two-dimensional cultures. Spherical clusters, also known as spheroids, have tissue-like structures and can maintain liver cell functions, create hypoxic conditions for cancer research, and direct stem cell differentiation. Our research group, along with others, has created spheroid arrays using microwell structures that produce spheroids with precise diameters in large quantities.",0
60,3," 

Microfluidic devices are used to control nutrient and oxygen supply in the perfusion culture of spheroids. However, conventional devices are only capable of producing one or few spheroids per chamber, while array-formatted spheroids are crucial for investigating the effects of mass transfer. A multi-microwell array chip has been developed to produce a high-density spheroid array with uniform size. The challenge of loading cells uniformly into microchambers has been addressed.",0
60,4,"

In previous reports on perfusion culture microfluidic devices, it has been challenging to gather the spheroids after culturing since they were grown in sealed microchambers. As a result, it is not possible to conduct further biological evaluations, such as mRNA and protein expression analyses, using traditional off-chip analytical techniques, such as polymerase chain reaction (PCR), southern and western blotting, on perfusion cultured spheroids in a microfluidic device. This constraint has made it difficult to understand the detailed mechanisms of the effects of perfusion on spheroid culture. In the case of array-formatted 3D liver tissue cultures, only viability and cell morphologies have been evaluated.",0
60,5," The issues associated with perfusion culture of spheroid arrays were addressed in this study by creating a microfluidic device consisting of a detachable microfluidic chamber chip and a multi-microwell array chip. This allowed for precise control of the spheroid perfusion culture in an array-formatted geometry and post-culture analysis of the spheroids. Human hepatocellular carcinoma (HepG2) cells were cultured under controlled perfusion conditions using this device, and the effects of perfusion on spheroid culture were analyzed.",0
60,6," Figure 1E depicts a larger view of a culture chamber present in the assembled microfluidic culture chip. The microfluidic network of this chamber is based on the perfusion culture microchamber array chip explained in our previous report [30]. The flow rate of the culture media present in each culture chamber is determined by the dimensions of the fluidic resistance channels and the pressure applied at the medium-inlet ports. The fluidic resistance channels are much narrower than the other channels and show the largest fluidic resistance in the microfluidic device. The multi-microwell array chip design was optimized for spheroid culture in our earlier report [9]. In this study, each culture chamber consisted of an 8x8 array of microwells (diameter, 300 μm; depth, 300 μm; pitch, 330 μm) (Fig. 1F) (detailed materials and fabrication protocols of the microfluidic chamber chip, and multi-microwell array chip are available in Section S1 and S3 Supporting Information).",0
60,7," colored dye solutions (Red: New coccine, Green: Fast green, Blue: Gardenia blue, Yellow: Gardenia yellow, Wako Pure Chemical Industries, Osaka, Japan) were introduced into the microfluidic device under a pressure of 7.2 kPa using a transparent PMMA support frame instead of a stainless steel support frame to evaluate the seal integrity of the fixtures. No mixing or leakage of solutions occurred, indicating a sufficient seal provided by the fixtures in both the microfluidic chamber chip and the multi-microwell array chip. (Fig. 1G)",0
60,8," The spheroids' survival rate was assessed after being cultured statically and with low-flow-rate perfusion on the seventh day. The microfluidic system was dismantled, and the spheroids were rinsed with Dulbecco's phosphate-buffered saline and treated with a viability kit from Life Technologies (Carlsbad, CA). The IX-71 inverted microscope (Olympus, Tokyo, Japan) was used to capture pictures of the spheroids, and the brightness and contrast of the images were adjusted to highlight the living and dead cells.",0
60,9," 'Basal metabolism was assessed through the measurement of glucose consumption and lactate production. The glucose concentration and lactate concentration were measured using a glucose test kit from Wako Pure Chemical Industries in Osaka, Japan and a Lactate Assay Kit II from BioVision Inc. in Milpitas, CA, respectively.'",0
60,10,"

The mean ± SD of molar ratios for lactate production, glucose consumption, albumin synthesis, cell number, and mRNA expressions were reported for 2 to 10 time points. Repeated-measures analysis of variance was used to perform statistical analyses, and P < 0.01 and P < 0.05 were considered significant.",0
60,11," Figure 2 illustrates the results of phase-contrast micrographs acquired from static, low-flow-rate perfusion, and high-flow-rate perfusion culture conditions at different time points during a 10-day culture period. The study found that the HepG2 cells formed one spheroid in each microwell after 3 days of culture regardless of the culture conditions. The non-adhesive microwell surface aided in the aggregation of the cells. The spheroids were maintained for at least 10 days of culture, and their size continuously increased. The authors ensured that the inoculation process prevented cell blockage in the microchannels of the microfluidic device.",0
60,12," The HepG2 spheroids' changes in diameter can be observed in Figure 3C. When placed in a static culture, the spheroid diameter growth rate slowed at 7 days but steadily increased until 10 days, which aligns with our previous report on static cultivation in multi-microwell chips with numerous wells. However, in perfusion culture, the spheroid diameter continued to increase even at 10 days, and high-flow-rate perfusion culture resulted in a faster growth rate than low-flow-rate perfusion culture.",0
60,13," The viability of the spheroids in static and low-flow-rate perfusion culture after 7 days of culture was confirmed using a live/dead cell-viability assay (Fig. 4). In both culture conditions, nearly all of the cells in the spheroids within the culture chambers were found to be alive.",0
60,14," The spheroids showed great potential for drug toxicity testing with the spheroids array, as they had high viability. Additionally, the microfluidic device enables the simultaneous testing of multiple drugs on a single device, as it is equipped with four distinct culture conditions in the culture chamber arrays (Fig. 1F).",0
60,15," The rate of albumin synthesis at 9 to 11 days of culture is depicted in Figure 5B, which is found to be in correlation with the culture conditions. It has been observed that the spheroid array under high-flow-rate perfusion exhibited significantly higher albumin synthesis activity compared to that under low-flow-rate perfusion (P < 0.01). Meanwhile, both static and low-flow-rate perfusion resulted in similar albumin synthesis activities. These outcomes demonstrate the potential application of our microfluidic device in examining liver cell-specific functions at different perfusion rates with the medium collected at regular intervals.",0
60,16,"

We developed a new microfluidic tool for cultivating spheroids with uniform size under controlled perfusion conditions. The microfluidic device (with dimensions of 47 mm x 96 mm x 35 mm, and the microfluidic culture chip measuring 26 mm x 76 mm x 2 mm) enabled controlled perfusion culture conditions for spheroids created in microwell arrays. In comparison to the previous perfused multiwell plate (86 mm x 128 mm x 35 mm), our microfluidic device had a smaller size and comprised of 16 smaller culture chambers. Our device also allowed for the collection of spheroids from the culture chambers, which is a significant limitation of other microfluidic cell-culture devices. The collected spheroids were used for traditional biological analysis methods such as ELISAs, live/dead assays, and real-time PCR. Moreover, this collected sample can be utilized for other techniques like cell sorting, imaging analysis, microarray analysis, and immunohistochemistry in the future. By using our microfluidic device, we were able to quantitatively compare the effect of perfusion to static culture on spheroid growth rates, which highlighted the impact of nutrient supply or waste removal on spheroid proliferation.",0
61,1," The typical approach in research has been to view culture as either an independent or moderating variable. However, this empirical study takes a different approach by examining culture as a dependent variable and investigating whether higher levels of economic performance can influence a national culture that is more supportive of entrepreneurial activities. The analysis controls for various country-specific factors and prior economic development levels. The findings show that individuals in countries with higher per capita GDP tend to value jobs that promote achievement, initiative, and interesting work. In contrast, individuals in countries with below-average economic performance are less likely to embrace entrepreneurial activities. The study suggests that the degree to which countries converge on pro-entrepreneurial values depends on the distribution of economic performance across these nations. The discussion outlines the theoretical and practical implications of these results.",0
61,2," Countries with a strong entrepreneurial culture are believed to have better-performing economies, which is supported by scholars from various academic disciplines. For instance, Edmund Phelps argues that a population that values personal development and achievement is crucial for economic dynamism, while Michael Porter emphasizes the importance of a 'productivity culture' that prioritizes innovation and market competition. This view is also shared by historians who link the decline of early industrial powers like Britain to a lack of entrepreneurial motivation. In response, politicians like Margaret Thatcher have sought to restore economic success through policies aimed at fostering an 'enterprise culture' focused on innovation, self-reliance, and profitability.",0
61,3,"

Estimating the impact of economic performance on culture can provide valuable insight for business decisions on market entry and adapting management practices to local conditions. Conversely, if national culture is not influenced by economic performance, it may indicate that national cultures are fixed and firms should base decisions on available point estimates of national culture, such as Hofstede's model. If culture is, in fact, affected by performance, then combining culture data with economic performance projections can help forecast cultural environments within the firm's planning horizon. Additionally, understanding the formation of enterprising values can be valuable for contemporary business models that value innovation and achievement orientation. The evidence could be used to evaluate the hypothesis that national cultures will converge with economic development and shed light on the shift towards more individualistic values post-World War II, which has been associated with greater economic growth.",0
61,4," 

There have been studies examining the correlation between national culture and economic performance. Franke et al. (1991) analyzed Hofstede's measures of individualism, power distance, masculinity, and uncertainty avoidance, as well as Bond's measure of Confucian dynamism. They found that individualism had a negative impact on per capita GDP growth from 1965 to 1987, but had a positive impact on per capita GDP level in 1965 and 1980. Meanwhile, Confucian dynamism was positively associated with GDP growth, but not with GDP level. In another analysis by Hofstede (2005), individualism was positively related to more recent measures of per capita GDP. However, other studies that used Hofstede-type measures to evaluate firm-level performance have produced mixed results. Ringov and Zollo (2007) discovered that power distance and masculinity had a negative influence on corporate social and environmental performance, while individualism and uncertainty avoidance had no effect.",0
61,5," Thirdly, research has been conducted on various aspects of enterprising culture. McClelland's (1961) pioneering investigation revealed that countries with a higher need for achievement (nAch), as assessed in 1925, experienced greater economic growth within the following 25 years. However, further analysis by Mazur and Roza (1977) discovered that the impact of nAch was unstable over time, as McClelland's nAch scores for 1950 did not correlate with economic growth over the next 21 years. Recent studies have examined large-scale national surveys to determine measures of national entrepreneurial orientation. For instance, a measure of entrepreneurial values, which was derived from the 1990 European Values Survey, was positively associated with regional growth rates from 1950 to 1998 (Beugelsdijk and Noorderhaven, 2004). Moreover, a measure of entrepreneurship propensity from the Global Entrepreneurship Monitor (GEM) data for 2002 was linked to economic growth, with the relationship being moderated by national income (Wennekers et al., 2005; Van Stel et al., 2005).",0
61,6," It is not unanimously agreed among scholars whether national culture and economic performance are closely related. The limitation of most studies is that they only measure culture at a single point in time, which hinders causal inferences. There are also unobservable country-specific factors that can affect economic performance and cannot be controlled for. Additionally, major events such as war or institutional shifts can cause fluctuations in economic output, which may affect cultural variables being attributed undue credit for performance levels.",0
61,7,"

To some extent, national values are learned responses to national environments, and their contingencies are affected by national economic performance. Economic growth has caused value shifts over time, with global prosperity being attributed to the worldwide shift towards more secular/rational values. There are also examples of how values have changed in rapidly growing market economies, such as the Chinese populations in Taiwan and Hong Kong. As lower needs are fulfilled, higher needs emerge in line with Maslow's hierarchy of needs.",0
61,8," A strong economic performance on a national level has the ability to boost entrepreneurial values in various ways. Initially, people tend to have a positive perception of the potential gains involved in entrepreneurial activities overall. In times of flourishing market opportunities, there tends to be more successful outcomes with relatively less failures. Moreover, the consequences of failures are less severe, which allows prospective entrepreneurs to gain knowledge from their mistakes.",0
61,9," In developed societies with higher income, entrepreneurship becomes more appealing due to measures that reduce the risks involved in starting a business. These societies typically have established welfare programs, and individuals have access to larger personal savings and financial backing from their families. Sahm's (2007) research establishes a link between better economic circumstances and higher risk tolerance among populations.",0
61,10," In wealthier economies, higher-order needs that can be fulfilled through entrepreneurship are more prominent. In low-income settings, basic needs for survival and security take priority, leading individuals to cooperate and reinforce collective values. However, as income levels rise, entrepreneurial activities are valued for their contribution to fulfilling higher-order needs for self-expression, growth, and achievement.",0
61,11," 

In nations with greater wealth, we anticipate a broader appreciation for entrepreneurial efforts across the population. Given demographic diversity, as the economy expands and discretionary income rises among various subgroups, different market segments reflecting specific service or activity demands will surface. Hence, more people will recognize opportunities for entrepreneurship that align with their own values and skill sets. As noted by Blau (1987), societies with higher incomes offer more market possibilities beyond agriculture and mass production, and greater means for those with entrepreneurial inclinations to meet requests for customized, professional, and boutique offerings.",0
61,12," 

Although not the typical Hofstede (1980) measures of ""culture"" such as individualism and collectivism, we opted to include the values we used in this study as they are considered aggregate values that are closely linked to enterprising or entrepreneurial culture in other research. For example, Phelps (2007) used values like achievement, initiative, and interesting work, which are also included in our study. Gasse (1982) suggested that income is a significant motivator for entrepreneurs, and a high value is placed on money in the capitalist system, according to Hirschman (1977). However, this value may be less strongly associated with economic performance, as monetary transactions' basic material needs are less noticeable when incomes are high in terms of satisfying them.",0
61,13,"""The World Bank's World Development Indicators (WDI) is the source of measurements for the economic performance of over 200 countries and entities. This includes yearly observations on national output, demographics, and employment. Similar to past studies, per capita GDP (in constant dollars) is utilized as the gauge of economic performance.""",0
61,14," The coefficients estimated from models that include regional/cultural grouping dummies to account for region-specific factors that may be linked to economic performance are mostly similar based on Table 3, except for the impact of increased per capita gross domestic product on job challenge, which is now positive but not statistically significant. Greater economic performance boosts achievement, interest, and initiative. Table 4 has the regional/cultural group effects added to the regressions.",0
61,15," The study suggests that economic performance can impact the development of national enterprising culture. According to the findings, countries with higher increases in per capita output over the course of ten years displayed a stronger entrepreneurial mindset at the end of the decade, prioritizing job opportunities that allowed for personal achievement, initiative, and engaging work. It is notable that entrepreneurial values can shift rapidly in response to economic conditions, as seen in other research (Yang, 1986).",0
61,16," ""The impact of economic performance on entrepreneurial values varies, with income being less influenced by national wealth. This is because increased national wealth leads to more easily meeting material needs through income-based transactions. However, the importance of individual expression and personal development, which can be directly fulfilled by entrepreneurial activities, will become more significant.""",0
61,17,"
The study's results have the potential to clarify the reasons behind the movement towards individualism and self-expression after World War II. It has been suggested that economic growth and improved living standards worldwide have allowed individuals to engage in more expressive activities without being preoccupied with basic needs. The study found that countries with better economic performance develop more entrepreneurial values, while those with poor performance have less entrepreneurial values. This indicates that the global values shift should not be attributed to pro-market values spreading regardless of economic performance. However, any movement towards entrepreneurial values may easily be reversed during economic downturns.",0
62,1, The article aims to investigate if the concept of 'forensic culture' can be interpreted as an 'epistemic culture' similar to that of other scientific cultures. This is relevant in light of the National Academy Science's calling out of 'culture' as a root problem in U.S. forensic science. The author disagrees with the NAS's characterization of 'scientific culture' and proposes a preliminary exploration of a 'forensic culture' that seems to have distinct features not found in research science. A sociological analysis of 'forensic culture' is needed for effective reform suggested by the NAS.,0
62,2," The concept of 'forensic culture' as discussed in this special section and conference is multifaceted. Different authors analyze this term from various perspectives, including race, ethnicity, media representation of forensic science, and its influence on popular culture. However, in this paper, 'culture' refers to Knorr-Cetina's 'epistemic culture' or 'scientific culture,' as stated in a recent report by the U.S. National Academy of Science (NAS). The paper examines the possibility of using the term 'forensic culture' in conjunction with this notion of culture. Can we talk about a 'forensic culture' that creates scientific understanding? Would such a culture be distinct from 'scientific culture,' and if so, how?",0
62,3," The study assumes that sociology of science is a suitable approach to answer the question at hand. Sociology of science investigates the social process of knowledge creation and has collected empirical data on this process in recent years. However, most of these observations have been focused on ""research science"" instead of ""mundane"" activities like industrial or regulatory science, even though these activities may outnumber research science. In the past, science studies contested the idea that science is only high-level experiments and instead appreciated practical, hands-on scientific work. This line of research valued tacit knowledge, invisible technicians, and good hands.",0
62,4,"
While acknowledging that the distinctions between the categories of 'scientist' and 'forensic scientist' are oversimplified, there are many individuals who inhabit a space between the two. These liminal individuals include both those who work for forensic laboratories and those who work independently, dividing their time between casework and research. However, for the purposes of discussing a distinct 'forensic culture', their existence is ignored. The observations made in this paper about forensic culture may only partially apply to these individuals and their institutional settings.",0
62,5," There is another meaning of the term 'culture' which refers to multiple 'forensic cultures' that intersect with national cultures. My discussion primarily pertains to American 'forensic culture' but may apply more or less to other national forensic cultures. Different forensic disciplines may vary in ways that do not necessarily apply equally to all. Although some of my observations may derive from being a 'participant-intervener' in debates surrounding forensic science, my data primarily consist of texts.",0
62,6," Forensic science is often noted for the difference between scientific inquiry and legal truth-finding processes, where law must settle on a truth within a limited time frame, while research science recognises no temporal limits on inquiry. Forensic culture follows the former principle, but there are exceptions like cold case review and post-conviction litigation. However, there are broader differences between research science and forensic science regarding the specificity of their knowledge claims and the data they use.",0
62,7," Philosophers and sociologists have attempted to explain how scientists can make general knowledge claims by relying on converging lines of evidence from various scientific activities. Despite vast disagreement among scholars regarding how exactly these claims are made, recent debates have focused on how and when these lines of evidence become accepted as 'scientific knowledge'. The 20th century philosophy of science, as advanced by both Popper and his critics, has made significant contributions in this area of inquiry. The philosophy concentrates on the making of general statements about the natural world, thereby stressing the importance of the large amounts of data on which each scientific activity is ideally based.",0
62,8," Reproducibility, or replication, is an essential characteristic of science as it tests the generalisability of scientific knowledge claims. This concept has been heavily debated by both philosophers and sociologists. Sociologists argue that replication studies provide little social capital in the prestige economy of academic science, leading to a lack of replications being performed. Collins' notion of the 'experimenter's regress' demonstrated that no single replication experiment could definitively confirm a theory, as cherished theories could survive failures to replicate by positing ad hoc explanations, with no natural limit to scientists' ability to resort to such explanations. The role of replication in scientific knowledge development remains contested between philosophers and sociologists.",0
62,9," Verification, which is common in forensic science protocols, produces repeatability rather than reproducibility. Repeatability refers to repeating the analysis in the same laboratory with the same researchers and materials, while reproducibility refers to reproducing the original setup with different materials in another laboratory. Reproducibility is necessary to ensure universal results, but it is rarely possible in forensic knowledge claims.",0
62,10," The self-regulatory mechanisms that govern and maintain the production of scientific knowledge rely heavily on the perceived value of this ""currency"". Scientists are deterred from misconduct, such as falsification of results and plagiarism, due to the implicit threat of losing this value. In theory, this serves as society's guarantee of the validity of scientific claims. Prestige and reputation in the scientific community are therefore important factors in establishing trust in scientific knowledge, as they provide superficial markers of credibility.",0
62,11," Scientific peer review is often seen as adversarial because it requires reviewers to take a critical approach and look for flaws. While this may seem similar to the adversarialism found in Anglo-American legal systems, there are important differences. Journal referees are expected to be critical but not unreasonably so, while forensic science is often even more adversarial than research science due to the demands of an audit culture and the ethical obligations of defense attorneys to criticize scientific conclusions in legal proceedings.",0
62,12," To prevent unauthorized access to sensitive materials, various techniques could be utilized, such as limiting the amount of information recorded and keeping it confidential. For instance, details of internal disagreements within the laboratory are usually not documented, and records of errors are often not compiled or are not made publicly available. Obtaining such information may require a legal discovery process, which can be challenging as defendants may issue broad requests for information. However, such requests may be necessary to obtain crucial information about a laboratory's performance in a specific field, which would otherwise remain unknown.",0
62,13," Forensic scientists have more negative views about the adversarial process than scientists do about peer review due to their experiences, which are limited to being reviewees. Unlike academic peer review, where scientists serve as both reviewers and reviewees, forensic scientists only face the barrage of disparagement in adversarialism. Therefore, they rarely express true belief in the ideal of adversarialism as the best process for determining truth in a legal forum.",0
62,14," Forensic scientists tend to view adversarialism negatively because it can create problems for knowledge production. The idea that adversarialism weeds out bad theories or leads to better knowledge is not applicable in the forensic context. When scientists disagree on evidence interpretation, it can cause issues for the forensic laboratory. They must either report the disagreement, which undermines the evidence's value, or conceal it and be subject to accusations of lack of candor.",0
63,1," The following excerpt is a response to Birgit Meyer's book, Sensational Movies, where the author reflects on Meyer's argument about heritage being the dominant discourse in debates about religion and culture in the Ghanaian video film industry. The excerpt raises questions about the politics of representation and outlines the significance of Meyer's approach for understanding heritage. The author draws on observations about contemporary Ghana to discuss the dominant themes in Meyer's chapter, including chiefly authority, the 'epic' genre, and audience perceptions of traditions and culture. The conclusion emphasizes the importance of focusing on imaginaries, media, and mediation in the study of heritage.",0
63,2,"

The significance of heritage in Ghanaian popular cinematic culture is conveyed through the titles of movies like The Good Old Days, Heritage Africa and Spirit of Heritage. The entertainment industry in Ghana has linked heritage to the country's religious and cultural politics, neo-liberalisation of the state, and the rise of Pentecostal Christianity in the past three decades. This is different from South Africa, where heritage has been adopted by the government to aid in national healing and nation-building. Although it appears in South African popular culture to promote new cultural forms like the vuvuzela or to rename commemorative days like Heritage Day to national barbecue day. Birgit Meyer's study on heritage, culture, and tradition in Ghana prompts me to consider if the two countries have similarities in this regard.",0
63,3," <The debate surrounding the cultural and entertainment value of culture, heritage, and tradition is shaped by opposing views represented by the state and independent popular video filmmakers. The state's Cultural Policy emphasizes the production of African films or films made by Africans for Africans, that depict traditional and romantic images of Ghana and the continent. The filmmakers are encouraged to incorporate the philosophy of Sankofa promoted by Kwame Nkrumah, independent Ghana's first Prime Minister and President. However, the state's desired portrayal of good tradition and African culture has colonial and missionary roots, which contradicts the idea of distinct African culture and tradition being propagated. Heritage is viewed as a form of power that serves the interest of maintaining dominant institutions and conceals its own historical construction to appear natural.>",0
63,4," Independent filmmakers were not interested in portraying Ghanaian culture in a flattering light, but instead sought inspiration from popular imaginaries that included extraordinary and sometimes disturbing elements. They rejected the restrictive and boring portrayal of the past in favor of creativity, as evidenced by their dismissive reactions to the concept of Sankofa. Meyer, however, demonstrates the complexity of these ideas by delving into the relationship between culture and entertainment through her discussion of chiefs.",0
63,5," 

The chapter's conclusion delves into the epic genre, which takes a novel approach to exploring the distant past. Specifically, it centers on the timeless village way of life. This genre's aesthetic breaks from the dominant views on heritage and culture proposed by Sankofa as well as Western anthropological norms. According to Emeka Nwabueze, a film producer and set designer, the epic entails fashioning a new culture, tradition, and world from scratch. The objective of the epic is to display fictional cultures and traditions rooted in the past but that had not existed in reality. Moreover, the demand for entertainment compelled filmmakers to create rare and innovative cultures with distinct cultural repertoires for each film. Nwabueze stressed the need for uniqueness, where every movie tells a brand-new story and showcases novel dress codes, architecture, and dance routines revealing unheard of historical traditions.",0
63,6,"

The chapter is enthralling, and I plan to use my recollections of Ghana, accumulated during a convention I attended in 2010, to shape my reaction. Co-managed by Birgit Meyer, the Heritage Dynamics initiative brought together academicians and PhD students studying religion, anthropology, dance, performance, history, heritage, and museum studies. The seminar explored the aesthetics of persuasion and the politics of authentication, taking delegates across Ghana on a conversational tour of heritage, culture, and tradition. To discuss culture's mediation in Ghanaian videos, I want to draw upon three instances from that period and the theoretical equipment developed within the forum of the project.",0
63,7," The National Museum of Ghana was our next stop, located a short distance away. While focusing on the history, culture, and arts of the country, the museum appeared more worn down and the exhibits were considerably older than those at the Memorial Park. En route, we passed by significant landmarks such as the Independence Arch, Black Star Square, and the presidential palace, which had an imposing shape resembling a chiefly stool. This was a conscious attempt by Nkrumah to link traditional authority, particularly chieftaincy, with state power. Nkrumah sought to establish new material signs of independent sovereign authority by adopting the Black Stool, the State Sword, and the Linguist's Staff as symbols of state power. (Senah 2013)",0
63,8," The persistence of chiefly authority in Ghana is emphasized by Meyer and others. In regards to the city, the author questions what other tactics chiefs have employed to maintain their power, especially in urban settings where their influence seems to be declining. Additionally, the author considers the role of tradition and how priests and pastors of charismatic churches attempt to rationalize their spiritual authority in light of the revelations depicted in modern Ghanaian films. Moreover, the author wonders about the claims made by chiefs, aside from spiritual powers disrupting technology, to reinforce their authority.",0
63,9,"

We were instructed to take our seats on the dusty courtyard's outer edge, which would double as the performance stage. Young men played the drums rhythmically, while the lead priestess, Dashi, executed her routine, falling in and out of trance with the assistance of her female apprentices, despite reassurances. The compelling ritual show lasted well into the afternoon, causing a commotion among the touring group and prompting discussions about performance, trance, dance, staging, and authenticity that reverberated all the way back to Accra.",0
63,10,"
As I read about the genre of the epic, memories of my trip came flooding back. The cultural tradition we experienced was concrete and fully established, while the epic set designers and stylists were creating and inventing Ghanaian heritage as they went. They were bricoleurs, constructing cultures and traditions that did not exist before. These choices were a response to the dominant morals of religion and culture in the public sphere, but the epic still had its own politics of tradition and heritage. After reading Birgit Meyer's commentary on ""Mediating Traditional Culture,"" I'm left to ponder what institutions and powers enable and sustain this new cinematic genre.",0
63,11," As we arrived at Cape Coast Castle, a group of eager children rushed towards us, asking for our names and shoving scraps of paper towards us. Reluctantly, I wrote down my name and made my way through the crowd towards the white-washed precinct. This former colonial outpost was a crucial site for the intercontinental slave trade, with distant authorities using it to administer commercial and sovereign affairs and ship off countless black bodies to the colonies. Its scale and importance reminded me of the Castle of Good Hope in Cape Town, South Africa, which was built by the Dutch to protect their commercial and colonial interests.",0
63,12," It is similar to how we questioned the authenticity of the door, I am curious about whether video-film audiences doubt the genuineness of representations of tradition in popular videos. The way that religious and spiritual authenticity is portrayed in films may influence viewer reactions to ritual objects. I am interested in understanding why audiences perceive tradition in this particular way. In other words, if the door of no return holds a physical sense of historical proof, what language do viewers use to interpret representations of tradition as convincing in popular video films?",0
63,13,"

The door of no return acts as a gateway into a popularized interpretation of the past. Peering through it is akin to glimpsing into a present-deliberated version of history. It also serves as a partition between the physical and the intangible. How do we acknowledge these interactions? 'Mediating Traditional Culture' equips us with a superb collection of theoretical tools by examining the correspondence between the imaginary, values shared by religion and culture, and the material world. This prompts us to embrace various forms of heritage production and implementation by placing emphasis on material evidences. By concentrating on the imaginative, it also allows us to evaluate how material evidences from the past are disseminated and develop into socially accepted frameworks of meaning. Therefore, 'Mediating Traditional Culture,' and together with the book, Sensational Movies, furnish us with a compelling and riveting theory to deal with present-day representations of the past.",0
63,14," Duane Jethro currently works as a post-doctoral fellow in the Archive and Public Culture Research Initiative located at the University of Cape Town. He is a former student of the University of Utrecht, and his thesis focused on exploring the connection between heritage, materiality, aesthetics, and the senses in post-apartheid South Africa. His written works have been published in a variety of publications, including Material Religion, African Diaspora, and Tourist Studies.",0
64,1," The formation of collective meaning through social processes is a topic explored in both organizational culture and institutional theory. To better understand how cultural aspects become embedded and transmitted, this paper uses DiMaggio and Powell's three isomorphic processes to examine acquiescence and resistance to cultural pressures. Additionally, the role of power usage, subcultures, and forms of resistance are discussed through Oliver's deinstitutionalization thesis. By applying isomorphic processes to organizational culture, the authors aim to bridge the gap between micro and macro theory and suggest future areas of research.",0
64,2,"
Institutional theory primarily focuses on how external forces shape an organization, while organizational culture centers on how internal processes create shared meanings and values. These approaches share ideas about persistent behavior patterns and collective processes. Although Pedersen and Dobbin examine how institutional pressures affect culture, they don't discuss culture's spread and maintenance. This article goes further by analyzing how coercive, mimetic, and normative pressures maintain culture and how deinstitutionalization creates resistance to isomorphic pressures, subcultures, change, and power within organizations.",0
64,3," Institutional theory has been explored in various ways by DiMaggio, Powell and Scott. Its central aim is to explain the uniformity of structure, culture and output among organizations operating in the same field. This uniformity, known as isomorphism, pertains to operational domains, organizing principles and evaluation criteria. External social-cultural values and beliefs significantly influence organizational norms, and compliance with those norms is facilitated by normative, coercive and mimetic processes. Organizational fields play a critical role in shaping organizational forms, processes and beliefs. Institutionally derived structures and processes may be unique to specific fields or domains, and conformity is promoted through various processes.",0
64,4," Institutional norms can be enforced through coercive processes, as seen in regulatory environments imposed by the government. Organizational behavior is governed by formal and informal processes that explicitly or implicitly prescribe acceptable conduct. When organizations violate group norms, they can face formal retaliation such as suspension or expulsion from industry groups.",0
64,5," Organizations often rely on mimetic processes when faced with uncertainty, particularly when dealing with environmental problems that are poorly understood, unknown or highly ambiguous. By mimicking the structures and processes of successful organizations, they provide themselves with viable solutions while avoiding costly efforts to understand the relationship between inputs and outputs. This risk averse strategy increases the certainty of organizational outcomes and can be actively pursued or simply taken for granted. (Kondra and Hinings 1998).'",0
64,6," Institutional theory researchers have expanded their focus beyond norm maintenance, to include critiques regarding adaptation to change and strategic decision-making within the initial framework that primarily explained stability and isomorphism. Evidence of academia's increasing interest in exploring uncertainty, cultural reproduction, and change within institutional theory can be found in The Academy of Management Review's special issue from February 2002.",0
64,7," Organizational culture is difficult to define or explain, and scholars have created diverse explanations rooted in different theoretical disciplines and assumptions (Alvesson 2002; Martin 1992, 2002; Martin and Frost 1999). A lack of consensus exists due to fundamental ideological and theoretical disputes within the literature (Alvesson 2002; Martin 2002).",0
64,8," There is a commonly used perspective on organizational culture that comes from Berger and Luckman's work from 1967 on the cognitive and symbolic aspects of organizational life. In the past, organizational theory research had focused on quantitative approaches and overlooked the influence of emotions, beliefs, values, and interpretation of roles. Early research on organizational culture aimed to fill this gap and provide a more qualitative understanding of culture that could explain seemingly irrational behaviors. Peters and Waterman's 1982 book, 'In Search of Excellence,' demonstrated how strong and unified cultures of successful organizations are established and maintained through physical artifacts, symbols, ceremonies, stories, slogans, dress, and settings.",0
64,9," The cultural reproduction at the organizational level assumes that the business environment largely informs it, with some cultural elements being used or manipulated to improve organizational performance. Value engineering or an integrative organizational approach is considered by some as a managerial perspective, while others argue that some cultural elements cannot be manipulated due to sublimated, shared meanings. Tangible elements like buildings, logos, policies, and written procedures are alterable, unlike sublimated and/or taken-for-granted cultural elements. The assumption that engineered cultural beliefs arise and are reproduced within organizations as determined by the business context alone disregards the interpretive role of individuals or complexity within resident cultural elements. The study of culture becomes highly complex due to the confluence of tangible artifacts, environmental determinism, value engineering, shared meaning creation, and voluntary action impacting culture.",0
64,10," Organizations have different segments that create distinct subgroups of people with related tasks and roles, which can result in segregated sub-universes of meaning. Sub-cultures can exist within an organization, which may undermine the overall cultural views. These sub-cultures may be influenced by external professional cultures, and their members may interpret information differently from others in the organization. Sub-cultures can perpetuate different and sometimes opposing viewpoints from the overall culture, resulting in varying frames of mind among different members. (Berger and Luckman, 1967; Van Maanen and Barley, 1985; Elsbach, 2002).",0
64,11,"

Martin (1992) proposed a conceptualization of culture based on integration, differentiation, and fragmentation, while Hardy (1994) explored various forms of power. These perspectives reveal how individuals with different cultural experiences and mindsets can have distinct interpretations. Critical theorists, unlike integrationists, view power relations in certain cultures as problematic and explore how power is embedded in rules, policies, and procedures. Consequently, culture determines the exercise and experience of power.",0
64,12," Different aspects of culture are reproduced by instrumental, symbolic, and embedded power, which vary depending on the frame of reference. For instance, instrumental power linked to resource access generates uneven resource distribution, affecting others (Hardy 1994). Furthermore, vertical authority, such as the ability to reward or punish, and lateral power, like specialized expertise or referent power, both have persuasive and influential capabilities. Symbolic power, on the other hand, is culturally-based and allows one to achieve preferred results while avoiding conflict (Hardy 1994). Language, ritual, and myth as cultural symbols play a role in legitimizing the exertion of symbolic power.",0
64,13,"Culture shapes individual identities through the power embedded within an organization's structures and processes, which does not require deliberate activity to mobilize. Therefore, different cultural frames of reference are created, allowing certain individuals to wield various forms of power and have a different experience from those in more dependent roles. (Adapted from Hardy, 1994).",0
64,14," Martin's (1992) research extends beyond frames of reference, allowing for the practical exploration of various perceptions of culture from diverse viewpoints. For instance, we can compare the outlooks of a manager, union officer, or CEO, each of which is equally valid, drawing on different cultural artifacts and power sources, both symbolic and physical. In each instance, meaning is generated by those who perceive and encounter the distinct culture or sub-cultural manifestation, transferred to others, and regenerated in the same or modified form via systems of symbolization or socialization.",0
64,15,"

Cultural nesting is used by Erez and Gati (2004) to explain how organizational culture is comprised of multiple perspectives. They propose that lower levels of culture are embedded within higher levels, meaning that change at any one level impacts all other levels in different directions. Schein's (1990) work on culture is referenced to demonstrate how external and internal aspects of organizational culture shape values and beliefs about human nature. Culture is learned and transmitted through social learning, role modeling, and observation which helps organization members cope with external and internal pressures. However, culture also adapts to its context, indicating that the structural and dynamic dimensions of culture are reciprocally related. Cultural nesting allows for the understanding of the interactions and distinctiveness of multi-levels of culture that contain both structural and dynamic characteristics.",0
64,16,"
Erez and Gati's (2004) contribution to the definition of culture involves the concept of nesting, which explains how different aspects of culture are formed, adopted, shared, obstructed, or altered across various levels, subgroups, and locations. According to the structural dimension of cultural nesting, culture exists at different internal levels, beginning with individual beliefs and values, and progressing into larger groups, departments, organizations, and even nations. The dynamic aspect of cultural nesting highlights the complex interplay of relationships that exist between these levels, and the various impacts that changes at one level may have on another. For example, globalization may require top-down changes in behavior through structural modifications, which are then supported by socialization and sanctions. However, changes in individual behavior may also play a role in shifting shared values and moral expectations from the bottom-up. Overall, culture is a dynamic process that evolves as it interacts with other nested levels of culture.",0
64,17," The notion of one-way cultural flows is problematic according to Erez and Gati's nesting model. The question arises as to how cultural manifestations can regulate and prescribe organization-wide behaviours without any sign of conflict. Moreover, Schein's idea of passing culture through stories, rituals, rules and procedures is debatable, as culture mainly operates through underlying values, ideas and assumptions. Culture comprises both visible behaviours and artefacts, as well as the unseen aspects related to tacit assumptions and values. (Erez and Gati 2004).",0
64,18," Culture can either be seen as a result of rationalized organizational actions, routines, or myths that lead to the formation of organizational carriers, or it can be viewed as something that creates and reproduces itself through the use of cognitive, structural, and routine carriers. Scott (1995) examines whether culture is created by or creates cognitive carriers, individual perceptions, and behaviors. For instance, a new employee may face different cultural carriers and conformity pressures when entering alone compared to joining a group as part of a merger.",0
64,19," Socialization can occur either through formal training or individualized learning. The process of socialization not only maintains the existing culture but also adapts to new cultural identities. The transmission and maintenance of culture is influenced by various factors, including external and internal organizational factors. Culture is sustained through socialization, selective recruitment, and developing a shared sense of identity. All of these factors help to strengthen interactions and networks within the organization.",0
64,20,"

Organizational culture that is nested refers to a situation where socially shared understandings are created through routines, interactions, and procedures. These understandings are then taken for granted and remain relatively stable. Culture is experienced through routine behaviors, dominant philosophies, norms, and rules of conduct. This is in line with Scott's concept of routine, structural, and cognitive cultural carriers. To reduce ambiguity and increase regularity and predictability, behavioral expectations, norms, and rules are communicated explicitly and tacitly to members of an organization. Explicit cultural elements can be observed in physical artifacts like policy manuals, collective agreements, and procedures. Some organizations rely on written rules that rely on coercive methods, while others depend on shared values and norms for enforcement.",0
64,21,"Culture encompasses both static structures and fluid processes. Similar to institutional theory, culture aims to elucidate how societal meanings are constructed and sustained. The crucial factor is achieving a delicate equilibrium between cultural homogeneity and heterogeneity, as well as comprehending the capabilities of both structure and change.",0
64,22," 

Institutionalized practice is at the core of on-going cultural reproduction. The process of developing and sustaining an appreciative orientation, improving upon existing cultural ideas, and occasionally dismantling or re-institutionalizing is vital. Isomorphic processes play a significant role in transmitting meaning, constructing reality and maintaining culture. Institutionalization serves as both process and property wherein social reality is defined by the established norms and individuals act accordingly to become part of an institutionalized culture. Polymorphism and ideas from Oliver's thesis of deinstitutionalization provide a deeper understanding of counter-cultural movements, prevention of cultural transmission, and agency nested in culture. Investigation of tensions among sub-cultures and change resistance are crucial for developing a dynamic understanding of culture.",0
64,23," While institutional theory traditionally views norms as originating from sources external to the organization, the application of institutional concepts to cultural phenomena is not a new idea. Many notable authors have acknowledged the relationship between institutional theory and organizational culture. Scott (1987) posits that there is a two-way interaction between institutional theory and culture, while DiMaggio and Powell (1983) discuss the influence of normative pressures on individuals within an organization. Furthermore, key surface elements of culture such as personal style, language, and communication have been identified as integral to organizational culture (Schein 1990).",0
64,24," According to some writers such as Chatman and Jehn (1994) and Pennings and Gresov (1986), there is a connection between organizational culture and industry characteristics. If institutional theory is correct in stating that industry characteristics are institutionally driven, then these studies suggest that institutionalization at a macro level impacts organizational culture. While Chatman and Jehn (1994) propose that organizations strive to replicate successful cultures instead of creating unique ones for competitive advantage, these works highlight the potential for institutional theory to clarify aspects of organizational culture.",0
64,25," Although there have been connections made between industry traits, organizational culture, and institutional theory in the past, there seems to be a lack of explicit integration between DiMaggio and Powell's (1983) three isomorphic forces and organizational culture. Our article aims to address this by examining how isomorphic processes (coercive, mimetic, and normative) contribute to the transmission, replication, and preservation of organizational culture through various aspects of intra-organizational institutionalization.",0
64,26," Table 1 portrays both formal and informal coercive pressures for cultural conformity. Formal pressures, which are sanctioned by the organization, involve rewards or punishment for specific behaviors and may require coercion. Human resource systems can be effective in communicating organizational culture and shaping behavior through rewards and sanctions administered during performance appraisals and disciplinary processes. These pressures are similar to regulations or market inducements that reward certain organizational activities. Efficient implementation requires clearly defined behavior expectations and well-defined linkages between expected behavior and rewards. Examples of this are individuals paid by piece rate or commission.",0
64,27,"

Rewarded behavior can differ among organizations, industries, and jobs based on institutionalized cultural values and behaviors. Investment banking has strict values and behavior norms with easily measurable outcomes, while the consequences of unsanctioned behavior can be significant. Barings Bank's example highlights the need for rigid control and formal or structural controls when normative controls are insufficient. Social and coercive controls often replace one another.",0
65,1," The idea of culture has been present in the literature on educational leadership and management since the 1970s. However, there has been little exploration of how leaders can influence culture and the ethical implications associated with it. Leadership must recognize culture as a powerful mediator within organizations and address it accordingly. The article proposes four levels of cultural activity: global, community, organizational, and sub- and counter-cultures. Leaders need different skills to navigate multicultural issues versus organizational culture, and their approach to culture is determined by the degree of perceived difference from norms. The focus on aligning to a single culture may perpetuate inequalities, and a deeper engagement with the complexity of culture is necessary.",0
65,2," Educational leadership has been exploring the nature and significance of organizational culture since the 1970s. Despite criticisms of its inadequate conceptualization and practical application, the concept has remained entrenched in the literature. While some may consider culture outdated, its enduring popularity can be seen in its continued use and frequent reference in texts related to educational leadership.",0
65,3," It is indeed a daunting task to review the use of the concept of culture over a span of 40 years, given the extensive literature available. However, it is important to do so as the persistence of the concept implies that it serves a necessary function. Moreover, culture is deeply connected to the unequal experiences of learners and is hence relevant to the goal of educational leadership that emphasizes social justice. As Schein (2011: xi) notes, almost every manager or scholar acknowledges the significance of the concepts of climate and culture. Therefore, it becomes imperative to examine the concept of culture and explore how it can enhance our understanding.",0
65,4," ""The article provides a brief overview of how culture has been studied in the context of educational leadership. It discusses the different lenses through which culture has been conceptualized and its historical significance. The article also examines how culture operates in educational organizations and its impact on practices. Furthermore, it places the study of culture within a broader context that includes issues of multiculturalism and organizational culture. The article concludes by emphasizing the importance of leaders deeply engaging with culture to promote social justice.""",0
65,5," The aim is not to provide guidance on culture management, but rather to deconstruct what appears uncontroversial in educational leadership literature. The goal is to create a sense of uncertainty so that people are forced to question what they previously took for granted, which can be problematic, challenging, and possibly hazardous. The purpose of this article is to disrupt the existing relationship between leaders and culture, rather than to offer a blueprint for action. Instead, it aims to give leaders a more profound comprehension of the issues at hand and a revised agenda to reflect on their own path forward, with social justice as their primary concern.",0
65,6," It is possible to analyze the academic development and practical implementation of culture through various frameworks, such as disciplinary, chronological, ideological, and methodological. This brief overview cannot fully illustrate the intricate history of cultural studies. Different disciplines offer unique perspectives, with anthropology focusing on scientifically describing individual societies, cultural studies examining power struggles within society, and psychology exploring the impact of culturally determined patterns on thought and behavior. Despite the undeniable richness of these fields, management and educational leadership have often borrowed from them in superficial ways without fully embracing their rigorous methods and concepts.",0
65,7," The passage discusses an ongoing ideological debate regarding the emergence of corporate culture and its impact on the power dynamics between managers and employees. Bates argues from a critical perspective that corporate culture has given managers a dominant role through the use of various forms of power. Contrary to popular belief, Bates suggests that culture is not simply a set of shared meanings but rather a complex negotiation process that includes rebellion and power struggles. (Bates, 2006:160).",0
65,8,"

Culture study involves methodological differences, with quantitative researchers relying on statistical analysis of questionnaire responses to comprehend and influence culture or climate, while qualitative researchers require ample, detailed data for progress. Even within each group, there are further sub-groups with differing approaches. Ethnographers, for instance, prioritize participant observation for understanding culture. However, there is still a feeling of dissatisfaction with research results and an inability to fully capture an organization's culture. The issue, according to Archer, is the absence of analytical units to differentiate cultural components, with cultures still being viewed as a whole. To move forward, better analytical tools are required.",0
65,9,"

There have been efforts to provide analytical frameworks. Deep culture, the unspoken and unconscious shared values of many members of an organization, and shallow culture, the obvious indicators of culture or the actions of the members, are distinguished by Hofstede (1984). Bates (1987) compare the prominent culture, examined horizontally throughout the organization, with sub-cultures and counter-cultures perceived as extending vertically through the organization. Prosser (1999: 7) provides a classification of ""wider culture"" (the national and international context), ""generic culture"" (of educators as a profession), ""unique culture"" (the unique culture of a school), and ""perceived culture"" (the culture viewed internally and by those who assess the school from outside) in relation to schools. None of these frameworks have been commonly used in education.",0
65,10," 
Culture studies tend to attract metaphors, creating imagery that strives to illustrate the essence of cultural concepts and instances. Examples of metaphors include comparing culture to computer bits, compasses, social glue, or pixels in a picture. Specific instances of school cultures may be described using metaphors such as the shopping mall school, or categorized into one of Stoll and Fink’s five types of school cultures: moving, cruising, strolling, struggling, or sinking. However, it is important to recognize that metaphors can contribute to imprecision in thinking and create the illusion that complex educational organizations can be fully captured by a single word or phrase.",0
65,11,"Some individuals use a broad, overarching description such as ""the unique and particular way of existence"" (Sparkes, 1991: 5) or the renowned phrase coined by Bolman and Deal (1991: 252) ""the way we conduct ourselves in this place."" The majority of explanations, however, make mention of a noticeable routine in human conduct within a specific physical context.",0
65,12,"

Despite the lack of widespread agreement on defining culture or establishing units of analysis, it may be tempting to dismiss the vast amount of literature on ""culture wars."" Some have even suggested abandoning the concept altogether in favor of other theoretical frameworks. However, culture remains a powerful force that shapes the options for thought and action within educational organizations. Leaders must work with culture, whether they acknowledge it or not, and even ignoring culture is still a cultural choice. Therefore, rather than attempting to define culture, leaders should focus on understanding and influencing it, recognizing that culture plays a significant role in an organization's performance.",0
65,13,"

The connection between education and organizational culture has been established as far back as the 1930s as noted by Waller in 1932. By 1987, a comprehensive understanding of school culture was presented by Erickson. While initial research in the 60s and 70s centered largely around quantitative studies of climate and school effectiveness, by the 80s, this had evolved into a broader range of research methods, as suggested by Prosser in 1999. From the 1970s, the British Educational Index shows a widespread use of the concept, with its use increasing exponentially through the years. Culture is shown to be a unique phenomenon that is present in various socio-economic classes, education sectors, organizational settings, and professional groups. The culture of a subject's curriculum or classroom is also widely recognized across organizations. The overall idea of culture is nuanced, with some terms being positive or negative, such as a learning culture, an audit culture, or an examination culture.",0
65,14," The correlation between culture and organizational performance is widely believed. This belief stemmed from the promotion of culture as a performance-enhancing tool by corporate evangelists like Peters and Waterman in the 1980s and 1990s. This concept has been eagerly embraced in the education sector, with many adhering to the notion of a charismatic leader who can transform a school's fortunes by influencing its culture. Nonetheless, some experts have cast doubt on the evidence supporting the linkage between culture and performance. Despite this, the importance of culture as a key factor in an organization's success has remained entrenched among educators and researchers.",0
65,15," The literature on culture in EMAL and other sources may reflect the approach of many educational leaders. The articles in EMAL that mention 'culture' can be categorized into two groups - a small portion that concentrates on defining and analyzing organizational culture in detail, and a large majority that use culture in vague terms, such as referring to organizational context or a general method for a specific area of activity. The most common approach to culture is to mention a single organizational culture as an ambiguous context, refer to as cultural wallpaper or background culture music. Although some authors mention changing culture, there is little discussion on how this could be interpreted and the ethical consequences of doing so.",0
65,16," The normative prescriptions for educational leadership have a strong integrationist ideological perspective that is deeply ingrained. The UK National College for School Leadership recommends producing a clear vision to establish a strong culture, and case studies suggest that a strong leadership culture is desirable. However, the integrationist perspective assumes that all organizations can unite behind a single benign culture that supports learners' interests, which is doubtful in light of evidence that schools and colleges do not work equally well for all learners. Each school or college's dominant culture is likely to favor some and disadvantage others, implicating culture in the modulation of power.",0
65,17," Organizational culture, as described by Lukes and Lakomski, can be seen as a form of covert power that shapes ways of thinking and acting. This cultural influence is not enforced through obvious coercion, but instead creates boundaries and penalties for those who transgress them. This aligns with Bachrach and Baratz's concept of the mobilization of bias, where one group's values and interests are privileged through subtle means. Culture is a pervasive force that cannot be escaped or easily changed, and is a defining point of reference for individuals and organizations. As such, it is a crucial factor for leaders to consider, and can be a powerful tool for promoting social justice.",0
65,18,"The impacts - both positive and negative - of globalization are the subject of much debate, with some even questioning if it exists at all. However, there is widespread apprehension about the ways in which advancements in technology and communication have altered economic and political interactions, leading to a fundamental change in the relationship between education and the state (Apple, 2000). This new dynamic has trickled down to schools and universities, influencing the prevailing mindset and shaping what is deemed achievable.",0
65,19," The culture of local communities is an important area for educational leaders to consider. Lee (2008) suggests that external cultures strongly influence the progress of learners. However, teachers' perceptions of these external cultures are shaped by their professional acculturation. For instance, Erickson (1987) describes professional assumptions surrounding the innate nature of ability and the need for schools to compensate for family deficits in language and reading development. These assumptions may be culturally specific and contested. Cultural influences may also impact goals, such as Quiroz et al.'s (1999) example of a Latino parent's negative response to their child's outstanding work, which may be viewed negatively within collectivist cultures. These external cultures can affect students' attitudes and practices and also shape educators' assumptions and value judgements surrounding them.",0
65,20," To alter results for numerous learners, both the internal and external cultures or the connection between the two may require modification. Educational leaders may need to influence community cultures or shape their internal culture to lessen friction between the two. Pe ́rez Carreo ́n et al. (2005) describe the cultural tensions between immigrant parents and their children's school in the USA, emphasizing the necessity of establishing a relationship built on trust to facilitate genuine communication and interaction between cultures. Kincheloe and Staley (1985) state that Native American learners who find school culture so unfamiliar that they feel no connection between school and home are likely to fail. On the other hand, other students consider them as two distinct options and transition between them, while some students see home and school as culturally alike and experience minimal disjunction. The values in the dominant organizational culture and curriculum are more closely connected to the middle or upper socio-economic class of policymakers and teachers (Ara ́ujo, 2005; Lumby, 2012).",0
65,21," Cultural markers, known as statements of vision or mission, serve as public testimony to the educational equivalent of a corporate culture. They generally pledge to unlock the potential of every student and are often found within a broader culture that heavily promotes positive and optimistic attitudes in a performative setting.",0
65,22," Cultural factors influence assumptions about thinking and learning, curricula, teaching, and assessment, resulting in minimal radical changes during periodic reviews. The value placed on vocational education varies between countries and cultural backgrounds, reflecting local cultural values. Despite being ineffective for many out-groups, the accepted technical processes of ""good"" teaching and assessment remain the gold standard. This mechanism of cultural dominance is often supported by out-groups, and disciplinary measures are frequently used to address children's resistance to curricula without considering their perspectives.",0
65,23," 

Groups centered around the various identities of staff and learners, such as their subject specialization, tenure, or geographic location, contribute to the cultural foundation that supports quasi-corporate cultures. These groups are typically led by an individual who sets the cultural standards for behavior, attitude, and territorial boundaries, as noted by West (1999). It's possible that group cultural norms could result in automatic resistance to any head teacher or teacher's requests.",0
65,24," Becher's (1988) comparison of a theatre stage might describe how sub-cultures operate. The corporate culture's symbols and rituals are displayed on the open stage, where everyone can see them. However, backstage there are less obvious behaviors that are concealed from public view, while understage activity is hidden even from the primary actors. Spaces, uniforms, and meetings are examples of what occurs on stage. Backstage, there are more covert cultural tactics like controlling who is allowed in. Countercultures compete and oppose the institutional norms in tumultuous under-stage scenarios. The power dynamic between students and staff is visible in the many planned and unintended acts of resistance that either try to reinforce or weaken cultural limitations. (Prasad and Prasad, 2000; Van Houtte, 2005).",0
65,25," Each group fulfills the psychological needs of its members by providing protection and self-validation, with a main focus on achieving status within the group and in relation to other groups by conforming to the group's norms. Adolescent gangs in schools are cultural groups that establish unique criteria, such as toughness or risk-taking, to compensate for a lack of academic success. While the article does not delve into the culture of learners' gangs or professionals, it is clear that the underlying motivation for such groups is to feel secure from psychological or physical harm and to receive recognition and appreciation. Leaders who seek to steer sub-culture groups in a particular direction must consider whether the proposed course of action respects the group's cultural choices or defies them. Demonstrating ""care"" in a way that disrespects or disagrees with a learner's cultural choices is an ineffective response to the power of their group culture.",0
65,26," Education leaders may face a greater challenge when adopting a differentiation perspective and engaging with sub-cultures and community cultures compared to dealing with a single organizational culture. To gain a comprehensive understanding of an organization's multiple and evolving cultures, Bryson (2008) proposes using Williams' (1980) analysis of dominant, emerging, and residual cultures. Residual cultures are those that remain from an earlier time, while emerging cultures are those in formation. Both residual and emerging cultures can either present alternatives to the dominant culture or be actively in opposition to it. Bryson recommends collecting data from various sources, both internal and external, to recognize the residual and emerging cultures from multiple perspectives. This approach will bring a better understanding of culture as a dynamic and contested phenomenon, rather than a static and uniform reality.",0
65,27," In managing culture and responding to its impact, the educational leadership and management literature of the past 40 years has revealed a lack of emphasis on the skills necessary to influence organizational culture. Instead, the focus has been on developing competency in dealing with 'multi' cultural issues related to the increasing diversity, particularly with regards to ethnicity, among students and educators. There is also an interest in 'internationalization' which has led to interest in 'inter' cultural issues. The engagement with 'culture' is perceived in different ways depending on whether one adopts a multi-cultural or integrationist perspective. The former emphasises the need to develop a specific cultural competence to accommodate the cultures that differ the most from the norm, such as those of ethnic minority students, while the latter does not require the same level of cultural competence.",0
65,28," There are various possible explanations for the divergence in attitude observed. One viewpoint suggests that minority ethnic cultures are distinct enough from the mainstream culture to require efforts to comprehend and acknowledge their diversity, so as to ensure inclusion of minority students and staff in the wider community. In addition, maintaining a strong organizational culture can promote positive values and attitudes related to learning and citizenship for all. However, an alternative interpretation posits that both ends of the spectrum seek to exert control over cultures perceived as being different, albeit in subtle ways. The degree of attention paid to understanding minority cultures and the willingness to modify existing practices may reflect the level of perceived threat posed.",0
65,29," Organizational cultures may not be completely under the control of leaders, but they can be influenced to some extent. It is crucial for leaders to determine the direction of this influence, which poses a moral challenge. While facing conceptual and methodological limitations, leaders must acknowledge that certain disputed concepts are inevitable. Culture may fall into this category, but it is important to engage with it rather than leaving it on the sidelines. However, engaging with culture requires a critical perspective that is currently lacking among educational leaders. Ignoring culture is essentially a decision to uphold the status quo, and this perpetuates harmful inequalities. Ultimately, culture holds significant potential to either benefit or harm an organization.",0
65,30," In accordance with this viewpoint and a belief in the ongoing negotiation of culture and community, this particular article does not provide a formula for establishing a robust culture or for re-culturing education. Rather than advocating for swift action, the author advocates for an integrationist perspective that focuses on understanding one's own culture and its relationship with alternative and oppositional cultures within the organization. Although it may not be feasible to fully comprehend the varied and occasionally conflicting cultures within an organization, it is advantageous to strive towards greater comprehension and engagement. There is currently a divide between research-based knowledge and impact, although the author believes that knowledge and understanding alone can incite change.",0
66,1," Psychologists have mainly examined the differences in individualism-collectivism of East-West cultures, but there are various other dimensions of cultural variation that remain unstudied. The author highlights religion, socioeconomic status, and regional location within a country as examples of understudied cultures with noteworthy psychological variations. It is suggested that widening the field of cultural research would expand psychologists' understanding of multiculturalism and cultural specificity. This, in turn, would impact clinical concerns, intergroup relations, and practical domains.",0
66,2," The theoretical tradition has contributed greatly to advancing the psychological understanding of culture. However, it has certain limitations, such as the emphasis on geographic or ethnic variation in self-construal. Hui and Yee (1994) pointed out that the concept of individualism-collectivism is often used to explain cultural differences even though Oyserman et al. (2002) found that these differences were not as pronounced as previously thought, and student samples may not represent the general population. Additionally, there is a tendency to equate culture with country, leading Triandis (1995) to emphasize that countries are not synonymous with cultures. Nevertheless, Triandis's concept of cultural syndromes is applicable to people who speak a certain language, live in a particular country during a specific period, and share certain attitudes, beliefs, and values. (Triandis, 1996)",0
66,3," Despite sharing a language, a historic time period, and a geographic region, a Southern Baptist male from Sacramento, a Sephardic Jewish grandmother from San Francisco, and an agnostic Chinese American student at the University of California, Berkeley could differ in their most significant attitudes, beliefs, norms, or values.",0
66,4,"

The article aims to encourage psychologists to study various types of cultural variations. One question that motivated this article is how an American male Jew, who speaks English, relates culturally to his Yiddish-speaking great grandmother from Eastern Europe or to a Hebrew-speaking Jew living in Israel. Despite speaking different languages and being separated in space and time, there may be some shared cultural practices such as reciting the same prayers, observing similar holidays, and having similar views on food. Additionally, the article suggests that some cultural differences may exist, such as certain aspects of individualism being more prominent in American Jews and Christians than in Israeli or Eastern European Jews.",0
66,5," The paragraph discusses various cultural influences that can be viewed as cultural identities, such as religion, socioeconomic status, and region within a country. These three types of cultural variation are chosen because they have distinct group affiliations and cultural dynamics, have been extensively explored in psychology as cultural influences, and are especially influential in shaping norms, values, beliefs and behaviors.",0
66,6," James did not intend to present a complete definition of religion, instead he viewed it as a collection of various occurrences. The emphasis of Varieties of Religious Experience was on subjective, transformative encounters, and the definition was designed specifically for the lectures.",0
66,7," Members of different religious groups exhibit differences in various psychological processes, even within a single country. An elegant study focused on cultural differences between Calvinist Protestants and Catholics in their work contexts. The researcher, Sanchez-Burks (2002), based his theory on highly developed Calvinist values of finding a calling in work. Participants were asked to wear shirts and ties and discuss business costs or wear Hawaiian shirts and play card games to create a work or casual frame of mind. In the work context, Calvinist Protestants were less attentive to relationality and could ignore emotional tones to focus on the meaning of words, while other religious groups did not show variations. In a nonconscious mimicry experiment, Calvinist Protestants did not mimic foot-shaking behavior in a work context but did in a casual context. Such cues had little effect on members of other religions.",0
66,8," Religious cultures vary in their definitions of religiosity. Some religions prioritize orthopraxy (practice) while others prioritize orthodoxy (belief). In Judaism, adherence to Jewish law is the primary indicator of religiosity, rather than strictly believing in God. However, belief in God still holds a significant role in Jewish culture. In contrast, for born-again Christians, both belief and practice are essential for measuring religiosity. Studies have shown that both factors contribute to self-rated religiosity in Christianity.",0
66,9," In terms of moral judgment, there are notable differences between religious cultures. Christian doctrine considers immoral thoughts to hold the same moral weight as the actions themselves, citing Jesus’ statement in Matthew 5:28. However, in Judaism, thoughts about immoral actions are not regarded in the same light as the actions themselves. For instance, Jews place less importance on thoughts about having an affair or being cruel to animals than Protestants. Although Protestants view immoral thoughts as more likely to result in action than Jews, this is not the reason why they assign more moral significance to thoughts. In fact, even thoughts about highly improbable immoral actions are deemed more immoral by Protestants than by Jews.",0
66,10," Theology plays a critical role in shaping the nuanced tendencies of different religious groups. According to the Jewish Talmud, God does not view an intention to commit an immoral action as morally consequential, but does consider an intention to perform a virtuous act as commendable. This is because Jewish scholars believed that people would overcome their evil intentions when given the chance to act on them, but would cultivate and act on their inclinations to do good. Therefore, Jews assign as much moral credit as Protestants to thoughts about highly virtuous actions such as giving a large sum of money to charity. While it is unlikely that Jewish individuals have directly read discussions on these issues in the Talmud, Cohen and Rankin argue that Jewish culture contains such notions.",0
66,11," The Task Force on Socioeconomic Status of the American Psychological Association (2007) recently emphasized the significance of disparities in socioeconomic status and social class on human development, physical health, and well-being. Poorer individuals tend to exhibit more adverse development outcomes, lower well-being, and worse physical health. These differences are commonly defined by several factors, including education, income, and occupational prestige. Subjective social class, or an individual's self-esteem of social class, is also considered by many researchers. This perception may not correlate with the objective conditions, such that one individual with a lower income may perceive themselves as belonging to a higher social class than someone with higher income. Socioeconomic inequity and class differences may include factors like social capital, privilege, and power, besides material resources.",0
66,12," Psychologists have focused on the impact of socioeconomic status and social class on areas like health and well-being, but they haven't always considered the various cultural beliefs and practices of people from different social classes. Just like religion affects people's values and norms, culture plays a role in shaping how people view the world. For instance, music is a cultural artifact that influences worldviews. Therefore, understanding these cultural differences is crucial to understanding how social class affects health and well-being outcomes.",0
66,13," Snibbe and Markus (2005) examined the contrasting perspectives of people from low and high socioeconomic backgrounds regarding agency. According to their research, individuals with high socioeconomic status are better able to regulate their environment and assert their influence. Conversely, individuals with low socioeconomic status are more prone to adapt to their surroundings and uphold their principles due to their incapability to manipulate their environment. As a result, Snibbe and Markus argued that the high socioeconomic culture esteems control and agency, while low socioeconomic culture values adaptability, resilience, and integrity more highly.",0
66,14," Snibbe and Markus (2005) conducted further experiments that yielded similar results. In the experiment, participants were asked to choose a pen as a reward from a selection of options. The researchers then informed the participants that the chosen pen was not available, invalidating their choice. High socioeconomic status participants displayed more upset reactions than low socioeconomic status participants who are more accustomed to adapting to not receiving what they want.",0
66,15," Snibbe and Markus (2005) conducted experiments to determine the relationship between educational attainment and socioeconomic status. Their focus was on European Americans to avoid confusing racial identification with the cultural variable of socioeconomic status. One of the experiments involved the spreading alternatives effect, which refers to the tendency for people to value more highly an alternative they chose, compared to an equally attractive alternative they did not choose. The study discovered that the effect occurs among college-educated participants but not among high-school-educated individuals. College-educated participants who select between two similarly attractive CDs came to value the one they chose more highly than the high-school-educated participants did.",0
66,16," People from different regions within a country display variations in their norms and values, including the significance of honor and reputation, and in individualism and collectivism. According to research on the culture of honor by D. Cohen, Nisbett, Bowdle, & Schwarz (1996), societies that rely on herding give more importance to honor and reputation compared to those that rely on agriculture. In such societies, an individual's livelihood depends on their reputation for being able to defend against threats. Southern Whites in the USA, who have descended from Scotch-Irish herding societies, are believed to value honor and reputation more than those in northern regions, who are more likely to be descended from farmers, as per D. Cohen and colleagues' proposal. Consequently, Southerners are more likely than northerners to respond to insults with violence.",0
66,17," Regional differences in countries other than the US are also intriguing. The study conducted by Kitayama, Ishii, Imada, Takemura, and Ramaswamy in 2006 on people residing in Hokkaido, Japan highlights the historical similarities between this region and the American Wild West. Settled by unemployed samurai during the Meiji government in the 1800s, Hokkaido's development may depend on personal success, self-reliance promoting survival, and a behavioral lay theory that prioritizes achieving individual goals, justifying American individualism's influence due to its historical frontier past, as previously argued by Oyserman et al. in 2002.",0
66,18," The hypothesis was supported by survey studies, field experiments, and lab experiments, all providing convincing evidence. Southerners were found to be more inclined towards violence to defend their honor compared to Northerners, as confirmed by survey results. Field experiments revealed that Southern businesses were more likely to consider a job applicant who had violently defended his honor, whereas Northern businesses were not different in their response. In the lab, White Southern males showed a greater tendency towards aggressive and confrontational behavior and responded with anger to being insulted, while White Northern males responded with confusion or amusement. The levels of cortisol and testosterone in Southern males increased, indicating a link between these hormones and stress and aggression.",0
66,19,"
Regional differences may display similar patterns across different countries. For instance, small towns in Japan and Australia may share some similarities in terms of culture and behavior. Researchers Kashima et al. (2004) examined how people's sense of self differed between large metropolitan cities and regional cities in Japan and Australia. The study focused on four aspects of the self: agency, assertiveness, relational self, and collective self. The results showed that Australians had a more individualistic self, scoring higher on agency and assertiveness, while the Japanese were more relational. However, both countries showed that metropolitan residents were less collective than those in regional areas. Women were also found to be more relational in both countries.",0
66,20,"examined moral judgments of individuals from different socioeconomic backgrounds in the US and Brazil, focusing on acts that were considered highly disgusting or disrespectful but were not harmful to others. The study found both country and socioeconomic status differences, with Brazilians finding the actions more immoral than Americans, and those of lower socioeconomic status being more likely to judge them as immoral rather than a personal choice or social convention. The researchers concluded that socioeconomic-status-based differences were more significant than the country differences.",0
66,21," Some argue for a middle ground by claiming that all cultures share similar ideas and meanings, but emphasize certain ones more than others. For example, Kluckhohn and Strodtbeck's values orientation theory states that all cultures have the same values but prioritize them differently. Similarly, Rozin suggests that cultural differences stem from varying default responses to stimuli, but that individuals from different cultures can still comprehend each other. Regardless, these default differences can lead to further divergence over time.",0
66,22," There are several ways in which people are exposed to different cultures, such as assimilation, acculturation, socialization, enculturation, and tourism. Researchers studying this topic often take two perspectives. Firstly, there may be a sensitive period for cultural acquisition, similar to that for language. Secondly, research has examined the stress that individuals can experience when navigating unfamiliar cultural norms, languages, and foods. Despite considerable attention, most research focuses on cultural transitions between countries.",0
66,23," 

Culture can display intriguing variations in these processes, and shifting between socioeconomic levels may have both similarities and differences to moving between countries. When someone is the first in their family to pursue higher education, they may encounter a situation that underscores the distinct cultural environments inherent in different social classes. Relocating within a country, like from Philadelphia to Tempe, may not appear as significant a cultural shift as traveling between countries. Though the people in either place are American and use English, they may have their specific standards, customs, and principles. The 2008 electoral map indicates Pennsylvania is a blue state while Arizona is red.",0
66,24,"Religious conversions involve unique processes and dynamics dependent on the individual's movement between cultures. Whether a person converts from one religion to another, gains or loses a religion, each type of conversion may have its own distinct processes. The processes involved may vary depending on the religion, with some religions using biological descent to determine membership while others base it on one's beliefs. Additionally, the conversion process may be gradual and highly ritualized or informal and sudden. The different types of cultural changes will have varying dynamics depending on the cultures in question. (Morris, 1996; James, 1902/1997)",0
66,25," 

Greater specificity is advised when psychologists categorize group memberships. As highlighted by Fiske (2002), labeling people as ""Asian American,"" ""Latino American,"" or ""African American"" can be misleading as these categories encompass thousands of cultures. Similarly, categories like high versus low socioeconomic status, Jewish versus Christian, and Northern versus Southern may also be too general.",0
66,26," Wider exploration of different forms of culture can unveil new and diverse cultural variations, affecting not just the cross-country discrepancies in individualism and collectivism but also moral reasoning, agency, relationality, honor defense and intra-country aspects of collective and individualistic cultures. This can even have implications for established theories like terror management theory, which explains how people affiliated with their cultures and derogate those from different cultures to cope with their mortality. While religious beliefs have been studied in this context, unanswered questions remain about the differing beliefs and values of diverse religious and cultural groups.",0
66,27," The role of culture in various domains, such as education, organization, and health, can enhance practical understanding. To exemplify this, the discussion focuses on the implications of culture in health psychology. While poor health among people of lower social class is attributed to factors like education and medical care, cultural factors may also play a role. Individuals belonging to lower socioeconomic status may prioritize resilience over changing their environments, which may lead them to adapt to health problems with integrity instead of seeking solutions. Moreover, lower socioeconomic status is often linked to religiosity, and people may perceive their illness as God's will and meaningful.",0
67,1," 

It is now possible to cultivate mouse spermatogonial stem cells (SSCs) in vitro, but these cells also include a greater quantity of progenitor spermatogonia. Additionally, isolated germ-line stem (GS) cells have limited proliferation. To investigate SSCs and progenitor spermatogonia, a microdrop culture system was applied to GS cells. Individual microdrops were seeded with either clusters or known amounts of GS cells using a micromanipulator. The number of surviving colonies was determined after 30 days, showing an increase in proliferation when more cells were seeded. Even three GS cells in a microdrop can proliferate and expand the colony size. These expanded GS cells underwent spermatogenesis in the testis of recipient mice. Therefore, the microdrop culture method can study SSCs' self-renewing capacity and monitor their culture conditions.",0
67,2," Sperm production throughout a man's life is possible thanks to spermatogonial stem cells (SSCs), which have the capacity for self-renewal and can differentiate into spermatozoa. Daughter cells of SSCs can either be SSCs or progenitor spermatogonia, which are defined as mitotic germ cells in the mature testis residing on the basement membrane of the seminiferous tubules. Progenitor spermatogonia act as transit amplifying cells to expand their population through sequential cell division, while SSCs are a subpopulation of spermatogonia. This expansion of spermatogonia is responsible for generating vast quantities of sperm.",0
67,3,"
SSCs were originally believed to be single isolated type A spermatogonia, while progenitor spermatogonia were thought to be connected to each other by cytoplasmic bridges. However, recent studies have shown that the stem-progenitor system is more flexible and adaptable, and progenitor cells retain some stem cell activity. Molecular markers for undifferentiated spermatogonia, including SSCs, have also been identified. GDNF is a crucial factor for the expansion, survival, and/or self-renewal of SSCs. The use of GDNF in culture medium has allowed for the expansion and maintenance of long-term cultures of SSCs in vitro, called germ-line stem (GS) cells. The development of these culture methods has made it possible to study SSCs at the molecular level.",0
67,4,"

During the initial phase of experiments on the microdrop method, GS cell colonies with an estimated 40-300 cells per colony were selected from the maintenance culture dishes. These were then transferred to microdrops of varying sizes, namely 5, 10, or 20 ll. All GS cell colonies (N=27 microdrops) underwent exponential growth despite the size of the microdrop, thus indicating that the proliferative rate of the GS cells wasn't influenced by the volume of the drop. The colony size doubling time averaged about 7 days during the first three weeks, but then slowed down uniformly, which may be due to the accumulation of waste products, nutrient limitations or decreasing space, in the small culture volume (Fig. 2B).",0
67,5," 
In the second trial, we examined the effectiveness of the microdrop culture method on smaller GS cell colonies. The regular dishes containing GS cell colonies were divided into small cell clusters consisting of 2-12 cells using a 26-gauge needle. Each cluster was gathered and planted into a 5-ll microdrop. By day 7, some of the GS cell colonies in some of the drops had expanded and grown, and most of these colonies persisted to proliferate. In comparison, if GS cell clumps did not exhibit any growth by day 7, they typically disappeared within two weeks. Among the 45 total drops, only eight demonstrated the constant expansion of GS cell colonies until the end of the research period (30 days). The expansion efficiency per drop was established to be eight out of 45 drops (17.8%). The 45 drops contained a total of 297 GS cells at the beginning of the culture duration; thus, the expansion of eight colonies indicates a proliferation efficiency of each GS cell of 2.7% (8/297) if we assume that every colony originated from a single GS cell. This proliferation efficiency may reflect the percentage of SSCs in the GS cell population since only SSCs can develop colonies.",0
67,6,"

The method of culturing microdrops was first introduced by Ralph L. Brinster [14], who explored techniques to establish cultures of ova and embryos. Brinster found that methods involving small droplets of media under liquid paraffin oil were effective in observing ova and embryos, as well as collecting quantitative data [15]. Many researchers have since adopted the microdrop method, which is now standard practice in many IVF programs [16-18]. The benefits of a microdrop-under-oil culture come from the oil overlay and reduced incubation volume. The oil serves as a protective barrier against contamination, evaporation, and fluctuations in temperature and pH, and can also remove toxic substances [19]. However, the use of microdrop method has been limited mostly to embryo cultures.",0
67,7," We investigated whether growing GS cells in the microdrop in vitro culture reflects the expansion of SSCs in vivo by transplanting the daughter cells into recipient mouse testes. We subcultured the GS colonies from experiment 3 to expand them further and then transplanted cells from those lines into the seminiferous tubules of the testes of W mice. A total of 11 mice with independent GS cells showed extensive colonization of donor GS cells and complete spermatogenesis histologically. Four mice exhibited GS cell colonization but not complete spermatogenesis, and three mice showed no colonization, as shown in Table 3 and Fig. 3, A-F.",0
67,8," 

In experiment 2, the transfer of smaller clumps of 212 cells GS cells into microdrops resulted in the expansion of GS cell colonies in eight of the 45 microdrops. It is known that GS cell colonies require SSCs for expansion. However, the limited proliferation of progenitor spermatogonia hinders the expansion process, even for SSCs with a self-renewing probability of less than 0.5. We observed a few colonies expanding for up to two weeks only to shrink and disappear thereafter. We believe this limited expansion may indicate colonies of progenitor spermatogonia or colonies with SSCs that failed to increase in number due to the low probability of self-renewal. We concluded that the successful expansion of colonies in microdrops most likely involved at least one or more SSCs in the colonies' initiation.",0
68,1," Economists, including those in the mainstream, have recently acknowledged the impact of culture on the economic process. While some, like original institutionalists, fully appreciate the complexity of culture and are skeptical of quantifying it, others, particularly those trained in statistical methods, may hastily include cultural information in their models without fully understanding its meaning. This article examines various attempts to quantify culture and reviews papers that incorporate cultural information into statistical analyses. The goal is to assess the potential for incorporating culture into statistical models in ways that prioritize its richness, according to institutionalists.",0
68,2," Economic ideas evolve with a significant time lag, just as economic reality does. Even practical individuals who consider themselves immune to intellectual influences are often enslaved by outdated economists, as famously noted by Keynes. Nonetheless, economic thinking eventually adjusts to accommodate new economic realities and exploit new analytical opportunities. Although the neoclassical model, which is often inaccurately referred to as the dominant economic model, is declining in importance, other models are appear to be rising in relevance. The neoclassical orthodoxy remains influential, but signs of a more pluralistic economics are emerging.",0
68,3," While acknowledging the theoretical possibilities, most mainstream economists still hold econometric modeling techniques in high regard. They remain receptive to new ideas, albeit with the intent of integrating them into their current empirical methodologies. This incorporation of previously unconventional ideas, such as the relevance of culture, harbors the potential to enhance econometric and statistical analyses while consolidating institutionalist ideas. However, the feasibility of quantifying culture remains uncertain, particularly to institutional and heterodox economists.",0
68,4," The focal point of this paper is to investigate whether cultural information can be integrated into common empirical models to enhance mainstream analysis while respecting the complexity of culture. Alternatively, it examines if culture can be measured in a significant manner. Though the paper will address culture in more extensive concepts, its primary emphasis remains on extensive cultural indicators, primarily national cultural values.",0
68,5," Culture can be defined broadly as the core aspects that lie below the surface of consciousness and the more visible products or expressions of a society. Tylor's definition emphasizes that culture is received without consent and becomes part of one's consciousness due to their membership in a society. Similarly, Hofstede views culture as the collective programming of the mind that distinguishes one group from another. McCurdy, Spradley, and Shandy stress that culture is learned and shared, influencing behavior and interpreting experiences.",0
68,6,"

Culture is often discussed as having various layers or aspects by cultural scholars. For instance, according to McCurdy, Spradley, and Shandy (2005, 8), there are two types of culture, namely tacit culture, which refers to the cultural knowledge that people don't explicitly express, and explicit culture, which encompasses cultural categories that are conveyed through language. On the other hand, Schneider (1968, 1) views culture as comprising individual components or units that are defined and differentiated based on specific criteria. These units, in turn, help shape people's perception of the world and their understanding of how things relate to each other.",0
68,7,"

F. Gregory Hayden (1988) defines culture as a transcendent, collective, systemic mental construct, encompassing a group's abstract ideas, ideals, and values; this construct is expressed through legends, mythology, supernatural visions, folklore, literature, elaborated superstitions, and sagas. Hayden distinguishes between culture and its expressions, such as cultural values, beliefs, and attitudes. Values are cultural criteria or evaluative standards for judgment with regard to what is ideal, and are slow to change. However, novel experiences or technological and/or environmental changes can inspire cultural evolution over time. Social beliefs are activity- and institution-specific, while beliefs and attitudes are more malleable than values and can adapt as necessary to align the demands of social participation with the slower-to-evolve cultural value criteria (Hayden 1988, 416-418).",0
68,8," ""While it cannot be denied that orthodox economists have neglected cultural factors in their analyses, it is also true that original institutionalists have not fully succeeded in linking culture to economic behavior. As Anne Mayhew (1987a, 602) points out, institutionalists have fallen short in offering more comprehensive and genuinely cultural descriptions and analyses of modern economies.""",0
68,9," ""The quest to identify and measure cultural characteristics across nations or regions has been ongoing for the past half-century among management scholars and social scientists. While anthropologists aim to uncover subtle cultural nuances through ethnographic fieldwork, other disciplines have more specific objectives. Management scholars seek to aid business people in navigating multicultural environments, political scientists explore how culture impacts political outcomes, and economists investigate how culture affects economic behavior and social provisioning. This article focuses on identifying the enduring, meta aspects of culture that profoundly shape behavior at the regional and national levels. It surveys popular attempts to gauge culture, weighing their strengths and weaknesses.""",0
68,10,"Geert Hofstede's measures of culture are widely recognized among international management scholars. Hofstede conducted a survey of IBM subsidiary employees in 72 countries in the late 1960s and early 1970s, which included questions about values. Based on statistical analysis and theoretical reasoning, he identified four cultural dimensions and their impact across the nations studied. Michael H. Bond later added a fifth dimension as a result of research conducted in China. (Hofstede 1994, 1998)",0
68,11," Hofstede (2001) further explores the implications of these categories and provides information on the methodology of the study. Ultimately, national scores for each dimension are computed by Hofstede for all countries that met the data requirements.",0
68,12," Hofstede-inspired work has been criticized by Kirkman, Lowe, and Gibson (2006) for its redundancy, but other scholars like Sivikkumar and Nakata (2001) have developed methods to better select samples for cross-cultural studies and identify cultural differences between nations. Additionally, Taras, Piers, and Kirkman (2012) conducted a meta-analysis of Hofstede-type studies to identify cultural changes over time and generated more accurate indices that initially correlated closely with Hofstede's. However, correlations weakened when based on newer data. Despite these critiques, researchers agree that Hofstede's work will continue to be important, and future research should focus on improving measures and ensuring their validity.",0
68,13," Trompenaars and Hampden-Turner (1998) have conducted research to measure and compare national cultures, focusing on different data and identifying a separate set of national cultural dimensions from Hofstede's. Their analysis highlights seven cultural dilemmas that need to be addressed in management, and they develop national indices for each dimension to make cross-national cultural comparisons.",0
68,14,"has not received the same level of academic recognition as Hofstede's work, despite offering a clear and comprehensive understanding of global cultural differences. One of the key strengths of Trompenaars and Hampden-Turner's approach is their identification of an additional cultural dimension and their ability to deliver explanations in a highly accessible language.",0
68,15," Project GLOBE (Global Leadership and Organizational Behavior Research Program) is currently working on identifying and measuring cultural dimensions. The researchers (House et al. 2004) surveyed around 17,000 managers across 951 organizations in industries like finance, food-processing, and telecommunications. Based on the analysis of the data, GLOBE identified nine cultural dimensions, namely power distance, uncertainty avoidance, humane orientation, institutional collectivism, in-group collectivism, assertiveness, gender egalitarianism, future orientation, and performance orientation. These values were assigned for each of the 62 countries, facilitating cross-cultural comparisons. Even though GLOBE started as a replication of Hofstede’s work, Hofstede (2006) has criticized their findings, suggesting that nine dimensions could be too many.",0
68,16,"

Shalom H. Schwartz and Wolfgang Bilsky embarked on a research journey in 1987 to develop a theory of universal human values, taking into account biological needs, interactional requirements, and societal demands for group welfare and survival. They then studied various national populations to investigate the importance that different groups placed on particular values and to explore the universality of those values. They also sought to identify value dilemmas that all societies must resolve and value variations across nations. Their initial samples were from Germany and Israel, but they later expanded to include Australia, Finland, Hong Kong, Spain, the United States, and ultimately twenty countries total. With each iteration, their theory was refined and new insights were gained. In their most recent work, Schwartz et al. identified nineteen basic values arranged on a circular motivation continuum to better understand the hierarchy of values and the tensions that arise among them. This line of research emphasizes understanding the universality of values rather than quantifying culture and values like other approaches.",0
68,17," There are weaknesses in any source of quantitative information about culture, as none of the authors can claim to have perfectly captured culture and provide information on all countries or subcultures. However, the information they do provide helps to make culture more understandable and can be incorporated into empirical and theoretical models. Despite little evidence of widespread use in empirical economics, there are signs of increasing interest. The next section reviews works that have incorporated cultural information into empirical models to understand economic phenomena.",0
68,18," Johnson and Lenartowicz (1998) addressed the criticisms of Franke, Hofstede, and Bond (1991) by using both Hofstede's and Schwartz's measures of culture to examine the culture-growth link. They adopted a two-stage approach to explore the relation of economic freedom to growth. Franke, Hofstede, and Bond (1991) found significant correlations between cultural measures and economic freedom, with Hofstede's uncertainty avoidance measure showing negative correlation while masculinity had a positive correlation but not statistically significant. Meanwhile, Schwartz's conservatism had a negative correlation while autonomy had a positive correlation with economic freedom.",0
68,19,"
Duane Swank (1996) explores the impact of culture on a nation’s political systems and its economic growth. Initially, he replicates the work done by Granato, Inglehart, and Leblang (1996). Swank constructs a new indicator based on the World Values Survey, which he calls communitarian polities – social corporatist and Confucian statist, or civic virtue. Social corporatist nations are linked with industrialized nations, while statist nations are characterized by the long-lasting control of mass-based parties. He contends that civic virtue is a significant predictor of political stability, which in turn is critical for economic growth. Swank’s survey discovers that Confucian statist nations have a three-point higher growth rate, while social statist nations have a two-thirds point higher growth rate than non-communitarian polities. In conclusion, Swank emphasizes that culture may play an important role, but further investigation is necessary to determine the degree and direction of cultural influence on economic growth.",0
68,20," David C. McClelland's (1961) study on the emphasis on achievement in children's stories from various countries was challenged by Sjoerd Beugelsdijk and Roger Smeets (2008), who questioned the reliability of McClelland's national scores for need for achievement (N achievement) and its relation to growth. These authors tested several models and found little statistical evidence of a relationship between N scores and growth. While they acknowledged a theoretical connection between entrepreneurial culture and growth, they concluded that McClelland's N scores were insufficient for measuring it accurately.",0
68,21," Rachel L. Mathers and Claudia R. Williamson (2011) studied how culture and capitalist institutions impact economic growth. They analyzed data from 74 countries between 1980 and 2004, focusing on per capita GDP growth. They used the Economic Freedom of the World Index and a cultural index based on trust, respect, individual self-determination, and obedience as dependent variables. They used a growth model with various control variables to explore the relationship between culture, economic freedom, and growth. They found that capitalist institutions are more effective when they align with certain cultural values. They concluded that cultural legitimacy is essential for capitalist institutions to bring about economic growth.",0
68,22," Sjoerd Beugelsdijk, Ton van Schaik, and Will Arts (2006) have added an interesting perspective to the analysis of culture and growth/development. They looked at whether there is regional cultural convergence or path dependency across Europe, given the continent's economic integration. Using European Values Survey data from 1990 to 1999, the authors found evidence to support a synthetic view - some cultural change has occurred, but path dependency is still evident. They call for further study before the issue can be fully resolved.",0
68,23," The cultural measures mentioned earlier were based on responses from samples of people from different geographical areas. It is important to question whether the samples used to collect cultural information are appropriate for the population being studied. For instance, if one is researching subsistence farming in developing nations, it would not be fitting to incorporate cultural data gathered from a sample of corporate executives. If such data was being used, it would require a reasonable explanation. The cultural measures mentioned earlier focus on national cultural characteristics; hence, caution should be taken when applying the indices in situations where there are significant regional or group-specific subcultures. When choosing among various sources of cultural information, one should choose the source that best represents the population under examination.",0
68,24,"

""In some of the mentioned instances, researchers incorporate various cultural measures into their models, and subsequently analyze their effects, or the lack thereof. This approach could be perceived as data mining. However, as cautioned by Deirdre N. McCloskey (1998), statistical significance and scientific significance should not be mistaken as being the same thing. Instead of merely modifying a statistical model until a satisfactory statistical match is obtained, one ought to provide a logical justification for the inclusion or exclusion of particular cultural data. Even if a cultural variable does not fit the statistical mold perfectly, it might possess crucial value (referred to as ""oomph"" by McCloskey 2000). Conversely, a cultural variable can demonstrate excellent statistical accuracy, but still have limited relevance to actual economic phenomena. A comprehensive grasp of cultural theory is necessary to steer empirical research.""",0
68,25," Institutionalists should be cautious of making deterministic conclusions according to Hayden (1988). Culture certainly affects all aspects of human and social behavior, but for institutions, culture acts as a limiting factor rather than a determinant one. While cultural values may set criteria, there are numerous alternative beliefs and institutional arrangements that can satisfy them. For instance, studies linking Confucian values with economic growth may have been conducted during a period of Asian economic dominance driven by other factors. Alternatively, technology may have progressed to where it was better integrated into an Asian institutional setting than a Western one, making the culture-growth relationship transitory. As such, researchers must weigh their statistical outcomes against historical and other evidence.",0
68,26," Culture, specifically core culture, does not undergo frequent changes according to Hayden. To solve the endogeniety problem, one must carefully select variables. According to Hayden, values serve as evaluative standards for what is ideal, while social beliefs are activity- and institution-specific. As a result, cultural variables that reflect social beliefs are likely to be endogenous over anything but very brief periods, whereas if one has quantified a core cultural value, it can be viewed as exogenous for the time periods typically studied.",0
68,27,"

For a culture measure to have meaning, it must meet the standards of construct validity, meaning the indicators used to measure it are valid and accurate (Thomas 2010, 37). Moreover, measures meant to reflect one specific aspect of culture should not overlap with others. Hofstede (2001) shared this concern when others suggested expanding his five cultural dimensions. Nonetheless, researchers should avoid attempting to overly refine culture measures beyond broad and slow-to-change national meta-values, which prove to be the most dependable indicators for statistical research.",0
68,28," Quantifying economic and social information will inevitably involve measurement errors, just like GDP imperfectly measures output and price indices imperfectly measure inflation. Any quantitative measure of culture will also imperfectly capture cultural information. Despite these imperfections, other quantitative data have been extensively used. However, it is important to minimize measurement errors and carefully craft conclusions that reflect the level of confidence the quality of the data warrants. Nonetheless, caution is not the same as avoidance.",0
68,29," This article explores the possibility of integrating cultural data into statistical models in a manner that enhances the conventional analysis while acknowledging the diversity of cultures. With the current rising interest of mainstream economists in cultural factors' effects on economic activities, it is a relevant question. Additionally, these economists possess knowledge of statistical and econometric techniques and may rely on these tools to incorporate new elements into their research.",0
68,30," The examination and conversation earlier indicated various existing or potential obstacles towards measuring culture. These include problems with sampling such as the challenge of determining cultural-economic relationships when dealing with several values, endogeneity issues, difficulties in differentiating core cultural values from more transient beliefs and attitudes, and gaining insights into cultural change timing and pace. Considering these factors, it appears that cultural quantification is still in its nascent phase of advancement.",0
68,31," Researchers have acknowledged the limitations in quantifying culture and have been cautious in placing too much weight on their empirical results. Mainstream researchers understand the difficulties and are working towards developing better methods of collecting and quantifying cultural information. Caution must be exercised in analyzing the existing data and appropriate statistical methods should be employed. The economic-growth literature has already begun this work, although it is important to remember that the foundation is still shaky and building an empirical cultural-economic structure with insufficient data could be risky.",0
69,1," In this study, we looked back at 140 patients who had culture-positive infections and 102 patients with culture-negative infections in their total knee arthroplasties (TKAs). We analyzed how well the patients' infections were controlled and their clinical outcomes with repeated debridement or repeated two-stage TKA in these two groups. The average follow-up period was 9.3 years (ranging from 5 to 14 years) for the culture-positive group and 10.6 years (ranging from 5 to 22 years) for the culture-negative group.",0
69,2," The initial treatment resulted in an infection control rate of 56% in both groups. However, the culture-positive group had a higher infection control rate at 90% while the culture-negative group had a slightly higher rate of 95%. Additionally, a functional knee was achieved by 90% of patients in the culture-positive group and 95% in the culture-negative group.",0
69,3," Based on the information presented, it appears that tailoring treatment to the specific types of infection present in patients who undergo TKA (total knee arthroplasty) can effectively manage and control infection while also maintaining the functionality and stability of the TKA implant. Further improvements in infection control rates can be achieved through repeated debridement and two-stage exchange TKA procedures following the initial treatment. These additional measures also increase the chances of successful long-term TKA function.",0
69,4," 

Periprosthetic joint infection is a difficult issue that can arise following total knee arthroplasty (TKA), occurring in approximately 1 to 4% of primary TKA cases (9-11, 29, 30). Timely and accurate diagnosis is critical, often requiring holding off on antibiotic treatment in order to attempt to extract an organism from preoperative joint aspiration or intraoperative tissue cultures. Once the cause is pinpointed, local and systemic antibiotic treatments can be tailored. However, despite extensive efforts, cultures often display a high false-negative rate, irrespective of clinical, radiographic, and surgical indications for infection. Negative culture rates for most infection series have varied between 0-25% (1, 5, 7, 21, 23, 24, 38).",0
69,5,"To validate prior findings, we conducted two analyses. Firstly, we compared infected TKA types without positive cultures during treatment to those with positive cultures to ascertain infection control rates. Secondly, we assessed whether additional debridement and two-stage exchange arthroplasty improved the infection control rates after an unsuccessful primary treatment in culture-positive and culture-negative scenarios.",0
69,6," We looked back at the data of 209 patients who underwent total knee arthroplasties between January 1991 and March 2008, and found that 11 patients were lost to follow-up before 2 years, and 7 patients died, leaving us with 191 patients (191 knees) to review. The records of these patients were entered into an ongoing computerized database. The study was approved by the institutional review board, and patients provided written informed consent. All patients had undergone TKA for osteoarthritis. Of the 191 patients, 44 were men and 147 were women, with a mean age of 66.3 ± 8.65 years (range 40-90 years) and a mean body mass index of 28.29 ± 4.31 kg/m2 (range 20.1-41.3 kg/m2). The minimum follow-up duration was 5 years (mean 10 ± 0.92 years, range 5-22 years) (Table 1).",0
69,7," The diagnosis of infection following TKA was based on several criteria. These included the presence of an abscess or sinus tract communicating with the joint space, positive preoperative aspiration culture findings on solid media, positive cultures on 2 or more intraoperative cultures, or one positive culture on solid media in combination with the presence of pus. In cases where cultures were negative, infection was diagnosed based on elevated ESR and CRP levels, synovial WBC count, synovial neutrophil percentage, presence of pus in the joint, and more than 5 neutrophils per high-power field on histologic examination. In patients who underwent TKA for infection between 1999 and 2004, diagnosis was based on serum serology and joint fluid culture due to the unavailability of serologic counts in the aspirated synovial fluid. Infections were classified as early postoperative deep, late chronic, or acute hematogenous infection according to Tsukayama et al.",0
69,8," The study participants were categorized into two groups based on the results of their preoperative joint aspirate and intraoperative periprosthetic tissues. The first group, known as culture-positive group, consisted of 140 patients with positive-culture results, while the second group, known as culture-negative group, consisted of 51 patients with negative-culture results who underwent PCR analysis instead. The isolated bacteria included gram-positive cocci and gram-negative bacilli, with fungal (candida albicans) and mycobacterium (mycobacterium tuberculosis) isolates coming from late chronic infections. 21 patients initially had negative cultures but later tested positive. Demographics, clinical characteristics, and treatment outcomes were compared between the two groups. Information on previous antibiotic treatment and follow-up cultures were also documented for the culture-negative group. (Table 1 and Table 2 provide further details).",0
69,9," Statistical tools like chi-square, descriptive, and Student's t-test were utilized to compare the demographics and comorbidities of culture-negative and culture-positive groups. Fisher's exact probability two-tailed t-test was carried out to study the differences among four types of infections regarding various discrete variables such as age, period of follow-up, CRP, ESR, leukocyte count, and leukocyte differential. Logistic regression was implemented to evaluate the rate of failure associated with different types of infection in both groups. Additionally, one-way analysis of variance was performed to verify disparities among different types of infection concerning the final clinical score. The significance level was set at P < 0.05, and SPSS software (version 18; SPSS, Chicago, Illinois) was employed for all the analyses.",0
69,10," There were some limitations in the study. Firstly, despite prospectively following all patients in the study, the design was retrospective to test the success of the classification-based treatment algorithm for infected TKA. Secondly, due to a limited number of patients, data could not be analyzed according to the infecting organism. Thirdly, a small number of patients were lost to follow-up or had died, which may not have influenced the study findings, unless they became reinfected. Fourthly, a false negative diagnosis could be made with serological markers used in patients with negative cultures. Finally, diagnosis of infection in patients who underwent total knee arthroplasty from 1999 to 2004 was dependent on serum serology and joint fluid culture, which could lead to a false negative diagnosis.",0
69,11,"In the group that tested positive for culture, 5% of knees required revision due to aseptic loosening of components, while 2 knees had to undergo above-knee amputation due to persistent infection despite two revisions. The patients who needed amputation were immuno-compromised and had prolonged antibiotic therapy. In the culture-negative group, 8% of knees were revised due to aseptic loosening. The survivorship rate of total knee prosthesis at 9.3 years was 94% with a 95% confidence interval of 0.91 to 0.97 in the culture-positive group, and 92% with a 95% confidence interval of 0.89 to 0.98 in the culture-negative group, using revision, arthrodesis, or amputation as the endpoint.",0
69,12," Based on the current study, it was found that there were no considerable variations in infection control rate and clinical outcomes in the culture-positive and culture-negative groups. The findings indicated that administering proper treatment based on infection types helped in controlling infections and maintaining a functional TKA with a strong fixation for most patients in both groups. Moreover, carrying out repeated debridement and two-stage exchange TKA after the initial treatment enhanced the infection control rate further and increased the chance of sustaining a functional TKA.",0
69,13," In a study conducted by Segawa et al. [33], it was found that most patients with deep postoperative infections were able to walk with little to no pain, with some using a cane for assistance. None of the patients had any radiographic indications that would have warranted immediate surgical intervention. In the current study, a small percentage of knees in both the culture-positive and culture-negative groups were revised due to aseptic loosening of components, while two patients in the culture-positive group had to undergo above-knee amputation due to persistent infection even after multiple revisions.",0
70,1," 

Studies on organizational culture typically make the assumptions that senior leaders determine the culture and that it relates to significant outcomes for the organization. However, there is limited empirical evidence supporting these assumptions, and the results are inconclusive. Little research has investigated the linking of these assumptions. This article aims to connect CEO personality to organizational culture and to measure the relationship between culture and objective indicators of firm performance. Data from 32 high-tech companies shows that CEO personality influences the culture, which in turn affects the company's financial performance, reputation, employee attitudes, and analysts' stock recommendations. These findings have implications for future research on organizational culture.",0
70,2," 
In the late 1970s and early 1980s, managers and scholars focused on the topic of ""organizational culture."" Several popular books, academic conferences, and special journal issues highlighted its promise as a tool for understanding how organizations work and succeed. The logic behind this idea had two parts that were easy to understand: (a) organizational cultures generally mirror the values and actions of leadership, and (b) cultures have a significant impact on firm performance.",0
70,3,"

Organizational cultures, defined as shared values and beliefs, are believed to be largely created by senior leaders. This assumption is reflected in the work of Schein, who claims that the main function of leadership is to manage culture. However, empirical studies of the relationship between senior leaders and organizational culture are scarce, according to Schneider, Ehrhart, and Macey.",0
70,4,"

The argument's second part suggested that organizational culture strongly influences organizational performance, but evidence for this is inconclusive. Several issues, such as defining culture and its associated dimensions, and methodological challenges like small sample sizes and using measures not meant for assessing culture, have hindered establishing a consistent direct link between culture and objective firm performance. (Schneider et al., 2013; Detert, Schroeder, & Mauriel, 2000).",0
70,5," Organizational culture is still believed to be shaped by leaders and important for firm performance, despite fragmented and inconclusive empirical evidence. Sackmann's review suggests that diverse measures of culture and performance are stalling paradigm development. There are almost no studies that have tested the effects of senior leadership personality on culture and performance indicators simultaneously. Our goal is to provide a clearer picture of how culture affects organizational performance and the origins of organizational cultures.",0
70,6," After reviewing previous studies on the impact of CEO personality and leadership on firm culture and performance, we proceeded to revalidate a measure of organizational culture developed by O'Reilly, Chatman, and Caldwell (1991) using data from over 1,000 participants. Next, we examined the connections between CEO personality, culture, and firm performance for 32 high-tech firms over a three-year duration.",0
70,7,"

Organizational culture is heavily influenced by the recurring behaviors of senior leaders. According to social learning perspectives, managers can develop and change cultures through normative and informational influence. This can be achieved through various mechanisms such as systems, structures, and processes designed to reinforce ways of thinking and behaving. However, the true origins of culture can be traced back to the values and personalities of organizational leaders. These dispositions are the primary building blocks of organizational culture.",0
70,8," Schneider and Smith's (2004) broad definition of personality encompasses individual attributes that shape and maintain consistent behavior across various situations over time. Personality traits encompass patterns of thought, emotion, and behavior that remain relatively stable. Values, which are subjective judgments and perspectives on important matters, are also enduring dispositions that inform situational preferences. Both personality and values are crucial antecedents of behavioral patterns. The CEO's behavior may serve as informative data on normative order within the organizational culture. (Parks & Guay, 2009).",0
70,9," Based on the evidence presented by Peterson et al. (2003) and Tsui et al. (2006), it appears that personality traits, specifically values and behavior, can be linked to CEO leadership and have an impact on organizational culture. However, the exact nature of these relationships remains unclear. One potential implication of this is that senior leaders hold a disproportionately large influence on the culture of an organization due to their status, authority, and responsibility.",0
70,10,"
It's interesting to note that despite the great interest in how culture affects firm performance, there still isn't much clarity on the matter. Siehl and Martin (1990) conducted an early study where they concluded that an empirical link between the two might never be demonstrated. Almost 20 years later, Gregory, Harris, Armenakis, and Shook (2009) recognized that there hasn't been a lot of detailed insight into the relationship. Reviewing the associations between culture and organizational effectiveness, Hartnell et al. (2011) found that culture had a significant correlation with employee job satisfaction, mixed results for subjective ratings of organizational processes and performance, but there weren't enough studies of objective performance indicators and culture to draw any conclusions.",0
70,11," It is understandable why there is a lack of clarity in assessing culture across organizations with CEO involvement. The task is daunting due to the challenge of designing studies, obtaining data, and resulting in small sample sizes with low power. Researchers have made the best of what is available, using pre-existing surveys that were not designed for culture research and then relabeling constructs as “culture”. However, the relationship between culture and firm performance varies by industry, and significant results may not apply in other settings. These difficulties are not meant to criticize culture research efforts, but rather to acknowledge the complexities involved.",0
70,12," There have been disputes regarding the meaning and evaluation of culture and performance, resulting in the application of diverse frameworks and metrics, making it hard to draw conclusions (Schneider et al., 2013). According to Hartnell et al. (2011), one explanation for the lack of association between culture and performance is that simple methods of assessing culture are too broad. Pettigrew (1979) also criticized the simplistic categorization of organizational culture, stating that it lacks analytical depth (p. 574).",0
70,13," There has been a shift in understanding the connection between organizational culture and firm performance. It ranges from a simple direct link to a more dependent relationship based on firm strategy and environmental conditions. Despite the intuitive belief in a direct link, the empirical results are inconclusive, as noted by various researchers (Christensen & Gordon, 1999; Khazanchi, Lewis, & Boyer, 2007; Sørensen, 2002).",0
70,14," 
The current proposition is that a leader's personality is shown in their regular attitudes and behaviors, which subsequently influence cultural norms and expectations. While it is not assumed that a CEO's personality would directly impact the company's performance, their behavior patterns (reflected in the questions they ask, who they hire, and the behaviors they reward) likely have a hand in shaping their company's culture, which affects what people prioritize and how they behave. Thus, it is predicted that certain CEO personality traits, such as those found in the Big Five, correspond to specific company cultures. Ultimately, the type of company culture can affect the company's performance.",0
70,15," Previous studies have demonstrated that leader emergence, job performance, culture, and the organization’s strategy can be linked to each of the Big Five dimensions under specific circumstances (Berson et al., 2008; Giberson et al., 2009; Judge, Bono, Iles, & Gerhardt, 2002; Nadkarni & Herrmann, 2010). Although it is possible to predict how combinations of the Big Five dimensions may influence organizational culture, for the sake of clarity, we only examine their potential direct impacts on organizational culture in this study.",0
70,16," Conscientiousness refers to the ability to control impulses and strive towards goals persistently. However, at excessively high levels, individuals may exhibit traits such as being meticulous, obsessed with regulations, and overly cautious. This implies that at the top management level, Conscientiousness is likely to foster cultures that are more compliance-focused, centralized, and cautious. Hence, it is expected that CEOs who possess high Conscientiousness will be inclined towards fostering cultures that prioritize accuracy, scrutiny, and attention to detail.",0
70,17,"

Individuals with high levels of Agreeableness are commonly perceived as being helpful, modest, and willing to negotiate, as noted in the research of Peterson et al. (2003). On the other hand, those who score low on the Agreeableness trait tend to be more competitive than cooperative, pessimistic, insensitive towards the emotions of others, and even hostile. There is some indication that possessing a low level of Agreeableness could actually result in an increase in performance, according to Lepine & Van Dyne (2001). We predict that CEOs who exhibit lower levels of Agreeableness will cultivate a more competitive and achievement-oriented corporate culture, with a greater emphasis placed upon meeting higher performance standards.",0
70,18," Individuals with high scores on Neuroticism demonstrate anxiety, emotional instability, defensiveness, and tend to get disturbed by minor threats or frustrations. On the other hand, those with low scores on Neuroticism are perceived as emotionally stable, relaxed, and secure. According to a meta-analysis conducted by Judge et al. (2002), an inverse correlation was found between Neuroticism and leader emergence. Therefore, individuals with high scores on Neuroticism are considered to be less collaborative in their working environment.",0
70,19," 

Extraversion is exemplified by a preference for frequent social interactions, as well as optimistic and energetic behavior. Additionally, extraverts display a preference for excitement. Notably, individuals who score higher on Extraversion have been shown to be highly sociable and capable of involving others, as evidenced by CEO studies linking high Extraversion to market-oriented cultures. Consequently, CEOs who exhibit sociability and optimism are more likely to cultivate a customer-centered organizational culture than those who lean towards introversion.",0
71,1," This paper investigates the distinct nature of Islamic culture in comparison to other cultures. The introduction delves into the definitions and usage of the terms culture and civilization. The first section provides an analysis of the unusual facets of Islamic culture, complete with examples. The second section scrutinizes how Islamic culture has faced challenges in modernization and secularization and how it has adapted in response. The third section explores the current status of Islamic civilization, including its struggle against Western civilization and the ensuing debates, through cultural and civilizational evaluations. Finally, the last part assesses the paper's thesis.",0
71,2,"Culture and civilizations are often confused even though they have distinct meanings. The scopes of these terms are still disputed by sociologists and historians. Muslim historian and sociologist Ibn Khaldun used the word ""Umran"" to mean both civilization and culture. In contrast, Ziya Gokalp specified that ""Harth"" meant culture, highlighting the difference between culture and civilization. He also believed that Islamic culture could coexist with Western culture.",0
71,3," Gokalp has derived the term ""harth"" for culture from the Qur'an, where it is used to refer to ""crop"". In the verse ""And when he is in authority, he runs about in the land to create disorder in it and destroy the crops and the progeny of men; and Allah loves not disorder"" (AlBaqarah, 206), the word ""harth"" is used. According to Gokalp, the culture of a population is akin to its crop, and if it declines, it leads to disorder and chaos in the country.",0
71,4," It could be argued that civilization has a broader application than culture, as it encompasses diverse cultures coming together. Culture denotes the tangible and intangible elements of a society. Thus, in this context, the moral and social principles developed by small societies or groups fall under culture. Conversely, the term ""civilization"" has a vast scope and may encompass all cultures that share identical traits within a civilization.",0
71,5," When considering the diverse meanings of the terms culture and civilization, it becomes clear that Islamic civilization has the potential to accommodate multiple cultures within it. Thus, groups and societies with distinct languages, culinary traditions, birth and death rituals, and so on could coexist harmoniously under the umbrella of Islamic civilization.",0
71,6," The Islamic Culture stands out from other cultures as it posits itself as the epitome of justice and truth. The Quran further emphasizes this uniqueness through versus that highlight the exclusive nature of following Islam. These verses include: ""Do They seek a religion other than Allah’s ..... (Âl-e Imrân, 84); “And who seeks a religion other than Islam, it shall not be accepted from him, and in the life to come he shall be among the losers (Âl-e Imrân, 86); He it is Who has sent his Messenger with guidance and the religion of truth, that He may make it prevail over all other religions (Al-Fath, 29).""",0
71,7,"The Islamic Culture is distinct from other cultures, as stated earlier. Islam's unique status as the only valid religion suggests that the Islamic Culture should be the only legitimate culture. This claim could be evaluated logically, with an inference having more than one truth value. If an inference has only one truth value among all the truth values, it is true. However, for the inference to be valid, all truth values must be true. Similarly, a cultural factor can only be considered Islamic if it aligns with the values of Islam. Other cultures may conflict with aspects of the Islamic Culture, making it unique.",0
71,8," It is brought into question how Islamic Culture can explain cases where Muslims behave inappropriately according to Islamic principles. To address this issue, we must differentiate between Islamic Culture and the various cultures of Muslims.",0
71,9,"

Although the phrase ""The Cultures of Muslims"" may initially appear synonymous with ""The Islamic Culture,"" this is not an accurate assumption. Like non-believers, Muslims are fallible human beings who may make mistakes as individuals. However, the mistakes made on an individual level do not implicate their entire community or religion, as it would be unacceptable for Allah to command wrongdoing. This sentiment is expressed in various verses, such as the one found in AlNahl, 91, which commands justice, good deeds towards others, and abstaining from indecency and evil.",0
71,10," Cultural values produced by Muslims that do not conform to the spirit and rules of Islam cannot be deemed as Islamic, despite culture being defined as a set of material and moral values generated by a society. Therefore, the attempts of certain western journalists to associate Islam with terrorism are ill-advised, as it is merely a rhetorical tactic to defame Islam by merging the word with a negative connotation like terrorism. However, such a strategy is nothing but a fallacy upon closer examination.",0
71,11," It is important to distinguish between Islamic Culture and the culture of Muslims in order to avoid this fallacy. Islamic Culture refers to cultural values that are in line with the spirit and rules of Islam, while the culture of some Muslims may include elements that contradict Islamic principles. Therefore, when assessing the culture of Muslim societies, it is preferable to use the term ""Muslim Culture"" or ""cultures of the Muslims"" instead of Islamic Culture.",0
71,12,"

The utilization of this concept opens the door for diverse cultures to coexist within the unity and universality of Islam. The Prophet Mohammad's (s.a.w.) statement ""The dispute of the Ummah is God's compassion"" suggests that differences in culture do not impede an Islamic way of life, and can instead be united under one roof. This interconnectedness can be expressed through the combination of the terms 'culture and civilization', with civilization corresponding to religion and Islam. Therefore, like religion, civilization is indivisible and unique. It follows that there are various cultures, such as Turkish, Arabic, and Persian, under the umbrella of Islam Civilization. A more detailed exploration of this subject will be undertaken below.",0
71,13," We aim to assess the correlation between culture and civilization through the lens of Ziya Gokalp, known in Turkey as the pioneer of sociology. Gokalp lived at a time when Islamic societies were undergoing their most severe decline in comparison to Western societies during World War I. He, along with other intellectuals in the Ottoman Empire, sought to find a solution to this decline, mainly focusing on modernization, Westernization, and Islamization. While some advocated for holding tightly onto Islamic principles to end this decline, others proposed Western countries as models to follow.",0
71,14,"

During that time, the main topic of debate was how Western and Islamic cultures could mix. Those who believed in Islamic values knew that this was not possible and unnecessary. On the other hand, those who were in favor of westernization believed that being a Muslim did not prevent someone from adopting Western culture. One of the strongest proponents of this idea was Gokalp, who identified as Turkish, Muslim, and Western. He explained the process of westernization by distinguishing between culture and civilization, claiming that while culture is specific to a nation, civilization is shared among societies.",0
71,15,"As Turkey established its republic and began modernizing, it also became westernized. The terms modernization and westernization essentially have the same meaning. Western civilizations have been successful in the last two centuries because they have exported their culture to other nations. This cultural influence has occurred as people adopt western values and culture as their own, either willingly or forcibly. As nations modernize, they also tend to westernize, even if they are not considered part of western civilizations.",0
71,16," It is important to examine the potential for one culture to influence another and whether this is a plausible scenario or not. To tackle this question, we must explore theories regarding the disappearance of cultures and civilizations throughout history. While some sociologists believe that cultural assimilation is a possibility, others disagree.",0
71,17,"Modernization refers to the social processes of industrialization, individualization, and secularization that were first experienced by Western societies. Other societies, such as Muslim societies, later underwent similar processes to varying degrees.",0
71,18,"

As Muslim societies began to modernize, they looked towards western societies as a model. However, Islam did not approve of the similarities with Christian societies. This is evident in the verse: “O ye who believe! Whose among you turns back from his religion, then let it be known that in his stead Allah will soon bring a people whom He will love and who will love him...” (Maidah, 54). Additionally, the prophet Mohammad (s.a.w.) said: “Whoever resembles a society, then he is from them”. Islam, as the religion of truth, could not accept elements that contradicted its core principles. Therefore, for the last two centuries, during which western culture has dominated, Islamic culture has strongly resisted secularism as it opposes Islamic values.",0
71,19,"""Thus, despite the influence of Western culture, Islam's civilization and its various cultures have managed to retain their distinctiveness. Nonetheless, in recent times, this trend has been slowing down and in some Muslim societies, has stopped altogether. Presently, Muslims are seeking to reaffirm their roots and uphold their traditional customs. A prime instance of this can be observed in Turkey.""",0
72,1," 'There is little consensus on the meaning of ""safety culture"" despite its popularity. Different fields, such as anthropology, management consulting, organization theory, and psychology, have varying interpretations of the concept. Culture can be viewed from different levels, including linguistic, tacit knowledge, and webs of significance. Cultural perspectives like integration, differentiation, and ambiguity are important in cultural analyses. Whether there is a single culture, subcultures, or no culture at all depends on empirical evidence. Researchers should employ methodological triangulation and be aware of different cultural perspectives. Managers should approach culture management with greater humility.'",0
72,2," Safety culture has been a topic of significant interest in recent years, with many scholars such as Vaughan, Reason, Pidgeon, Cooper, Cox and Cheyne, Hale, and Richter and Koch discussing it. The concept initially emerged in the Norwegian oil industry during the late 1980s and has since been adopted by nearly every oil and drilling company in the North Sea. This paper will examine the history of oil drilling in the North Sea to illustrate the theoretical points. Despite the widespread interest in cultural perspectives, James Reason aptly notes that few phrases are more commonly used in discussions about hazardous technologies than safety culture, yet few are so widely sought after and yet so poorly grasped.",0
72,3," There exists numerous responses to foundational inquiries such as the definition of ""culture"" and ""safety culture."" Is it feasible to manipulate or regulate it? Is quantification possible? Does a solitary culture exist, or are there numerous subcultures, or is there an absence of culture at all? Is its primary feature integration, differentiation, or ambiguity? (Reference: Richter and Kochs' document in Safety Science volume 42, 2004, and the exchange of letters to the Editor that occurred in the same year.)",0
72,4," Safety culture is often viewed as a part of organizational culture, which was highly discussed in the 1980s. However, anthropologists have a different interpretation of culture compared to management theorists. The latter group tends to have a more simplistic understanding of the concept. In order to fully comprehend safety culture, it is necessary to review the key points of this debate and understand the anthropological perspective. My discussion draws on the works of traditional anthropologists, such as Clifford Geertz, Robert Keesing, and Maurice Bloch. Unlike Mary Douglas and her 'grid/group theory,' I argue for a more open-ended approach.",0
72,5," Culture, as defined by anthropology, can be described as a shared collection of ideas, values, attitudes, and norms that distinguish one group of people from another. It informs all aspects of society, influencing our approach to safety, technology, politics, economics, and our daily behavior and thinking. Essentially, culture has a pervasive influence on virtually everything we do.",0
72,6," Some of the definitions of culture in anthropology encompass both material and social aspects, while others, such as Geertz's definition, argue that a broad definition of culture would be unhelpful since it encompasses everything. Because Geertz's symbolic approach is used as the starting point for discussions about safety culture in some papers and discussions, it is advisable to read his work more closely.",0
72,7,"

Culture can be considered as a distinct set of ideas, or more accurately, a structured system of significance. This separation of culture allows for an examination of its changes (or lack thereof) in contrast to the social systems. However, it is imperative to highlight that this is simply an analytical viewpoint that aims to differentiate between the social and cultural aspects of human existence and treat them as independent yet interconnected elements. Geertz further emphasizes that for a cultural system to exist, it must possess a certain level of coherence.",0
72,8,"

Geertz views culture as the framework of significance that shapes human experience and behavior. He famously compares humans to animals entangled in a web of meaning they themselves have created. This web of meaning, or culture, can be deciphered through the interpretation of symbols that carry significance. These symbols, according to Geertz, are as evident as weddings and agriculture, and can be analyzed for their public cultural meaning. Rather than search for strict laws of behavior, the goal is to uncover the meaning of these symbols.",0
72,9," Geertz has received criticism from various authors, including Keesing who argues that culture is not a uniform entity. Keesing believes that there are always conflicts between individuals and subcultures, involving power struggles, value clashes, and disputes over knowledge and truth. Contrary to Geertz's notion of culture as ""webs of significance"", Keesing claims that culture also encompasses ideologies and power. Building on Scholte's critique, Keesing contends that few individuals actively create culture, while the majority is simply caught up in it. Both Keesing and Scholte thus propose that culture is not something that most people ""make"", but rather something that captures and controls us - in other words, ideologies.",0
72,10," Keesing emphasizes the importance of placing symbolic and interpretive anthropology within broader social theory, as culture is created through ongoing struggle between differing interests. For Keesing, the relationship between symbolic production and power and politics is the most critical question. This emphasis on power is similarly shared by authors like Foucault and Bourdieu, and has become central to much contemporary cultural studies. Keesing argues that it is more appropriate to talk about the ""cultural"" rather than culture itself, and this has become standard practice among anthropologists who now speak of cultural processes.",0
72,11," It is debatable whether discussing ""cultural conditions"" instead of ""culture"" solves the many problems highlighted by Keesing. Culture is not a fixed entity as it keeps changing due to internal and external factors. Therefore, using the term ""cultural conditions"" may be considered splitting hairs. Keesing's argument seems contradictory as he argues against culture but acknowledges that humans are trapped in webs of significance created by culture. The discussion should extend to more philosophical, metaphysical, and ontological realms, such as determining whether power, politics, and the economy are ""givens"" while culture and beliefs are ""dependent variables."" Keesing does not provide a satisfactory answer to such questions or show interest in epistemological inquiries. In my view, such reductionism is not productive.",0
72,12," Bloch believes that the notion of culture holds utmost significance for social and cultural anthropologists. Therefore, he refuses to discard culture as a valuable concept but intends to dispute certain common beliefs regarding it. One common belief in the field is that culture is closely linked with language, either because culture is abstract and conveyed as language text or because culture is similar to language in an absolute sense (Bloch, 1998).",0
72,13," According to Bloch, language is not crucial for conceptual thinking despite the apparent contradiction in his claim. He argues that a substantial portion of our knowledge is non-linguistic and is acquired through experience and practice, where concepts derive from implicit meanings formed via these networks. However, this non-linguistic knowledge can sometimes convert to explicit discourse under special conditions, but it changes in character during the process. Everyday practical tasks are acquired through imitation and participation, and a linear and logical syntax, which is a linguistic model, cannot account for the speed and efficiency of how we perform them. Language is just a component of culture, and as such, not a necessity. (Bloch, 1998, p. 14).",0
72,14," It is crucial to prioritize embodied experience and approach knowledge with caution if it relies solely on explicit language, as this type of knowledge is often disconnected from practical applications such as work. Bloch's perspective aligns with the anthropological concept of ""tacit knowledge"" and is an insightful viewpoint. (Reference to Polanyi's work is included as well.)",0
72,15," 
There are varying definitions of the term 'culture' from different perspectives. Geertz sees culture as necessary for both thought and action, but not necessarily in a stagnant or timeless manner. Bloch's interest lies in experiences, practices, and implicit knowledge. In contrast, Keesing stresses the importance of power, conflict, and discourse, considering them crucial social phenomena centered on conceptualization and language. It is crucial to consider these different perspectives in cultural analyses, operating on various levels - from explicit linguistic discourses to underlying, tacit assumptions and beliefs, and even questioning epistemological assumptions.",0
72,16," Restricting culture to a single definition is unlikely to be productive as the term has multiple meanings. Instead, a more pragmatic approach is advisable. Geertz's approach of considering culture as a separate system of meaning can be useful for analytical purposes, but this does not imply treating it as a uniform system or isolating it from other factors like social organization, technology, practice or power. The key to a good anthropological analysis is to clarify the relationship between these ""subsystems.""",0
72,17," In the 1980s, there was a surge of fascination towards organizational culture and management. Notably, two popular scientific books - In Search of Excellence (Peters and Waterman, 1982) and Corporate Cultures (Deal and Kennedy, 1982) - were published. These books outlined the characteristics of prosperous companies and how they functioned, becoming immensely popular both in the United States and Europe.",0
72,18," Corporations that have a strong culture and emphasize basic values and common goals tend to do well, as highlighted in these books. Culture can be a useful management tool and can replace other forms of control, like bureaucratic control.",0
72,19," The books share a positive trait which focuses on employees as the prime asset of the organization. In addition, most of the literature stresses the significance of management in shaping the company culture. Although this is crucial, one should be cautious and doubtful of certain aspects of these theories.",0
72,20," Despite being influenced by Japanese organizational philosophy, it is apparent that some of the measures that were implemented in Japan cannot be deemed suitable for Europe due to cultural disparities. It is important to acknowledge that improving organizational culture cannot and should not be pursued independently from national culture.",0
72,21," The literature reveals an overly optimistic view of managers' capabilities, as evidenced by Sørhaug's assertion that it is uncritically positive and unlimited in its potential. While management is certainly important, the notion that it is all-encompassing is refuted by examples of changing leadership yet static organizational culture. Additionally, the literature's focus on manipulation is problematic, exemplified by Sejersted's observation that it recommends simultaneously brainwashing employees while treating them as individuals, without addressing the potential conflict between these approaches.",0
72,22,"Culture cannot be imposed from above by management-consulting firms but is a fundamental aspect of human social organization that must be taken into account in corporate planning. Several organizational studies show that competing sub-cultures exist within companies, with the shop floor often having a counterculture that conflicts with management's goals and values. While some argue that culture can be successfully managed, studies suggest that it cannot be controlled but may be influenced to some extent. The debate on this topic will be revisited at the end of the paper. (Source: Reynolds, 1994; Krackhardt and Kilduff, 1990; Tompson and McHugh, 2002, p. 205)",0
72,23," It is ethical to influence a culture depending on the goals achieved and the methods employed. In the case of establishing a safety culture, extensive measures can be justified, but there is a boundary that not all safety experts and managers recognize. Certain tactics may work counterproductively if the employees do not perceive them as relevant, leading them to undermine such efforts.",0
72,24," The concept of organizational culture is valuable, but often, management literature and some organization theory only focus on the practical aspects. To truly comprehend this intricate phenomenon, we need to adopt a holistic approach that encompasses different levels, including both obvious and implicit elements.",0
72,25," There are numerous intriguing studies on organizational culture exploring it as the complex phenomenon it truly is. However, due to the overwhelming literature on this topic, I intend to only discuss the authors cited in Richter and Kochs' paper in Safety Science Volume 42, Issue 8, 2004, and the subsequent letters to the Editor by Hale in Volume 42, Issue 10, 2004. I find both the paper and the letters to be highly engaging and enlightening, offering valuable insights into both organizational and safety cultures.",0
72,26," Richter and Koch's definition of safety culture is influenced by Geertz, but they analyze it through Martin's three cultural perspectives - integration, differentiation, and fragmentation. Within the integration perspective, culture is seen as shared understandings in an organization. The differentiation perspective highlights the lack of agreement in interpretations and the focus is on sub-cultures. The fragmentation perspective is understood as ambiguity in cultural manifestations and lacks clarity in interpretations and meanings. Although Martin is unclear on whether there is common ground in this perspective, Richter and Koch inadvertently exclude it from their definition of culture as shared understandings and meanings.",0
72,27," Alvesson, Richter, and Koch (2004) aim to merge different perspectives into the idea of multiple cultural configurations, which consists of macro-culture, local culture, and situations, as outlined by Alvesson (1993). However, Alvesson critiques Martin's concept of fragmentation and suggests that ambiguity does not require a specific paradigm, but rather a research strategy (1993, p.117). Nvestad argues that Richter and Koch have overlooked Alvesson's point, and also notes that a paradox exists in the analysis of cultural fragmentation in that it appears impossible to function as an organization due to the lack of common understandings (Nvestad, 2006).",0
72,28," Alvesson and Martin do not fully agree with Schein's integration perspective. Schein believes that culture consists of fundamental assumptions that help with external adaptations and internal integration, and he analyzes culture at various levels, including manifest expressions, artifacts, and underlying unconscious themes. Additionally, Schein argues that culture must be unitary, a point that will be revisited later in the paper.",0
72,29," The anthropological perspectives discussed at the beginning of the paper can be examined in relation to Alvesson, Keesing, Martin, Schein, and Geertz. While Alvesson's emphasis on metaphors and meanings aligns him with Geertz and symbolism, his attention to sub-cultures, cultural ambiguity, and power is also reminiscent of Keesing. Martin shares similar themes with Alvesson and Keesing, and Schein's focus on cultural integration mirrors Geertz's perspective - despite being labeled as a functionalist.",0
72,30," The theoretical picture regarding safety culture is unclear. However, I believe that all perspectives are valuable in studying this topic. The true measure of their usefulness lies in how they align with empirical studies, which we will examine further in the context of the oil industry.",0
72,31," Organizational culture, as defined by Schein, refers to a set of assumptions that have been successful in dealing with external adjustments and internal integration, and are consequently passed down to new members as the correct way to perceive, think and feel. On the oil rig 'Texas', workers were well aware of these assumptions, namely that the job must be done as quickly as possible, even if it meant losing a finger or two. The newcomers were socialized effectively and learned to accept these values as fact because only those who did were allowed to stay. This value system was borrowed from the American drilling-tradition: those who could not handle the work were let go. As a result, power was also an important consideration, and anyone who did not agree with these basic assumptions was terminated from their employment.",0
72,32," The result of the process of elimination was a strong internal integration, where both the bosses and the roughnecks shared the same fundamental values, which were expressed as tacit knowledge. Cultural preservation, rather than alteration, was the norm, creating a closed community in ""Texas"" that operated in opposition to Norwegian society. This contradicted the nation's desire for Norwegianization, causing the Norwegian drill workers to become Americanized.",0
72,33," ""Although some may dismiss these views as mere conservative longing for the past, numerous employees on the modern oil rigs were actually celebrating the not-so-distant past. Despite the fact that the majority of those in charge and those on 'Welfare' were Norwegian, they had, through a prolonged process of socialization, adopted crucial aspects of 'Texas-culture' and their beliefs, attitudes, presuppositions, and implicit knowledge were unwilling to be altered.""",0
72,34," Safety Management Systems are important, but a comprehensive system does not necessarily indicate a strong safety culture. It is crucial that employees understand and accept these systems. Within the field of drilling, there was resistance to certain measures such as incident reporting and wearing protective gear. The roughnecks did not view these measures as important and disliked the bureaucracy that came with them. As a result, they undermined some measures and only paid lip service to others. The tacit knowledge found on most drilling rigs clashed with these measures and bureaucracy. Some roughnecks even talked about the ""good old days"" without bureaucracy. Additionally, some roughnecks were hesitant to seek medical attention for minor injuries.",0
72,35," 

Despite the presence of 'Systems', there was also a significant amount of 'double communication' from management, as exemplified by messages like 'Take your time – but be quick!', 'Report incidents – but don’t do foolish things!', and 'Don’t break safety rules – but use your head!'. Similarly, roughnecks expressed typical sentiments such as 'Safety rules are ok – but it takes too long if we always follow them!', 'We report many minor incidents – then we don’t need to report the serious ones!', and 'Protective equipment is important – but unpleasant to wear!'.",0
72,36," It is possible to change a culture, but it takes a long time. From an anthropological perspective, culture cannot be managed or controlled entirely. While there may seem to be similarities between cultural control in management literature and Geertz's perspective on culture as a set of control mechanisms, cultural content is constantly evolving and lasting, making it challenging to manipulate or control. Regardless of managers' or employees' efforts, culture will inevitably change over time.",0
72,37," Anthropologists and psychologists have differing opinions on whether culture can be measured. While some psychologists believe it is possible to measure culture and safety climate through a reciprocal model, others disagree. Cooper is a proponent of this approach and suggests breaking down culture into sub-components and observable behaviors, which can be more easily measured. By directly measuring each safety culture component, it becomes possible to quantify culture in a meaningful way.",0
73,1," 

Ninety samples of synovial fluid from 82 horses were analyzed, along with 40 control samples. Using blood culture medium enrichment (BACTEC), 71 of 90 samples (79%) were culture-positive, which was significantly higher than any other method. None of the samples analyzed by BACTEC enrichment were negative, while some samples examined by other methods were. Although slightly more positive samples were identified through agar culture after LC and/or CE compared to DA, this difference was not considered significant. All control samples were culture-negative when tested by any of the 5 techniques. Samples without enrichment isolation yielded the most isolates. BACTEC enrichment produced same-day culture results as agar culture with or without LC for 19/23 samples, while CE results were delayed by at least one day in 20/23 samples.",0
73,2," Blood culture medium enrichment proves to be more effective than alternative methods in the isolation of bacteria from SF of horses. Moreover, the incorporation of an automated system enables the enrichment process to occur without significantly delaying the retrieval of microorganisms.",0
73,3," 

Synovial infection in horses is a significant clinical condition that can lead to permanent disability if not diagnosed and treated promptly. Confirmation of the diagnosis and appropriate antimicrobial treatment require isolation of the causative microorganism, but this often proves difficult. Viable microorganism concentration in infected synovial fluid (SF) is typically low, and routine culture may not recover phagocytized microorganisms. Additionally, antibiotics and intrinsic inhibitors present in SF can inhibit culture, resulting in low isolation rates, as reported in studies on human patients and horses. One study found that only 37.5% of horses with clinical synovial infection were able to have isolates recovered.",0
73,4,"

There are various methods that have been proposed to enhance the isolation of bacteria from synovial fluid (SF). According to human studies, the use of lysiscentrifugation (LC) pretreatment led to an increase in the number of positive cultures when compared to standard agar culture of normally sterile body fluids. LC pretreatment involves the release of phagocytised microorganisms through short-term incubation of samples in lytic buffers, followed by maximising the inoculum through centrifugation and pelleting of microorganisms. For human SF samples, commercial LC systems such as Isolator 1.5 microbial tube have been found to increase the number of positive agar cultures by 23%. (Taylor et al. 1987; Gould et al. 1988; Hughes et al. 2001; Yagupsky and Press 1997).",0
73,5," Enrichment in broths like brain heart infusion (BHI), tryptic soy broth (TSB) or thioglycolate broth (Thio) can be used as an option for maximising the inoculum for agar culture. These conventional enrichment (CE) broths are known to support the growth of aerobes and anaerobes. Enrichment in liquid media offers the advantages of inoculating a larger volume while diluting growth inhibitors. However, research has shown that CE is rarely useful for culture of body fluids, including human SF, despite its advantages over direct plate culture. (Morris et al., 1995; Derby et al., 1997; Hughes et al., 2001; York and Thomson, 2004).",0
73,6," The efficacy of different methods for bacterial isolation from infected synovial fluid in horses has not been directly compared. Thus, the objective of this study was to compare the effectiveness of five methods - direct agar culture, LC pretreatment + agar culture, CE + agar culture, combined LC pretreatment and CE + agar culture, and blood culture medium enrichment in an automated setting (BACTEC) + agar culture - in parallel on SF samples from horses with clinically diagnosed synovial infection.",0
73,7," Direct culture of human SF was performed on four types of agar plates, including Columbia agar with 5% defibrinated sheep blood, Columbia agar with 5% defibrinated sheep blood supplemented with colistin and nalidixic acid (CNA agar), chocolate agar, and Schaedler agar. Two drops of SF were inoculated on each plate, and the plates were incubated under specific conditions. The plates were inspected daily, and if no growth was detected after 4 days, the culture was considered negative. CFUs were counted and recorded if growth was observed.",0
73,8," LC pretreatment involved incubating 0.5 ml of SF with 4.5 ml of sterile saline and 50 ml of Triton X-1004 for 15 minutes, with regular vortexing. The mixture was then centrifuged at 800 g for 20 minutes, and the resulting deposit was cultured on agar plates as described for DA. The number of CFUs was counted on each plate and compared to the results of direct agar culture.",0
73,9," Blood culture medium enrichment combined with automatic processing of bottles could be the sole culture technique for equine SF samples, as it showed a higher positivity rate compared to other methods and recovered microorganisms without delay. However, direct agar culture can distinguish between contaminating and significant organisms based on colony counts. Nevertheless, the control samples being negative for all techniques prove that contamination during collection and handling is not a significant problem when following aseptic procedures. The study's outcomes indicate that blood culture medium enrichment combined with automatic processing is a promising approach to culture equine SF samples.",0
73,10," 
Another limitation of relying solely on blood culture medium enrichment is that the BACTEC Peds/Plus F blood culture bottle cannot facilitate the growth of obligate anaerobes. However, alternative culture techniques were employed to promote their growth since low volume anaerobic BACTEC culture bottles are yet to be developed. Essentially, every agar culture was conducted in duplicate using a rich agar (SCH) that was incubated in an anaerobe pouch system. Additionally, thioglycolate was chosen as the conventional enrichment broth due to its strong recovery of anaerobes from human sterile body fluids (Reinhold et al. 1988; Scythes et al. 1996). Nevertheless, even with all the efforts made, no obligate anaerobes were found in the present study.",0
73,11, The majority of samples showed growth of microorganisms detected within 24 hours by the automated system in this study. The reliability of automatic detection was confirmed by the short TTD and low percentage of instrument-false-positives and -negatives. The spectrum of species isolated and the insignificant influence of antibiotic administration prior to sampling on isolation rate and TTD aligned with previous observations on culturing SF from horses with the BACTEC system (Dumoulin et al. 2010).,0
73,12,"
The median TTD for samples positive after BACTEC enrichment only was significantly longer compared to the median TTD for samples positive by at least one other culture method in this study. Tanju (2004) conducted a study where BACTEC blood culture bottles were spiked with various microorganisms diluted into human blood, finding a correlation between TTD and initial inoculum concentration for most organisms. Thus, it is hypothesized that the lower concentration of microorganisms in samples positive after BACTEC enrichment exclusively in this study suggests the system's value in recovering isolates from samples with a low microorganism concentration, as is often the case in synovial fluid samples (Hughes et al. 2001).",0
74,1,"
The concept of investment treaty arbitration as public law contradicts the idea of international law as a law between representative public agencies. International law is valuable for its ability to advance a wide range of public policy goals in a coordinated manner, which includes goals that go beyond the economic realm, such as international societal, environmental, cultural, and other related goals. Recognizing investor rights under international law could have implications for this concept of international law, and hence, a more thoughtful approach is required for a radical 'internationalized public law' approach to investment treaty arbitration.",0
74,2,"Since the beginning of the century, new literature has significantly progressed public law perspectives on investment treaty arbitration, playing a vital role in creating a global awareness of the public nature of investment disputes with host States.",0
74,3," 
The drive to recognize investment treaty arbitration as fundamentally a public law matter needs to continue. Embracing a public law perspective will enhance our comprehension of the character, extent, and significance of host States' regulatory power and enable us to evaluate accountability and related concerns in investment treaty arbitration.",0
74,4," This article argues that viewing investment treaty arbitration from a domestic or national public law perspective, in which it is seen as analogous to judicial review of domestic agency decisions, is incongruous with the structure of public international law and the concept of investment treaties as embodying inter-State relations between representative agencies. A public law perspective emphasizes investment treaty disciplines as constraints on State power in relation to private interests, while a traditional public international law perspective regards investment treaty disciplines primarily as governing relations between States as representative public agencies.",0
74,5," Focusing on limiting State power with regards to private interests in the commercial sector could potentially undermine the importance of public international law, which governs legal relations between representative public entities. Public international law operates with an 'inter-representative' quality that highlights the expectation of State-to-State relationships serving as platforms for advancing harmonized and comprehensive international public policies regarding various aspects including the economy, society, culture, health, environment, and other vital matters.",0
74,6," The perspective of 'internationalized public law' is a new version of the public law approach to investment treaty arbitration. Unlike previous perspectives, this approach presents investment treaty arbitration as 'internationalized public law.' However, there are some concerns regarding this approach, such as the potential promotion of indeterminate balancing principles as general principles of law and the possibility of recognizing investor rights under international law. These issues may further detract from the concept of international law as a law between publicly representative entities.",0
74,7,"

This piece commences by presenting the perspective of 'internationalized public law' on investment treaty arbitration in Part II. Part III evaluates different justifications provided for the 'internationalized public law' viewpoint, including legal justifications centered on the consent of States, the possible ascent of general principles of law as a source of law, and functional justifications. Moreover, Part III contemplates the potential justification of an 'internationalized public law' standpoint on the grounds that investors can be perceived as right-holders under investment treaties, and that they assert those rights in the same way as citizens assert rights against governments in domestic public law proceedings. In Part IV, the last section of the article, several remarks on questions and matters associated with the importance accorded to private capital within public international law in an increasingly transnationalized economic environment are presented. These queries generate added hesitation around whether an 'internationalized public law' approach to investment treaty arbitration is actually desirable.",0
74,8,"

The perspective of 'internationalized public law' is justified through legal justifications based on State consent and the potential rise of general principles of law as a source of law, as well as functional justifications. With legal justifications, the argument is that State consent and general principles of law provide the necessary authority for a shift in investment treaty arbitration from a national to an internationalized public law perspective. General principles of law are seen as providing the substantive basis for arbitral decision-making, despite the uncertainty of certain concepts that are capable of recognition as general principles of law.",0
74,9," It is possible that considering States' consent as representatives of their people could establish international investment law as 'internationalized public law'. It is reasonable to assume that States anticipated arbitral tribunals would create a distinct set of enforceable interpretations for investment treaty investor protection standards, surpassing the imprecise form seen in treaty texts. These tribunals constitute a new global network.",0
74,10,"

Perhaps investment treaties were not entered into with the intention of weakening public international law through arbitral jurisprudence. Even scholars like Gus Van Harten and Martin Loughlin, who argue that investment treaty law can transform into global administrative law through state consent, acknowledge that it is unclear how much thought went into the established arbitration system and its implications when states signed these treaties.",0
74,11,"

It is possible that support for acknowledging new general principles of law in investment treaty arbitration will gain widespread acceptance. Alternatively, if proportionality is proposed as a ""principle of general international law,"" rather than a ""general principle of law"" under Article 38(1)(c), it raises significant practical, doctrinal, and theoretical concerns.",0
74,12," Investment treaty arbitration can be viewed as internationalized public law based on functional justifications. These include the ability for individual claims against governments, the granting of damages against governments as a public law remedy, and the enforceability of awards under the ICSID Convention or the New York Convention.",0
75,1," It is commonly acknowledged that comparative law has experienced significant growth in the last 30 years. It is also well-known that constitutional law has been a major beneficiary of this trend, although comparative lawyers tended to steer clear of public law topics for much of the 1900s. Nevertheless, administrative law has been notably absent from the comparative boom, particularly outside Europe. This article examines the reasons why these two areas of public law have seen such a vast difference in the use of comparison. It also explores recent developments in administrative law and highlights several aspects of the field that would benefit from more extensive application of comparative methods around the world.",0
75,2," Comparison has become the dominant methodology in legal scholarship in recent times, as evidenced by the content of articles in top legal publications and the curricula of leading law schools. This trend has also taken hold among legal practitioners, judges, and policy-makers globally, who often look to foreign and international law for guidance. While this has led to a greater focus on theory, some have noted that comparative law still lacks strength in this area.",0
75,3," The inherent suitability of comparison for examining private law issues has been argued due to the greater contextual complexity of public law and its nationally-specific nature. The main arguments are that public law is influenced by a broader range of external factors than private law, including politics, history, and economics, making it difficult to conduct meaningful and useful comparative study in public law without a comprehensive understanding of these factors.",0
75,4," Public law is specific to a particular country's government and social structure, making it difficult to compare or transplant from other systems. This argument highlights the functionalist and harmonization objectives that dominate comparative legal scholarship, which can be traced back to the Paris Conference. However, some argue that this bias has limited the cohesive development of comparative law as a discipline.",0
75,5,Most scholars deem the worldwide proliferation of constitutionalism and the extensive implantation of fundamental constitutional concepts as central factors contributing to the upsurge of interest in comparative constitutional law.',0
75,6," Hirschl has identified four recurring elements in constitutions adopted since World War II, besides the frequent inclusion of human rights. These elements are provisions for the establishment of key government institutions and their relationships, distribution of government power, a mechanism for amending the constitution, and provisions for independent courts with jurisdiction over constitutional issues.",0
75,7," The ADJR Act aimed to simplify the intricate procedures involved in seeking relief through the constitutional judicial review remedies. It consolidates the review grounds, remedies, and application process in judicial review. Nonetheless, under the ADJR Act, jurisdiction is confined to decisions ""made under an enactment,"" which courts interpret narrowly as requiring that a decision be ""expressly or implicitly required or authorized by the enactment"" and that it ""grant, change or otherwise impact legal rights or responsibilities, and in that sense the decision must arise from the enactment.""",0
76,1," The principle of good faith is a flexible concept that is widely used in civil law countries but less so in common law jurisdictions. It allows judges to deviate from black letter law if they believe it would lead to absurd outcomes. This principle gives the judiciary the power to take various actions, including invalidating a contract, changing the price, suspending or modifying a clause, or granting injunctive relief, compensation of damages, or a removal claim. However, using the principle to redistribute wealth in favor of poor parties could compromise the concept of contracts as a social mechanism for mutual gain and result in efficiency losses. Therefore, judges should be cautious when using the principle of good faith and assess how self-interested parties would have allocated risk in a pre-contractual situation.",0
76,2," From an economic standpoint, the default rules of contract law attempt to replicate a fully detailed contract. They assign risk to the party that can avoid it or insure it at the lowest cost. They also establish norms for preventing opportunistic behavior, which can lead to an unfavorable redistribution of wealth between parties rather than enhancing their individual wealth. Therefore, contract law endeavors to distribute risks and impose obligations prior to, during, and after the contract's execution in a manner that would have been selected by fair yet self-interested parties if they had taken the time to spell it out. Nevertheless, the rules enshrined in the law may, on occasion, result in unforeseen and absurd consequences that are adequate for most but not all scenarios.",0
76,3," The principle of good faith is more prominent in civil law countries than in common law countries, and it allows courts to deviate from black letter law for the sake of flexibility. Without this principle, contract law would be less adaptable and innovative, and parties would have to write longer contracts for defensive purposes, as seen in legal orders that use good faith reluctantly. This is because parliaments cannot update laws as often as required and cannot micromanage contract law. In contrast, the use of good faith empowers the judiciary to change the outcome of legal decisions in certain circumstances, thus promoting fairness and efficiency.",0
76,4," The judiciary's power from the principle of good faith has been misused for various purposes, such as importing ideology into contract law, leading to judicial activism and potentially replacing parliament. Judicial overuse of the concept under the guise of ""maintaining justice"" can also lead to the redistribution of wealth from the rich to the poor party. Additionally, judges may stipulate important clauses in contracts without possessing the necessary information to act in the best interest of all parties, despite good intentions.",0
76,5,"

In this piece, the economic aspect of good faith is discussed and applied to cases from the Turkish Supreme Court. The article focuses solely on objective, contractual good faith, and excludes subjective good faith in property law, which could possibly result in ownership acquisition by a purchaser acting in good faith. The argument is presented that utilizing the principle of good faith to transform contract law into a means of redistributing wealth for the sake of less advantaged parties could undermine the concept of a contract as a tool for creating mutual gains for all parties involved. This could lead to undesired economic consequences in the form of losses in efficiency. Instead, the principle of good faith should only be applied with caution and reluctance to reconstruct fully specified contracts. Judges with an understanding of the factual environment in which a contract was formed should question how parties would have allocated risk in a pre-contractual situation.",0
76,6," If parties are required to explicitly assign risks and remove contingencies, it can lead to opportunistic behavior and higher incentives to do so in comparison to jurisdictions where courts allocate risks. Contracts may be more authentic but drafting them is also more costly. The lack of the good faith principle and limited court intervention in some jurisdictions contribute to longer and more detailed contracts, as can be observed in English contracts. In contrast, German contracts tend to rely more on the principle of good faith and are therefore less detailed and costly.",0
76,7," 
When comparing the two solutions, both have their advantages and disadvantages. English courts adhere more strictly to the parties' intentions as outlined in the contract. On the other hand, the widespread use of good faith serves as a useful public service that acts to fill gaps in incomplete contracts and reduces the likelihood of opportunistic behavior before and after the contract is signed (Ayres and Gertner 1989:87).",0
76,8,"

There is a general consensus among scholars in countries that recognize the principle of good faith that it should only be invoked as a last resort. Although it has the ability to fundamentally alter a contract, it should only be used in cases where the formal rules of contract law would lead to absurd consequences. The Turkish Supreme Court shares this opinion and stated in a 1984 decision that the good faith principle, outlined in Article 2/2 of the Civil Code, is an exception to the absoluteness of the law and right. However, it should only be used as a corrective measure in exceptional cases where the application of legal provisions would result in unjust consequences.",0
76,9,"

Despite the development of the principle of good faith by European and German scholars, it does not seek to transform contracts into a tool for redistributing wealth. Instead, its goal is to strengthen and amplify the true purpose of a contract: to maintain it as a means of generating mutual benefits under just circumstances, or, in economic language, to maximize economic efficiency. The application of this principle also reduces transaction costs for the involved parties.",0
76,10," The rejection of partial performance can be referred to, and while it is explicitly stated in the default rule, an exception can be made under the principle of good faith. For example, if a seller delivers 999 packs of rice instead of 1000 but offers to deliver the remaining one pack the next day, it would not be fair for the buyer to reject this partial delivery. Hence, the court will not enforce the default rule.",0
76,11," When the law and default rules do not address risk allocation, it can create an incomplete and unfair situation. However, the principle of good faith can be used to efficiently allocate risk. For example, the medical doctors who exchanged practices could use good faith to determine a fair risk allocation.",0
76,12," The good faith principle has a structured limitation on its usage, despite being applicable in countless cases and having the potential to result in various legal outcomes. Judicial interpretation cannot be conducted arbitrarily as the principle has an internal framework. Some potential outcomes include contract invalidation, alterations in price, suspension or changes in a contractual clause, injunctive relief, compensation for damages, profits disgorgement, or removal claims.",0
76,13,"

One major criticism of the principle of good faith is its broad and vague nature, which could potentially give judges too much power. Rather than attempting to provide a specific legal definition for the principle, this article simply acknowledges that it enables the judiciary to intervene in contracts when other methods of interpretation fail and prevents parties from acting in bad faith. Additionally, the principle of good faith is designed to promote mutually beneficial outcomes for all parties involved and prevent one party from unfairly exploiting the other.",0
76,14," The plaintiff had a lifelong care contract with someone and fulfilled all their obligations until the other party passed away. When the plaintiff requested the agreed compensation, the deceased's heirs argued that the contract was invalid due to a form requirement breach. The court decided that it is wrong to claim contract invalidity due to form requirements after fulfilling a lifelong support or adoption contract and the plaintiff was entitled to compensation.",0
76,15,"

It is clear that allowing someone to use their right solely to harm others is not productive. Consequently, Turkish law, along with many other legal systems, establishes a limit to the owner's rights through the concept of ""misuse of right"" in order to increase efficiency.",0
76,16," The principle of good faith includes an 'obligation to contract', which is the main issue in this case. The owner of a flat was refused a subscription and water supply services by the state water supply company due to unpaid bills from the previous evicted tenant. The Supreme Court ruled that the company, being a monopoly, must fulfill its obligation to contract.",0
76,17,"

The case involves a monopoly water supplier, leaving the customer with no choice but to purchase water from them, which is a basic necessity. In such cases, price and terms of supply must be regulated to prevent exploitation. Contract law must therefore follow the principles of public and administrative regulatory law. In a competitive market, such legal intervention may not be necessary, as companies would fear losing customers to their competitors. However, in monopoly markets, the legal system needs to have a deeper role in regulating contract freedoms to ensure fairness.",0
76,18," 

In addition, this particular situation depicts that the outcome not only aligns with notions of fairness and justice but also illustrates that choosing an alternate approach would create inappropriate incentives. If, in this case, an agreement did not exist that permits the electric company to charge for the actual electricity used, it would encourage everyone to consume electricity without entering into a contract, resulting in the electric company being burdened with the costs of proving the damage or the unjust enrichment amount later. This would, in turn, increase the prevalence of unlawful electricity consumption.",0
76,19," The respondent, who was a minor at the time, gave a gift to his future wife. However, 11 years after getting married, he argued that the gift was invalid as he lacked the capacity to make such a decision. The Supreme Court rejected this claim, stating that it goes against the principle of good faith. Although the Court did not mention any specific sub-categories of good faith, it can be assumed that they view the respondent's actions as an abuse of his rights.",0
76,20," It is unclear whether the proposed solution aligns with protecting women, justice, and efficiency. While reducing the protection of minors may save time, it comes at the cost of wasting resources and impacting society. Without sufficient evidence, it is uncertain whether these costs outweigh the benefits of protecting women. However, the court emphasized the importance of the time lag between forming and refuting the contract. If the man had refuted the contract earlier, it could have led to a redistribution of wealth, which is not justifiable economically.",0
76,21," In a scenario where joint ownership was established, the parties distributed their immovable property through a written agreement, which did not adhere to the official requirement of concluding such a contract at the land registry. Each owner then proceeded to lease out his/her portion of the immovable property to third-party occupants for a few years. Along the way, one of the co-owners sold his/her share of the property to a third party. Subsequent to this, another shareholder sought to exercise his/her preemption right. However, the court pronounced that it would be against the principle of good faith for a co-owner, who did not raise any objections to the initial allocation before, to seek such a right in a scenario where a third party has already purchased the property through legitimate means. The Supreme Court did not explicitly refer to any subcategories of good faith in its decision, but it can be inferred that the court regarded the respondent's action as an abuse of their right.",0
76,22," The court's ruling aims to prevent opportunistic behavior after a contract has been signed, and it overrides the mandatory requirement for the contract to be concluded at the land registry. This is because the form requirement protects against impulsive decisions and ensures that decisions are in line with an actor's long-term preferences. In this specific case, the joint-owners had agreed to end their joint-ownership and divide the property, with agreements already made on the distribution of assets and use of the immovable. It was only after some time had passed that one joint-owner exercised their pre-emption right.",0
76,23," The case pertains to a mobile phone contract where the concern was the interest rate charged on overdue bills. Though the contract did not stipulate a specific interest rate, the GSM operator had the power to set it unilaterally. However, the GSM operator charged an interest rate of 12% per month, higher than its competitors' rate of 8%. The court held that the GSM operator's discretion in setting the interest rate is not absolute, and charging a 12% interest rate instead of an 8% rate amounted to a misuse of freedom.",0
76,24,"

The Supreme Court upheld the validity of the clause, assuming it was negotiated between parties, but declared that the only way to abide by the principle of good faith was to establish an interest rate not surpassing that of comparable companies. However, we believe this interpretation exceeds the principle of good faith as setting a higher interest rate for overdue bills may be a reasonable business tactic. By communicating to subscribers that tardy payments will incur significant costs, the company signals to on-time payers that they are valued but to defaulters that they should look to another operator. The elevated rate plays the role of a contractual penalty, deterring delinquent customers and preventing the company from incurring expenses related to reminders, court procedures, and so on. Through this focus on the customers who pay on time, the company can advance better deals for that particular performance.",0
77,1," This article uses an innovative approach to analyze the theoretical and practical foundations of world trade law by employing the interactional international law theory developed by Jutta Brunnée and Stephen Toope, as well as Lon L. Fuller's jurisprudence. The interactional approach is chosen for two main reasons: first, it provides a suitable framework for identifying the social foundations of world trade based on economic and legal inputs into the system, and second, Fuller's contributions are relevant to world trade law because of the economics foundation of his morality of law thesis and his reflections on fidelity to law, legality, and adjudication. Additionally, Fuller's jurisprudence is useful for discussing the procedural challenges facing the World Trade Organization compliance regime due to its attention to the limits of adjudicating institutional rules that apply to the allocation of economic resources.",0
77,2," Despite the widespread polarization, there are more contemplative voices that recognize the interconnectedness of the economic and legal concepts, especially in the context of a modernized world with growing interdependence. While rationality now dominates law, statecraft, and economic relations, it has also fundamentally transformed economic ideals, practices, and institutions. Thus, world trade law is a way of re-articulating legalism to fit modern economic governance. Rethinking the legal also demands rethinking the economic, including its claims to truth and promises of maximizing internal and external wealth.",0
77,3," The article will be presented in seven parts. Part two will provide an overview of the interactionalist approach to public international law. Part three will shed light on the social roots of the global trading system and examine the often-ignored role of legal commitments. Part four will explore the dispute between anti-legalists and legalists regarding conformity, a disagreement that has contributed to various distorted views on the content and function of global trade regulations. In part five, the essay will argue that interactionalism is the most effective theory for analyzing the GATT/WTO regulations. Part six will outline the challenges of applying the interactional approach to global trade law, and finally, part seven will give a conclusion.",0
77,4," The presence of common understandings that pertain to legality and reasonableness is crucial for the advancement of this field. The utilization of Fuller's criteria for assessing the legitimacy of an international regulation can enable a logical evaluation of the rule, making a distinction between a law and a social norm that may become law through interactions with associated actors.",0
77,5," The social foundations of world trade can be misinterpreted due to two main causes. Firstly, there is a challenge in balancing legal means for achieving trade liberalisation with normative ideals such as human rights and environmental concerns. Secondly, there is a divide between the collective administration of legal rules for trade liberalisation and individual implementation of these rules by WTO member states. This divide makes it difficult to determine whether a breach of rules is based on normative concerns under (GATT Article XX) or solely for the purpose of protectionism. As a result, it is unclear whether upholding WTO law or normative concerns should take precedence.",0
77,6," It seems that Cho's communicative approach aligns with the interactional approach in two distinct manners. Initially, it acknowledges the development of norms over time - from a focus on self-interest and short-term advantages in open trade to an emphasis on appropriateness and communication - which creates a cycle of learning and mirroring norms. Secondly, Cho's communicative approach and Fuller's jurisprudence both express doubts about the steadfastness of 'loyalty to law.'",0
77,7," The extensive contribution of WTO jurisprudence lies in its ability to foster adherence to the law rather than to power, thereby bringing together all members of the global trading system around a shared ideal. Any legal void would be filled by narrow-minded criteria such as political circumstances without adherence to the law. Thus, the self-awareness of the participants regarding the normative framework in which the community operates is an indispensable aspect of the community of law.",0
77,8," The WTO dispute settlement system has not only become an effective communication tool in the development and execution of trading laws, but it has also established a reciprocal system and a normative reference system that limits the unilateral exercise of power. From a historical perspective, this system has evolved to impose significant constraints on might over right.",0
77,9," Social norms arise from a foundation of commonly held beliefs that support the importance of having norms, which then lead to specific norms dictating behavior. Once established, these shared beliefs become the background knowledge that influences how individuals perceive themselves and their surroundings, develop priorities, and evaluate ideas.",0
77,10,"

Legal experts and political analysts have confirmed that the world trading system, previously known as GATT, has transformed into a legal system that is now known as the WTO legalistic order. However, there are people who disagree with this and argue that it has become a mere set of procedural rules that do not encourage the idea of rules being necessarily obligatory. Political scientists can shed some light on this issue as there are similar debates in the field of political economy. Some scientists believe that the primary function of the WTO dispute settlement system is to act as an enforcement tool, which supports the legalistic account that it should penalize non-compliance.",0
78,1," The article analyzes the recent advancements in Chinese law and judicial practice governing arbitration agreements. It suggests that by implementing certain modifications in mainland Chinese regulations and practice, the country can establish itself as an arbitration-friendly jurisdiction internationally. The article emphasizes the need for clear statutory guidelines and a consistent approach to determine the place of arbitration and the applicable law. Therefore, it recommends that parties involved in contracts with Chinese elements should explicitly specify the place of arbitration and the governing law of the arbitration agreement.",0
78,2," From a textual analysis of the current PRC law, it appears that applying the law of the seat of arbitration as the applicable law of the arbitration agreement may not be valid. In recent years, the development of PRC law has led to complications and uncertainties on several related issues.",0
78,3," The Law on Applicable Law in Foreign-Related Civil Matters, which went into effect on April 1, 2011, includes Article 18 stipulating that if the parties have not agreed on the law that governs the validity of the arbitration agreement, then either the law of the place of the arbitration institution or the law of the place of arbitration will apply. However, there is no guidance on when to apply the law of the place of the arbitral institution versus the law of the place of arbitration, or which law takes priority in case of conflicting laws.",0
78,4,"

On the 28th of December 2012, the Supreme People's Court released Opinion No. 1, tackling several issues related to foreign-related civil matters, effective from the 7th of January 2013. According to Article 14 of this opinion, in cases where there is no agreement between the involved parties regarding the law governing the arbitration agreement, the arbitral institution, or the place of arbitration, or if the agreement is ambiguous, the People's Court may use the law of the PRC to authenticate the validity of the arbitration agreement. Unfortunately, the Supreme People's Court failed to clarify certain critical aspects, such as what consists of an agreement on the ""place of arbitration,"" how to identify the ""place of arbitration,"" the legal impact of the ""place of arbitration"" on the arbitration agreement, the arbitral procedures, and the resulting awards, and the legal relationship between the ""place of arbitration"" and the ""place of the arbitration institution.""",0
78,5," It is unclear under current PRC law where an arbitral award is deemed to have been made. While the New York Convention does not provide guidance on this matter, ICCA's Guide (2013) indicates that the majority of Contracting States believe that an award is made at the seat/place of arbitration, which is a legal concept determined by the parties or the arbitral institution/tribunal. This aligns with Article 20 of the Model Law and Article 31(3) specifies that the award's date and place of arbitration should be determined in accordance with Article 20(1), and the award shall be considered made at that place. However, these key provisions are absent from the current PRC Arbitration Law (1995), although this issue is addressed in the CIETAC Rules (2012) in Article 7 (Place of Arbitration).",0
78,6," The ICC and CIETAC Arbitration Rules allow for the seat of an arbitration to be determined by the court or commission, unless agreed upon by the parties. This means that the ICC Court of Arbitration can choose the location of the arbitration, even if their headquarters are in Paris. Similarly, the CIETAC may choose the seat of arbitration to be their own domicile or a location relevant to the circumstances of the case. With the recent launch of the CIETAC Hong Kong Arbitration Centre, it is likely that arbitrations conducted there will have their seat in Hong Kong, despite the commission's headquarters being in Beijing.",0
78,7," It may be more intriguing to consider whether Chinese courts would acknowledge the legitimacy of an arbitration agreement that specifies arbitration administered by non-Chinese arbitration institutions, such as the ICC International Court of Arbitration, with the seat of arbitration in China, but non-Chinese law governing it. An exemplar of this scenario would be the ‘Arbitration: ICC Rules, Shanghai’ clause in the German Züblin (2004) case where the parties stipulate that the arbitration agreement is governed by French law. It is argued that, under the designated governing law, the Chinese courts must uphold such arbitration agreements despite current PRC law, preventing them from being declared invalid. Careful and specific selection of a proper governing law could save the agreement from being invalidated.",0
78,8," The Supreme People’s Court did not consider the validity of the arbitration clauses under the law of the other agreed place of arbitration (Brussels) in the Amoi (2009) case. It is unclear why Xiamen was chosen over Brussels. The parties may have intended to have a fallback option in case the arbitration clauses were found invalid in one place of arbitration. If the arbitration clauses were found valid under Belgian law, the parties could potentially seek recognition and enforcement of a resulting Belgian award in China. However, it is uncertain whether the People's Court would recognize and enforce the award given its prior finding that the arbitration clauses were invalid under PRC law.",0
78,9," The Amoi (2009) case's arbitration agreement is within the scope of the New York Convention. Despite stating China as the place of arbitration, it also mentions Belgium, which is a contracting State to the Convention. As per Article II of the Convention, the People’s Court should recognize the agreement and refer the parties to arbitration, unless the agreement is null and void, inoperative, or incapable of being performed. Additionally, the ICCA’s Guide (2013) highlights that the Convention must apply if the future award will qualify as non-domestic according to the second sentence of Article I(1) of the Convention, even though the seat of arbitration is in China.",0
78,10," It could be argued that the choice of arbitration location was implied by the name of the designated arbitration commission, as it was named after a specific city in Guangdong province. However, even though applying the law of the place of arbitration would not have changed the outcome of the case, the Supreme People's Court still held that the designation of the arbitration commission alone does not constitute the designation of the place of arbitration.",0
78,11," In the Shenzhen Food Group (2010) case, the Supreme People's Court determined that stating the law governing the contract did not extend to the arbitration agreement, and that designating an arbitration institution did not constitute choosing the place of arbitration. This implies that clear and specific agreement to both the governing law and place of arbitration is necessary, or else the court may apply PRC law to determine the arbitration agreement's validity. A more specific choice of English law could have resulted in valid arbitration clauses.",0
79,1," The Israeli Supreme Court rulings on children's rights in the early 1990s were presented as a new doctrine, attributed to the ratification of the UN Convention on the Rights of the Child and Israel's Basic Law. However, this article argues that the recognition of children as rights bearers is not new and can be seen in earlier case law. The development of the case law has been non-linear, and the article analyzes the spiral progression of this process and provides explanations for the Israeli case law's particular course in recognizing children's rights.",0
79,2,"
Contrary to what the Supreme Court has stated, children have been viewed as rights bearers for a while now. In fact, the Israeli Supreme Court recognized children as such back in the 1950s and 1960s, with their decisions being even more extensive than those made after the ratification of the Convention. However, the recognition of children's rights had a significant setback in the 1970s and 1980s before making a comeback in the mid-1990s. This article tracks these developments and proposes possible reasons for the unique path taken by Israeli case law.",0
79,3,"

To analyze the recognition of children as rights bearers and its changes, it is essential to define its key features. After reviewing related literature, such as Doek 2007, Eekelaar 1986, Freeman 2000, and Woodhouse 1993, I found three significant components: (1) acknowledging the child's separateness as a person and rights holder, (2) prioritizing the child's rights and interests in legal proceedings, and (3) recognizing children's agency in decisions that affect them.",0
79,4,"

Licht-Petran (2010) identified four key differences between the best interests principle and the children's rights principle as applied in Israeli case law. First, the best interests principle does not recognize the child as a legal entity with specific rights, meaning that neither the state nor parents have any obligation towards them. Second, the best interests principle is subjective and vague, whereas the children's rights principle is more concrete. Third, the best interests principle tends to be paternalistic, ignoring the child's wishes, while the children's rights principle requires consideration of their rights in decision-making. Fourth, there is no discussion or regulation regarding the weight of the child's best interests compared to others, unlike the children's rights principle which considers the relationships between different parties' rights and interests. While this article will not delve into the specifics of concrete rights, it will examine how Licht-Petran's observations fit into the analysis conducted here.",0
79,5,"

The first and primary section of this article focuses on how Israeli case law views the three aspects and their evolution in terms of acknowledging children as rights holders. In the second and final segment of the paper, possible avenues for future research are proposed to help unravel the intriguing findings from the first part.",0
79,6,"
In the 1950s, Supreme Court rulings began to emphasize the importance of recognizing children as individuals with their own interests and rights separate from those of their parents. Justices Kister and Silberg, who based their viewpoint partially on Jewish law, were among those who made these statements. The Steiner case in 1955, which dealt with a petition to send a girl back to her father in Austria, was particularly influential. Justice Silberg emphasized that children should not be regarded as objects or mere resources for their parents' pleasure or benefit, but as individuals with their own concerns and needs that should be taken into account.",0
79,7,"

The recognition of a child as an individual entity became evident in the mid-1990s when the rhetoric changed to acknowledge children as rights holders. Previously, there had been no recognition of this fact. Following this point forward, there was a distinctive and unequivocal presentation of the child's separate legal identity grounded in the doctrine of children's rights. This concept was emphasized by Chief Justice Shamgar in the case involving Jehovah's Witnesses, previously mentioned. Justice Shamgar explained that the idea of children's rights denotes that a child is an independent being, whose interests and rights are separate from those of their parents.",0
79,8," The principle of child-centeredness complements the separateness principle by emphasizing that all legal issues concerning a child should be viewed from the perspective of the child's rights, needs, and interests. However, this approach does not mean that the child's perspective will always be the deciding factor in legal proceedings, nor does it preclude acknowledging the rights of others. Rather, the child-centered approach is justified by the concern that children's rights and interests may be overlooked due to their relative vulnerability. This shift toward child-focused decision-making reflects a growing understanding that legal and cultural discourse has traditionally prioritized adults and their interests.",0
79,9," ""During the early years of the Supreme Court's legal philosophy, Justice Kister made an influential statement emphasizing the importance of prioritizing the rights and well-being of children within parent-child law. In the 1986 Tsabar case, he clearly distinguished between legal systems based on 'parental rights' versus those prioritizing 'the child's rights and best interests.' Drawing on Jewish law, he noted that upholding the child's residence according to their best interests, progress, and rights is a unique aspect of this legal framework.""",0
79,10,"Children’s rights have been increasingly prioritized since the 1990s, as evidenced by various decisions. For example, in 1995, Justice Cheshin emphasized placing the child's interests at the forefront by imagining the world through their perspective. This sentiment has also been echoed in lower court rulings.",0
79,11," The early case law reveals two distinct approaches. The first approach, which was more commonly adopted, asserts that parents do not have any custody rights. Judge Kister's ruling in the Steiner case clearly supports this view, where he explains that the father's custody rights in English law come from his own rights, which he cannot claim under Jewish law. The father is expected to act in the best interests of his children, but he does not have any custody rights granted to him under Jewish law.",0
79,12," Judge Kister, during his tenure in the Supreme Court in the 1970s, reiterated his belief in numerous rulings. For instance, in the 1971 case of John Doe v. Richard Roe, he declared that Jewish law does not have a phrase for ""the right to keep the child."" Rather, it only indicates that the child should be ""with his father"" or ""with his mother."" This implies that these are not parental rights but rather the child's entitlement to be with a parent based on their best interests.",0
79,13," 

The second perspective, which also depends on Jewish law, acknowledges that parents have rights but emphasizes the superior importance of children's rights. Rabbi Kafih stated in 1981 during the Nagar case that ""parents are not lifeless entities. They possess both body and soul, they have emotions, and the mother has a biological right to satisfy her desire to hug her child.""",0
79,14," In the 1980s, adoption decisions acknowledged parental rights as constitutional rights. Justice Barak stated in State of Israel v. Jane Doe, an adoption case, that a parent’s legal right is to meet their obligations towards their child. This view was echoed in other decisions which recognized the constitutional right of natural parents to fulfill their obligation towards their child, and that the law protects the family from state interventions. These rulings placed importance on parental rights as constitutional rights but did not grant similar status to children's rights to custody. The significance of these rulings lies in the shift in rhetoric they herald.",0
79,15," The decisions made by the District Court and the Supreme Court in an adoption case dealing with a petition to revoke parental rights in the absence of the father represent the various approaches toward custody rights. In 2004, Judge Rotlevi, for the minority in the District Court, relied on the Convention and stated that the child's rights, needs, and interests should be the starting point on the custody question. He emphasized that the child had been denied the right to grow up with their parents since birth.",0
79,16," Justice Cheshin proposed a third approach where parents' and children's rights are interconnected but uneven in terms of status. In case of a disagreement, the child's right takes precedence over the parent's right. According to Justice Cheshin, the interests of parents and children are generally aligned and complementary. However, the rights of the child are not subservient to those of the parent but in fact, superior.",0
79,17," In regards to the recognition of children as rights bearers, I will analyze their right to express their opinions and have their desires taken into account. Freeman (1983: 3) emphasized the significance of this right by stating that we have separated ourselves from children, leading to the dehumanization of the young. This right requires that children's abilities are recognized, and they are given a voice in decisions involving them whenever possible.",0
80,1,"

This discussion builds on Switzerland's example to consider the potential benefits of creating a codified set of private international law regulations in the European Union. Switzerland's Federal Act on Private International Law is considered one of the most comprehensive set of PIL regulations in the world, containing 225 articles that cover a range of topics, including international civil procedure and the recognition of foreign judgments. The author argues that a comprehensive codification of PIL rules offers numerous advantages over having these rules dispersed across multiple acts and regulations. These include enhanced accessibility, greater uniformity and coherence, and increased legal certainty. Ultimately, the author suggests that the EU should initiate preparatory work for the enactment of a comprehensive PIL regulation.",0
80,2,"

As foreign cases and PIL issues become more frequent, the legal system must coordinate the diversity of national laws in a less complicated way. Lawyers working internationally must inform their clients of where to bring a claim, which laws apply, and what outcome to expect. Judges who deal with cross-border scenarios occasionally need a private international law system and conflict of laws rules that they can easily navigate. The international context requires legal certainty and predictable outcomes, just like purely domestic situations.",0
80,3," The current complexity of PIL in the EU is largely attributed to the growing number of regulations. This prompts the question of whether a new legislative act is necessary. Rather than enacting more separate regulations, it may be more effective to consolidate all existing rules on PIL into one coherent act of legislation. This would help to avoid confusion and streamline the process.",0
80,4," The current version of the Swiss Federal Act on Private International Law, known as the Swiss PIL Act, encompasses 225 articles, featuring a General Part composed of 38 provisions. The act deals with crucial aspects like jurisdiction, recognition, international civil procedure, and the enforcement of foreign judgments, covering every corner of private international law and serving as a comprehensive codification.",0
80,5," In several law schools in England, PIL is not taught at all and in some, it is only offered as an elective subject. Due to this, the majority of European lawyers lack specific training in this area and may not even possess a fundamental understanding of PIL. Furthermore, judges seldom encounter questions related to PIL, and when they do, they must educate themselves on a case-by-case basis on the intricate laws and navigate through the myriad of rules from various sources.",0
80,6," It is crucial for the EU legislator to ensure that accessing the area and comprehending the rules on PIL is simple and convenient through its legislation. This is imperative for both the legal practice and the judiciary, along with the law-seeking citizens' viewpoint.",0
80,7," The PIL Act is designed to be user-friendly with reminders to judges to double-check for international conventions that may take precedence over the Act. Furthermore, each section dealing with specific subject matters includes references to relevant international treaties. The PIL Act explicitly refers to specific Hague Conventions which take precedence over the Act, ensuring accurate compliance by practitioners.",0
80,8," It may be prudent for the European Union legislative body to incorporate an Article 1 that mimics the aforementioned provision in an all-encompassing EU private international law regulation. Such a move could offer European legal practitioners an initial direction and streamline their comprehension of the topic and ultimately, the resolution of the relevant legal case.",0
80,9," Article 1(2) of the PIL Act could be a possible template for the codification of the European Union. This would help judges in Europe get directions, especially with regards to Hague Conventions that are effective in their respective Member States and may have priority over the European PIL regulation.",0
80,10," Consideration could be given to adding a new section in Article 1 of the Swiss PIL Act and a comprehensive EU PIL Regulation that gives priority to uniform substantive law in cases where it is applicable. This would eliminate the need for PIL rules. The proposed article would prioritize the Convention on Contracts for the International Sale of Goods (CISG) in international sales scenarios, as long as the case falls within the scope of CISG's application for the relevant EU Member State.",0
80,11," Having a General Part in recent national PIL Acts, as well as the Swiss PIL Act, is important in avoiding the repetition of principles and promoting coherence throughout the legislation. This approach is now part of the international norm for codifying PIL in a separate statute, and not having a General Part would be a regression compared to the progress achieved by national PIL law Acts over the past decades.",0
80,12," The Swiss comprehensive PIL Act has had a highly positive impact. Its structure effectively identifies the connections between rules on jurisdiction and applicable law, treating both areas with a unified set of regulations. This approach minimizes conflict, reduces the potential for competing interpretations, and encourages a cohesive perspective on the entire matter. In instances where a term might be defined differently for jurisdiction and applicable law, any deviation must be justifiable. The same applies to terms defined differently for the various topics in the Special Part.",0
80,13," The PIL Act's qualities make it easy to teach the subject, unlike the complex EU PIL system which was a concern during the Freiburg conference. In Geneva, the Swiss PIL Act is taught to 250 students annually with no teachability issues. After completing the one semester course on PIL, students are able to solve complex issues in all core areas of PIL. Efficient teaching and learning of the subject helps future lawyers and judges handle the matter reliably in their practical lives.",0
80,14," 

Swiss students sometimes liken the accuracy of the PIL Act, the clarity of its organization and regulations, the seamless interplay of its Special and General Parts, as well as the coexistence and interaction of global conventions and national PIL Act to mathematics. Students from other countries are reminded of the efficient workings of Swiss watches. They are unlikely to associate it with disorder and confusion but, rather, a system of rules that are well-coordinated, consistent, and interact smoothly with one another, frequently resulting in clear and predictable outcomes.",0
80,15," It should be noted that each of the previous thorough national codifications of PIL has a General Part. Thus, the comparative study's second takeaway is that a contemporary European Union PIL legislation must include a General Part, which seems like an obvious requirement from a comparative law standpoint.",0
80,16," The precedence set by Switzerland indicates that the General Part ought to commence with the establishment of jurisdiction and then proceed with rules regarding the applicable law, concluding with general rules aimed at recognizing and enforcing foreign judgements. Implementing this order promotes consistent interpretations, thereby minimizing inconsistencies and conflicts.",0
81,1," Comparing legal systems is a distinct branch in law due to its significant role. National borders cannot confine the knowledge of any branch in law. The definition and purpose of comparative study in civil procedure have faced criticism, and there are particular challenges with studying similar systems in different legal systems, including differences in purpose, definition, and concept. The disparities between civil law and common law systems, such as differences in judicial organs, judges' appointment, and judicial formalism, exacerbate the issues of comparative study. However, understanding these differences can facilitate comprehension of these legal systems and discern common principles, encouraging the utilization of each other's findings while recognizing the impediments of comparative study.",0
81,2," Comparative law not only enhances understanding of foreign laws, but also aligns with the global standardization and harmonization of law. Law is not limited to interpreting domestic laws; it can offer diverse problem-solving approaches applicable to domestic issues. These approaches have already been developed within developed nations.",0
81,3," The assertion that procedural law is not subject to comparative analysis is contested by some scholars. They argue that civil procedure is no different from other areas of law, and that procedural principles are based on particular rules, such as Loipolitiques, which may not be applicable or transferable to all countries and communities.",0
81,4," According to recent historical narratives and experimental evidence, national legal systems are aligned with the legal traditions of their countries. Civil law countries have procedural and substantive codes that are distinct from those of common law nations. Scientific research supports the concept that legal roots significantly shape a society's structural characteristics, including the relationship between individuals and the state. As a result, this impacts the codes, procedures, and rules, and has a broad economic impact.",0
81,5," According to this theory, the utilization of civil procedural law models is an incorrect use of comparative law and will ultimately lead to dissatisfaction. As a result, civil procedure will become nothing more than a law branch that cannot utilize comparative studies. However, since twelve universal procedure congresses have addressed almost all significant problems and challenges in procedure since 1950, we could argue that the opposing perspective is accurate.",0
81,6," The civil procedure aims to define the legal rights and responsibilities of individuals and to provide a mechanism for resolving disputes. Without a proper procedure, individuals may resort to their own power to settle matters, leading to unjust outcomes dominated by the stronger party.",0
81,7," The ideal goals of civil procedure include accurately determining rights through a just trial process, conducting proceedings promptly, ensuring accessibility for all, and striving for precision, fairness, speed, and efficiency. Essentially, civil procedure exists to uphold the private rights of individuals, with rules put in place to settle any disputes regarding those rights.",0
81,8,"

Studying the civil procedure rules allows us to see how they can impact, punish, compensate, and clarify human actions. Litigation is often compared to a game where parties are players and judges are referees. This game is highly competitive and has winners and losers. Understanding the rules is challenging as they are abstract, but can be grasped through experience. Thus, comprehending civil litigation may be easier than grasping civil procedure.",0
81,9," Based on the aforementioned results, it can be inferred that defining civil procedure in comparative law is challenging. Nevertheless, if an individual intends to define civil procedure, J.A Jolowicz's accurate definition seems plausible. Jolowicz suggests that civil procedure entails the techniques used in court procedures, and that the initiation of litigation is a voluntary process, where the plaintiff's actions aim to gain benefits. Lastly, civil procedure cannot occur without a defendant.",0
81,10," The legal framework for international transactions varies greatly among countries with different levels of economic and legal development, resulting in obstacles and problems in the process of ratifying and implementing these transactions. The differences in concepts, techniques, and legal methods among legal systems create a variety of applicable rules in international commerce. Judges, who are trained in national legal systems, may face difficulties in understanding concepts and expressions of foreign legal systems.",0
81,11,"Through comparative studies, there is a chance to reconsider and adjust national laws of different systems, by understanding and acknowledging other legal systems. This can be through incorporating or exporting methods, so as to offer diverse approaches to address similar concerns.",0
81,12," 

When Japan chose to implement the German civil procedural code in 1889, it appears that they didn't conduct a deep analysis of the relevant laws, but instead aimed to follow a modern model. This was likely influenced by Germany's success at the time. After World War II, American lawyers encouraged the adoption of certain civil procedural models from common law, but it doesn't appear that this was done with a thorough comparative analysis.",0
81,13," 
Some legal experts view the reliance of civil procedure on the national power framework and societal norms of efficiency and culture as a hindrance to utilizing comparative studies. However, advocates of this approach point to the benefits of international trade and globalization, as well as the knowledge gained from the European Court of Justice, and argue that it can lead to the emergence of universal common principles and a model civil procedural law based on collective wisdom.",0
81,14,"

Both legal systems differ in their ability to adapt to modern situations. Common law is more dynamic because its rules gradually adjust to society's changing needs on a case-by-case basis, and there is less probability of a large gap between economic needs and the law. In contrast, French civil law, born out of revolution, aimed to create an unchangeable, complete law. However, in practice, the French law has adapted to commercial realities. Germany has based its framework on Savigny's vision and seeks to establish a dynamic codex, while Spain has made periodic reforms towards civil law.",0
81,15," The civil courts are primarily competent in the first instance since their competence is broad and covers various cases such as personal status, financial and real estate conflicts, and verdict executions. Their local jurisdiction applies to French departments, with varying main civil courts based on population and judicial activity volume. France has 163 main civil courts for 100 departments, alongside courts with specific competence for allocated cases by law. The circuit court is also competent in dealing with minor civil claims such as neighbor conflicts, land lease cases, and debts less than 10,000 pounds, as a substitution to magistrates' courts.",0
81,16," The history of the commercial courts in the French judicial system dates back to the end of the Middle Ages, making them the oldest courts. France currently has 135 commercial courts, which are syndical courts comprised of merchants appointed by their peers.",0
81,17,"The commercial court has jurisdiction over more than just commercial cases. It also handles disputes between merchants, conflicts involving commercial activities (such as bill of exchange) that may not necessarily involve businessmen, conflicts regarding commercial companies, and bankruptcy proceedings in commercial and industrial enterprises.",0
81,18,"

The 2005 constitutional law reforms were the most significant changes England had seen in 300 years. These reforms included the transfer of the Lord Chancellor's judicial function to the lord chief justice, who now serves as the president of the England and Wales courts. Emphasis has been placed on the importance of an independent judiciary, and the United Kingdom Supreme Court was established. One of the most significant aspects of the law was the creation of an independent jury for judges' appointments, as well as the appointment of an ombudsman to handle complaints about the process. There was widespread agreement that historical standards of appointments should be modernized, and the Judicial Appointments Commission was established in April 2006 to appoint judges based solely on their eligibility. In the United States, some state judges are elected and can receive financial support similar to that of political candidates.",0
82,1," As high-tech applications increasingly require multi-material components, careful consideration must be given to material compatibility, as reactions between different materials in adjacent regions can weaken the component. Stress concentration and, in extreme cases, failure can also occur due to mismatched material properties. To address this issue, this paper outlines an effective evaluation method for material affinity, including the definitions, evaluation criteria, and calculation formula deductions for physical and chemical affinities.",0
82,2," 

With the advancements in technology, there is a growing need for components made of various homogeneous and heterogeneous materials to meet specific functional requirements. To achieve this, different materials with diverse microstructures and compositions must be bonded or sintered together, resulting in various interfacial regions. However, if chemical reactions occur between the adjacent regions, the resultant weakens the interface, making it easier for peeling to take place. For example, a component made of an aluminum core and a carbon shield can endure large loads while resisting friction. However, the resultant aluminum carbide has low strength and cannot bear heavy loads.",0
82,3,"Material affinity refers to the degree of interface stability between two distinct materials that are bonded or sintered, and it includes both physical and chemical affinity. Physical affinity measures the interface's stability under working conditions, while chemical affinity indicates its chemical stability under the same conditions. Assessing chemical affinity between two materials is the first step in determining their material compatibility. If their chemical affinity is low, a strong chemical reaction may result, preventing them from being connected, and physical affinity need not be considered. However, if the chemical affinity is high, one must further evaluate their physical affinity. If it exceeds the allowable value, the materials may be deemed suitable for use in two adjacent regions.",0
82,4," 

In this paper, the author introduces a new concept called ""material affinity"" which measures the bonding strength of the interface between two material regions bonded together. This concept includes both chemical and physical affinity and is evaluated using specific criteria. The paper provides examples of how to evaluate material affinities for mechanical or thermal analyses. Using these criteria, the material affinities of several material pairs are determined, yielding guidelines for selecting suitable material pairs. By using this evaluation criteria, designers can choose suitable or optimal materials for designing components made of multi-materials in different fields of high-tech. While the paper only provides examples of mechanical and thermal applications, the evaluation criteria can be applied in other areas as well.",0
82,5, The material pair of aluminum and nickel exhibits the strongest physical affinity in mechanical analyses since they possess similar Poisson's ratios. This finding suggests that the difference in Poisson's ratios has a greater impact on physical affinity compared to the difference in Young's moduli among studied material pairs.,0
82,6, The material pair of aluminum and copper has the lowest maximum peeling stress in mechanical analyses because their Young's moduli have similar values. The material pair of aluminum and molybdenum has the lowest maximum shear stress because their Poisson's ratios have similar values.,0
82,7," 
To conclude, the material combination of aluminum and copper shows the highest physical coherence among the studied pairs due to the aforementioned factors. Hence, when choosing materials for neighboring areas, it is ideal to opt for materials with analogous Poisson's ratios for mechanical analysis or similar thermal expansion coefficients and Poisson's ratios for thermal analysis.",0
83,1," 

The field of intelligent materials is a novel and emerging area that has gained importance in recent times. It is a multidisciplinary subject that falls under the category of frontier research. Due to the inherent properties of smart materials, they have significant applications in various industries. The current paper aims to discuss the concept of intelligent materials and their two distinct types. It also focuses on their fundamental properties, actuator functionality, and their applications in intelligent control systems. Furthermore, this study compares smart materials to traditional materials and highlights their superior qualities.",0
83,2," Intelligent materials have the ability to perceive changes in their surrounding environment and respond accordingly. There are two categories of smart materials based on their functions. The first category includes sensing materials that are sensitive to various stimuli such as stress, strain, physical, chemical, optical, thermal, electrical, magnetic and radiation effects. The second category includes intelligent materials that can be driven or respond to changes in the external or internal environment. These materials include shape memory alloy, piezoelectric materials, electrostrictive materials, magnetostrictive materials, electrorheological fluids, magnetorheological fluids, and functional gel. Depending on the needs, these materials can change their mechanical properties such as shape, size, stiffness, vibration frequency, damping, and internal friction based on temperature, electric field or magnetic field. Different materials can be used to produce various execution or driving elements.",0
83,3," The term 'smart structure' refers to a type of non-biological structure that is capable of determining purpose and making decisions. This field of research originated in the 1980s with the integration of a radar antenna into military planes, which was called the 'intelligent cortex'. Later, the concept of 'intelligent cortex' was expanded to encompass entire structures, and this became known as 'intelligent structure'. Implementing smart structure technology requires expertise in materials design, sensing technology, adaptive computer algorithms, and energy utilization optimization. The applications of smart structure technology are diverse and include use in spacecraft, aircraft, and large civil structures.",0
83,4," The topic covered in this paper delves into the idea of intelligent materials, highlighting two types of such materials. Additionally, we explore the fundamental qualities of smart material actuators and their implementation in intelligent control. When tested against conventional materials, it becomes evident that smart materials exhibit remarkable superiority.",0
83,5,"

System science is based on the proposition that everything exists in a system, which can be examined from a systemic perspective and described using systemic methods. In reality, all things exist in relation to other things, forming groups that are interconnected in some way. Without this interconnectedness, there is no group, and it has no mathematical meaning. Although some things may seem non-systemic, the self-organized criticality theory sees beaches as an important model for understanding profound systemic rules and mechanisms. It suggests that beaches are dynamic and nonlinear systems with rich characteristics.",0
