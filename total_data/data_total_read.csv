index_article,index_paragraph,content,label
1,1,"Neurogenesis is a strictly controlled process generating and maintaining the complex CNS cytoarchitecture. In the adult brain, neurogenesis constitutes in addition a form of cellular neuronal plasticity by continuously generating new neurons from resident neural stem cells (NSCs). Neurogenesis progresses through several sequential events, including proliferation, neuronal lineage restriction of precursors, cell cycle exit, migration and integration into target area, differentiation, as well as morphological and functional maturation. At the end of this process, newly generated cells can be found as functionally integrated and active neurons [1-3]. Neuronal precursors and newly generated neurons can be identified by their expression of doublecortin (DCX) [4,5]. In the adult CNS, expression of DCX is mainly detected in the adult dentate gyrus of the hippocampus and in the subventricular zone/rostral migration stream/olfactory bulb axis (SVZ/RMS/OB) [4,6-8]. Based on the close association between DCX expression and neurogenesis [5], we previously generated transgenic mice, to monitor neurogenesis in vitro and in vivo, in which reporter genes were driven by the DCX promoter [9-13].",1
1,2,"The potential of involving adult neurogenesis in therapeutic strategies to replace pathological neuronal losses urges for a better understanding of neurogenesis at the molecular and cellular levels. In addition, accumulating evidence indicates that abnormal neurogenesis might be involved in the pathogenesis of neuropsychiatric disorders [14-16]. Therefore, to understand and dissect the molecular mechanisms driving neurogenesis in vivo, various models have been developed over the last years. For example, transgenic models have been generated based on cell-type specific promoters such as nestin, GLAST, PLP (proteolipid protein), or DCX to investigate the biology of neural stem cells, radial glia, oligodendroglial precursors and neuronal precursors, respectively [11,17-21]. However, these reporter mice are not suitable for long-term studies such as fate tracing or studies on the long-term functional integration of the newly generated neurons. For example, in the SVZ/OB axis and in the dentate gyrus DCX is expressed in newly generated neurons only transiently (mostly less than 1 month in rodents’ DG and OB) [4], and thus, the DCX reporter mice are not applicable for fate mapping studies.",1
1,3,"To remedy this absence of suitable tool for neuronal precursor fate analysis, we generated transgenic mice bearing the tamoxifen-inducible CreERT2 recombinase gene under the control of the DCX promoter. In this report, we demonstrate that this new transgenic tool allows for time-resolved permanent labeling of newly generated neurons and long-term analysis of their fate. Moreover, it provides a platform to induce and eliminate expression of genes in a crucial time window of neuronal maturation and study the functional consequences of these manipulations.",1
1,4,"A 2380-bp Sal I-Not I fragment of pCAG-CreERT2bpA-SS1 vector containing the CreERT2 cDNA was subcloned into the BamH I and Not I site of the phuDCX-3509-DsRed2 cassette [9], which contains the promoter region of human DCX, resulting in the phuDCX-3509-CreERT2 (Additional file 1). A 7.7-kb DCX-3’UTR (3’UTR) was amplified with RT-PCR, following the manufacturer’s instructions (Invitrogen Kit; catalog No. 11904-018). PCR amplifications were performed with the sense primer 5’-ACTAGTAAGATGATAGGCTAAATCAAAGCC-3’ and antisense primer 5’-GCGGCCGCTTTTTTTTTTTTTTTTTTTATTGAAATCAAATTTTAT-3’. The Spe I and Not I sites were inserted in the 5’ terminal of primers respectively (the italic sequences with underlines). PCR products were cloned into a pCRII vector (TOPO TA Cloning Kit; Invitrogen; catalog No. K4600-01) to obtain the pCRIITOPO-3’UTR plasmid. A 7.7-kb Spe I-Not I fragment of pCRII-TOPO-3’UTR was subcloned into the Spe I and Not I site of the phuDCX-3509-CreERT2 cassette to get the phuDCX-3509-CreERT2-3’UTR targeting plasmid.",1
1,5,"The targeting plasmid, phuDCX-3509-CreERT2-3’-UTR, was linearized by digestion with Sal I-Not I. The purified linearized DNA was microinjected into the pronuclei of fertilized oocytes of FVB inbred mice. Genotypes of the offspring were determined by PCR analysis and Southern Blot of tail DNA. An initial screen of the offspring was performed via PCR analysis with Cre sense primer 5’-TGCATTACCGGTCGATGCAAC-3’ and the antisense primer 5’-GAAATCAGTGCGTTCGAACGCTAGA-3’. Cre-positive mice were further analyzed with Southern Blot (Additional file 1). A 1.27-kb Sal I-Hind III fragment of pCAG-CreERT2-bpA-SS1 vector was employed for preparing the probe with random primer (GE Healthcare Kit; catalog No. RPN 1633), the labeling probe was purified with MicroSpin S-300 HR (GE Healthcare Kit; catalog No. 27-5130-01) following the manufacturer’s instructions. In case of positive insertion this probe detects a 7424 bp fragment after digestion of the genomic DNA with Kpn I, or two fragments after digestion with EcoR V (the size of one fragment is 8415 bp and the other at least is over 4103 bp). (All restriction enzymes are from Roche Applied Science).",1
1,6,"Animal experiments were carried out in accordance with the Council of European Communities Directive of the 24 November 1986 (86/609/EEC) and approved by the HelmholtzZentrum Munich Institutional Animal Care and Use Committee. To expand the DCXCreERT2 transgenic mouse line, DCX-CreERT2 transgenic mice were backcrossed with wildtype C57Bl/6J mice. DCX-CreERT2 transgenic mice were in addition mated with two reporter lines: CAG-CAT-EGFP mice [22] or ROSA26lacZ mice [23] to obtain DCX-CreERT2: ROSA26lacZ or DCX-CreERT2:CAG-CAT-EGFP double transgenic mice. Recombination activity in these lines induces expression of the corresponding reporter gene and was used for the various analyses described hereafter.",1
1,7,"Tamoxifen (TAM, T-5648, Sigma-Aldrich) was dissolved in corn oil (C-8267, Sigma-Aldrich) at a stock concentration of 10 mg/ml. To analyze the expression of CreERT2 or reporter genes in embryonic stages 20 μg TAM/g bodyweight was injected once intraperitoneally (i.p.) into pregnant mothers at different gestational stages. One day after the TAM injection, embryos were dissected for whole-mount X-Gal staining or immunostaining. To follow the fate of cells targeted at embryonic stages during adulthood, the same protocol of TAM injection was employed in pregnant females of 17.5 day gestational stage, and the offspring was sacrificed at 2 months of age. To identify whether the CreERT2 recombination can be activated with a single TAM injection in adult brain (8 to 10 week-old), one dose of 200 μg TAM/g bodyweight was injected (i.p.) and mice were analyzed 1 day later. Finally, study of the expression patterns of CreERT2, reporter genes and cell-type specific markers in the adult brain was realized by injecting daily 100 μg TAM/g bodyweight (i.p.) for 5 consecutive days. These mice were analyzed 2 days (D2), 8 days (D8), 15 days (D15), or 29 days (D29) after the last TAM injection.",1
1,8,"Twenty-four hours prior to perfusion, mice were injected with 200 μg/g bodyweight BrdU (5-Bromo-2’deoxyuridine; B5002; Sigma-Aldrich) prepared in sterile PBS, pH7.4.",1
1,9,"For whole-mount X-gal staining, embryos were fixed by immersion in 4% paraformaldehyde (PFA), 5 mM EGTA, 10 mM MgCl2 in PBS solution for 30 minutes at room temperature (RT). They were then rinsed in 0.1 M sodium phosphate buffer pH 7.4 (PB), 2 mM MgCl2, 0.01% sodium deoxycholate, 0.02% NP-40, and incubated with X-gal staining buffer (0.1% X-gal, 2 mM MgCl 2 , 0.01% sodium deoxycholate, 0.02% NP-40, 5 mM K3Fe(CN)6, 5 mM K4Fe(CN)6 in PB) for several hours in the dark at 37°C to visualize the beta-galactosidase (b-gal) activity as a blue reaction product. Stained embryos were washed twice in PBS and post-fixed with 4% PFA in PBS overnight at 4°C. X-gal staining of free floating sections was carried out as described above, with the modification that sections were post-fixed with 4% PFA in PBS only 1 h at RT, and then lightly counterstained with Eosin Y (0.1%, E4382, Sigma-Aldrich).",1
1,10,"Embryos for immunohistology were fixed by immersion in 4% paraformaldehyde (PFA) in 0.1 M phosphate buffer pH 7.5 for 2-8 hrs. Thereafter the whole embryo was embedded in paraffin, and sagittally sectioned (8 μm) using a Microm HM 355 s Microtome (Leica). Brains of adult mice were removed after transcardial perfusion with 4% PFA in 0.1 M phosphate buffer pH 7.5. Brains were post-fixed for 2 hours in the same fixative. Thereafter, brains were immersed in 20% sucrose at 4°C overnight and embedded in OCT compound. Brains were sectioned using a Leica cryostat into serial coronal or sagittal sections (40 μm) for a systematic sampling of the entire brain.",1
1,11,"For immunofluorescence staining, free-floating sections were rinsed with PBS and blocked with PBS++ (PBS++: 5% fetal calf serum, 0.3% Triton X-100 in PBS) for 1 h at RT. However, in cases of staining involving the detection of BrdU, sections were pretreated in 2 N HCl at 37°C for 30 min, followed by a 10 min neutralization in 0.1 M borate buffer and six washes in PBS prior to blocking. Then they were incubated in PBS++ containing primary antibody dilutions (see Table 1) for 24 hours at 4°C, followed by three 10 min washes in PBS. Sections were then incubated with secondary antibody conjugated to cyanine 2 (cy2), cy3 or cy5 diluted in PBS++ for 2 h at RT (1:400, Jackson ImmunoResearch Lab). After three 10 min washes in PBS, sections were incubated with 5 mg/ml 4’,6’-diamidino-2-phenylindole (DAPI) (SigmaAldrich, D9564) for 20 min, followed by three 5 min washes in PBS. Finally, sections were mounted with Aqua poly/Mount (Polysciences, 18606).",1
1,12,A minimum of 100 positive cells per region of interest in each animal and for each time point were counted to quantify the recombination events. Data are presented as mean ± SD.,1
1,13,"We previously demonstrated that a 3509-bp DCX genomic fragment could properly drive expression of reporter genes in neuronal precursors and immature neurons in vitro and in vivo [9,10]. Therefore, the CreERT2 encoding sequences were subcloned downstream of this DCX regulatory fragment (Additional file 1). Two male founders carrying the CreERT2 transgene were obtained after pronuclear injection. Both founders transmitted their transgene to the F1 generation and Southern blot analysis suggested that only 1 copy of the transgene was integrated into the host genome (Additional file 1).",1
1,14,"Cre-recombinase activity was assessed on the F1 generation of both founder-derived lines following mating with Rosa26 lacZ reporter mice bearing a lacZ expression cassette activated following recombination [23]. Two month-old DCX-CreERT2:Rosa26 lacZ mice were perfused two weeks after a tamoxifen (TAM) or vehicle injection and stained for b-gal activity. Both DCX-CreERT2 transgenic lines exhibited the expected TAM-induced b-gal expression in the adult neurogenic regions, i.e. SVZ and dentate gyrus (Additional file 1). In contrast, no b-gal activity was observed following vehicle injections in the progeny derived from founder 2. However, in mice derived from founder 1, numerous b-gal positive profiles could be detected after vehicle injection indicating unspecific recombination events (data not shown). Therefore, only the transgenic DCXCreERT2 founder 2 line was expanded and employed for the following experiments.",1
1,15,"To validate that CreERT2 expression coincides with endogenous DCX expression in the DCX-CreERT2 transgenic mice, we investigated their respective expression patterns. At the cellular level, CreERT2 was detected in virtually all DCX+ cells of the developing CNS (E15.5). Furthermore, one day after injection of TAM, the CreERT2 has been translocated to the nucleus (Figure 1a). Similarly, in the adult brain, CreERT2 expression was, one day after TAM injection, strictly restricted to the nucleus of DCX+ cells (Figure 1b). Nuclear localization is induced by TAM administration and is a prerequisite for CreERT2 activity [24].",1
1,16,"To determine the time window in which CreERT2 exerts its function in the nucleus after the TAM injection, DCX-CreERT2 adult mice were perfused at different time points post-injection and the sub-cellular localization of the CreERT2 was assessed. Seven days after TAM injection, the nuclear localization was dramatically decreased as compared to the first day. At this time point, CreERT2 expression was still co-localized with DCX, but its distribution returned to be mostly cytoplasmic (Figure 1c). Furthermore, two weeks after TAM injection, CreERT2 was exclusively localized in the cytoplasm (Figure 1d and 1e). Taken together, our results indicate that the CreERT2 nuclear localization rapidly recedes after the last TAM administration, indicating that CreERT2 activity was transient and virtually ceased after 7 days.",1
1,17,"Having confirmed the correct co-localization of CreERT2 with DCX+ cells, we then analyzed recombination activity and specificity. To this end, we mated DCX-CreERT2 mice with Rosa26 lacZ or CAG-CATEGFP reporter mice, which allow to monitor the activation of the respective reporter gene expression, following successful excision of the loxP-flanked cassette. The fate of DCX-expressing cells can then be followed by analyzing reporter gene expression at various time points following recombination.",1
1,18,"The CreERT2 activity at embryonic stages was analyzed first. Twenty-four hours after a single TAM injection performed on E14.5, X-gal staining revealed that b-gal expression was restricted to the developing CNS and dorsal root ganglia (DRGs) (Figure 2). This distribution coincided with the pattern of endogenous DCX expression at this stage (Figure 2a). Activation of CreERT2 at E17.5 by a single TAM-injection led to a wide distribution of EGFP reporter expression in the adult brain (Figure 2d to 2k and Additional file 2). EGFP+ cells were detected in most regions of the brain parenchyma, such as in the granular cell layer of dentate gyrus, striatum, cortex, thalamus, Ammon’s horn (CA1), etc. according to DCX expression pattern at E17.5.",1
1,19,"Noteworthy, virtually all EGFP+ cells expressed NeuN, and thus had become mature neurons (Figure 2d to 2g). EGFP expression was neither detected in DCX-positive cells in the SVZ (Figure 2f and 2g), nor in the rostral migrating stream (RMS) (data not shown) and subgranular zone (SGZ) of the dentate gyrus (Figure 2d and 2e). A few EGFP+ cells could be found in or in close association to the ependymal layer of the lateral ventricles (Figure 2f, arrows). These EGFP+ cells, however, did neither co-express NeuN nor DCX and their nature remains to be elucidated.",1
1,20,"Due to the lower numbers of neurons continuously generated in the adult CNS, adult mice were injected with TAM on 5 consecutive days and then perfused for analysis 4 weeks after the last injection. At this time point, SVZ-generated EGFP+ cells reached the OB and were distributed mainly within the granular cell layer (GrO) (Figure 2h and 2i) and to a lower extent in the periglomerular cell layer (pGl). The EGFP+ cells present in the OB were found to express the mature neuronal marker NeuN, whereas no co-expression of DCX could be detected (Figure 2h and 2i). Within the rostral RMS in contrast, a few scattered EGFP-expressing cells appeared to have retained expression of DCX. Moreover, only rare EGFP+ cells could be found in the SVZ (data not shown). Similarly to cells detected in the OB, four weeks after TAM administration, EGFP+ cells in the dentate gyrus expressed NeuN and were devoid of DCX (Figure 2j and 2k).",1
1,21,"The efficiency and the specificity of the recombination event in DCX-expressing cells were evaluated in the adult SVZ and SGZ. The percentage of all DCX+ cells expressing EGFP was defined as the efficiency of recombination, and the percentage of all EGFP+ cells expressing DCX was defined as the specificity. Since levels of accumulated EGFP within cells were relatively low at the earliest time point studied, EGFP signals were amplified using an anti-EGFP antibody in all following experiments. In the SVZ, we observed that approximately 94% DCX+ cells were co-expressing EGFP two days after the last TAM injection (Figure 3c and 3o). At the same time point in the SGZ of the dentate gyrus, EGFP could be detected in approximately 77% of DCX-expressing cells (Figure 3d and 3o). Moreover, approximately 96% EGFP+ cells in SVZ and 90% EGFP+ cells in SGZ (Figure 3p) were co-expressing DCX, demonstrating that the CreERT2 activity was highly efficient and specific.",1
1,22,"In order to characterize further the kinetics of the DCX+ cells’ emigration from their site of birth to their target structures, the distribution of EGFP-expressing cells following recombination was investigated over time. To this end, adult mice were sacrificed eight, fifteen or twenty-nine days after the last TAM injection (D8, D15 and D29, respectively). Co-localization of EGFP expression with DCX and NeuN was analyzed within the SVZ-RMS-OB axis and within the dentate gyrus at these time points.",1
1,23,"In contrast to the high percentage of EGFP-expression within DCX+ cells two days after the last TAM injection, the percentage of EGFP-expressing DCX+ neurons in the SGZ decreased to 41% at D8, and declined gradually to roughly 25% of all DCX+ cells at D15 (Figure 3). Concomitantly, the frequency of co-localization in the SVZ decreased at D8 to 26.7%, further diminished to 12.5% at D15 (Figure 3). Finally, at D29, only rare EGFP+ cells remained within the SVZ and were found to express DCX, whereas no co-localization could be detected in the SGZ at this time point. Taken together, our data indicate that the main emigration wave of EGFP-labeled neurons departed away from the SVZ within the first 15 days (Figure 3).",1
1,24,"EGFP+ cells migrating along the RMS from D2 to D15 were found to maintain an immature neuronal morphology and only rare co-localization with NeuN could be documented (Figure 4). Over the next 4 weeks, expression of NeuN within EGFP+ cells was broadly induced as cells reached the GrO or the pGl of the olfactory bulb (Figure 2h and 2i, Figure 4 a, e and 4i). Notably, in the GrO, we found only weak expression of DCX in EGFP+ cells. In contrast, DCX was still strongly expressed in the cytoplasm of EGFP+ located at the anterior end of the RMS (Figure 2i, arrow), revealing that the expression of DCX decreased gradually as EGFP+ cells migrated into their target areas (data not shown). These observations reveal that DCX expression in cells migrating to the olfactory bulb is regionally regulated. In a similar fashion, EGFP-expressing cells in the dentate gyrus integrated in the inner granular layer over time and gradually induced the expression of NeuN. Quantitative analyses revealed that 15 days after the last TAM administration, more than 80% of EGFP+ cells found in the dentate gyrus (Figure 4m) and virtually all EGFP+ cells found in the olfactory bulb (data not shown) expressed the mature neuronal marker NeuN.",1
1,25,"To further characterize the neuronal phenotypes of EGFP-labeled neurons, the presence of neurotransmitter-specific markers and calcium-binding proteins was investigated by immunohistology at D29 (Figure 5). In agreement with previous studies [25,26], expression of GAD65, a marker found in GABAergic neurons, could be detected at this time point in EGFP-expressing cells located in the OB. Moreover, a sub-population of periglomerular EGFP+ cells was found to co-express TH, a marker specific for dopaminergic neurons (Figure 5).",1
1,26,"On the other side, VGLUT2, a commonly used marker for glutamatergic terminations, could be detected in the granular layer of the dentate gyrus and surrounded EGFP+ cells at D29, revealing that EGFP-expressing cells received glutamatergic inputs (Figure 5). In addition, we scrutinized for the expression of the calcium-binding proteins calbindin-D28K, calretinin and parvalbumin in the EGFP-labeled granule neurons at this time point. The calbindin-D28K, which is expressed in mature granule neurons, could be detected in most EGFP+ cells of the dentate gyrus (Figure 5). In contrast, no parvalbumin and only weak expression of calretinin could be detected in EGFP+ cells of the dentate gyrus at this time point, although cells expressing high levels of parvalbumin or calretinin, the latter been specifically found in newly generated granule cells, could be detected in the vicinity (see for example arrow in Figure 5e).",1
1,27,"DCX expression takes place in a relatively heterogeneous population of neuronal precursors and young neurons of various maturation stages and proliferative statuses. Administration of BrdU to label proliferative cells was performed at various time points following recombination. At the earliest time point investigated, D2, approximately 51.1% of EGFP+ cells in the SVZ, but only 7.7% of EGFP+ cells in the SGZ incorporated BrdU respectively, confirming that a fraction of the cells was still proliferating (Figure 6). The higher proportion of mitotically active cells in the SVZ might be explained by the emigration of post-mitotic young neurons out of the SVZ towards the OB, leaving the most immature cells behind. Furthermore, no more BrdU incorporation in EGFP+ cells was observed in SGZ at D15 (Figure 6), underscoring the temporally limited proliferative capacity of DCX+ cells. In contrast, although no more BrdU incorporation in EGFP+ cells was observed in SGZ at D15, a few BrdU+/EGFP+ co-labeling cells could be found in RMS (data not shown), suggesting that some EGFP+ cells in SVZ/RMS/OB axis could keep proliferative capacity until at least D15.",1
1,28,"Following administration of TAM to adult DCXCreERT2:CAG-CAT-EGFP mice, EGFP+ cells could be detected outside of the described neurogenic regions. In this respect, scattered DCX-expressing cells have previously been reported in adult cerebral cortex of rodents, cats and primates [7,27]. To validate that EGFP expression in cells located outside of the neurogenic regions ensued from concomitant expression of DCX, we scrutinized by immunohistochemistry DCX expression pattern in the whole adult brain in respect to the activation of the EGFP expression.",1
1,29,"Low to moderate levels of DCX expression could be detected in cells dispersed throughout the cerebral cortex (Figure 7). Some weak DCX expression could also be perceived in corpus callosum, as well as around the 3rd ventricle and hypothalamus, the molecular cell layer (MCL) and the granular cell layer (GCL) of cerebellum (data not show). Four weeks after TAM injection, EGFP+ cells also appeared in these regions (Figure 7). The reporter expression levels however were significantly higher than the endogenous DCX expression levels, since upon recombination, expression of the reporter gene was under the control of a strong promoter. Importantly, EGFP+ cells located outside of the neurogenic regions were not proliferative, as demonstrated by the absence of BrdU incorporation. Therefore, the nature and fate of these immature neurons remains to be deciphered.",1
1,30,"In this report, we demonstrated that CreERT2-mediated recombination can be efficiently and specifically targeted in vivo in DCX-expressing cells, i.e. in the neuronal precursors and young neurons, using a DCX promoter-driven CreERT2. In contrast to DCX promoter-driven reporter lines previously generated [10,11], the DCXCreERT2 construct described here additionally encodes the 3’UTR region of the DCX mRNA. The large DCX 3’UTR is known to contain post-transcriptional regulation elements of gene expression [28]. However, under experimental conditions used in this study, no overt differences in the expression pattern of the CreERT2 transgene could be documented in comparison to former lines devoid of DCX 3’UTR sequences. Nevertheless, the presence of DCX 3’UTR could lead to a more faithful CreERT2 expression pattern within the DCX-expressing cell population and more investigation will be required to understand its function.",1
1,31,"One day after TAM administration, the CreERT2 protein was translocated to the nuclear compartment of DCX-expressing cells where it could proceed to recombination. The latter resulted in a rapid activation of reporter expression; b-gal or EGFP could be readily detected in the embryonic, as well as in the adult CNS, one day after tamoxifen injection (Figure 2). Following five daily tamoxifen administrations, 94% DCX+ cells in SVZ and 77% DCX+ cells in the dentate gyrus induced expression of EGFP, demonstrating a high efficiency of recombination using our experimental paradigms. On the other side, about 96% of EGFP+ cells in SVZ and 90% of EGFP+ cells in SGZ were co-expressing DCX, confirming that the recombination activity was induced with high specificity. (Figure 3). As the fate of EGFP+ cells was observed to be solely neuronal, we conclude that the absence of DCX expression in a small fraction of the EGFP+ resulted from the maturation-associated downregulation of DCX+ over the 5 days of TAM injection.",1
1,32,"Although the nuclear translocation of the CreERT2 was transient, expression of the reporter got permanently induced following recombination, which allows for the long-term analysis of cell types arising from DCX+ cells. Hence, one month after recombination in the DCX-CreERT2, the vast majority of the EGFP+ cells in the neurogenic target regions expressed NeuN, a marker found in mature neurons. In addition, a few EGFP+ cells along the neuroblasts’ migratory route or localized outside neurogenic regions were found to express low levels of DCX. Importantly, one month after the last TAM injection, no co-localization between the EGFP signal and the expression of GFAP (astrocyte marker), CNPase (oligodendrocyte marker) or Iba I (microglia marker) was detected (data not shown). This substantiates evidences that DCX-expressing cells are determined to become neurons under physiological conditions. This contrast with the use of the nestin promoter to drive the expression of the CreERT, which resulted in the labeling of the neural stem cell population generating thereafter a continuous flow of new neurons and glia [17].",1
1,33,"Calbindin-D28K, calretinin and parvalbumin belong to the superfamily of low molecular weight calcium-binding proteins and are characteristic of different subpopulations of neurons [29]. Hence, in the dentate gyrus, Calbindin-D28K is as marker of mature granule cells while calretinin is transiently expressed in postmitotic newly generated neurons [30,31]. In agreement with the latter, we observed that EGFP+ granular cells in the dentate gyrus were expressing Calbindin-D28K, a few of them expressed low levels of calretinin, and none of them expressed parvalbumin four weeks after recombination (Figure 5). The absence of co-localization between EGFP and parvalbumin reinforced evidence that this GABAergic subpopulation is not replenished by a constant addition of new neurons in adult dentate gyrus, although this matter is still under debate [32-34].",1
1,34,"Following recombination in DCX-CreERT mice, EGFP+ cells were also found within non-neurogenic brain areas. In mammals, DCX+ cells have been reported outside neurogenic regions, including temporal and prefrontal cortex layer II, piriform cortex layer III/endopiriform nucleus, corpus callosum, nucleus accumbens, ventromedial striatum, ventrolateral septum, bed nucleus of the stria terminalis, molecular cell layer, granular cell layer and white matter of cerebellum. The distribution and frequency of these DCX+ cells appear to increase in superior species of the phylogeny, although it remains to be elucidated to which extent this is due to an increase of DCX expression levels and thereby a better immunohistochemical detectability [7,8,35-37].",1
1,35,"Intriguingly, the numbers of EGFP+ cells around the 3 rd ventricle and hypothalamus appeared markedly higher than the numbers of DCX+ cells detected in these regions. The reason of this discrepancy may be related to a very low expression level of DCX in these cells, which would be hardly detectable using current antibodies. In contrast, once DCX-associated recombination occurred, the expression of reporter genes is controlled by a strong constitutive promoter allowing for an easy detection of targeted cells.",1
1,36,"The origin and function of DCX-expressing cells outside of the neurogenic regions remain to be elucidated. For instance, it was reported that the neural stem cells can be isolated from virtually every region of the adult CNS [38]. In addition, upon specific treatment, neurogenic events have been induced within the adult cortex, striatum, CA1 region of the hippocampus, and even within the white matter [39-42]. It is tempting to conclude that some of the DCX-expressing cells detected in these regions were generated by a very low rate continuous neurogenesis. However, the absence of BrdU labeling obtained in these cells under physiological conditions suggests that such a mechanism of DCX+ cells generation would be marginal in the best case.",1
1,37,"On the other side, there exists good evidence that the extra-neurogenic DCX-expressing cells might have been generated during developmental neurogenesis, but never fully completed their maturation process [43]. These cells would remain in the parenchyma as “quiescent” local neuronal precursors. The existence of such quiescent precursors has also been suggested following grafting experiments in which neural stem cells were injected into the ventricles during cortical development [44]. Detection of these cells at a later time point revealed that stem cells were integrated as neurons into various brain regions, but at the same time, a certain amount of cells remained as immature neurons in the parenchyma, potentially as a reservoir of precursor cells available for plasticity or local repair.",1
1,38,"Recently, another mouse model expressing the DCXCreERT has been reported [34]. In contrast to our model based on the human DCX promoter, Cheng and colleagues used a BAC construct encoding the murine DCX promoter. The latter, together with a possible positional effect of the transgene may explain the differences observed between the two models. For instance, in contrast to our mouse model, the model from Cheng et al. is exclusively active in DCX-expressing cells within the hippocampus [34]. Also, the authors claim that recombination in their DCX-CreERT mice takes only place in post-mitotic neuronal precursors. Given the fact that a significant fraction of all DCX-expressing cells are still in a proliferative state (see Figure 6 and [10]), this suggests that the induction of the DCXCreERT transgene expression reported by Cheng is delayed in respect to the endogenous DCX. Thus, the DCX-CreERT mouse model presented by Cheng and colleagues appears to be well-suited for the study addressing the maturation and fate of newly generated granule cells of the dentate gyrus. Still, there is a lack of model(s) addressing the fate of DCX-expressing cells located outside of the dentate gyrus - such as in the subventricular zone (SVZ) - which is now possible by the model presented in this manuscript.",1
1,39,"We report here a transgenic mouse model based on an inducible Cre recombinase driven by the DCX promoter (DCX-CreERT2). Taken the high specificity and efficiency of recombination in neuroblasts and young neurons, this transgenic mouse model constitutes a powerful tool for tracing neurogenesis and fate-analysis of newly generated neurons. It is moreover a valuable model for studying molecular mechanisms of neural plasticity and neurogenesis through induction or silencing of specific genes in neuroblasts and young neurons. Finally, the possibility to analyze the long-term fate of newly generated neurons will be an asset in the development of innovative therapies against neurologic diseases.",1
2,1,"Despite considerable worldwide efforts made in recent years to control malaria [1], the disease is still a major public health problem with nearly 250 million cases and about one million deaths each year. Eighty five percent of deaths occur among children under five [2] from which nearly all are in sub-Saharan Africa. In 2007, malaria was declared to be the most important disease in this age group, in Benin, leading to 43% of all medical consultations and 29% of hospital admissions [3]. The National Malaria Control Programme (NMCP) has implemented WHO/GMP’s (World Health Organization/Global Malaria Programme) recommended preventive and curative strategies [4]. These include i) Artemisinin combination therapy (ACT) which is dispensed at health centers and has recently been made available to communities for children under five years old; ii) Intermittent preventive treatment (IPT) during pregnancy; iii) Long-lasting insecticide-treated mosquito nets (LLINs) which have continued to be distributed following the nation-wide deployment among high-risk populations (i.e. children of under five and pregnant women) and iv) Indoor residual spraying (IRS) using carbamate insecticide applied in specific districts through the President’s Malaria Initiative [5].",1
2,2,"Many studies have demonstrated that the use of insecticide treated nets reduced uncomplicated malaria episodes by at least 50% [6]. Unfortunately, insecticide resistance in malaria vectors has dramatically increased in Africa [7], especially in Benin [8-10] and may seriously compromise the success of vector control management. Two studies conducted in experimental huts in South Benin, where Anopheles gambiae was resistant to pyrethroids, have reported that significant reduction in the efficacy of pyrethroids was applied either in treated nets or IRS [11,12]. In order to manage insecticide resistance, the Centre de Recherche Entomologique de Cotonou (CREC) in collaboration with the Institut de Recherche pour le Développement (IRD) and the NMCP has evaluated successfully (WHOPES phases I and II) a new insecticide resistance management (IRM) strategy combining in the same household a LLIN and a carbamate treated plastic sheeting [13,14]. In the context of a future community-based evaluation of this promising IRM strategy (phase III trial), the malaria burden was evaluated in a health district of southern Benin where a nation-wide distribution of LLINs to children <5 had been implemented in 2007.",1
2,3,"This epidemiological study was carried out in the Ouidah-Kpomassè-Tori Bossito health district in southern Benin (Figure 1), from December 2007 to November 2008. The population size in the study area was 178,314 inhabitants according to the results of the 3rd General Census of the Population and the Environment (RGPH3) of February 2002. The population is rural and lives on agriculture with scattered settlement. The main ethnic group is Aïzo. The climate is essentially subequatorial, with two dry seasons (a long dry season from December to March and a short dry season in August and September), and two rainy seasons (a long rainy season from April to July and a short rainy season from October to November). The average annual rainfall is around 1,200 mm, of which 700-800 mm and 400-500 mm rain down respectively in the first and in the second rainy season. The hottest months (31°C) are February to April and the coldest months (27°C) are July to September. Less than 30% of children are present at the health centre when sick. They are mostly treated by traditional medication [15]. A recent survey in Benin indicated that less than half of febrile children <5 were received anti-malarial drugs of which only 7% of cases were given ACT [16,17].",1
2,4,"Twenty eight villages were chosen according to the following criteria: having between 250-500 inhabitants, distance between any villages greater than two kilometers and the absence of a local health centre. From these, seven villages were randomly selected. Geographical, demographical and environmental characteristics are described in Table 1. After census, about 60 children aged 0-71 months were randomly selected in each village. They were clinically monitored for a total of 48 days spread over one year. Children born during the study were not included. Ethical clearance was given for the study by the National Ethical Committee in Benin (Comité National Provisoire d’Ethique pour la Recherche en Santé, Reference number IRB00006860) and IRD ethical committee. Mosquito collectors gave their written informed consent and were treated free of charge for malaria presumed illness. They were also vaccinated against yellow fever. Each head of family or the guardian of the selected child gave their written informed consent. During the monitoring periods, all children of villages, whom participating in the study or not to, were treated free of charge by the medical staff.",1
2,5,"Active case detection (ACD) for malaria episodes was carried out during eight periods of six consecutive days at six weeks intervals throughout the year. Each day a nurse assisted by a local village helper trained for the study, visited the households in the sample. A physician supervised the field work. The presence or absence and state of health of each child were recorded daily on a specially prepared form (one form per household). The nurse examined and recorded data on every case of sickness detected at home. A thick blood film was taken from every sick child. Children were treated according to the clinical diagnosis made by the nurse. When malaria was suspected, the patient was treated with artemether-lumefantrine for three days according to the recommendations of WHO and NMCP [19,20]. Crosssectional surveys (CSS) were carried out at each monitoring clinical period (n = 8) on every asymptomatic child (confirmed by axillary temperature < 37.5°C). A thick film sample was taken on the fourth day to be sure that asymptomatic children were free of illness in preceding days. Cross-check quality controls were conducted every six weeks during the collection of field data.",1
2,6,"Data were collected two weeks before each clinical monitoring. Adult mosquitoes were caught using Human Landing Catches (HLC) technique [21]. In the study area, 896 human-nights of capture of human landing mosquitoes were organized every six weeks over a year period (128 nights per village; eight places per village and per night, half indoor and half outdoor). Treated nets were present in the mosquito collection sites. The mosquito species were identified using morphological characteristics according to the identification keys of Gillies & De Meillon [22] and Gillies & Coetzee [23]. All mosquitoes of An. gambiae complex and Anopheles funestus group were stored in individual tubes with silicagel and preserved at -20°C for P. falciparum circumsporozoite index estimation and molecular identification.",1
2,7,"The ownership, the use and the correct use of LLINs (Permanet® 2.0) which were distributed in October 2007 were checked over weekly-survey. The visits of the nurse were unannounced and took place in the late evening around 9.00 PM when children were expected to be asleep [24]. The unannounced visits determined the ownership (whether the LLINs were seen during the control), the use (whether children were sleeping under it during the control) and the correct use (whether the LLINs were correctly hung and tucked and were not torn). The rates of LLINs ownership, use and correct use were calculated relative to the total number of observations.",1
2,8,"Laboratory processing was done at the CREC, Cotonou. Parasitological infection was detected on Giemsa-stained thick smears. Asexual stages of each Plasmodium species were counted in the blood volume occupied by 200 leucocytes and parasite density was calculated by assuming 8,000 leucocytes/μL of blood. Thick smears from each village were read by the same experienced technician, under the supervision of a parasitologist. The readings of the two technicians were also compared on the same set of blood samples. Their estimations of parasite detection and parasite density did not differ significantly. Cross-check quality control was regularly done on a randomly selected sample representing 10% of all thick smears.",1
2,9,"After scoring field-collected Anopheles mosquitoes and identifying the species of each specimen by Polymerase Chain Reaction (PCR) [25], the presence and relative frequency of the molecular M and S forms of An. gambiae sensu stricto (s.s) were determined according to the method of Favia [26]. Infection of mosquitoes was determined on the head and thorax of individual vector specimens by ELISA using monoclonal antibodies against P. falciparum circumsporozoite protein (CSP) [27]. The method of Martinez-Torrez was used for the molecular detection of the L1014F kdr allele [28].",1
2,10,"Demographic, parasitological, clinical and entomological data were double entered independently in the Access 2003 database. Parasitological and clinical data were analyzed using the svy command (STATA 11.0). For each person only one blood sample per monitoring period was considered for analysis. When a pathological condition was detected, the blood sample taken during the clinical episode was retained for analysis. Parasitological data were analyzed separately in terms of prevalence of P. falciparum asexual blood forms, density of P. falciparum asexual blood forms in parasite positive blood thick films and prevalence of P. falciparum gametocytes. A generalized estimating equation (GEE) approach, which can be used with normal distributions and discrete data was used for statistical analysis of repeated measures. To take into account the interdependence of observations made on the same person, an exchangeable correlation structure was used in which the correlation between these observations made on one person at different times was assumed to be the same. The prevalence of asymptomatic malaria infections was analyzed as a binomial response by using a logistic regression model.",1
2,11,"The association between the parasite density and the occurrence of clinical episodes was tested using a Poisson regression model, taking clinical status (pathological episode versus asymptomatic state) as the dependent variable, and parasite density as the independent variable. In this type of model, a random intercept variable is allowed to vary with subjects, and this random subject-specific intercept allows the interdependence of the observations made on the same person to be taken into account. For each pathological period, the probability that it was caused by malaria was estimated by the Attributable Fraction (AF) calculated from the odds ratios associated with the estimated parasite density in the logistic model [29,30]. The pathological episodes were clinically defined by a high axillary temperature (≥37.5°C), sweats, shivers, headaches, nausea or vomiting [31] or by a history of fever during the 48 hours proceeding the first day of ACD or, for infants under one year of age, anorexia or any pathological condition described by the mother [32,33]. For individuals, the number of malaria attacks over a given periods was estimated by the sum of probabilities that pathological episodes were due to malaria, depending on the parasite density.",1
2,12,"The three dependent variables (i.e. prevalence rate of P. falciparum infection, mean parasite density in positive children and clinical incidence rate) were analyzed according to demographic (age groups 0-23, 24-59, 6071 months and sex), environmental (season and villages) and sanitary (LLIN’s ownership, use and good use) variables. The Chi 2 test was used to compare the rate of ownership, use and correct use of LLINs. An optimum pyrogenic parasite density cut-off was calculated using the estimated AFs with a logistic model. The sensitivity and the specificity were similarly determined [34]. The sensitivity was estimated by the ratio of malaria episodes with positive cut-off to a total of malaria episodes. The specificity was estimated by the ratio of no malaria febrile episodes with parasite density below the cut-off to the total of no malaria febrile episodes. The suitable positive Likelihood-ratio (>10), negative Likelihood-ratio (<0.1) results and Youden’s J index were also determined from the model.",1
2,13,The human biting rate (HBR) was expressed as the number of anopheles bites per human per night. The sporozoite index was calculated as the proportion of mosquitoes found to be positive for CSP. The entomological inoculation rate (EIR) was calculated as the product of the HBR and the sporozoite index and expressed as the number of infected bites per human per year.,1
2,14,"A total of 440 children in seven villages were parasitologically and clinically monitored during 18,262 persondays from which 402 (2.2%) were missing for the following reasons: 366 not found and 36 refusals. Ten children died during the study. The mean age of the children at inclusion was 2.1 years. The female/male ratio was 1:1. Each child in the survey was visited on an average of 42 days out of the 48. A total of 3,074 thick blood films were taken, comprising 2,838 in asymptomatic children and 236 in sick children, with an average of seven per child",1
2,15,"Plasmodium falciparum, Plasmodium malariae and Plasmodium ovale were present alone or mixed (Table 2). The annual prevalence rate of P. falciparum infection was 21.8% (95%CI 19.1-24.4). In the multivariate random-effects logistic regression model, age of children, season, village and correct use of LLINs, but not the ownership and the use of LLINs were significantly associated with the prevalence of infection (Table 3). The correct use of LLINs conferred a 26% individual protective effect against infection prevalence (OR = 0.74 (95% CI 0.62-0.87), p = 0.005). The prevalence of infection increased with age. Children aged 1 to 2 years and 3 to 5 years were three to five times more frequently infected than children aged less than one year (22.0% (CI95% 17.0-27.0) and 33.0% (CI95% 28.4-37.6) versus 7.8% (CI95% 5.2-10.5)). The prevalence of infection was higher during the dry season (24.7% (CI95% 21.6-27.8) than during the rainy season (18.6% (CI95% 15.7-21.5)). The prevalence of infection was higher in Satré, Wanho, Kindjitopka and Hèkandji than in Dokanmè, Aidjèdo and Guézohoué.",1
2,16,"The mean parasite density in positive asymptomatic children was 586 P. falciparum asexual forms per μL of blood (95%CI 504-680). According to multivariate random-effects linear regression model, increased parasite density was associated with some villages (Dokanmè and Satré) but not with age of children, season, ownership and use of LLINs (Table 4). Plasmodium falciparum gametocyte annual prevalence rate was 3.0% (95%CI 2.2-5.6) and differed significantly between the dry (3.8% (95% CI 2.9-4.8)) and the rainy season (2.2% (95%CI 1.4-3.0)), p = 0.008.",1
2,17,"During the study 236 pathological episodes were detected. A total of 110 pathological episodes were parasite positive: 102 children with P. falciparum alone, three individuals with P. malariae alone, two individuals with P. ovale alone and three individuals with mixed infection. The P. malariae single infections showed densities of 480, 2,360 and 200 parasites/μL and P. ovale single infections showed densities of 4,800 and 9,800 parasites/μL. Three mixed infections with P. falciparum and P. ovale showed combined densities of 3,760 Pf + 720 Po, 960 Pf + 400 Po and 280 Pf + 120 Po (Table 2). In all age groups, the mean parasite density was lower in healthy children than sick children (Figure 2). Four parasite positive cases with P. falciparum referred to the health centre were diagnosed as severe malaria with anaemia. Among the 236 pathological episodes, there were 74 episodes attributable to P. falciparum malaria (Table 5). The optimal pyrogenic parasite cut-off of 2,000 P. falciparum asexual blood forms per μL was determined as corresponding to levels of sensitivity and specificity of 94.0% and 94.5% respectively (Table 6). The mean annual clinical incidence rate was 1.5 per child per year (95%CI 1.2-1.9).",1
2,18,"Overall 13,602 mosquitoes including 115 An. Gambiae sensu lato (s.l.) (65 and 50 indoor and outdoor, respectively) and 67 An. funestus (40 and 27 indoor and outdoor, respectively) were caught in the seven villages. The number of CSP positive An. gambiae s.l. and An. funestus were nine and four respectively. The aggressiveness of culicidae and malaria vectors (An. gambiae s.l. and An. funestus) were 5,541 (95%CI 2,008-15,288) and 74 (95%CI 17-318) bites per human per year. The annual EIR was 5.3 (95%CI 1.1-25.9) infected bites per human per year. The 1014F kdr allele was present in both molecular M and S forms. The frequency of this mutation was respectively 0.47 (95%CI 0.37-0.57) and 0.61 (95%CI 0.43-0.80) in the M and S forms.",1
2,19,"The LLINs ownership rate reached 91.8% (2,769/3017; 95%IC 90.8-92.8) and remained high through the year. Use was significantly higher during the rainy season than the dry season 73% (1,062/1,451; 95%CI 70-75) and 67% (1,047/1,566; 95%CI 64-69) respectively, p = 0.0001. It significantly decreased to 31% (118/385; 95%CI 26-31) in the middle of dry season. Correct use was also the highest during the rainy season (68% (990/1,566; 95%CI 65-70)) compared to the dry season (42% (665/1,171; 95%CI 40-45)), p < 0.0001, (Figure 3C).",1
2,20,"This prospective longitudinal study allowed the epidemiology of malaria in the health district of Ouidah-KpomassèTori Bossito after the nation-wide distribution of LLINs to children in October 2007 to be characterized. Previous studies have described the epidemiology of malaria in Benin, by focusing mainly on malaria transmission [35] and on clinical and parasitological aspects as well in rural areas [36-38] as in the city of Cotonou [39]. Other authors [40] described the process indicators, results and impact of malaria control which were useful for the implementation of the monitoring and assessment system of ‘’Roll Back Malaria’’ in Benin. The large scale and selective distribution of LLINs in Africa in the last decade were also the subject of several studies which concerned mainly the acceptability and/or the population perception without investigating their parasitological and clinical effects [41-47]. Pyrethroid resistance in malaria vectors has been observed in many African countries [7]. Nevertheless, no loss of effectiveness of LLINs has been reported at an operational level [48].",1
2,21,"The entomological findings showed that the health district of Ouidah-Kpomassè-Tori Bossito is a mesoendemic area with a mean annual EIR of 5.3 infected bites (95%CI 1.1-25.9). This EIR was found in conjunction with the annual prevalence rate of 21.8% (95%CI 19.1-24.4) observed in young asymptomatic children [29,49,50]. It confirms Velema’s parasitological observations in the same area twenty years ago [36]. As regards the resistance of An. gambiae to pyrethroids, the L1014F kdr allele reached 50%, in accordance with previous studies carried out in southern Benin [8,18]. The annual infection rate increased with age in accordance with what is usually observed in mesoendemic area [50]. The high infection rate in the dry season could be influenced by the peak observed at the end of the rainy season (33%) just one month after the national distribution of LLINs (Figure 3A, Table 3). The parasite density of positive children did not vary with age group or season (Figure 2). These results may be attributed to the protection conferred by LLINs. In mesoendemic areas, the acquisition of immunity against malaria would develop gradually and bring about a decrease in parasitaemia with increasing age [51].",1
2,22,"The calculated AF of pathological episodes to malaria helped to determine the optimum parasite pyrogenic cutoff at 2,000 P. falciparum asexual blood forms per μL. The use of AF to define the pyrogenic parasite cut-off allows the best trade-off between sensitivity and specificity level [54]. In stable malaria areas, P. falciparum parasitaemia is dependent on the season and age, which affects the malaria-AF of pathological episodes and thus the malaria case definition according to pyrogenic parasite density cutoff [33,55]. In the present study, the parasite density did not vary with season or age. Therefore, the AF could be considered the same whatever the season and the age group. The cut-off of 2,000 falciparum asexual blood forms per μL was close to the value of 1,000 found in mesoendemic area on children under 3 years [36] and to the 3,000 to 6,000 found in hyperendemic area among children aged 0 to 12 years in south of Benin respectively [37].",1
2,23,"In the health district of Ouidah-Kpomassè-Tori Bossito, one pathological episode out of three was attributed to malaria. To avoid a maximum of missed cases the malaria case definition took into account signs evoking malaria or history of fever during the 48 hours preceding the first day of ACD as advised Mcguinness [33]. Mean annual incidence rate of falciparum clinical malaria was 1.5 per child per year. In P. falciparum high-endemic area, the pyrogenic cut-off of parasitaemia in persons of a given age is similar for all Plasmodium species [56]. Given the high parasite density, P. malariae could have been responsible for one malaria clinical case with 2,360 parasites/μL and P. ovale for two cases with a parasitaemia of (4,800 and 9,800 parasites/μL) respectively.",1
2,24,"In 2001 before the national distribution of LLINs, in south of Benin, 4.3% of household owned a treated net (ITN) and 2.4% of children under five years old slept under ITNs [40]. In 2006, ITNs possession was estimated to 25.6% and its utilization by the children less than 5 years was 21% in Ouidah [15]. After the national distribution of LLINs, ownership rose to over of 90% and was continuous over of the year (Figure 3C). Throughout the 12 months of the study, two children out of three were found sleeping under LLINs during unannounced and nocturnal inspections. Some studies have already concluded that free distribution of nets via a national campaign is effective in rapidly increasing their possession and use [42,57,58]. This high percentage of use may have been the result of adapted sensitization to the beliefs and behaviours of the communities and to the presence of medical staff assisted by a local village helper. Indeed, the success of sensitization depended strongly on the partnership between the study team and the local leaders as described by Paré Toé [47]. The 31% reduction of LLINs use during the dry season in Benin is comparable to that observed in most of the West African countries (Figure 3C) [24,41,43].",1
2,25,"In conclusion, the health district of Ouidah-KpomassèTori Bossito is a mesoendemic area characterized by a moderate level of pyrethroid resistance of vectors and a high heterogeneity of malaria infection between villages. Malaria infection and disease did not vary through the year. The used LLINs rate was high and only the correct use of LLINs was found to reduce malaria infection without influencing malaria morbidity.",1
3,1,"Porcine circovirus type 2 (PCV2) and the associated disease postweaning multisystemic wasting syndrome (PMWS) have caused heavy losses in global agriculture in recent decades. Rapid detection of PCV2 is very important for the effective prophylaxis and treatment of PMWS. To establish a sensitive, specific assay for the detection and quantitation of PCV2, we designed and synthesized specific primers and a probe in the open reading frame 2. The assay had a wide dynamic range with excellent linearity and reliable reproducibility, and detected between 102 and 1010 copies of the genomic DNA per reaction. The coefficient of variation for Ct values varied from 0.59% to 1.05% in the same assay and from 1.9% to 4.2% in 10 different assays. The assay did not cross-react with porcine circovirus type 1, porcine reproductive and respiratory, porcine epidemic diarrhea, transmissible gastroenteritis of pigs and rotavirus. The limits of detection and quantitation were 10 and 100 copies, respectively. Using the established real-time PCR system, 39 of the 40 samples we tested were detected as positive.",1
3,2,"Porcine circovirus type 2 (PCV2) is widespread in the commercial swine population [1-5], and is accepted as the causative agent of a number of diseases in these animals, particularly postweaning multisystemic wasting syndrome (PMWS) [6]. To date, PCV2 infection is common in some regions of China [7], and is considered as a major problem in pig production. There is therefore an urgent need for specific and effective methods to detect the virus.",1
3,3,"By comparison with conventional PCR and ELISA, real-time PCR offers an effective way to detect target fragments specifically, rapidly and quantitatively. Falsepositive results and pollution can be prevented effectively at the same time. Therefore, real-time PCR has been developed quickly and has become the main method for pathogen detection [8].",1
3,4,"In this study, we designed and synthesized specific primers and a TaqMan probe for PCV2. We have established an assay that is specific and sensitive for detection and quantitation of PCV2.",1
3,5,"The primer and TaqMan probe design were based on nucleotide sequences of open reading frame 2 (ORF2) retrieved from GenBank (EU921257.1), using the PCV2 strain from China (BJ0804) as a master sequence. The primers and probe (Table 1) were designed using Primer Premier 5.0, Oligo Primer Analysis software and DNAman 4.0. The length of the amplified product was 149 bp.",1
3,6,"The standard plasmid was constructed by inserting a PCR fragment into a pGEM-T Easy vector according to the manufacturer’s instructions (Promega, Madison, WI, USA). The plasmid was propagated in Escherichia coli JM109 cells and was purified and subsequently quantified using an ND-1000 spectrophotometer (NanoDrop, Wilmington, DE, USA). Ten-fold dilutions were made to obtain 1010 -100 per μL plasmid sample (containing 100 ng/μL yeast tRNA) for the real-time PCR. The dilutions were stored at -20°C, while the plasmids were stored at -70°C.",1
3,7,"PCR amplifications were performed in 25-μL reaction volumes containing 1×PCR buffer, 200 μM dATP, dTTP, dCTP and dGTP, 1.25 U DNA polymerase, 2 mM MgCl2 (TaKaRa, Dalian, China), 200 nM of each primer, and different quantities of the plasmid DNA templates. Amplifications were programmed as follows: one step of 94°C for 5 min, 30 cycles of 94°C for 30 s, 60°C for 20 s and 72°C for 20 s, and one step of 72°C for 7 min. Amplicons of 149 bp were separated through 2% agarose gel containing 5% Goldview (SBS Genetech, Shanghai, China). Negative and positive reference samples were applied in each reaction.",1
3,8,"Real-time PCR was carried out on an ABI 7500 thermocycler (Applied Biosystems, CA, USA) with a final volume of 25 μL. The real-time PCR reactions contained the following ingredients: 1×PCR buffer, 400 nM primers, 200 nM TaqMan probes, 400 μM each of dATP, dTTP, dGTP and dCTP, 1.25 U Taq DNA polymerase, and 4.5 mM MgCl2. Real-time PCR reactions were run as follows: 95°C for 10 min and 45 cycles of 95°C for 15 s and 60°C for 40 s. For a standard curve, serial dilutions of 10 10 to 100 copies of the plasmid were used. Each assay was performed in duplicate and each run included two negative controls.",1
3,9,"To establish the limit of quantitation (LOQ) of the assay, samples containing 107, 105, 103 and 102 copies per sample were run in triplicate, and samples containing 90, 80, 70, 60, 50, 40, 30 and 20 copies were also included. Samples containing 10 copies and one copy per sample were also run to estimate the limit of detection (LOD) of the assay.",1
3,10,"The standard PCV2 plasmid with 10^7, 10^5 and 10^3 copies was used to evaluate the coefficients of variation (CVs) of the real-time PCR. Intra- and inter-assay CVs for Ct values were both included. To test the specificity of the assay, plasmid samples containing 10^8, 10^7, 10^6, 10^5 and 10^4 copies together with cDNA of porcine reproductive and respiratory, porcine epidemic diarrhea, transmissible gastroenteritis of pigs and rotavirus and DNA of porcine circovirus type 1 were run under optimal conditions of the assay. Negative controls were also contained in the run.",1
3,11,Three PCV2-positive samples and 37 serum and tissue unknown samples were tested using conventional PCR and real-time PCR under optimal conditions. Products from conventional PCR were examined in 2% agarose gel.,1
3,12,Ten-fold serial plasmid dilutions were used to construct the standard curve by plotting the logarithm of the plasmid copy number against the measured Ct values (Figure 1). The standard curve generated had a wide dynamic range of 102-1010 copies/μL with a linear correlation (R2) of 0.9999 between the Ct value and the logarithm of the plasmid copy number.,1
3,13,"For reliable quantitation of the results under ideal conditions, approximately 100 initial template copies were required, thereby specifying the LOQ of this assay. When the number of template copies fell below 100, the Ct values lay outside of the linear range (Figure 2). The target sequence could be detected in all amplification reactions down to 10 copies, but not when only one copy was present (Figure 3). These results indicate that the LOD value was ~10 copies.",1
3,14,"The CVs for the Ct values ranged from 0.59% to 1.05% in the same assay and from 1.9% to 4.2% in 10 different assays (Table 2). No increase in fluorescence was observed in the negative control and PCV1, PRRS, PED, TGE and RV samples.",1
3,15,"Table 3 and 4 showed that the PCV2-positive rates in the unknown samples of conventional PCR detection and real-time PCR detection were 78.3% and 97.3%, respectively. The real-time PCR approach increased the detection of PCV2 samples by 18% over that achieved by conventional PCR.",1
3,16,The viral loads were mostly between 10 and 1000 copies/μL sample with a few samples containing up to 108 copies/μL. Three hundred and sixty and 1560 copies of PCV2 were detected per microliter in the PPV and PRV DNA extracted from serum samples. It appeared that the pigs from which the PPV and PRV DNA samples were obtained were co-infected with PCV2.,1
3,17,"Serological surveys have shown that up to 100% of investigated farms and up to 100% of individual pigs sampled in parts of Europe, the United States and Canada are seropositive for PCV2 [9-11]. Using ELISA on samples collected in seven provinces and municipalities in China, the seropositive rate was found to be up to 42.9% [12].",1
3,18,"PCV2-induced diseases on farms are reported to increase pig mortality from 2-3% to 14-30% [13]. Therefore, rapid and sensitive detection and quantitation assays for PCV2 are urgently needed both by the pig industry and research community. In comparison with conventional PCR, TaqMan real-time PCR is more sensitive and less easily contaminated. The main difficulty of using conventional PCR is that contamination occurs when products are examined in gels, which leads to false-positive results in later experiments. For this reason, real-time PCR is widely used, and in addition, it has heightened sensitivity and requires less time than conventional PCR.",1
3,19,"The major conserved region for PCV2 located in ORF2 is likely to be the ideal reference fragment to detect PCV2, because this region displays the highest diversity between PCV1 and PCV2 and there are more sequenced isolates available from PCV2 than there are from PCV1 [14]. Hybridization probes that combine only with the target products have primarily been used in previous studies to detect PCV2, and the results of these studies have shown high sensitivity and specificity. Several other methods are available to detect and quantify PCV2. Brunborg et al. [14] have used a TaqMan probe to detect an 84-bp fragment in ORF2 and to quantify the viral load in different tissues and serum samples. In a report by Chung et al. [15], PCV2 was quantified in naturally infected and challenged pigs using a TaqMan real-time PCR that detected a fragment of 269 bp. Yang et al. [16] have used SYBR Green I based on nucleotide sequences of ORF2 for the detection of PCV2.",1
3,20,"In this study we designed different primers, a different probe and a different real-time PCR system, which amplified a 149-bp fragment to detect PCV2. The realtime PCR approach increased the detection of PCV2 samples by 18% over that achieved by conventional PCR. Tests on the reproducibility of the method suggest that the established real-time PCR system appears to be reliable and stable. A series of experiments were carried out to assess the reproducibility, sensitivity, and specificity of the assay. Using several other swine viruses as template, no cross-reaction signals were detected, which demonstrated the specificity of the assay. The established real-time PCR system that we developed might not only provide an effective way to detect PCV2 rapidly and sensitively, but might also be applied to assess the effectiveness of vaccines developed to combat PCV2. The real-time PCR detection system complements and extends previous methods for detection and quantitation of PCV2. The specific detection method can also provide an alternative approach for detection of PCV2.",1
4,1,"In Nigeria, nearly 110 million of clinical cases of malaria are diagnosed per year, translating into about 50% of the adult population experiencing at least one malaria episode per year, while young children can have up to two to four attacks of malaria annually [1]. In addition to the direct health impact of malaria on the Nigerian population, the economic loss linked to malaria in this country is estimated to ~132 billion Naira (±878 million USD) per year. In order to combat this devastating situation, the Nigerian authorities developed in 1996 a first National Malaria Control Policy, and in 1999 the Roll Back Malaria (RBM) programme was initiated.",1
4,2,"National drug efficacy trials conducted in 2002 in Nigeria demonstrated that the first line treatments then employed, chloroquine and sulphadoxine/pyrimethamine (SP) were no longer adequate and in 2005, the highly efficacious artemisinin-based combination therapy (ACT) was introduced in the country [1]. Artemetherlumefantrine was elected first-line treatment for uncomplicated malaria with artesunate-amodiaquine (AS + AQ) recommended as an alternative [2]. Nowadays, SP is not recommended for the treatment of uncomplicated malaria due to its high resistance which can be as high as 35% but it is still in use for intermittent preventive therapy (IPT) in pregnant women. Similarity in the structure of SP and SMP denotes a potential for cross resistance [1,2].",1
4,3,"Although the use of ACT for the treatment of uncomplicated malaria has been introduced several years ago, its utilization in the field is still below expected levels. The reasons explaining this situation include the poor availability and/or relatively high cost of ACT on the African market. One of the key elements of the RBM strategy is that malaria patients should have access to appropriate and adequate treatment within 24 hours of the onset of symptoms [1,2]. An anti-malarial drug to be used at home must, therefore, be safe, effective, affordable, easy to administer and preferably available in a single dose package. Following these lines, fixed-dose combinations (FDC) are preferred to co-blistered drugs as they prevent inadequate dosing (preventing drug resistance) and contribute to increase treatment compliance.",1
4,4,"In view of the ideal profile to be found in an antimalarial drug, the combination of artesunate and sulphamethoxypyrazine/pyrimethamine (AS + SMP) represents an interesting treatment option in case first-line drugs are not readily available. In fact, this product is easy to use, safe, and has previously demonstrated high efficacy in several endemic areas whether it is taken under a 24- or 48- hour regimen [3-5]. Previously offered as a co-blistered drug [6,7], the AS + SMP combination is now available as a FDC, which can easily be taken by malaria patients (three tablets only). In addition, since the SMP component has broad-spectrum anti-microbial activity, it also presents the interesting advantage of offering ancillary benefits against infections that may have been wrongly diagnosed as malaria [8,9].",1
4,5,"In order to evaluate the safety and efficacy of the 24hour therapy of AS + SMP FDC in south-west Nigeria, a cohort of children suffering from uncomplicated malaria were treated either with this ACT, or with a 48hour therapy of AS + AQ FDC.",1
4,6,"This study was conducted at the University College Hospital and at the Oni Memorial Children’s Hospital both located in the urban areas of Ibadan, Oyo State, Nigeria. The intensity of malaria transmission varies considerably throughout Nigeria. Ibadan is located in the forest savannah woodland zone with average rainfall of 975 - 1474 mm/year [10]. Malaria, mainly caused by Plasmodium falciparum, is endemic in the region with a six-month transmission season (May-October) reaching its peak in August [11]. The overall entomological inoculation rates for Anopheles gambiae s.l. range from 18 to 145 infective bites per person per year [2]. Specifically in south-west Nigeria, the reported seasonal (sixmonth) entomological inoculation rates were 128.7 in 2001 and 131.3 in 2002 [11].",1
4,7,"This study was approved by the Joint Ethics Committee of University of Ibadan and University College Hospital, Ibadan, Nigeria. The study was conducted in accordance with all requirements of the ICH Guidelines for Good Clinical Practice as well as the requirements of the Declaration of Helsinki. Clinical trial approval was obtained from the National Agency for Food and Drug Administration and Control in Nigeria (NAFDAC). Written informed consent was obtained from all parents or guardians of eligible children prior to enrolment.",1
4,8,"Children presenting to each of the two study sites were screened for eligibility and invited to participate in the study if they met the following inclusion criteria: aged between 1 and 13 years; body weight between 6 and 40 kg; history of fever in the previous 24 hours or measured fever (axillary temperature >37.5°C); mono-infection with P. falciparum, with parasitaemia in the range of 2,000-200,000 asexual parasites per microlitre of blood; and no general danger signs or signs of severe and complicated falciparum malaria as per WHO guidelines [12].",1
4,9,"A randomized, controlled, open-label trial design was used. Assuming a proportion of 94% patients cured (with PCR-corrected cure rate at day 28 as primary endpoint) with AS + SMP, an equal proportion of patients cured with AS + AQ, a sample of 250 patients (taking into account 10-15% loss to follow-up) was required in each treatment arm to detect the 6% difference in parasitological cure rates with a power of 80% (a = 0.025 one-sided). Sample size calculations were done using nQuery Advisor 5.0. The randomization code was computer-generated with stratification per treatment centre, from which treatment groups were assigned.",1
4,10,"At enrolment, a physical examination was performed, weight and axillary temperatures recorded and a medical history was obtained from parents/guardians including presenting symptoms and current medication. A finger prick blood sample was obtained for thin and thick blood smears and blotted on filter paper for parasite genotyping. A blood sample was also obtained for assessment of haematological and biochemical parameters.",1
4,11,"Eligible children were then assigned into one of the two treatment groups according to the randomization code. The treatments were given in the clinic by the recruiting physician. One group received three doses of artesunate/amodiaquine 100/206.2 mg tablets (Amonate®, Dafra Pharma ltd., Kenya), crushed mixed with clean water and administered at 0, 24 and 48 hours. The second group received artesunate/sulphamethoxypyrazine/pyrimethamine 100/250/12.5 mg tablets (CoArinate FDC ® Junior, Dafra Pharma Ltd., Kenya), crushed, mixed with water and administered at 0, 12 and 24 hours. Treatment doses were given based on the age of the patient: children under 7 years received 1/2 tablet per dose (50/153.1 mg As/AQ and 50/125/6.25 mg As/SM/P) while children aged 7 years and older received a full tablet per dose. They were then observed for 1 hour after drug administration for vomiting. If vomiting occurred within 30 min after administration, the full treatment dose was re-administered. If vomiting occurred between 30-60 min after administration, half the treatment dose was re-administered.",1
4,12,No prior therapy was given and the only concomitant therapy administered were antipyretic drugs in patients with temperatures ≥38.5°C.,1
4,13,"The children on 12 hourly regimen whose second dose fell at night were admitted for the treatment to be given by the nurses on duty to ensure treatment compliance. Clinical and parasitological evaluation (thin and thick smears) was done on each day of follow-up (days 1, 2, 3, 7, 14, 21 and 28), or on any other day if the child was feeling sick. Patients were called back on these days or visited at home. During each visit, a brief clinical history was obtained to assess new complaints and possible side effects and a physical examination was performed. The haemogram and biochemical analysis (bilirubin, creatinine and liver enzymes AST, ALT) were done on days 0, 7 and 14 to detect possible significant abnormalities. Filter paper blood samples for parasite genotyping were obtained on day 28 or earlier if presented with repeat of the symptoms. Patients were excluded from the study if they withdrew consent, left the study area or reported taking anti-malarial medication during the follow-up period.",1
4,14,"Response to drug treatment was assessed using modified WHO clinical classification system: all patients were not febrile at presentation, hence a temperature < 37.5° C was not an exclusion criterion and patients were followed up for 28 days in this area of intense transmission. The clinical classification system consisted of adequate clinical and parasitological response (ACPR), late parasitological failure (LPF), late clinical failure (LCF) and early treatment failure (ETF). The cure rates on day 28 were adjusted on the basis of the PCR genotyping results of paired samples for patients with recurrent parasitaemia after day 14 of starting treatment.",1
4,15,"A finger prick blood sample was taken to prepare thick and thin blood smears on days 0, 1, 2, 3, 7, 14, 21, 28 and on any other (unscheduled) visit. The slides were air dried, stained with 10% Giemsa for 20 min and read independently by two technicians. Parasite density (the number of parasites and gametocytes per μl) was calculated by counting parasites against 200 leukocytes and assuming a leukocyte count of 6,000/μl of blood. A slide was considered negative after reading at least 200 power fields. Thin blood smears were specifically used to identify Plasmodium parasite species. All qualitative discordant slides and slides with a parasite density difference ≥50% were read by a third microscopist. For quality control 10% of randomly selected slides were reread by an independent microscopist, not involved in the study.",1
4,16,"Filter paper blood spots were collected on days 0, 28 or any other day of recurrent parasitaemia. Genotypes of the parasite population in each sample collected from patients with microscopically confirmed P. falciparum infections at enrollment, and during follow-up if the patients were parasitaemic on or before D28 were determined using PCR techniques. Analysis of genetic polymorphisms was performed on paired primary and posttreatment parasites samples obtained from the two treatment groups. Paired primary and post-treatment parasites were analysed using parasite loci that exhibit repeated numbers of polymorphisms to distinguish true treatment failures from new infections. Briefly, block 2 of MSP-1 (merozoite surface proteins-1), and the Block 3 of MSP-2 (merozoite surface protein-2) and region II of GLURP were amplified by two rounds of PCR using primers and amplification conditions [12,13]. Ten microliters of the PCR products were resolved by electrophoresis on a 2% agarose gel and sized against a 100-base pair molecular weight marker (New England Biolabs, Beverly, MA). The banding pattern of the posttreatment parasites were compared with matched primary parasites.",1
4,17,"The case report forms were double checked to ensure complete and accurate data collection. Dual data entry was done by two clerks after which data was compared, corrected and validated by the data manager. Data analysis was done using Epi Info version 6 and SPSS version 11. The primary analysis was a non-inferiority analysis (with clinically relevant difference of 6% and one-sided significance level of a = 0.025) based on PCR-corrected adequate clinical and parasitological response (ACPR) on day 28 as primary efficacy endpoint [15]. Secondary endpoints included gametocyte carriage, fever and parasite clearance time and packed cell volume levels. Chisquare and Fisher exact or Yate’s correction tests were used to compare proportions between treatment groups. Normally distributed continuous variables were compared using Student’s t test between two independent groups while non-parametric tests (Wilcoxon rank-sum) were used to analyse skewed data. Kaplan Meier was used to analyse the significance between the rates of reinfection in the two treatment arms. Two tailed p-values <0.05 were considered statistically significant. The Intention-To-Treat (ITT) population including all patients who were randomized to either of the two treatment groups and received at least one dose of study medication was used for safety analysis.",1
4,18,"Out of 3,500 children screened for malaria, 500 were enrolled into the trial; 250 were assigned to the AS + AQ treatment arm and 250 to the AS + SMP arm (Figure 1). Thirty three children (6.6%) were lost to followup, of which 21 in the AS + SMP arm and 12 in the AS + AQ arm. Both treatment groups were comparable in terms of baseline demographic, clinical, parasitological and laboratory characteristics (Table 1).",1
4,19,"There were two early treatment failures, one in each treatment arm (0.4%). The PCR corrected cure rates for day 28 was 97.9% in the AS + AQ arm and 95.6% in the AS + SMP arm (p = 0.15). The re-infection rate was 1.7% in the AS + AQ arm and 5.7% in the AS + SMP arm (Table 2, 3 and Additional file 1) (p = 0.021).",1
4,20,"The median fever clearance time was similar in the two treatment groups: 1 day for both AS + SMP and AS + AQ (p = 0.271). The median parasite clearance time was also similar in the two treatment groups with a range of 1 - 7 days for AS + SMP and 1 - 3 days for AS + AQ (p = 0.941). The proportions of children with gametocytes over the follow-up period were similar in both treatment groups. Sixteen children in each treatment arm had gametocytes on day 0 (7.0% for AS + SMP and 6.7% for AS + AQ) (Table 2). On day 28, the proportion of children with gametocytes was reduced to 2.2% for AS + SMP and 3.4% for AS + AQ (p = 0.408) (Figure 2). On day 14, the proportion of children with anaemia was reduced to 1.3% both in AS + SMP and AS + AQ treatment group (Figure 3).",1
4,21,"Serious adverse events were not reported in any of the patients. There was no significant difference in the proportions of patients reporting adverse events in the two treatment groups. Five patients (2.2%) treated with AS + AQ reported one or more of the following adverse events: vomiting (n = 1), excessive sleepiness (n = 2), abdominal pain (n = 1), and weakness (n = 3). Three patients (1.3%) treated with AS + SMP reported vomiting, one of these patients also reported nausea as adverse event. None of these patients needed to be admitted as a result of these events. For all children, laboratory values (packed cell volume, liver enzymes, bilirubin) remained within normal levels during the follow-up period (Table 4).",1
4,22,This study is documenting the efficacy and tolerability of AS + SMP compared to the recommended artesunate-amodiaquine (AS + AQ) ACT for the treatment of uncomplicated P. falciparum malaria in children in an endemic area of south-western Nigeria. The study was based on a 28-day follow-up period.,1
4,23,"Many African countries have adopted artemisinin based combination therapies (ACTs) as first-line therapy against uncomplicated malaria, particularly artemetherlumefantrine (AL) and AS + AQ. However based on field experience, there is a need to assess other forms of ACT in order to identify a suitable alternative to recommended treatments in case those are not readily available to the patients who urgently need to be treated. The 28-day cure rates observed in this study were 95.6% in the AS + SMP treatment arm compared to 97.9% in the AS + AQ treatment arm (p = 0.151) suggesting that the therapeutic efficacy of both drugs were similar.",1
4,24,"These findings are in agreement with previously reported studies on AS + SMP from other endemic and non-endemic malaria areas [3-7]. The observed AS + AQ cure rate is also similar to those stated in other studies [16-18]. The significantly higher under 5 year old children in the AS + AQ group would have possibly led to a lower inability to clear malarial parasites in the AS + AQ group as a result of their relatively low immunity. The loss to follow up rate was also significantly higher in the AS + SMP group than the AS + AQ group (21 versus 12) this may not be related to the drug efficacy as these losses were mainly due to movement to and from schools as well as other family social issues. The fact that 3,500 children had to be screened in order to attain the postulated sample size of 250 children per treatment arm suggests that a high proportion of the cases of fever in children are not due to malaria infection, but e.g. due to bacterial infections [9]. On the field, in the absence of parasitological confirmation, the anti-microbial profile of the SMP component of AS + SMP would have provided clinical benefits to such children even if malaria would have been wrongly diagnosed.",1
4,25,"Gametocyte carriage before and following treatment were similar in the two treatment arms, which is expected to be the result of the action of artesunate [19]. Interestingly, sulphadoxine/pyrimethamine (SP) was shown to increase gametocyte carriage following treatment of uncomplicated malaria infection [20], but this does not seem to be the case for SMP. In fact, Sowunmi et al reported that, despite slower clearance of sexual parasitaemia in children treated with AQ + SMP compared with those treated with AL, treatment with the former was not associated with increased gametocyte carriage [19].",1
4,26,"Both AS + SMP and AS + AQ treatments were well tolerated and the frequency of reported adverse events was similar in the two treatment arms. In reality, the reported adverse events were difficult to distinguish from signs and symptoms of malaria. It is notable that the reported frequency of those with itching treated with AS + AQ was low, similar to what was previously reported by Sowunmi et al in 1989 [21]. Serious adverse events such as icterus or intravascular haemolysis were not reported by any of the children. However the packed cell volume on follow up was found to be significantly lower in patients treated with AS + SMP and this may be related to high frequency (23.9% in males and 4.6% in females) of glucose six phosphate dehydrogenase (G6PD) deficiency in the study area [22]. This would have been substantiated if all patients were screened for G6PD Deficiency.",1
4,27,"In summary, this study demonstrates that AS + SMP FDC given as three doses over 24 hours (12-hour intervals) has similar efficacy as AS + AQ FDC given as three doses over 48 hours (24-hour interval) in terms of fever and parasite clearance for the treatment of uncomplicated Plasmodium falciparum malaria in children in Nigeria. Both drugs also proved to be safe though AS + SMP has a higher re-infection rate. AS + SMP represents a good alternative to recommended first line treatments in areas where these are not available, or only offered at high costs. A continuous surveillance on the development of drug resistance is however essential as a result of potential cross resistance between SP and SMP.",1
5,1,"Chronic depression represents a public health worldwide problem. Despite the existence of several drugs for depression treatment, these medicines have many significant adverse effects, and many patients do not display satisfactory responses to the current therapeutic arsenal [1]. The etiology of depression is incompletely understood, and this precludes development of more effective drugs. Compelling literature data suggests a crosstalk between immunological changes and major depression [2,3]. It has been demonstrated that systemic administration of pro-inflammatory cytokines or some bacterial products to rodents elicits a condition described as sickness behavior, characterized by decreased food consumption and locomotor activity, social isolation, and changes in the circadian cycle, which is followed by depressive behavior [3-5].",1
5,2,"Toll-like receptors (TLR) are recognition units that distinguish microbial structures. Gram-negative bacterial lipopolysaccharide (LPS) commonly signals through TLR4, leading to activation of several intracellular pathways [6]. It has been demonstrated that depression-like behavior induced by LPS in rodents is dependent on cytokine production; importantly, depressed patients display elevated cytokine plasma levels [2,3]. Furthermore, it has been recently shown that TLR activation following infection can induce systemic inflammation, accompanied by signs of brain-controlled illness in rats [7,8].",1
5,3,"Kinins are a group of peptides that are rapidly generated in response to several stimuli [9]. Once released, kinins activate two G protein-coupled receptors, called B1 and B2. B2 receptors are constitutively expressed throughout several tissues, whereas B1 receptors are not commonly expressed under normal conditions, although they are rapidly upregulated after infection, trauma, or by certain cytokines [10-13]. Of relevance, a series of previous publications has demonstrated an important role for TNFa in the up-regulation of kinin B1 receptors [14-17]. Therefore, B1 receptors are likely induced under certain pathological conditions, being involved in several chronic inflammatory and pain processes [9,10].",1
5,4,"Previous studies have demonstrated that LPS from either E. coli or P. gingivalis can induce a marked up-regulation of kinin B1 receptors in animal models of peripheral inflammation, via cytokine production [14,15,18]. Of relevance, recent studies also suggest that kinin B1 receptors have also been implicated in some diseases involving the central nervous system (CNS), such as epilepsy, Alzheimer’s disease and neuropathic pain [19-21]. Taking into account the above mentioned data, the present study was designed to test the hypothesis that kinin B1 receptors might be implicated in depression-like behavioral changes elicited by systemic administration of E. coli LPS, in mice submitted to a previous stressing forced swimming session. This experimental protocol was based on the concept that internal and external stressors are able to interact, culminating in a general illness state, which causes an allostatic overload [2,22,23]. Efforts have also been made to define some of the mechanisms responsible for B1 receptor induction in the context of LPS-treated depressed animals by using biochemical and molecular techniques, such as flow cytometry, ELISA and real-time PCR. We have also aimed at determining whether antagonism of kinin B1 receptors could modulate glial activity, throughout immunohistochemical studies.",1
5,5,"The following drugs and reagents were used: imipramine, LPS from E. coli serotype 0111:B4, aprotinin A, benzethonium chloride, EDTA, HTAB, hydrogen peroxide, PMSF, TMB and Tween-20 (all from Sigma Chemical Company St. Louis, U.S.A); R-715, kindly provided by Dr. Domenico Regoli (University of Sherbrooke, Sherbooke, Quebec, Canada); SSR240612 was kindly provided by SanofiSynthelabo Recherche (Montpellier, France). FR173657 was donated by Fournier Laboratories (Dijon, France). The stock solutions of the drugs were prepared in PBS in siliconized plastic tubes, maintained at -18°C, and diluted to the desired concentration just before use.",1
5,6,"Male CF1 and C57/BL6 wild-type, or TNFa p55 receptor knockout mice (25 to 30 g) were used in this study. Animals were housed under conditions of optimum light, temperature and humidity (12 h light-dark cycle, 22 ± 1°C, under 60 to 80% humidity), with food and water provided ad libitum. CF1 mice were obtained from the central animal house of the Universidade Federal de Pelotas (UFPEL, Brazil). C57/BL6 wild-type, or TNFa p55 receptor knockout mice were supplied by the Universidade Federal de Minas Gerais (UFMG, Belo Horizonte, Brazil). All experiments were performed between 08:00 AM and 08:00 PM. Experiments were conducted in accordance with current guidelines for the care of laboratory animals and ethical guidelines for the investigation of experimental pain in conscious animals laid down by Zimmermann (1983) [24]. All the experimental procedures were approved by the Animal Ethics Committees of Universidade Federal de Santa Catarina (SC) and Pontifícia Universidade Católica do Rio Grande do Sul (RS).",1
5,7,"As a pre-stressful stimulus, the animals were subjected to forced swimming for 5 min, in a water temperature of 23 ± 1°C. Subsequently, they were injected with LPS from E. coli (serotype 0111:B4) at the doses of 450 mg/kg (CF1 mice) or 1000 μg/kg (C57/BL6 wild-type, or TNFa p55 receptor knockout mice), by i.p. route. The control groups received saline (0.9% NaCl solution, 10 ml/kg, i.p.). The protocol of forced swimming and the selected doses of LPS were determined on the basis of pilot experiments (not shown).",1
5,8,"The animals were assessed in behavioral paradigms at 6, 24 or 48 h time points after LPS administration, depending on the experimental protocol. All the behavioral parameters were evaluated by trained experimenters blind to the treatment groups. Separate groups of mice were euthanized at different time-points after LPS injection, in order to perform biochemical, molecular biology and immunohistochemical assays, as described in the next sections.",1
5,9,"To verify the involvement of kinin receptors in the behavioral changes elicited by LPS from E. coli, the animals were treated with one of the following drugs before behavioral tests: the selective antagonists of kinin B1 receptor SSR240612 (5 mg/kg, i.p., 30 min; or 10 mg/kg, p.o., 1 h) or R-715 (0.5 mg/kg, i.p., 30 min), or the selective kinin B2 receptor antagonist FR173657 (30 mg/kg, i.p., 30 min). The classical tricyclic antidepressant imipramine (10 mg/kg, i.p., 30 min) was used as a positive control drug. Control animals received saline solution (0.9% NaCl solution, 10 ml/kg), at the corresponding schedules of treatment used for the antagonists. For molecular biology and immunohistochemical studies, animals were treated with SSR240612 (5 mg/kg, i.p.), 30 min before LPS, and were sacrificed at defined time-points as described in the next sections. The doses of kinin antagonists and imipramine were determined on the basis of previous publications [25-27].",1
5,10,"To assess the depression-like behavior following the 5-min forced swimming session in animals treated with LPS from E. coli, we employed a tail-suspension model according to the methodology originally described by Steru et al. (1985) [28]. At different time intervals after LPS treatment (6, 24 or 48 h), the animals were suspended 50 cm above the floor by means of an adhesive tape, placed approximately 1 cm from the tip of the tail. The time during which mice remained immobile was quantified (in s) over a period of 6 min.",1
5,11,"Anhedonia represents decreased sensation of pleasure, which can be evaluated in mice by measuring reduction of sucrose intake. The protocol used in our study was adapted from the method described by Strakaliva et al, 2004 [29]. For three days, mice received 1% sucrose solution, and they were subjected to forced swimming, twice a day, for a total of six sessions (temperature water 16 to 19°C, for 5 min), as a pre-stressful stimuli. After the last swimming session, mice were treated with LPS from E. coli (450 μg/kg, i.p), followed by a 24-h period of food and water deprivation, according to the original protocol [29]. Sucrose intake was assessed for 12 h, where mice had free access to two bottles, one with 1% sucrose solution and another with tap water. The weight differences of bottles were used to calculate the consumption of sucrose with the following formula: % sucrose intake = [sucrose intake (g)] × 100/[sucrose intake (g) + tap water (g)]. The animals were treated with the selective kinin B1 receptor antagonist SSR240612 (10 mg/kg, p.o., 1 h) or the antidepressant imipramine (10 mg/kg, i.p., 30 min), both administered before LPS injection. Control animals received saline solution, at same schedule of treatment.",1
5,12,"To analyze the effects of swimming session plus LPS treatment on the locomotor activity, the animals were evaluated in an open-field test [30], 6 or 24 h after endotoxin administration. The experiments were conducted in a sound-attenuated room, under low-intensity light. Mice were individually placed in the centre of an acrylic box (40 × 60 × 50 cm), with the floor divided into 9 squares. The number of squares crossed with the four paws was registered over a period of 6 min.",1
5,13,"Mouse colonic temperature was recorded using a commercially available thermometer (Pro-check®), which was dipped in Vaseline and inserted about 0.5 cm into a gently hand-restrained mouse. After recording the initial colonic temperature (t = 0), the body temperature of mice was evaluated 6 or 24 h after LPS injection.",1
5,14,"Mouse hippocampi and cortex were collected using a special apparatus, after euthanasia by decapitation, at 1, 3, 6 and 24 h following LPS injection. Total RNA was extracted using Trizol reagent (Invitrogen), according to the manufacturer’s instructions. The concentration of total RNA was determined by measuring the absorbance at 260 nm. In order to obtain the reverse transcript (cDNA), 2 μg of total RNA were reverse transcribed using oligo(dT) as a primer (0.05 μg), 50 U of reverse transcriptase (Promega), dNTP (144 μM; Promega), reaction buffer [10 mM dithiothreitol (DTT), 3 mM MgCl2, 75 mM KCl, and 50 mM Tris-HCl, pH 8.3], and 2 U of RNAsin Plus (Promega), in a final volume of 12.5 μl. The cDNA was obtained after incubation of the samples for 5 min at 70°C, 4°C for 5 min, 37°C for 60 min, 70°C for 5 min, and 4°C for 5 min.",1
5,15,"B1 receptor and BDNF mRNA expression was carried out through fluorescence-based real-time PCR. To this end, approximately 100 ng of cDNA were amplified in duplicates using TaqMan-based chemistry with specific primers and FAM-labeled probes for mouse BDNF (cat# Mm00432069_m1), B1 receptor (cat# Mm00432059_s1) and glyceraldehyde-3-phosphate dehydrogenase (GAPDH; cat# Mm03302249_g1) as the endogenous control for normalization. Amplifications were carried out in a Thermalcycler (StepOne Plus, Applied Biosystems) for 50 cycles; the fluorescence was collected at each amplification cycle and the data analyzed using the 2-ΔΔCt method for relative quantification. Expression of the target genes was calibrated against conditions found in naive animals, i.e., nontreated mice.",1
5,16,"Brain samples were collected 24 h following LPS treatment, and fixed in a phosphate buffered saline (PBS) solution containing 4% paraformaldehyde for 24 h at room temperature. Subsequently, the samples were submitted to standard histological proceeding in order to be embedded in paraffin. Hippocampus sections were cut approximately at the level of 3 mm from bregma [2,31]. To determine glial activity, immunohistochemistry was carried out on paraffin tissue sections using CD68 antibody (1:150; Cell Signaling Technology, Beverly, MA, USA). Following quenching of endogenous peroxidase with 1.5% hydrogen peroxide in methanol for 20 min, high temperature antigen retrieval was performed by immersion of the slides in a water bath at 95 to 98°C in 10 mM trisodium citrate buffer pH 6.0, for 45 min. After overnight incubation at 4°C with the primary antibody, the slides were washed with PBS, incubated with the appropriate biotinylated secondary antibody (Dako Cytomation), and then processed using the Streptavidin-HRP reagent (Dako Cytomation), according to the manufacturer’s instructions. Sections were developed with DAB (3,3’-diaminobenzidine) (Dako Cytomation) in chromogen solution and counterstained with Harris’s hematoxylin. Control and experimental tissues were placed on the same slide and processed under the same conditions.",1
5,17,"Images were acquired by Sight DS-5M-L1 digital camera connected to a light microscope Eclipse - 80i (Nikon). Settings for image acquisition were identical for control and experimental tissues. For each mouse, the number of CD-68 positive cells was counted in four different fields of CA1, CA2, CA3 and dentate girus (DG) hippocampal sub regions, using 40X magnification.",1
5,18,"The animals were submitted to forced swimming and treated with LPS from E. coli, as described before. Subsequently, they were euthanized by decapitation at distinct intervals of time following LPS (1, 3, 6, 12 and 24 h). TNFa levels were determined in serum or in whole brain by means of a standard sandwich ELISA technique, according to the recommendations of the supplier (R&D Systems, USA). For the brain assays, the tissues were removed and placed in a PBS solution containing 0.05% Tween 20, 0.1 mM PMSF, 0.1 mM benzamethonium chloride, 10 mM EDTA, 2 μg/ml aprotinin A, and 0.5% BSA. The mouse brains were homogenized and then centrifuged at 3,000× g for 10 min, and the supernatant was employed for ELISA analysis.",1
5,19,"Cerebral spinal fluid (CSF) samples were taken from the cisterna magna using a method adapted from Liu and Duff [32]. Mice were submitted to forced swimming and treated with LPS from E. coli (450 μg/kg, i.p.), as described before. One, three or twenty four h after treatment, mice were anesthetized with a mixture of ketamine (100 mg/kg; i.p.) and xylazine (10 mg/kg; i.p.), and placed on stereotaxic instrument. The head was positioned in a 135° angle with the body, and a sagittal incision of the skin was made inferior to the occiput. To aspirate the CSF, the metal part of an insulin needle was adapted at one end of a polyethylene 50 tubing, and at the other end a 50 μl Hamilton syringe was attached. The needle was attached to the bottom end of the manipulator bar, and 3 mm of it was inserted into the cisterna magna. The CSF collected was transferred to a 0.5 ml Eppendorf tube, and frozen immediately on dry ice and then kept into -80°C until use. CSF from naïve animals was used as control.",1
5,20,"The BD Cytometric Bead Array (CBA) was used to quantitatively measure cytokines in the CSF. The CBA Mouse Inflammation Kit® (BD Bioscience, San Jose, CA) was used according to the manufacturer’s instructions to simultaneously detect interleukin-6 (IL-6), interleukin-10 (IL-10), interferon-g (IFN-g), tumor necrosis factor alpha (TNFa), and interleukin-12p70 (IL-12p70). Flow cytometer readings were performed using FACSCanto II red laser in a medium range of 633 nm. Data were acquired using FACSDiva software and analyzed using FCAP Array software (all from BD Bioscience). The captured cytokines were detected via direct immunoassay using six different antibodies coupled to phycoerythrin (PE). Standard curves were generated for each cytokine using the mixed cytokine beads standard provided by the kit. The concentration of the standards ranged from 20 to 5000 pg/ml. Five standard curves were plotted such as: cytokine concentration X mean fluorescence intensity (MFI), using a four-parameter logistic curve fitting model. The concentrations of each CSF cytokine were determined from these four-parameter equations using the MFI value of each cytokine. If a sample had a cytokine concentration below the detection limit for the assay, a value of 0 was assigned for that concentration.",1
5,21,"For the behavioral parameters and Elisa protocols, the results are presented as the mean ± SEM of 6 to 8 animals. For the real-time PCR, flow cytometry and immunohistochemical experiments, the results are given as the mean ± SEM of 4 independent experiments, performed in triplicate. The statistical comparison between these values was performed by one-way analysis of variance followed by Newman-Keuls post hoc test. P values less than 0.05 (p < 0.05) were considered as indicative of significance.",1
5,22,"The results depicted in Figure 1a demonstrate that systemic administration of E. coli LPS (450 μg/kg, i.p.), following a 5-min forced swimming session, elicited time-related depression-like behavior in mice, according to assessment in the tail-suspension paradigm. The increase of immobility time in animals pre-treated with LPS was statistically significant at 24 h (P < 0.01), but not at 6 h (P > 0.05; results not shown), returning to control levels at 48 h (P < 0.05), in comparison to saline-treated mice. As could be expected, treatment with the classical antidepressant drug imipramine (10 mg/kg, i.p.), given 30 min before the behavioral assessment, produced a marked reduction of the immobility time (47 ± 16% of reduction; Figure 1a). Of interest, i.p. treatment with the selective B1 receptor antagonists R-715 (0.5 mg/kg, 30 min) or SSR240612 (5 mg/kg, i.p., 30 min), or even oral administration of SSR240612 (10 mg/kg, 1 h), caused a significant inhibition of depression-like behavior induced by LPS (Figure 1c). The percentages of inhibition for animals treated with B1 receptor antagonists were: 46 ± 6%, 33 ± 7% and 30 ± 6%, respectively. On the other hand, the selective kinin B2 receptor antagonist FR173657 (30 mg/kg, i.p., 30 min) failed to significantly alter the immobility time in our model (P > 0.05; Figure 1b).",1
5,23,"It is well known that LPS treatment evokes some classical CNS-associated changes in rodents [3-5]. Confirming literature data, our results demonstrate that E. coli LPS administration in mice previously submitted to forced swimming, is able to cause a marked reduction of body temperature (Figure 1e), and of locomotor activity when assessed in the open-field arena. The locomotor activity was significantly reduced at 6 h after LPS (P < 0.05), returning to the control levels at 24 h (Figure 1f). Body temperature was found significantly reduced at 6 h (P < 0.01), but not at 24 h after LPS (P > 0.05). Remarkably, the administration of R-715 (0.5 mg/kg, i.p.), 30 min before the test, did not display any significant effect on this parameter as assessed at 6 h (Figure 1e). Considering the oral bioavailability of SSR240612, the next experiments were carried out using only this antagonist.",1
5,24,"We wondered whether the effects of selective kinin B1 receptor antagonists might be related to changes of B1 receptor expression in CNS structures. Therefore, B1 receptor mRNA expression was measured in the hippocampus and frontal cortex of mice submitted to a session of forced swimming, followed by LPS administration (450 μg/kg, i.p.). Quantitative real-time experiments revealed a time-dependent, marked increase in B1 receptor mRNA levels in hippocampus, which peaked at 1 h (about 2.5-fold increase) (Figure 2a) while in the cortex this increase was almost 40 fold 1 h after LPS treatment (Figure 2b).",1
5,25,"As observed in Figure 3, forced swimming followed by LPS treatment produced a marked increase in CD68 immunoreactivity in mouse hippocampus, indicative of increased glial cell activation. Of relevance, CD68 labeling was almost completely inhibited in animals pre-treated with the selective kinin B 1 receptor antagonist SSR240612 (5 mg/kg, i.p.), but not by the antidepressant drug imipramine (10 mg/kg, i.p.), both given 30 min before LPS. These findings suggest that different mechanisms appear to mediate imipramine and kinin B1 receptor antagonist antidepressant-like effects. It has been described that depression is associated with decreased expression of neurotrophic factors, such as BDNF [33-35]. In our study, real-time PCR experiments revealed a marked decrease in BDNF expression in hippocampus of mice submitted to our protocol of depression, when assessed at both the 6- and the 24-h timepoints (an approximate 50% reduction). However, this parameter was not significantly affected by pre-treating animals with the kinin B 1 receptor antagonist SSR240612 (5 mg/kg, i.p., 30 min) (Figure 4).",1
5,26,"Next, in order to correlate the changes elicited by LPS with cytokine production, we assessed levels of TNFa in whole brain or mouse serum. The animals were submitted to a forced swimming session and treated with E. coli LPS, as described above. This series of results showed the occurrence of a marked, time-dependent increase in TNFa production, either in brain or in serum of LPStreated mice. In serum, TNFa levels peaked between 1 and 3 h (an approximate 90-fold increase), returning to basal levels 6 h following LPS administration (Figure 5a). The increase of TNFa in the brain was maximal between 3 and 6 h after LPS (about 1.8-fold augmentation), being reduced to control values after 12 h (Figure 5b). We also analyzed cytokine content in CSF from LPS-treated mice, using flow cytometry analysis. The cytokines IL-6, IL-10, IFN-g were below detection levels, while the concentration of IL-12 was similar to that observed in naïve animals (data not shown). Of interest, CSF TNFa levels peaked 1 h after LPS injection and remained elevated until 3 h later (about 340 and 90-fold increase, respectively) (Figure 5c).",1
5,27,"Since previous literature data have shown a close interrelation between TNFa and B1 receptor upregulation [10,14], we further investigated the role played by TNFa in the depression-like behavior observed in our experimental paradigm. For that purpose, we employed TNFa p55 receptor-deficient mice. As TNFa p55 receptor knockout animals used in the present study are C57/BL6 inbred, we employed this mouse strain in this part of the study. In C57/BL6 mice, a dose of 1000 μg/kg of E. coli LPS was necessary to evoke a significant increase in immobility time in the tail-suspension test, comparable to that obtained with a 450 μg/kg dose in CF1 mice (about 1.5-fold in relation to saline-treated animals). Strikingly, the depression-like behavior caused by forced swimming plus LPS treatment (1000 μg/kg, i.p.) was virtually abolished in mice with genetic deletion of TNFa p55 receptors (Figure 5d). Of note, the increase of B1 receptor mRNA expression in mice submitted to forced swimming plus LPS treatment was completely absent in TNFa p55 receptor knockout animals (Figure 5e).",1
5,28,"During the last few years, several advances have been achieved in our understanding of the genetic, biochemical and immunological changes implicated in depression [35]. Concerning the immunological mechanisms, certain pro-inflammatory cytokines, mainly IL-6, IL-1b and TNFa, have been recently pointed out as pivotal molecules for depression-related behaviors following infection. These cytokines are likely able to coordinate local and systemic inflammatory responses to pathogens [2,22]. In the depression-like behavioral paradigm employed herein, we demonstrate that administration of LPS (450 μg/kg, i.p.) in mice previously submitted to a 5-min swimming session, produces earlier signals of sickness behavior, such as decreased body temperature and locomotor activity 6 h post-LPS, which are followed by a later manifestation of depression-like behavior, i.e. an increase of immobility time in the tail suspension test, 24 h post-LPS. This is in line with literature data indicating that sickness behavior represents a normal initial response to infectious stimuli [33,36], although depression-like states might persist after initial sickness alterations have resolved [3,37].",1
5,29,"To the best of our knowledge, there is no previous study correlating kinin B 1 receptors and depression. These receptors are commonly absent under normal conditions in the periphery, but might be rapidly up-regulated by stressful stimuli. Interestingly, basal expression of B 1 receptor has been described in spinal cord and some brain structures, such as cerebral cortex, hippocampus, thalamus, hypothalamus, amygdala, and choroid plexus epithelial cells [10,38,39]. Even though the exact role of kinins in the brain is not clear, basal expression of B1 receptor in the nervous system is compellingly suggestive of a central role for these molecules [10,19,40]. Herein, we have assessed whether B1 receptors might be implicated in the depression-like behavior induced by LPS and pre-stressful stimuli.",1
5,30,"The depression-like state observed in the tail suspension test was significantly reduced by the antidepressant imipramine, in a dose which was effective in stressed rodents [27]. Interestingly, the increased immobility was significantly inhibited by treatment with either selective B1 receptor antagonists R-715 or SSR240612. These results are indicative of a relevant role for B1 receptors in depression-like behavior. Our in vivo data were reinforced by real-time PCR experiments, which demonstrated a marked increase in B 1 receptor mRNA expression in hippocampus, and notably, in the cortex of mice submitted to forced swimming plus LPS administration. Alterations of hippocampal plasticity have been widely demonstrated in depression associated with stressful insults [32,40-42]. Nevertheless, the present study is, to the best of our knowledge, the first demonstration that infection associated with a stressful stimulus might up-regulate B1 receptors in the CNS, leading to depressive behavior. Conversely, treatment of mice with the selective B2 receptor antagonist FR173657 failed to significantly affect immobility time in our depression paradigm. This is well aligned with the proposed physiological roles of kinin B 2 receptors [43]. Considering this paradigm, the participation of B2 receptors was not further considered in the present study.",1
5,31,"Of high interest, functional data obtained in the tail suspension test was extended by results employing the anhedonia paradigm of sucrose intake, in which SSR240612 was able to completely reverse reduced sucrose consumption in LPS-treated mice. It is well known that depression is likely associated with anhedonia states, where pleasure sensations are reduced or even missing [29,44]. It is noteworthy that stressful forced swimming plus LPS administration resulted in a significant decrease in sucrose consumption in Swiss mice, a parameter that was reversed by the antidepressant imipramine, which reinforces the validity of our experimental design [45]. On the other hand, sickness behavior-induced hypothermia was not significantly altered by the administration of the B1 receptor antagonist R-715. This evidence indicates that blocking B1 receptors is able to reverse later depression-like symptoms without interfering with early sickness behavior, which seems to be coordinated mainly by cytokines [46].",1
5,32,"The major immunocompetent components of the CNS are represented by microglia and astrocytes, and the activation of these cells likely contributes to the pathogenesis of depression [43,47,48]. Our data clearly demonstrate that forced swimming followed by LPS treatment results in activation of microglia in mice, as indicated by an enhancement of CD-68 immunostaining in hippocampus 24 h after LPS injection, when B1 mRNA levels return to basal. It has been demonstrated that microglial activation in response to several kinds of injury drives the release of neurotoxic mediators, such as pro-inflammatory cytokines [3,49]. Of relevance, systemic treatment with the selective non-peptide B1 receptor antagonist SSR240612 virtually abolished the CD-68 immunopositivity, but notably this parameter was not significantly altered by imipramine. This allows us to suggest that antidepressant-like effects of B 1 receptor antagonists, but not that caused by imipramine, are related to inhibition of microglial activation. These findings are quite relevant and open a new avenue to understand depressive states, especially those associated to infection.",1
5,33,"Depression is clearly associated with synaptic plasticity changes, resulting in decreased BDNF function, among other biochemical alterations. It has been demonstrated that under stressful conditions, the BDNF gene is repressed leading to neuronal apoptosis in hippocampus [40,50]. Of interest, BDNF infusion in some brain regions induces antidepressant-like effects in animal models [50-52]. Additionally, most monoaminergic antidepressant drugs are known to restore normal BDNF transcriptional levels [33-35,34]. Our depression model caused a sustained reduction in BDNF mRNA expression in hippocampus (up to 24 h). Of note, BDNF mRNA expression was not significantly altered by previous administration of the selective B 1 receptor antagonist SSR240612. Therefore, although B1 receptor antagonism prevented microglial activation, it failed to restore decreased brain levels of BDNF. These results suggest that SSR240612 seems to have an antidepressant-like activity by acting through different mechanisms from usual antidepressants; acting preferentially by an inflammatory pathway, and not by interfering with BDNF.",1
5,34,"As mentioned above, pro-inflammatory cytokines are deeply involved in the pathogenesis of depression [53,54]. Of note, patients with major depressive disorder have increased expression of soluble TNFa receptors [55,56], and patients under treatment with TNFa antagonists display a general improvement of depressive symptoms and life quality [57,58]. Herein, we reinforce this hypothesis by demonstrating that LPS administration in pre-stressed mice results in a marked increase of TNFa levels in serum, CSF and whole brain. TNFa production was initially augmented in serum (between 1 and 3 h), and later increased in whole brain (between 3 and 6 h). Therefore, it is possible to argue that increased TNFa levels in serum are the main factor responsible for sickness behavioral changes (i.e. hypothermia and reduced locomotor activity), whereas the elevation of this cytokine in brain underlies the depression-like behavior in the tail suspension test. In addition, multiplex cytokine analysis demonstrated a marked increase of TNFa levels in CSF obtained from LPS-treated mice (between 1 and 3 h), although the levels of other cytokines remained unaltered.",1
5,35,"The presence of TNFa in the CSF supports the idea of a communication pathway between the brain and the immune system. When toll-like receptors on macrophage-like cells residing in the circumventricular receptors are activated, they respond by producing proinflammatory cytokines, such as TNFa [3]. As the circumventricular organs lie outside the blood-brain barrier (BBB), and the BBB is relatively impermeable to cytokines, the mechanisms by which circulating cytokines might influence the brain function remain a matter of debate [34]. One established theory is that they can enter the brain by volume diffusion [3,58,58]. Cytokines might additionally gain access to the brain through sites where BBB is somewhat compromised, e.g. by stressful events or immunologic challenges, such as those used in our protocol [34]. Besides, kinins enhance permeability of BBB. This would disturb BBB functioning, leading to various neuropathological conditions related to cytokine entrance into the brain, including depression [59,60].",1
5,36,"To gain further insights into the relevance of TNFa in our experimental paradigm, we employed TNFa p55 receptor-KO mice. Both depression-like behavior and upregulation of B1 receptors induced by forced swimming plus LPS treatment were virtually abolished in TNFa p55 receptor-KO mice. The relevance of TNFa for the up-regulation of B1 receptors has been described before by our group [14-17]. The experimental evidence provided herein clearly suggests a link between the cytokine TNFa and the kinin B 1 receptor upregulation in depression genesis. The present data provide good evidence suggesting that generation of this pro-inflammatory cytokine seems to exert a critical role for LPS to induce B1 receptor upregulation, as already demonstrated [14].",1
5,37,"Most experts agree that depression should be viewed as a syndrome, not a disease [60]. The current hypothesis linking depression and the immune system suggests that cytokines and other immune mediators work as ‘’sensor’’ molecules, capable of transforming noncognitive stimuli (i.e. inflammatory process) into cognitive stimuli, allowing the CNS to recognize them, and to elaborate an integrated response to the peripheral event. Therefore, molecules released during peripheral inflammatory events may influence central factors controlling homeostasis and behavior [58,59]. Our findings bring a new piece of evidence into the depression disorder puzzle which may help to understand its etiology: kinin B1 receptors might exert a critical role in affective disorders, such as depression. The participation of B1 receptors in depressive alterations seems to be related to microglial activation, an event that seems to be associated with the subsequent production of TNFa in the brain. It is tempting to suggest that a clinical trial with orally available selective B1 receptor antagonists should be performed to evaluate whether or not these molecules could help treating clinical symptoms of depression.",1
6,1,"Type I interferons (IFNs) play an essential role in both the innate immune response and the induction of adaptive immunity against viral infections. Viral infections trigger the production of type I IFNs (IFN-a/b) [1,2], which leads to the activation of several hundred IFN-stimulated genes (ISGs). These genes encode a variety of antiviral proteins and cytokines, leading to the protection of the host from further viral infections [3,4].",1
6,2,"The main viral sensors in most mammalian nucleated cells are RNA helicases, retinoic acid-inducible gene I (RIG-I) and melanoma differentiation-associated protein 5 (MDA-5), which recognises viral single-stranded RNA (ssRNA) and double-stranded RNA (dsRNA) [1,5-9]. Many cells also recognise viral dsRNA through Toll-like receptor 3 (TLR3) [1,10]. The binding of virus-derived nucleic acids to RIG-I, MDA-5 or TLR3 results in a coordinated activation of the transcription factor kappa B (NF-kB) interferon regulatory factor 3 (IRF-3), leading to IFN-b production in mammals [6,7,10].",1
6,3,"Although a variety of cellular signalling has been evolved in host cells for detecting and responding to viral infection, most viruses possess mechanisms to evade these host immune responses to various degrees [7,11]. For example, many viruses have developed a multitude of mechanisms to evade the IFN response by either blocking IFN synthesis or interfering with the functions of IFN [12].",1
6,4,"In the case of influenza A viruses, the non-structural gene (NS) has been shown to be responsible for viral anti-IFN activities [13-16]. The NS gene of influenza A viruses encodes for two proteins [17]. The first is through the translation of unspliced mRNA, which encodes a protein of 26 kDa known as non-structural protein 1 (NS1). The second is a 14 kDa nuclear export protein (NEP, formerly called NS2) translated from spliced mRNA [18].",1
6,5,"The NS1 protein antagonises both the induction of IFN-b [19,20] and the activity of several IFN-induced proteins with antiviral activities such as protein kinase R (PKR) and 2’-5’oligoadenylate synthetase (OAS) [21-23].",1
6,6,"The NS gene can be classified into separate gene pools, termed alleles A and B [24,25]. Between allele A and B, 63-68% nucleotide identity and 66-70% amino acid identity was found between the NS1 proteins. The NS allele A is more common and is the only subtype found in mammalian-adapted isolates. In a comparison between amino acid sequence of avian allele A and B viruses with an amino acid sequence of human viruses, six amino acid motifs, or signatures, were found between human and avian allele A viruses, and 35 signatures between human and allele B viruses, indicating that allele B viruses are more distinct from mammalian origin viruses [26]. This suggests that the adaptation of NS1 plays an important role in the pathogenicity of avian influenza viruses in mammalian species.",1
6,7,"In our previous study concerning the genetic relationship among H10 avian influenza viruses with different pathogenicity in mink (Mustela vison), we found that these differences were related to amino acid variations in the NS1 protein. We demonstrated that in a model system using polyinosinic-polycytidylic acid (poly I:C)stimulated mink lung cells, the NS1 protein of influenza A virus isolated from mink (A/mink/Sweden/84 (H10N4)) down regulated type I IFN promoter activity to a greater extent than the NS1 protein of prototype H10 virus (known as virus/N (A/chicken/Germany/N/49 (H10N7)) [27].",1
6,8,"In this study, we extend our previous work to further investigate the effect of the NS1 from different gene pools on type I IFN promoter activity, the production of IFN-b, as well as the expression of the IFN-b mRNA in response to poly I:C.",1
6,9,"First, we studied the ability of NS1 from “mink/84” and “chicken/49” to inhibit the induction of transcription of the IFN-b gene, using the model system ISRE-Luciferase and Poly I:C stimulation. This reporter system relies on expression of IFN and the subsequent signalling from the IFN-a/b receptor leading to expression from the ISRE reporter gene (luciferase). Although both NS1 from “mink/84” and “chicken/49” showed a significant suppressive effect on the luciferase activity, it was considerably stronger in cells transfected with “mink/84” with an average of 6.8 fold decrease (85.3%) in A549 cells (Figure 1A), compared with “chicken/49”, that on average produced a 20.8% decrease in A549 cells.",1
6,10,"To find out whether the difference in inhibition of IFNb promoter is duo to difference in- or insufficient expression of the NS1 proteins in A549 cells, the level of expressed NS1 proteins was confirmed by western blot analysis. The cells were lysed at 0, 2, 4, 8, 16 and 24 hours post transfection and western blotting was performed. The NS1 proteins from both constructs were expressed in high quantity and the level of allele A NS1 was comparable to NS1 protein of allele B (Figure 1B). The western blotting showed that the expressed protein from both “mink/84” and “chicken/49” was homogenously accumulated in A549 cells and there was no notable difference between alleles in term of NS1 production (Figure 1B). Thus, the results indicated that the difference in IFN-b induction in the presence of allele B NS1 protein was not due to difference in allele B NS1 protein expression and accumulation in the cells.",1
6,11,"At this point it was not clear if this result corresponded to differences in the ability to downregulate IFN production, or that the signalling pathway leading to ISRE transcription is influenced, or both. To sort out this, IFN protein production was measured by an ELISA.",1
6,12,"The IFN-b protein was detected in the cell medium of the control cells after a lag of 2 to 4 hours after poly I:C stimulation, followed by the linear accumulation of IFNb in the cell culture supernatant. The peak yields for control cells were reached about 16 to 24 hours poststimulation (Figure 2A). Although low levels of IFN-b were secreted by cells transfected with different NS1s, significant differences were observed between these NS1s. Those cells expressing the NS1 protein of “mink/84” virus were weak producers of IFN-b, with at least 10 times lower levels of IFN-b secreted in the cell culture supernatant than the control cells. In these cells IFN-b secreted to the supernatant reached the maximum yield 8 hours post-stimulation and declined rapidly to a low level for the rest of the experiment. By contrast, cells expressing the NS1 protein of “chicken/49” were better producers of IFN-b with the profile lower but similar to that observed with the control cells (Figure 2A). This indicates that NS1, in this system, suppresses IFN protein production rather than the signalling from the IFN receptor.",1
6,13,"To determine whether the reduction of IFN-b production was caused by the suppression of the expression of the IFN-b gene, we compared gene expression kinetics in A549 cells stimulated with poly I:C in the presence or absence of different NS1 proteins.",1
6,14,"In the control cells, IFN-b mRNA was detected in increased amounts during the entire period of the experiment (Figure 2B). The same profile was observed in the cells expressing the NS gene of “chicken/49 ” (Figure 2C). Transcript levels in the control cells were significantly increased 2 to 4 hours post-stimulation, reaching a plateau at the end of the experiment. Four hours after stimulation, the NS1 protein of the “mink/84” effectively suppressed IFN-b gene transcription in A549 cells (Figure 2D). The activation of the IFN-b gene expression in cells transfected with plasmids carrying the NS gene of “chicken/49” resulted in increased levels of IFN-b mRNA showing the same trend similar to the control cells.",1
6,15,"The RT-PCR analysis of the INF-b mRNA presented in the stimulated A549 cells expressing NS1 of “mink/84” or “chicken/49” confirmed that the NS1 protein of “mink/84” effectively suppressed IFN-b gene transcription in A549 cells, indicating that the main target of the “mink/84” NS1 is the induction of IFN.",1
6,16,"One of the main strategies of the influenza A viruses to avoid host immune responses is to inhibit IFN-a/b expression or signalling to the neighbouring cells, which induce their antiviral state by the stimulation of transcription from the ISRE promoter-containing genes [28]. The viral NS1 of influenza A viruses is known to be an important regulator of innate immunity on many levels [13-16]. The NS1 inhibits host immune responses through two functional domains: an N-terminal RNA binding domain and a C-terminal effector domain [19]. The effector domain interacts with proteins involved in the 3’-end cellular mRNA processing, inhibits mRNA export and pre-mRNA splicing of host cell transcripts and interacts with components of the nuclear pore complex as well as the mRNA export machinery [29-34]. The N-terminal RNA binding domain binds to both single- and double-stranded RNA that might inhibit the activation and/or signalling of antiviral proteins, such as RIG-I, PKR, OAS/RNase L, activators of mitogenactivated protein kinase and transcription factors involved in type I IFN and inflammatory cytokine signalling [20,22,23,35-37].",1
6,17,"Our previous study indicated that the NS1 protein is a potential key factor for the different pathogenicity levels of the H10 avian influenza viruses in mink (Mustela vison) [27]. In this study, we applied an expression plasmid system carrying the ORF of NS1 of two avian influenza viruses, showing the difference in pathogenicity in mink [38]. Furthermore, these viruses represent different NS alleles, one from A (""mink/84”) and the other one from B (""chicken/49”). A comparison of the predicted amino acid sequences of the two NS1 proteins showed 71 amino acid differences (Figure 3). However, the two NS1 proteins were found to be very similar regarding the previously identified important amino acid residues for the function of NS1 protein in the infected cells [23,29,30,34,39,40].",1
6,18,"Notably, the only difference was found in the site important for the NS1 protein’s interaction with the 30kDa subunit of cleavage and polyadenylation specificity factor (CPSF30) [27]. The NS1 protein interaction with the CPSF30 inhibits 3’-end processing of cellular premRNA [29,30,34]. This function is mediated by two distinct domains: one around residue 186 [30] and the other around residues 103 and 106 [41]. The NS1 protein of “mink/84” possessed the amino acid Glu186, Phe103 and Met106, whereas the NS1 protein of “chicken/49” possessed Tyr 103. A previous study [41] showed that mutations at the NS1 protein CPSF30 interaction sites dramatically changed the effect of the NS1 to control host gene expression.",1
6,19,"Both “mink/84” and “chicken/49” NS1s had a negative effect on the activation of the ISRE promoter, as shown by the luciferase activity. But the reduction was much stronger in cells transfected with the “mink/84” NS1 plasmid with an average of 85.3% decrease in A549 cells (Figure 1A), whereas pNS-chicken/49 on average produced a 20.8% decrease in A549 cells. As this final product is dependent on both the induction of IFN and luciferase from the IFN receptor, the exact mechanism by which this interference is mediated through can be either by inhibiting IFN induction signals via RIG-I, MDA-5 or TRL-3, the processing of IFN mRNA, or the downstream effects via IFN receptor signalling or luciferase mRNA processing.",1
6,20,Several studies have indicated that the blocking of virus-induced IFN-b promoter activation is mediated by the N-terminal RNA binding domain of the NS1 protein [42-44]. The 71 amino acid differences between the two NS1 proteins will most likely result in differences on the three-dimensional structure of the NS1 protein that could affect the function of NS1 in the suppression of IFN-b promoter activation.,1
6,21,"Since the induction of the IFN-b promoter is associated with the production of IFN-b, we next investigated the level of endogenous IFN-b mRNA and the amount of IFN-b secreted in the cell supernatant. It has been observed that the NS1 protein of “mink/84” but not “chicken/49” strongly suppressed the expression of the IFN-b gene and secretion of IFN-b in the cell culture supernatant. In the time course study using A549 cells stimulated with poly I:C, IFN-b production displayed three distinct phases. After an initial rapid increase it reached a peak and then declined to lower levels. The production of IFN-b by poly I:C stimulation in A549 cells displayed a 2- to 4-hours lag followed by a steady increase in the accumulation of secreted IFN-b in the cell culture media. Maximal yields were observed at 16 to 24 h post poly I:C stimulation (Figure 2A). Similar observations were made when mRNA levels were measured. The expression during poly I:C stimulation revealed an early up regulation of IFN-b transcripts starting at or before 2 h with a peak at 18-24 h after stimulation. During the first 4 h post-stimulation, we observed an up regulation of IFN-b mRNA transcripts in A549 cells expressing the NS1 protein of “mink/84”.",1
6,22,"Future experiments are required to investigate the exact molecular mechanism behind this observation. This may require the use of animal experiments and also includes tools like reverse genetics, genomics and proteomic tools that allows the analysis of many parameters involved in the complex interplay between the NS1 and the host innate immune machinery.",1
6,23,"All these observations indicate that different nonstructural protein 1 (NS1) of influenza viruses, one from allele A and another from allele B, show different abilities to suppress the induction of IFN mRNA; however, the exact mechanism is unknown. The results also demonstrate that the production of an important cytokine, IFN-b is affected by the function of NS1 protein from different genetic gene pools.",1
6,24,"It is possible that NS1 interacts with one of the inducing pathways, or both, or that the mRNA processing is blocked. The latter can be studied by investigating another inducible gene other than an IFN-dependent one.",1
6,25,"After establishing an assay protocol for different part of our study, both NS1 construct were tested in duplicate at three independent experiments (each experiment was set up separately and carried out on different days).",1
6,26,"The NS1 open reading frames (ORF) of influenza A virus strains A/mink/Sweden/3900/84 (""mink/84”) and A/chicken/Germany/N/49 (""chicken/49”) were amplified using the primers NS1Kpn 5’ (5’-ATTCGGTACCAGCAAAAGCAGGGTGACAAAG-3’) and NS1XhoI 3’ (5’TACCCTCGATAGAAACAAGGGTGTTTTTTAT-3’). Twenty-five microliter PCR-mix contained 1xPlatinum Taq buffer (Invitrogen), 200 μM dNTP, 2.5 mM MgCl2, (Invitrogen) and 3 μl cDNA. Reactions were placed in a thermal cycler at 95°C for 2 min, then cycled 35 times between 95°C 20 sec, annealing at 58°C for 60 sec and elongation at 72°C for 90 sec and were finally kept at 8° C until later use.",1
6,27,"The 690 bp PCR products were digested with Kpn and XhoI and cloned between the Kpn and XhoI sites of the mammalian expression vector pcDNA3.1 (Invitrogen, Carlsbad, CA, USA), creating pNS-mink/84 and pNS-chicken/49 plasmid respectively. The integrity of the plasmids was confirmed by sequencing.",1
6,28,"A549 cells, a type II alveolar epithelial cell line from human adenocarcinoma, (ATCC, CCL 185) were cultured in Dulbecco’s modified Eagle medium (DMEM) and supplemented with 10% FCS in a humidified atmosphere of 5% CO2 at 37°C.",1
6,29,Transcriptional activity was assayed in the A549 cells. Cells were co-transfected with plasmids containing either the NS gene of “mink/84” or “chicken/49” together with reporter plasmids driving expression of Firefly luciferase (pISRE-TA-Luc) (Invitrogen) under the control of the IFN-stimulated response element (ISRE). The pRen-Luc plasmid containing the Renilla luciferase gene (Invitrogen) was used as internal control. The activity of the reporter gene were standardised by the Renilla luciferase activity. The inhibitory effect in cells expressing the various NS1s was expressed in folds of luciferase activity.,1
6,30,"The transfection of the plasmids was conducted with FuGENE 6 reagent (Roche Molecular Biochemicals, Indianapolis, IN) in six-well plates according to the manufacturer’s instructions. Initial experiments were conducted to optimise the efficiency of the transfection protocol. The day before transfection, cells were collected and seeded into six-well plates at 1 × 10 5 cells per well to achieve 70-80% confluence on the day of transfection. Each transfection group consisted of six wells in which three were poly I:C stimulated and three mock treated. Stimulation of the cells with the poly I:C was performed 24 hours after transfection of the pcDNA3.1/NS1 plasmid through the addition of 5 μg/ml poly I:C mixed in 100 μl DMEM without serum. Twenty-four hours later, the cells were harvested according to the protocol for the luciferase assay kit (Stratagene, Heidelberg, Germany), using 300 μl lysis buffer for each well. Samples were kept on ice and centrifuged for 2 min at 14,000 × g to remove cell debris before measurement of the luciferase activity. Luciferase activities were measured using 20 μl of each sample according to the manufacturer’s protocol.",1
6,31,"All the transfections for western blot analysis were performed following the same protocol as described above. Briefly, cells were washed and lysed at 0, 2, 4, 8, 16 and 24 hours post transfection using Bio-Plex cells lysis kit (Bio-Rad Laboratories, Hercules, CA) according to the manufacturer’s instructions. After incubation for 20 min at 4°C and three times thawingfreezing steps at -70°C, the lysates were centrifuged at 4500 rpm for 20 min. Concentration and quality of the protein were measured using Nanodrop ND1000 (Nanodrop Technologies, Wilmington, DE.) and by SDS-polyacrylamide gel electrophoresis (SDS-PAGE) followed by Coomassie blue staining. A total of 50 μg of the cell lysate was separated bySDS-PAGE in Ready Gel J 7.5% (Bio-Rad) and then electronically transferred onto polyvinylidene difluoride (PVDF) membrane (GE Healthcare, Uppsala, Sweden). The membranes were incubated in blocking buffer (PBS, 2% (wt/vol) bovine serum albumin) at room temperature for one hour on slow agitation, the NS1and bactin proteins were detected using anti-NS1 polyclonal, the NS1 antibodies was raised in goat against a peptide mapping near the C-terminus of influenza A NS1 (sc-17596, Santa Cruz Biothechnology, INC) and anti b-actin (Sigma-Aldrich, Stockholm, Sweden), followed by incubation with primary antibodies diluted in TBS-2% BSA at 4°C overnight.",1
6,32,"The concentration of IFN-b in stimulated A549 cell supernatants was determined using a commercially available VeriKine™ human IFN-beta sandwich enzymelinked immunosorbent assay (ELISA) kit (PBL interferon source, Piscataway, NJ, USA) according to the manufacturer’s instructions. The cell supernatants were collected at 0, 2, 4, 8, 16, 24 and 48 hours post-poly I:C stimulations. Briefly, microtiter strips were incubated with 100 μl of IFN standards, blanks and samples. After one hour of incubation, the strips were washed and detection antibodies were added. After incubation and an additional washing step, streptavidin conjugated to horseradish peroxidase (HRP) was added, and the strips were incubated at room temperature for 1 hour. The strips were again washed before the addition of the tetramethyl benzidine (TMB) substrate solution, after which the strips were incubated for 15 min at room temperature in the dark. The reaction was terminated by the addition of stop solution, and the optical density of the wells was read at 450 nm using a microplate reader Multiscan EX (Thermo scientific, MA, USA). Values for the samples were compared to those for the standard curve and the amount of IFN-b was estimated from the standard curve.",1
6,33,"RT-PCR was used to study the level of IFN-b mRNA expression in Poly I:C-stimulated A549 cells. The housekeeping gene b-actin was used as a control. RT-PCR was performed using the following primer pairs specific to human IFN-b and b-actin mRNA: IFN-b forward 5’ GGCCATGACCAACAAGTGTCTCCTCC 3’ and reverse 5’ ACAGGTTACCTCCGAAACTGAGCGC 3’, resulting a product of 550 bp; and b-actin forward 5’ TGGGTCAGAAGGACTCCTATG 3’ and reverse 5’ AGAAGAGCTATGAGCTGCCTG 3’. Twenty-five microliter PCR-mix contained 1xPlatinum Taq buffer (Invitrogen), 200 μM dNTP, 2.5 mM MgCl2, (Invitrogen) and 3 μl cDNA. Reactions were placed in a thermal cycler at 95°C for 2 min, then cycled 35 times between 95°C 20 sec, annealing at 63°C for 60 sec and elongation at 72°C for 90 sec and were finally kept at 8°C until later use.",1
6,34,"A549 cells were seeded in six-well plates and transfected with either pNS-mink/84, pNS-chicken/49 or empty pcDNA 3.1 vector as described above. Cells were stimulated with 5 μg/ml poly I:C mixed in 100 μl DMEM without serum. Cells were harvested and RNA was extracted for RT-PCR assays at 0, 4, 8, 16 and 24 hours post-stimulation.",1
6,35,"RNA was isolated using TRIzol Reagent (Invitrogen) according to the manufacturer’s protocol. RNA was DNAse-treated and quantified and purity measured at OD260/280 using a Nanodrop ND1000 (Nanodrop Tec., Wilmington, DA, USA). All RNA samples had an OD260/280 ratio in water between 1.9 and 2.1. 2 μg RNA was used to make cDNA templates using Superscript II (Invitrogen) according to the manufacturer’s instructions and oligo-dT primers (Invitrogen).",1
7,1,"Development of an anticancer compound is always a fascinating challenge in the field of cancer chemotherapy. Research is ongoing globally to identify new leads. The anticancer activities of several substituted naphthalimides (1H-benz[de]isoquinoline-1,3-diones) are well documented [1,2]. For example, substituted naphthalimides containing N-(2,2-dimethylaminoethyl) chain best represented by Mitonafide (5-nitro group in the aromatic ring) and Amonafide (5-amino group in the aromatic ring) have been shown to possess significant anticancer activities. Both Mitonafide [3,4] and Amonafide [5,6] have undergone Phase I-II clinical trials with limited success. We have recently reported appreciable antitumor activity of some new compounds belonging to N-(2-chloroethyl)and N-(3-chloropropyl) naphthalimides [7]. From the literature search, it was found that there was no report, to our knowledge, that describes the anticancer potential of known N-(2-hydroxyethyl) and N-(3-hydroxypropyl) naphthalimides (compounds 1a-j). Hence we have undertaken the present study of evaluating their potency. In this report we have documented the findings that shows that 6-nitro-2-(3-hydroxypropyl)-1H-benz[de]isoquinoline-1,3-dione (compound 1i) is the most active member in the series.",1
7,2,"A total number of ten substituted 2-(2-hydroxyethyl)and 2-(3-hydroxypropyl)-1H-benz[de]isoquinoline-1,3diones (compounds 1a-j) (Figure 1) were prepared following established procedure. Out of these ten compounds, test compound 1i [8] was most extensively investigated. Mitonafide was received earlier as a gift from Prof. M.F. Brana, University of San Pablo-CEU, Madrid, Spain. Anticancer drugs, propidium iodide and annexin V-FITC detection kit (A2214) were procured from Sigma-Aldrich Corporation, St. Louis, MO, USA.",1
7,3,"The following human tumor cell lines namely Leukemia: acute lymphoblastic MOLT-4, promyelocytic HL-60; Lymphoma: histiocytic U-937; Breast: MCF-7; Neuroblastoma: IMR-32, SK-N-SH; Colon: 502713, COLO205, HCT-15, SW-620; Liver: Hep-2; Prostate: DU-145, PC-3 and Lung: A549 obtained either from National Centre of Cell Science (NCCS), Pune, India or National Cancer Institute, Fredrick, MD, USA were used. Cell lines were grown in tissue culture flasks in RPMI-1640 medium with 2 mM glutamine (Invitrogen Corporation, USA) containing 1% antibiotics (100 units penicillin/ml and 100 μg streptomycin/ml, Cambrex Bioscience Inc., USA), pH 7.4, sterilized by filtration and supplemented with 10% heat-inactivated fetal bovine serum (FBS, Invitrogen Corporation, USA) at 37°C in an atmosphere of 5% CO2/95% relative humidity in a CO2 incubator and routinely sub-cultured. Trypsin (0.02%) was used for dislodging adherent type cells.",1
7,4,"All the test compounds 1a-j were initially screened against U-937 and HL-60 cell lines by MTT assay as per standard procedure [9]. Compounds 1d and 1i were also screened in MOLT-4 (Table 1). Drug stock solutions (20 mg/ml) were prepared in cell culture DMSO. These were serially diluted with complete growth medium stated above to obtain different drug concentrations [final DMSO concentration was 0.5% highest to 0.001% lowest]. Cells were seeded at 1 × 10 4 (U-937), 2 × 10 4 (HL-60) or 1 × 10 5 (MOLT-4) per well in 96-well cell culture plates and incubated with respective drug solutions of different concentrations for 96 hr and processed. All vehicle controls contained same concentration of DMSO. The plate was read in a microplate reader at 540 nm. Curvefit software was used to calculate the IC 50 values. IC50 value < 10 μM is considered as active as per National Cancer Institute (NCI), USA, protocol.",1
7,5,"Cytotoxicities of test compounds 1d and 1i were further evaluated against 11 other human tumor cell lines by SRB assay method [10] as stated in Table 2. Growth inhibition value 50% or more at 1 × 10 -5M is considered as active. Established anticancer drugs such as doxorubicin, 5-FU, cis-platin, BCNU, hydroxyurea, paclitaxel and mitomycin C were used in parallel for comparison as indicated in the respective Table 1 and 2.",1
7,6,"PBMC was isolated from heparinized venous blood obtained from healthy human volunteer by Ficoll-Paque (Histopaque 1077, Sigma-Aldrich Corporation, St. Louis, MO, USA.) density gradient centrifugation as per standard procedure [11]. PBMC (1 × 105 cells/well) were cultured in complete RPMI-1640 media as usual and incubated with compounds 1d and 1i for 48 hr followed by MTT assay. IC50 values were calculated using Curvefit software.",1
7,7,"The effect of compound 1i on different phases of cell cycle of MOLT-4 was explored by flow cytometry [12]. In brief, 1 × 10 6 MOLT-4 cells were incubated with compound 1i (10.0 and 16.7 μM) for 24 hr and camptothecin (5 μM) for 3 hr. The cells were next washed twice with ice-cold phosphate buffered saline (PBS), harvested, fixed with ice-cold PBS in 70% ethanol, and stored at -20°C for 30 min. After fixation, the cells were incubated with RNase A (Sigma-Aldrich Corporation, St. Louis, MO, USA, 0.1 mg/ml) at 37°C for 30 min, stained with propidium iodide (Sigma-Aldrich Corporation, St. Louis, MO, USA, 50 μg/ml) for 30 min on ice in dark and analyzed for DNA content using BD-LSR Flow cytometer (Becton Dickinson, USA). Data were collected in list mode on 10,000 events and analyzed using Mod Fit 2.0 software (Figure 2).",1
7,8,"Annexin V-FITC/PI double staining method was followed [13] for the assay in MOLT-4 cells (1 × 106/well, 6-well plate) after incubation of the cells with 10.0 and 16.7 μM of compound 1i and 5 μM of camptothecin for 6 hr at 37°C (Figure 3). Similar assay was conducted in HL-60 by using another apoptosis detection kit (BD Biosciences Pharmingen, San Diego, USA). For this, HL-60 cells (5 × 105/well) were treated for 24 hr with compounds 1i, camptothecin and cis-platin (10 μM concentration each). Cells were processed and stained with Annexin V-FITC/PI according to the manufacturer’s instructions and analyzed on a FACScan flow cytometer (Becton Dickinson, USA) using Cell Quest software at two wavelengths 515 and 639 nm. Vehicle (DMSO) treated unstained and stained [annexin V-FITC/PI] cells were used as controls (Figure 4).",1
7,9,"The activities of caspase-3 and caspase-6 in MOLT-4 cells (2 × 106/ml) following incubation with compound 1i (3.3 16.7 μM) and camptothecin (5 μM) for variable periods were measured by using respective colorimetric assay kit (R&D Systems, USA). Blank cell lysate control was also included. Enzyme-catalyzed release of pNA was monitored using a microplate reader at 405 nm (Figure 5A and 5B).",1
7,10,"MOLT-4 cells were incubated with compound 1i (10 μM) in DMSO for different time periods. Control cells received DMSO only (< 0.5%). Treated and control cells were washed in PBS, centrifuged at 1500 rpm for 10 min. Pellets were divided into 1 mm 3 pieces and fixed immediately in 2.5% glutaraldehyde in 0.1 M phosphate buffer (pH 7.2) for 2 hr at 4°C, post-fixed with 1% OsO4 in the same buffer for 2 hr, dehydrated with acetone, cleared in propylene oxide and embedded in Epon812 [14]. Semithin (1 μm) sections were cut, stained with toluidine blue and morphology of treated cells was observed [14] at different times under light microscope [Olympus, Japan]. Photomicrographs were taken with Olympus Digital Camera (C4000) (Figure 6). Ultrathin sections of silver color (60-90 nm) were cut on a LKB ultramicrotome IV, mounted on copper grids and stained with uranyl acetate and lead citrate. The sections were viewed and photographed in a JEOL-100CXII electron microscope at 60 kV (Figure 7).",1
7,11,"S-180 tumor cells maintained in vivo in Swiss albino mice were used for incorporation of 3H-thymidine and 3H-uridine (specific activity 1.0 mCi/ml each, obtained from Board of Radiation and Isotope Technology, Mumbai, India) following treatment with 8 μM concentration of compounds 1d and 1i as described earlier [15]. Mitonafide at the same concentration was used for comparison.",1
7,12,Values were recorded as the mean ± S.E.M. (standard error mean) of three experiments. Experimental results were analyzed by Student’s t-test. P < 0.05 was considered as the level of significance for values obtained for treated groups compared with control group.,1
7,13,"In vitro screening of compounds 1a-j against U-937 and HL-60 revealed that compounds 1a-c, 1e-1h and 1j did not show appreciable activity as their IC50 values were above 10 μM. Compounds 1d and 1i having IC50 values in the range of 0.7 and 6.0 μM in U-937, HL-60 and MOLT-4 were found to be cytotoxic (Table 1). The IC50 values of compounds 1d and 1i were much less than that of doxorubicin, 5-FU, cis-platin, BCNU and hydroxyurea used as standards (Table 1) suggesting greater antitumor properties in compounds 1d and 1i. In view of this, compounds 1d and 1i were selected for further screening in a battery of human tumor cell lines. The results summarized in Table 2 revealed that compound 1d has elicited significant growth inhibition in two (IMR-32 and COLO-205) out of six cell lines used while compound 1i elicited significant growth inhibition in five (SK-N-SH; 502713, SW-620, DU-145 and PC-3) out of ten cell lines tested. It appears that compound 1i is the most active member.",1
7,14,Compounds 1d and 1i showed high IC50 values of 698 and 273 μM respectively against human PBMC in vitro suggesting that these compounds were devoid of significant cytotoxicity against normal cells.,1
7,15,"MOLT-4 cells exposed to 10.0 and 16.7 μM of compound 1i for 24 hr exhibited increase in sub-G1 fraction which may comprise of both apoptotic cells and cell debris implying up-regulation of cell death machinery. The effect was much more for the higher concentration of the compound. For instance, the sub-G1 fractions of control and camptothecin-treated cells were 0.68% and 11.92% respectively whereas the same were 4.69% and 21.02% for compound 1i at the low and high concentrations (Figure 2). This might indicate a dose dependant increase in apoptosis of MOLT-4 cells inflicted by compound 1i. The cell cycle analysis also showed accumulation of treated cells in S and G2/M phases. Increase in S phase fraction could be due to stimulation of DNA synthesis or delay in movement of cells from S to G2/M phase. Concomitant rise in G2 /M fraction indicates delay in exit of daughter cells from the mitotic cycle. Therefore the findings suggest delayed turnover of cells leading to reduction of tumor cell number.",1
7,16,MOLT-4 and HL-60 control and treated cells were stained with annexin V-FITC/PI and gated into LR (Lower Right) and UR (Upper Right) quadrants. Cells in LR and UR were considered as early apoptotic (annexin + /PI - ) and late apoptotic (annexin + /PI + ) respectively. Extent of apoptosis was expressed as the sum total of the percentages in LR and UR quadrants. Cells in LL (Lower Left) and UL (Upper Left) quadrants were considered live and necrotic respectively. Apoptosis induced by compound 1i was compared with that of camptothecin (Figure 3) and camptothecin and cis-platin used as standards (Figure 4). Apoptosis recorded in untreated control MOLT-4 and HL-60 cells were 3.61% and 2.54% respectively.,1
7,17,"In MOLT-4, total apoptosis exhibited by camptothecin at 5 mM concentration was 8.89%. In contrast compound 1i at 10.0 and 16.7 mM concentrations was effective in inducing 27.54% and 30.86% apoptosis respectively. The necrotic cell populations for compound 1i at these doses were 5.15% and 4.80% respectively (Figure 3).",1
7,18,"In HL-60, compound 1i induced 98.62% apoptosis at a dose of 10 μM (LR 3.49%, UR 95.13%). This is in contrast to 15.82% and 7.51% apoptosis respectively induced by camptothecin and cisplatin at the same dose. Thus compound 1i was more effective than standards in inducing apoptosis in HL-60 (Figure 4).",1
7,19,Treatment of MOLT-4 cells with compound 1i was associated with marked increase in caspase-3 as well as caspase-6 activities that confirm the apoptotic mode of cell death. Up-regulation of caspase-3 by compound 1i was maximum at 5.0 μM concentration at 12 hr posttreatment (Figure 5a) while caspase-6 activity was highest also at 5.0 μM concentration at 24 hr post-treatment (Figure 5b). Similar activations were produced by camptothecin at 5.0 μM concentration (Figure 5a-b).,1
7,20,"The morphology of MOLT-4 cells treated with compound 1i at 5 and 10 μM was monitored by light microscopy at different time points. The number of apoptotic cells increased with higher concentration of the compound and longer incubation period. Figure 6b represents the characteristic morphology of apoptotic cells following 36 hr of incubation at 10 μM concentration. Marginalization of chromatin material accompanied by cell shrinkage, nuclear condensation/fragmentation and formation of cytoplasmic vacuoles, considered as hallmark of apoptosis, were clearly visible. Control cells showed large sized nuclei having nucleoli (Figure 6a).",1
7,21,"In transmission electron microscopy, MOLT-4 control cells (Figure 7a-b) exhibited a high nucleocytoplasmic ratio and the nucleus had a finely dispersed chromatin with nuclear pores. The nucleoli were clearly visible in most of the cells. The mitochondria with cristae (MC) in various size and shape (oval and elongated), rough endoplasmic reticulum and ribosomes were seen. MOLT-4 cells treated with 10 μM of compound 1i for 36 h revealed damaged mitochondrial cristae and highly reduced rough endoplasmic reticulum suggesting apoptosis (Figure 7c-f). No inflammatory changes in nuclei and cytoplasm coupled with absence of breakage in plasma membrane ruled out the possibility of necrotic events. Vacuolization was also seen in treated cells. Literature survey also revealed similar observations [16,17].",1
7,22,"Since compound 1d and 1i have structural similarity with mitonafide, studies were conducted to ascertain whether drug-induced tumor growth inhibition was also due to the inhibitory effect of these compounds on nucleic acid synthesis. Accordingly 3H-thymidine and 3H-uridine incorporation by S-180 cells collected from untreated tumor bearing mice was measured after treating the tumor cells in vitro. The untreated S-180 cells demonstrated an almost linear pattern of 3H-thymidine and 3H-uridine incorporation over a period of 60 min. Exposure of tumor cells to test compounds at the concentration of 8 μM resulted in gradual and marked inhibition of 3 H-thymidine and 3 H-uridine incorporation comparable to that of mitonafide at the same concentration (8 μM). After 1 hr of incubation with compound 1d and 1i 3H-thymidine incorporation was declined by 96% and 95% respectively against 95% reduction by mitonafide exposure. Thus the compounds showed remarkable inhibitory effect on DNA synthesis. Inhibition of RNA synthesis, in contrast was less spectacular as inhibition of 3 H-uridine was 92%, 94% and 89% for mitonafide, compound 1d and 1i respectively (Figure 8).",1
7,23,"The nature and position of a substituent in a molecule are known to play important roles in deciding its antitumor property. The present study has shown that out of the five different substituents (R = H, 6-Br, 6-Cl, 6-NO2, 5-NO2) present in the aromatic ring portion of substituted N-(hydroxyalkyl)naphthalimide moiety, the 6-NO2 substituent is crucial in exercising the antitumor activity. This is in agreement with our earlier finding in other (chloroalkyl) naphthalimide compounds wherein we found 6-nitro-2-(3-chloropropyl) naphthalimide as the most active antitumor agent in that series [7].",1
7,24,"Compound 1i that showed most pronounced antitumor activity interfered with S and G2/M phases of cell cycle of MOLT-4 cells. As a preparatory step towards cell division, a cell duplicates its DNA in S phase of cell cycle. Thus, interference of S phase by compound 1i as observed in flow cytometric measurements, suggests that it affects DNA duplication process of tumor cell before mitosis. This possibility was confirmed in S-180 cells in which compound 1i inhibited 3 H-thymidine incorporation into DNA, implying suppression of DNA synthesis. Moreover, it inhibited 3H-uridine uptake, indicating concomitant inhibition of RNA synthesis. Taken together, the results suggest that inhibition of DNA and RNA might have played a role in mediating the antitumor effect of compound 1i.",1
7,25,"Delay in exit from G2/M, the final phase of cell cycle, was another flow cytometric observation in compound 1i treated MOLT-4 cells. A situation like this develops when there is defect in DNA damage repair, spindle attachment with centromeres and polymerization of spindle microtubules [18]. In view of these reports, it appears that the compound has adverse effect on the mitotic apparatus causing up-regulation of the spindle checkpoint control leading to delayed mitotic exit of daughter cells. It is known that vinca alkaloids [19] and paclitaxel [20] mediate their antitumor effects by interfering with spindle microtubules. Compound 1i may act in a similar fashion like them.",1
7,26,"Induction of apoptosis or programmed cell death is a common mechanistic pathway of several antitumor agents [21]. Compound 1i has exerted its antitumor action by this pathway as well. This is evident from sharp rise in sub-G1 fraction, light and electron microscopic studies showing morphological imprints of apoptosis and marked increase in caspase 3 and 6 in treated cells. Apoptosis is controlled by a diverse range of cell signals which may originate intracellularly via the mitochondria or extracellularly via death receptors on cell membranes. These two pathways of signals converge and form a common irreversible execution phase mediated by caspase 3 and 6. Whether the pro-apoptotic signal elicited by compound 1i followed the intrinsic (mitochondrial) or extrinsic (death receptor) pathway is not clearly understood. However, extensive damage of mitochondrial cristae in treated cells, as observed in ultrastructural study, favours mitochondrial pathway. Like the present finding, induction of apoptosis by many naphthalimides including amonafide and amonafide analogs has been reported [22,23].",1
7,27,"In essence, the present study demonstrated significant antitumor activity by compound 1i against murine S-180 tumor cells and a panel of human tumor cell lines in vitro and the effect was mediated by inhibition of cell proliferation and up-regulation of programmed cell death. Since the compound did not elicit any cytotoxicity against normal human PBMC, it holds promise for further development as a potential antitumor agent.",1
8,1,"Erlotinib, one of the epidermal growth factor receptor (EGFR) tyrosine kinase inhibitors (TKIs), is active and relatively well tolerated in chemotherapy-naïve elderly patients with advanced non-small cell lung cancer (NSCLC) [1]. Image-guided stereotactic body radiotherapy (SBRT) and helical tomotherapy (HT) using hypofractionation in patients with early-stage medically inoperable NSCLC is feasible and well tolerated [2]. For stage III NSCLC, hypofractionation yields equivalent survival rates, but without often fatal symptomatic pneumonitis, compared to conventional radiotherapy [3]. The addition of standard-dose erlotinib to chemoradiotherapy is feasible, without an increase in toxicity [4]. Little information is available on fatal pulmonary toxicity due to irradiation pneumonitis when erlotinib is concurrently given with SBRT and used thereafter as maintenance therapy for NSCLC.",1
8,2,"A 77-year-old man was diagnosed with NSCLC, cT2N2M0, stage III A. Chest computed tomography (CT) showed a soft tissue mass measuring 4 × 3.9 cm in the right upper lung, with mediastinal lymphadenopathy. Carcinoembryonic antigen (CEA) was also elevated to 12.9 mg/dl. The Patient received oral erlotinib 150 mg/day as the first line therapy. Three months later, the CEA increased from 12.9 ng/ml to 29.1 ng/ml. Then, erlotinib was added concurrently to the radiotherapy regimen. This regimen comprised 54 Gy given in nine fractions delivered with SBRT using HT, at 95% of the prescribed isodose for the planned target volume. The split courses with 3 fractions per week were prescribed. (Figure 1 and 2) Targeting was based on new, separate CT scans for each split course.",1
8,3,"The tumor volume (ml) vs. the right lung volume was 116.1 ml vs. 1282.9 ml in the first treatment course and 90.9 ml vs. 1475.9 ml in the second treatment course. The mean lung dose, V15, and V20, where Vx was the percentage of lung volume that received at least × Gy [5] for separate lung images, is shown Table 1. The whole-course V20 and mean lung dose for the total lung were 10% and 10.24 Gy, respectively. By 2.5 months after the combination therapy, the tumor shrank from 4 × 3.9 × 4.5 cm to 2.4 × 2.9 × 2.1 cm and erlotinib 150 mg/day was prescribed as maintenance therapy. Unfortunately, the patient developed dyspnea three months after the combination therapy. He was transferred to the medical intensive care unit. In a series of image studies, opacities of a diffuse ground-glass pattern, subpleural bleb formation in the marginal areas, airspace consolidation and fibrosis in bilateral whole lung fields were noted, and radiation pneumonitis was suspected (Figure 3, 4, 5, 6) [6,7]. The patient received empirical antibiotics, steroid therapy, antioxidant, and supportive treatment. Four more months after the combined therapy, the patient died of respiratory failure.",1
8,4,"Image-guided SBRT with HT using hypofractionation in patients with early-stage medically inoperable NSCLC is feasible [2]. The hypofractionated scheme yields equivalent survival rates, without fatal, symptomatic pneumonitis for patients with stage III NSCLC when compared with conventional radiotherapy [3]. Belderbos et al. [8] reported that radiation dose escalation was safe up to 94.5 Gy in 42 fractions with a mean lung dose 13.6 Gy or less in 6 weeks in NSCLC patients. The patients underwent irradiation 5 days per week, and twice daily when more than 30 fractions were prescribed, with at least a 6-h interval in between each fraction. According to linear-quadratic (LQ) modeling [9], the biologic effect of 94.5 Gy/42 fractions converted to a hypofractional dose of 6 Gy per fraction (EQD6), for which the acute effects and late normal tissue effects would be equivalent to 72 and 54 Gy, respectively. The mean lung dose (≥ 21 Gy), V20 (> 31%) [10], and ipsilateral V20 Gy [5] correlates with radiation pneumonitis. Nonetheless, the Radiation Therapy Oncology Group 0236 protocol using SBRT via HT for NSCLC provided safe and effective treatment when the V20 was restricted to less than 10% to 15% [11]. The V15, V20, and mean lung dose for each separate lung by divided course are shown in the Table.",1
8,5,"Erlotinib, an EGFR TKI, is an effective anti-tumor agent for treatment of NSCLC among elderly patients [1]. Erlotinib could be used as a single agent in select subsets of patients with advanced NSCLC [12]. In a comparative trial, only 0.8% of patients developed interstitial lung disease in the erlotinib arm [13]. Moreover, addition of standard-dose erlotinib to chemoradiotherapy was feasible and without evidence of increased toxicities [4]. However, prior tissue injury from radiation therapy could lead to cells with altered responses when the drug is subsequently applied [14]. Erlotinib enhanced radiation responses including cell cycle arrest, apoptosis induction, accelerated cellular repopulation, and DNA damage repair [15]. Therefore, it is possible for erlotinib to induce an altered response in cells when erlotinib is applied after irradiation.",1
8,6,"Though SBRT applied by HT allows for minimization of normal tissue exposure to high radiation doses [16], the large amount of low-dose irradiation to non-target organs at risk (OAR), and thus, the incidence of lung toxicity can become high [17]. Recently, non-target OARs were impacted by arc therapy due to the low dose bath phenomenon and these effects could be magnified by agents known or unknown to be associated with recall effects [18]. Irradiation modulates the anticancer drug’s pharmacokinetics even under low doses and in off-target areas [19]. Additionally, combined low-dose radiation and erlotinib induced symptomatic pneumonitis in one NSCLC patient [20]. Another NSCLC patient developed radiation recall dermatitis induced by erlotinib [21]. According to these reports, we believe EGFR inhibitor might not only enhance the effects of radiation, but also might enhance the adverse effects of radiation, especially when prescribed following previous concurrent treatment with radition. Furthermore, radiation modulates the systemic efficts of drugs regardless of the treatment effects or side effects. Erlotinib appears to modulate the effects of irradiation, both good and bad.",1
8,7,"To our best knowledge, this is the first report of radiation pneumonitis caused by erlotinib combined with image-guided SBRT via HT with hypofractionation followed by erlotinib presecribed for maintenance. Oncologists should be alert to the potential risk of fatal pulmonary toxicity caused by this multimodality treatment. Radiotherapy plus targeting agents must be conducted in well-designed clinical trials.",1
8,8,Written informed consent was obtained from the patient’s family for publication of this case report and the accompanying images. A copy of the written consent is available for review by the Editor-in-Chief of the journal.,1
9,1,"Classical swine fever virus (CSFV) is a small, enveloped, positive-stranded RNA virus that causes classical swine fever (CSF), a highly contagious disease of swine and wild boars [1]. CSFV belongs to the genus Pestivirus of the family Flaviviridae. The genus also includes bovine viral diarrhea virus and border disease virus which are important livestock pathogens [2,3]. CSF viruses can be divided into three major groups with ten subgroups by genetic typing [4]. Recent phylogenetic analyses indicated that there has been a switch in the virus population from the historical group 1 or 3 to the recent group 2 in many European and Asian countries [4-9]. Noteworthy, all live-attenuated vaccine strains used in different countries belong to group 1 [4], including the subgroup 1.1 Chinese lapinized vaccine strain (C-strain) which was derived by serial passage of a virulent strain in rabbits. The C-strain has been used for prophylactic vaccination in China since 1954. Two independent studies also reported that subgroup 2.1 strains recently branched away from the vaccine C-strain and became dominant in China [10,11].",1
9,2,"E2 is the major envelope glycoprotein exposed on the surface of the virion. It is essential for virus attachment and entry into the host cells as well as cell tropism [12,13]. This glycoprotein has been implicated as one of the virulence determinants [14,15]. In addition, it can induce neutralizing antibodies and confer protective immunity in pigs [16-21]. The antigenic structure of E2 has been identified using a number of monoclonal antibodies (mAbs). Two independent antigenic units, B/C and A/D (residues 690-800 and 766-865, respectively) have been identified in the N-terminal half of E2 [22,23]. In this context, deletion of the C-terminal half did not affect antibody binding [22-24], and the first six conserved cysteine residues as well as the antigenic motif 771LLFD774 are important for the antigenic structure of E2 [22,25].",1
9,3,"Genetic diversity of E2 among different groups has been extensively studied [4,10,26-29]. The N-terminal half of E2 is more variable than the C-terminal half [10], suggesting that the antigenic units could be under positive selection apparently due to constant exposure to high immunologic pressure. Different patterns of reactivity with mAbs provided clues of antigenic variation of E2 among different CSFV isolates [11,25,30-33]. A study using neutralizing mAbs to select mAb-resistant mutants showed that, in most cases, single point mutations could lead to complete loss of mAbs binding [22]. Furthermore, amino acid (aa) substitutions at position 710 on the E2 proteins of different strains affected binding and neutralization by a panel of mAbs [34]. Single amino acid exchanges between a group 1 vaccine strain LPC and a group 3 field isolate could totally reverse the mAbs binding pattern [35]. Taken together, variability by one or more amino acids within antigenic units may result in the antigenic variation of E2. To our knowledge, all studies that attempted to resolve antigenic variation of glycoprotein E2 utilized mouse mAbs [11,25,30-35]. No attempt has been made to probe the antigenic variation or group-specific antigenic determinants using anti-CSFV sera from pig, the natural host of CSFV.",1
9,4,"In this study, we raised pig antisera against CSFV vaccine C-strain and a representative subgroup 2.1 strain QZ-07 to assess the extent of antigenic variation within antigenic units of glycoprotein E2. Rabbit polyclonal and mouse monoclonal antibodies were raised against recombinant E2 (rE2) protein from C-strain to evaluate if antigenic variation of E2 results in differences in cross-neutralization. A series of variant C-strain rE2 proteins with single substitutions based on amino acid differences between the C-strain and group 2 isolates were used to define residues involved in antigenic variation of E2.",1
9,5,"The use of prokaryotic-derived truncated rE2 proteins has been applied in antigen production, antigenic domain identification and epitope mapping [24,36-40]. In this study, two types of truncated rE2 proteins were expressed in E. coli Rosetta (DE3) cells (Figure 1A and Table 1). One protein, rE2-BC (aa 690-814), covered the N-terminal 123 residues which are considered to constitute the minimal antigenic domain required for binding to pig anti-CSFV serum [24]. The other protein, rE2-AD (aa 690-865), contained both antigenic units B/C and A/D [22,23]. Western blotting indicated that rE2-BC and rE2-AD proteins of the vaccine C-strain had the molecular weights of 20 and 25 kDa, respectively, and reacted strongly with pig anti-C-strain hyperimmune serum (Figure 1B). Therefore, the prokaryotic-derived rE2 proteins were suitable for use as immunogens to generate polyclonal and monoclonal antibodies as well as for the antibody binding assessments.",1
9,6,"To assess the antigenic variation of E2 between the subgroup 1.1 C-strain and subgroup 2.1 field isolates, the respective rE2-AD proteins were cross-examined by ELISA with antisera collected from pigs at different time points after immunization with the vaccine C-strain or infection with strain QZ-07 (representing subgroup 2.1). Figure 2 shows that each antiserum reacted much more strongly with rE2-AD protein of the homologous strain (used to prepare the serum) than that of the heterologous strain. Figure 3 further compares binding efficiency of anti-C-strain and anti-QZ-07 sera (collected at 78 days post immunization with the C-strain and 25 days post infection with strain QZ-07, respectively) to rE2AD proteins derived from C-strain and 8 subgroup 2.1 strains. The homologous binding efficiency was set at 100%. The anti-C-strain serum exhibited significantly low efficiency of binding to subgroup 2.1 rE2-AD proteins (below 60% efficiency). Binding of anti-Q7-07 serum to the C-strain rE2-AD protein was even more inefficient (below 20% efficiency), and the band was barely visible on the blot. Binding of anti-QZ-07 serum to heterologous subgroup 2.1 proteins was varied.",1
9,7,"A two-way neutralization analysis using the pig antiCSFV sera revealed that heterologous neutralization was less effective, especially with sera collected at the early days following vaccination or infection (Figure 4). Interestingly, neutralization efficiency also differed between subgroup 2.1 strains QZ-07 and HZ1-08. Since strain variation influences the ability of antisera to neutralize heterologous viruses, and inefficient binding of antisera to heterologous rE2-AD proteins was also observed (Figure 3), we sought to determine whether variation of glycoprotein E2 affects CSFV cross-neutralization. Thus, we raised a rabbit antiserum (polyclonal antibodies) and three monoclonal antibodies (mAbs) against C-strain rE2-AD protein. The rabbit antiserum neutralized the QZ-07 virus less efficiently (log10 1.8) than the C-strain (log10 2.1). Furthermore, substitution of cysteine residues in the antigenic unit B/C with serine residues abolished the reactivity of mAbs 1E7 and 6B8 to E2. However, such mutagenesis did not affect the reactivity of mAb 2B6 (Table 2). These results indicate that these cysteine residues are involved in the structural conformation of E2 [22,23] and that mAbs 1E7 and 6B8 bind to conformational epitopes. In addition, mAb 2B6 only bound to C-strain although its neutralization efficiency was low.",1
9,8,"To determine the amino acid residues responsible for the observed antigenic variation, E2 sequences of 108 CSFV strains representative of each group were obtained from GenBank and aligned. Twenty major variable residues were identified within the antigenic units. Table 3 shows the variability of these residues between vaccine strains and representative group 2 strains.",1
9,9,"We used site-directed mutagenesis to systematically substitute amino acids in C-strain E2 protein with those found at the same positions in subgroup 2.1 proteins (Table 3 - 2nd last row). The binding of the wild type and variant C-strain rE2 proteins to C-strain and strain QZ-07 antisera was determined by binding ELISA. Wells of plates were coated with equal quantities of proteins and the antibodies were above saturation levels to ensure that antibody concentration was not limiting. The binding of the wt C-strain rE2 protein to either of the sera was set at 100%. None of the substitutions changed the binding of the variant rE2 proteins to antiC-strain serum significantly (binding efficiency was between 80%-130%), suggesting that these residues did not contribute individually to the overall capacity of Cstrain rE2 protein to bind the antibodies (Figure 5A). However, thirteen substitutions increased binding of the variant C-strain rE2 proteins to anti-QZ-07 serum (i.e., above 150% binding efficiency threshold). Substitution of D705N, L709P, G713E, N723S, or S779A caused a significant increase in binding efficiency (i.e., above 200% threshold), while a moderate increase was observed with D725G, N729D, N777S, T780I, D847E, M854V, T860I, or N863K substitution (between 150% and 200% efficiency).",1
9,10,"The residues that caused significant or moderate increase of binding efficiency formed three distinct clusters in the antigenic units (Figure 1A). The first cluster is located in the N-terminus of antigenic unit B/C at the amino acid positions 702-731. The second cluster is at the boundary between the two antigenic units at positions 774-799 and the third one is in the C-terminus of antigenic unit A/D at positions 841-864. Interestingly, hydrophilicity analysis further demonstrated that these regions contribute to major hydrophilic differences between CSFV C-strain and strain QZ-07 (Figure 5C).",1
9,11,"To get more insight into antigenic and genetic evolution of the antigenic units, the diversity of codon and amino acid was analyzed by a variant Simpson’s index [41]. Figure 6 shows that the thirteen residues associated with antigenic variation (Figure 5 and Table 3) lie along the diagonal (x = y), indicating that these residues are highly diversified due to accumulation of large numbers of nonsynonymous mutations in their codons. In contrast, the six cysteine residues and residues in the 771LLFD774 motif [25] lie along the x axis due to high conservation even though their codons have accumulated a moderate number of synonymous mutations. However, the antigenic residues identified by mAb-resistant mutants analysis [22] were mapped as having random distribution (Figure 6).",1
9,12,"Phylogenetically, CSFV consists of three major groups [4]. Recent studies revealed that viral populations have shifted from the historical group 1 or 3 to group 2 in most European and Asian countries [4-10]. Glycoprotein E2 is a principal target of neutralizing antibodies and an important protective immunogen [16-21]. The E2 glycoproteins of three groups are genetically and antigenically different [4,10,11,25-35]. However, the basis of this antigenic variation has not been clearly demonstrated at the molecular level.",1
9,13,"Our data show that both pig anti-C-strain and anti-QZ07 sera bound heterologous rE2-AD proteins (from CSFV strain QZ-07 and C-strain, respectively) with <60% efficiency compared to homologous proteins (Figure 3A), indicating that these proteins are antigenically different. Further, the E2 protein of vaccine C-strain is antigenically distinct from those of a wide spectrum of subgroup 2.1 strains. Antigenic variation was also detected among subgroup 2.1 strains as indicated by the inefficiency of pig anti-QZ-07 serum to bind HZ1-08- and QZ2-06-derived rE2-AD proteins (Figure 3). Our data further demonstrate that the previously reported differences in antigenicity detected by mouse mAbs [11,25,30-35] also occur in the context of pig anti-CSFV sera.",1
9,14,"We performed neutralization experiments to assess whether the differences in the efficiency of antibody binding to rE2 proteins (Figure 3) correlate with the ability of the antibody to block CSFV infection. A two-way neutralization determination showed that pig anti-CSFV sera neutralized heterologous strains less efficiently (Figure 4). Rabbit polyclonal antibodies against purified C-strain rE2-AD protein also showed less efficiency at neutralizing strain QZ-07. Furthermore, two conformational anti-C-strain-rE2-AD mAbs (1E7 and 6B8) had lower binding and neutralization efficiency against the heterologous strains compared to C-strain (Table 2), suggesting that the neutralization differences seen with pig anti-CSFV sera were, at least in part, due to differential expression of antigenic epitopes on the E2 glycoproteins of CSFV strains. Such antigenic variation may explain why subgroup 2.1 CSFV strains persist in China despite the wide use of vaccine C-strain. Antibody selection may be one of the reasons for the switch of viral populations from group 1 to 2.",1
9,15,"We used site-directed mutagenesis to introduce amino acid substitutions in the C-strain rE2 proteins in order to probe whether variable residues (Table 3) contribute to the antigenic variation seen with subgroup 2.1 strains. Unlike the mutations in the antigenic motif 771LLFD774 that disrupted the structural integrity of E2 protein [25], none of the substitutions had a significant effect on binding to anti-C-strain serum (Figure 5A). We infer that the recombinant proteins were not grossly misfolded and the substituted residues may not be critical for the overall structural stability of glycoprotein E2. In contrast, of the 20 substitutions, 13 enhanced binding of the variant C-strain rE2 proteins to anti-QZ-07 serum (Figure 5A). The most dramatic increase in binding was caused by the GtoE substitution at aa position 713 (Figure 5A and 5B). Sequence alignment revealed that all group 2 strains have residue 713E, while all the vaccine strains have 713G (Table 3). Chang et al. recently reported that residues 713 E and 729 D were critical for specificity of a group 3.4 field strain rE2 protein to mAbs [35]. It appears that 713E is a common antigenic determinant for both groups 2 and 3.",1
9,16,"Our work demonstrates that although residue 729D enhanced binding to pig anti-QZ-07 serum, residues 705N, 709P, 723S, and 779A had much more significant contribution (Figure 5A). Notably, the same residues are found at positions 705 and 723 on E2 proteins of subgroup 2.1 and subgroup 3.4 strains. It is possible that these two residues may also show superior contribution to the antigenicity of subgroup 3.4 glycoprotein E2 if probed with pig antisera against group 3 strains. In this study, we used polyclonal sera from pigs C-strain-immunized or infected with a field strain which contained the full spectrum of immunization- or infection-induced antibodies. This is why these polyclonal sera could identify more residues responsible for antigenic variation of glycoprotein E2 than mouse mAbs [35]. Furthermore, pairing of the polyclonal antisera against the group 1 C-strain and representative group 2 field strain could probe the residues that mediate antigenic variation between the two groups, another advantage over mAbs.",1
9,17,"Based on the data revealed by the site-directed mutagenesis analysis (Figure 5A), the antigenic variation among subgroup 2.1 strains is not unexpected since each of the 8 subgroup 2.1 strains used in this study has some unique strain-specific substitutions (data not shown). The C737R substitution in the antigenic units of strain QZ2-06 appears to affect binding the most. This can be explained by the fact that the cysteine residue at this position is critical for the antigenic structure of the protein [22]. We speculate that E782V substitution in strain HZ1-08 is the key determinant of antigenic variation between strain HZ1-08 and our reference subgroup 2.1 strain QZ-07.",1
9,18,"Three discrete antigenic regions were mapped at aa positions 702-731, 774-799 and 841-864, in the antigenic units of E2 protein (Figure 1A). Several antigenic residues identified by mAb-resistant mutants analysis [22] or epitope mapping [35] and substitutions with significant increase in binding of variant rE2 proteins to anti-QZ-07 serum examined in this study are clustered in the 702-731 region (Figure 5A), implying that evolution of this region is the primary cause of antigenic variation of glycoprotein E2. The N-terminus of antigenic region 774-799 contains the conserved antigenic motif 771LLFD774 [25] and a conserved linear 772LFDGTNP778 epitope [39], suggesting its essential role in maintaining the integrity of antigenic structure of E2 protein. In addition, the substitutions of N777S, S779A, and T780I in this region enhanced binding of variant rE2 proteins to anti-QZ-07 serum (Figure 5A). Therefore, region 774-799 may have multiple functions in shaping the antigenicity of E2.",1
9,19,"Finally, we analyzed E2 sequences of CSFV in order to compare codon and amino acid diversification in relation to antigenic evolution. We employed a variant Simpson’s index that has been used to quantify codon and amino acid diversity in the antigenic epitopes of influenza virus hemagglutinin glycoprotein [41,42]. The diversity of each of the thirteen amino acid residues involved in antigenic variation is equivalent to that of the corresponding codon (Figure 6: the unique distribution along the x = y diagonal), indicating a remarkable correlation between genetic and antigenic evolution within the antigenic units of glycoprotein E2 in nature. In contrast, the antigenic residues identified by mAbresistant mutants analysis [22] are randomly diversified (Figure 6: randomly distributed grey-colored residues), suggesting that in vitro selection may not explain natural selection in pig. Co-diversification of codons and amino acids involved in antigenic variation in the field strains could be one of the immune evasion mechanisms that CSFV employs under immune pressure as a result of extensive vaccination [43].",1
9,20,"This study demonstrates antigenic variation of CSFV glycoprotein E2 between the vaccine C-strain and group 2 field strains or even within group 2 strains currently circulating in China. Of the three discrete regions associated with antigenic variation, substitutions in the first region (aa 702-731) are the primary determinants of the antigenic variation of E2. Since glycoprotein E2 variation affects CSFV cross-neutralization, subsequent work will determine whether these antigenic residues contribute to the observed neutralization differences. Our findings may provide useful information for the development of differential serological assays and novel CSF vaccines with improved immunogenicity and efficacy.",1
9,21,"Swine testicle (ST) cells were grown in Minimum Essential Medium (MEM, Gibco, USA) supplemented with 10% fetal bovine serum (FBS). The following CSFV strains were used: the subgroup 1.1 vaccine C-strain widely used for prophylactic vaccination in China and two subgroup 2.1 strains recently circulating in China (strains QZ-07 and HZ1-08). CSFV vaccine C-strain was obtained from Zhejiang Jianliang Biological Engineering Company (Zhejiang province, China). Two subgroup 2.1 strains were originally isolated from spleens of naturally infected pigs and replicated in ST cells in our laboratory. These three viruses were propagated and titrated in ST cells. Stocks were aliquoted and stored at -80°C until use. The virus stocks were sequenced to confirm that the E2 genes had the expected sequences. The other 6 subgroup 2.1 strains were not isolated and only their E2 genes were directly cloned in plasmids. Sequence data is available in GenBank as listed in Table 3. Details of their molecular phylogenetic relationships have been described elsewhere [10,26].",1
9,22,"All E2 sequences covering the complete antigenic region were retrieved from NCBI database. The nucleotide and amino acid sequences were aligned using Clustal X software (version 1.83). Sequences with 100% nucleotide identity were excluded. The remaining sequences included 23, 82 and 3 sequences representing groups 1, 2 and 3, respectively. This dataset was used to identify the major variable residues (see Table 3) and to analyze the codon and amino acid diversity (Figure 6).",1
9,23,"The plasmids containing full-length E2 gene of the vaccine C-strain and eight subgroup 2.1 strains used in this study were previously described [10,26]. The C-strain specific primer sets C-E2-AD-f/C-E2-AD-r and C-E2BC-f/C-E2-BC-r were used to amplify the fragment covering the two antigenic units (B/C+A/D) and the fragment only containing antigenic unit B/C, respectively. Primer set QZ-E2-AD-f/QZ-E2-AD-r was used to amplify the fragments covering the two antigenic units of group 2 isolates (Table 1). PCR amplicons were digested with restriction enzymes BamHI and XhoI, gel purified and ligated into prokaryotic expression vector pET-30a(+). To construct the eukaryotic expression plasmid, a 1212-bp cDNA fragment encoding the signal sequence and full-length E2 of C-strain was amplified with primer set C-E2-f and C-E2-r (Table 1), and cloned into pcDNA3.1 following BamHI and XhoI digestion.",1
9,24,"E. coli Rosetta (DE3) cells containing different recombinant plasmids were cultured to an optical density (OD) between 0.6 and 0.8 at 600 nm. Expression of His-tagged rE2 proteins was induced with 1 mM isopropyl-b-D-thiogalactoside (IPTG, Sigma-Aldrich). Cells were harvested and disrupted by sonication. After centrifugation, the inclusion bodies with rE2 proteins were resuspended with 1/10 volume of buffer (100 mM NaH2PO4·2H2O, 10 mM Tris-base, and 8 M Urea). The supernatant was collected after centrifugation and purified by Ni-NTA affinity column (Novagen, Madison, WI) according to the manufacturer’s protocol. Finally, the proteins were refolded by washing the column with 40 ml of Tris-buffered saline (TBS, pH 7.4) containing 1 M urea and eluted from the column with 200 mM imidazole in TBS. The purified rE2 proteins were confirmed by Western blotting with mouse monoclonal anti-His-tag antibody (Sigma-Aldrich) and quantified by the Bradford assay.",1
9,25,"The pig hyperimmune serum against CSFV vaccine Cstrain was previously prepared and stocked in our laboratory. The pig antiserum to the C-strain (pig antiC-strain) or to the strain QZ-07 (pig anti-QZ-07) was induced by intramuscular immunization of 30-day-old CSFV-free pigs with the attenuated vaccine C-strain by prime-boost strategy or infection with 10 5 TCID50 of strain QZ-07 in a biosafety level III facility, respectively. The sera were collected at different times post-vaccination or infection and stored at -80°C until use. The sera at highest titers collected at 78 days post immunization with the C-strain and 25 days post infection with strain QZ-07 (see Figure 2) were used for binding ELISAs in Figure 3A and Figure 5A and Western blots in Figure 3B and Figure 5B.",1
9,26,The rabbit antiserum to the rE2-AD protein of C-strain was generated as follows: New Zealand white rabbits were immunized and boosted two times with 0.5 mg of the purified rE2-AD protein of C-strain (expressed in E. coli) emulsified with an equal volume of complete/incomplete Freund’s adjuvant (Sigma-Aldrich). Blood was drawn for antiserum preparation once maximum level of antibody production was reached.,1
9,27,"For monoclonal antibodies against the rE2-AD protein of C-strain, four 5-week-old female specific-pathogenfree BALB/c mice were immunized subcutaneously with 0.1 mg of the purified rE2-AD protein of vaccine C-strain emulsified in complete Freund’s adjuvant. The mice were intraperitoneally boosted twice with rE2-AD protein emulsified in incomplete Freund’s adjuvant at 2-week intervals. The mice were euthanized 2 weeks after the last boosting and spleen cells were harvested. Splenocytes were fused with SP2/0 myeloma cells using 50% (v/v) polyethylene glycol (PEG, Sigma-Aldrich). The resulting hybridomas secreting antibodies against rE2AD protein were selected by immunofluorescence assay (IFA), and then clonally expanded. Antibody subtyping was performed using mouse mAb Isotyping Reagents (Sigma-Aldrich) according to the manufacturer’s instructions. Ascites were produced in pristine-primed BALB/c mice. Experiments with animals were approved by the Laboratory Animal Management Committee (animal welfare ethics is part of its duties) of Zhejiang University.",1
9,28,"To identify the antigenic units recognized by mAbs, cysteine codons of the C-strain E2 gene in eukaryotic expression plasmid were mutated to serine codons by site-directed mutagenesis as described previously [22].",1
9,29,"Multiple E2 sequence alignment was used to identify variable residues. Twenty major variable residues were identified in the antigenic units (Table 3). These do not include KtoR or StoT substitutions (K720R, K734R, K761R, S797T, and R845K substitutions). To substitute C-strain residues for those found in group 2 isolates, plasmids encoding individual mutations (listed in Table 3) were generated by site-directed mutagenesis. Substitutions were made on plasmids encoding the antigenic unit B/C or two units (B/C+A/D) of C-strain E2 protein depending on where the residue being substituted is located in the antigenic units.",1
9,30,"All substitutions were performed using QuikChange Site-Directed Mutagenesis Kit (Stratagene CA, USA) according to the manufacturer’s instructions. The primers were designed via the QuikChange Primer Design Program http://www.stratagene.com. The desired nucleotide changes in each mutant were verified by sequencing. Expression and purification of variant rE2 proteins was done as mentioned above.",1
9,31,"All ELISAs described in this study were performed in triplicate under stringent conditions to avoid nonspecific reactions. Antibodies were diluted using phosphate-buffered saline (PBS, pH 7.4) containing 5% nonfat dry milk (PBS/NFDM); each washing step included 5 washes with PBS containing 0.5% Tween 20 (PBS/Tween). Briefly, a 100-μl volume of different rE2 proteins (10 μg/ml in 50 mM sodium carbonate buffer, pH 9.6) was added into each well of 96-well microtiter plates (MaxiSorp, Nunc, Denmark) for overnight incubation at 4°C. The wells were washed with PBS/Tween and then blocked with PBS/NFDM at 37°C for 2 h. The wells were washed and incubated with different antibodies for 1 h. The wells were washed again and then incubated with horseradish peroxidase conjugated SPA at 37°C for 1 h. Thereafter, wells were washed and incubated with 100 μl/well of the chromogenic substrate 3,3’,5,5’-tetramethylbenzidine (TMB, Sigma-Aldrich) at 37°C for 4 min. The reaction was stopped by adding 50 μl of 2 M H2SO4 . Finally, the OD450nm was measured using spectraMax @M2 microplate reader (Molecular devices Corp., USA).",1
9,32,"The binding efficiency of rE2-AD proteins from Cstrain and 8 subgroup 2.1 strains with the two pig antisera to the C-strain and strain QZ-07 (Figure 3A) was normalized to anti-His-tag binding first, and then expressed as the ratio of antibody bound to individual group 2 rE2-AD protein to that bound to the rE2-AD proteins of C-strain or strain QZ-07, which was set at 100%. The mean binding efficiency of each individual protein was calculated for three independent ELISA assays.",1
9,33,"For variant C-strain rE2 proteins in Figure 5A, rE2-BC proteins were used for A692S, D705N, E706K, L709P, G713E, N723S, D725G, N729D, S736I, V738T, T745I, N777S, S779A, T780I, R788G, and S789F substitutions because these residues are located in the antigenic unit B/C. rE2-AD proteins were used for D847E, M854V, T860I, and N863K substitutions since these residues are located in the antigenic unit A/D. The results were first normalized to anti-His-tag binding and then expressed as the ratio of their binding to the antibodies to that of binding to C-strain wild type rE2-BC or rE2-AD binding to the reference serum depending on the kind of variant protein being compared. Relative binding of greater than 200% efficiency were designated as significant increases in antibody binding. Binding efficiencies between 150% and 200% efficiency were considered as moderate increases whereas those between 50% and 150% efficiency were considered as limited effect on antibody binding.",1
9,34,"The antigenic reactivity of different rE2 proteins was assessed by Western blotting. The proteins were separated by 15% SDS-PAGE and transferred to nitrocellulose membranes (PALL Corp., USA). The membranes were subsequently blocked (overnight at 4°C) in blocking buffer (PBS/NFDM) and then incubated at 37°C for 1 h with different antibodies. After incubation, membranes were rinsed for 20 min in PBS/Tween, and bound antibodies were detected with SPA-conjugated with horseradish peroxidase diluted at 1:2500. For color development, 4-chloro-1-naphthol (4-CN, SigmaAldrich) was used.",1
9,35,"The neutralization indices (NI) of the antibodies against different CSFV strains were determined by virus neutralization assay. Briefly, ST cells were seeded in 96-well tissue culture plates and incubated overnight at 37°C. Two-fold serial dilutions of the different heat-inactivated sera were mixed with equal volumes of 100 TCID 50 virus suspensions, incubated at 37°C for 1 h and subsequently transferred to confluent monolayers of ST cells in 96-well plates. The starting dilution of each serum was 1:50. At 72 hours post-infection, the cells were fixed and stained for the presence of glycoprotein E2 by immunofluorescence assay. The NI is the log10 of the antibody dilution factor (reciprocal of dilution) when 50% of the wells are protected from infection. Since the starting dilution factor was 50, the NI value of 1.7 is the detection threshold of our neutralization assay.",1
9,36,"Immunofluorescence assay (IFA) was used to verify the reactivity of the CSFV strains or cysteine-mutated E2 proteins with different antibodies. Briefly, cells infected with CSFV strains at 72 h or cells transfected with cysteine-mutated recombinant plasmids at 48 h were fixed in 3.7% paraformaldehyde at room temperature for 60 min and permeabilized for 10 min with 0.1% Triton X-100 in PBS. The cells were incubated for 1 h with different antibodies, and then stained with goat anti-rabbit antibody conjugated with Texas green or goat antimouse antibody conjugated with Alexa red (Molecular Probes Inc., USA) for another 1 h. Cells were examined under the IX71 inverted fluorescence microscope (Olympus, Japan).",1
9,37,"Hydrophobicity profile was generated using DNASIS software by the method of Kyte and Doolittle [44]. Evolution analysis was performed using an information-theoretic method described by Plotkin and Dushoff [41]. Briefly, we plotted the diversity of codons found at each residue against the diversity of amino acids found at the same residue. The diversity of codons or amino acids was quantified by a variant Simpson’s index: D = 1-pi2, where pi denotes the relative frequency of the i-th codon or amino acid at the residue in the multiple sequence alignment.",1
10,1,"Breast cancer is known to have both a genetic and nongenetic etiology. Several common genetic susceptibility variants have recently been identified, predominantly by genome-wide association studies (GWAS). These include single nucleotide polymorphisms (SNPs) at loci containing the genes FGFR2, LSP1, MAP3K1, TOX3, MRPS30, COX 11, SLC4A7, and at chromosomes 8p24 and 2q35 [1-5]. To date, the only SNP associated with breast cancer risk with genome-wide statistical significance (P < 10 -7 ) coming from candidate gene approaches is CASP8 [6]; more equivocal evidence has been reported for SNPs in TGFB1 [6] and ESR1 [7], among others.",1
10,2,"It is important to determine how these common SNPs combine with other known risk factors such as age at menarche, parity, age at first birth and body mass index (BMI) [8,9] to influence breast cancer risk because this knowledge could be used to improve risk prediction models [10,11]. The identification of modification of SNP associations by other risk factors could also provide insight into the biological mechanisms by which genetic variants are implicated in breast cancer etiology. Many of these SNPs and other risk factors have been observed to be differentially associated with estrogen receptor (ER)-positive and ER-negative disease [1,4,5,7,12,13] and so interactions between them may also differ by disease subtype.",1
10,3,"We, therefore, aimed to assess effect modification for 12 SNPs, 10 of which have been clearly associated with breast cancer risk (10q26-rs298158 (FGFR2), 8q24rs13281615, 11p15-rs3817198 (LSP1), 5q11-rs889312 (MAP3K1), 16q12-rs2803662 (TOX3), 2q35-rs13387042, 5p12-rs10941679, 17q23-rs6504950, 3p24-rs4973768 and CASP8-rs17468277) and two for which there is less clear evidence of a main effect (TGFB1-rs1982073 and ESR1-rs3020314). The potential effect modifiers considered were age at menarche, ever having had a live birth, number of live births, age at first birth and BMI. A secondary aim was to evaluate these interactions in susceptibility to breast cancer subtypes defined by ER and progesterone receptor (PR) status. Data for white women of European ancestry were combined from 21 case-control studies participating in the Breast Cancer Association Consortium (BCAC).",1
10,4,"A description of the 21 case-control studies participating in this pooled BCAC analysis is provided in Table 1, with more detailed information given in Additional Data Table S1 in Additional file 1. These included 11 population-based studies and seven studies with at least 1,000 cases and 1,000 controls. All studies collected selfreported information for cases and controls on age at diagnosis (cases) or interview (controls), racial/ethnic group (white European, Asian or other) and at least one of the following: age at menarche, ever having had a live birth, number of live births, age at first live birth (if parous), BMI (or height and weight). The time-point at which these variables were assessed for each study is detailed in Additional Data Table S1 in Additional file 1. Additional risk and other lifestyle factor information were not available at the time of the present analysis. All studies used structured questionnaires to collect these data, with the exception of the CNIO-BCS and the LMBC study, for which the information was abstracted from medical records. Nineteen studies also provided information on the ER and PR status of the tumors for a subset of cases. This information was mostly abstracted from medical records.",1
10,5,"Genotyping methods have been previously described [1,6,7,12,14]. Briefly, five studies (ABCFS, GENICA, kConFab/AOCS, MARIE and SASBAC) used Sequenom’s MassARRAY system and iPLEX technology (Sequenom, San Diego, CA, USA) for most SNPs. All other genotyping was done using Taqman® Assays-byDesignSM (Applied Biosystems, Foster City, CA, USA). SNP CASP8- rs17468277 is in complete linkage disequilibrium with CASP8-rs1045485, which has previously been reported to be associated with breast cancer [6]. All studies included at least one blank well (containing no DNA) per 384-well assay plate, at least 2% of samples in duplicate, and a common set of 93 samples from the Centre d’Etude Polymorphisme Humain (CEPH) used by the HapMap Consortium (HAPMAPPT01, Coriell Institute for Medical Research, Camden, NJ, USA). Genotyping call rates and duplicate concordance rates were calculated after excluding samples that had previously repeatedly failed; all were greater than 95%. Concordance with CEPH genotypes was greater than 98%.",1
10,6,"Overall genetic associations were evaluated for each of the 12 SNPs by estimating odds ratios (ORs) and their 95% confidence intervals (CI) via logistic regression, assuming multiplicative per-allele effects for the risk allele, as first reported in the literature (see Table 2). Main effects of risk factors were assessed only in the 11 population-based studies using logistic regression, adjusted for age (categorical: ≤34, 35 to 39, 40 to 44, 45 to 49, 50 to 54, 55 to 59, 60 to 64, 65 to 69, 70 to 74, ≥75 years; and continuous, the latter to account for differences between cases and controls in the extreme agegroups) and study (categorical). Risk factors considered were age at menarche (categorical: ≤11, 12, 13, 14, ≥15 years; and continuous), ever having had a live birth (no, yes), number of live births (parous women only, categorical: 1, 2, 3, ≥4; and continuous), age at first birth (parous women only, categorical: ≤19, 20 to 24, 25 to 29, ≥30 years; and continuous) and BMI, defined as weight in kilograms divided by the square of height in meters (categorical: ≤24.99, 25.00 to 29.99, ≥30.00; and continuous).",1
10,7,"Since BMI is known to be positively associated with breast cancer risk in postmenopausal women, but inversely associated with risk in premenopausal women [9], we analyzed the interactions with BMI separately for women aged <55 years and ≥55 years, considering these as a surrogates for pre- and post-menopausal status, respectively. Results from analyses using a younger age limit (50 years) to determine surrogate categories for premenopausal status were similar and are therefore not presented. Estimates of per-allele ORs for SNPs stratified by risk factors (for the categories defined above) were obtained using a single logistic regression model including appropriate dummy variables, in addition to those for the main effects of the risk factor categories.",1
10,8,"Interaction, or modification of genetic associations by other risk factors, was assessed for each SNP/risk factor combination by fitting logistic regression models. Each model included dummy variables for study plus three parameters, one for the main per-risk-allele effect, one for the main risk factor effect (all modeled as continuous variables, except ever having had a live birth) and a single interaction term for the product of the number of risk alleles and the value of the risk factor. This was tested statistically by a likelihood ratio test comparing this model to that without the interaction term. Effect modification by BMI was assessed separately for women <55 and ≥55 years of age.",1
10,9,"In addition, a parametric bootstrap test was used to estimate interaction P-values adjusted for multiple testing [15]. For each of the 72 interactions tested, we estimated the probability of being a case for each subject under the null hypothesis of no interaction, by applying the logistic regression model including only main effects for study (categorical), SNP (per-allele) and risk factor (continuous, except ever having had a live birth). Each replicate of the parametric bootstrap consisted of, for each interaction tested: (i) generating a dummy casecontrol status for each subject by sampling from a binomial distribution based on the estimated probability of being a case (by generating a single random number from the uniform distribution and assigning “case” to subjects for which this was less than the probability of being a case and “control” otherwise); and (ii) based on this dummy case-control status and the actual data for all other variables, fitting the interaction model described above and noting the likelihood ratio test P-value for the comparison of this model to the main effects only model applied to the same data. The minimum P-value was recorded for each of 10,000 replicates and the adjusted P-values were estimated as the proportion of replication P-values less than the corresponding unadjusted P-value.",1
10,10,"All statistical analyses were carried out using Stata: Release 10 (Statacorp, College Station, TX, USA) [16] with the exception of power calculations which were done using Quanto (University of Southern California, Los Angeles, CA, USA) [17,18].",1
10,11,"The 21 participating studies contributed 26,349 cases and 32,208 controls of self-reported white European race/ethnicity, all with available data for at least one of the 12 SNPs considered and at least one of the other risk factors considered (minimal data). Of these, 17,603 cases from 18 studies (all except BBCS, MCCS and USRT) were interviewed within two years after their breast cancer diagnosis and 29,187 controls came from the same 18 studies. Forty-six percent of cases and 38% of controls were under age 55 years at diagnosis and interview, respectively. ER and PR status was known for 19,561 and 16,962 cases, respectively. Details by study are provided in Table 1. In total, 12,822 cases and 19,703 controls with minimal data were included from 11 population-based studies and 16,107 cases and 23,140 controls with minimal data were included from seven studies with at least 1,000 cases and 1,000 controls.",1
10,12,"When analyses were restricted to population-based studies, the expected associations with breast cancer were observed for the risk factors, with one exception. After adjustment for age and study, each one-year increase in age at menarche was associated with a 4% (95% CI = 2 to 5%) decrease in breast cancer risk, and being parous was associated with a 16% (95% CI = 10 to 22%) decreased risk. For parous women, each additional live birth was associated with an 11% (95% CI = 8 to 13%) decrease in risk, while each five-year increment in age at first birth was associated with a 7% (95% CI = 4 to 10%) increase in risk. Obesity (BMI ≥ 30.0 kg/m^2 ) was associated with a 20% (95% CI = 10 to 29%) lower risk of breast cancer for women under age 55 years. The one unexpected observation was that obesity was not associated with breast cancer risk in women aged 55 years and older (OR = 0.96, 95% CI 0.88 to 1.04).",1
10,13,"Table 2 provides estimated per-allele ORs and their 95% CIs for the 12 SNPs considered, for all included subjects with genotype data, and for the subsets of women with information available for each of the four risk factors considered. All ORs were adjusted for study, and each subset was adjusted for study, age and the relevant risk factor. The OR estimates in the overall and subset analyses were very similar, and provide no evidence of confounding by the risk factors, nor of bias in OR estimates related to data availability.",1
10,14,"For the vast majority of SNP/risk factor combinations, there was no evidence that the per-allele OR for the SNP varied by category of the risk factor. This was true for analyses based on data from all studies (Additional Data Table S2 in Additional file 1), for analyses based on population-based studies only (Additional Data Table S3 in Additional file 1) and for analyses based on the seven studies with at least 1,000 cases and 1,000 controls (Additional Data Table S4 in Additional file 1). Restricting analyses to the 18 studies with cases interviewed within two years after their breast cancer diagnosis made no substantial difference to the results obtained (data not shown). Similarly null results were observed for analyses restricted to ER-positive and ER-negative breast cancer (Additional Data tables S5 and S6 in Additional file 1) and for analyses restricted to PR-positive and PR-negative breast cancer (Additional Data Table S7 and S8 in Additional file 1).",1
10,15,"The strongest evidence of interaction (unadjusted P = 0.002) was for the modification of the association with 11p15-rs3817198 (LSP1) by number of live births. Per-allele OR estimates increased from 1.04 (95% CI = 0.97 to 1.11) for women who had had just one live birth to 1.24 (95% CI = 1.11 to 1.38) for women with at least four live births, and an interaction OR of 1.05 per live birth and per allele was estimated. This trend was also observed when data from only populationbased studies and from only studies with at least 1,000 cases and 1,000 controls were considered (P = 0.01 in both sub-analyses). Evidence for this interaction was observed when the analysis was restricted to ERpositive and PR-positive disease (P = 0.004 and P = 0.01, respectively; Figure 1), but not for analyses based on ER-negative and PR-negative cases (P = 0.3 and 0.06, respectively). However, considering that 72 tests for interaction were carried out, chance cannot be excluded as an explanation for these results. The multiple-test-adjusted P-value for the modification of the 11p15-rs3817198 association by number of live births was 0.12. The adjusted p-values for all other interactions tested were all ≥0.61.",1
10,16,"Post-hoc power calculations estimated that for age at menarche (per year), parity (per live birth) and age at first birth (per five-year age increase), our study had 90% power at a significance level of 0.0007 (corresponding to a multiple-testing-adjusted P-value of 0.05) to detect interaction ORs of at least 1.06 for all loci tested except CASP8-rs17468277, for which the minimum was 1.08. For BMI (per five-unit increase) the minimum interaction OR detectable with 90% power in both age strata (<55 and ≥55) was 1.08 for the more common variants and 1.10 for CASP8-rs17468277. For parity, considered as never or ever having had a live birth, the study had similar power to detect interaction ORs of at least 1.20 for CASP8-rs17468277 and 1.16 for the remaining loci.",1
10,17,"This combined analysis of more than 25,000 cases and 30,000 controls found no conclusive evidence that age at menarche, parity, age at first birth or BMI modify the established associations of breast cancer risk with 10q26rs298158 (FGFR2), 8q24-rs13281615, 11p15-rs3817198 (LSP1), 5q11-rs889312 (MAP3K1], 16q12-rs2803662 (TOX3), 2q35-rs13387042, 5p12-rs10941679, 17q23rs6504950, 3p24-rs4973768 and CASP8-rs17468277) nor the putative associations with TGFB1-rs1982073 or ESR1rs3020314. This was also true for disease subtypes defined by ER and PR status.",1
10,18,"The strongest evidence of effect modification was for number of live births and 11p15-rs3817198 (LSP1). However, the observed trend of increasing relative risk with increasing parity was not statistically significant after correction for multiple testing. It should be noted that the interaction OR was 1.05 per allele and per live birth. This corresponds to an estimated per-allele OR increasing from 1.04 for women with one child to 1.24 for women with four or more children, for a SNP with an estimated average OR of 1.08 across all levels of parity. Such weak interactions would only result in very small differences in estimates of joint effects relative to those from models assuming multiplicative effects. This finding in this very large study highlights the difficulty of identifying modifying effects of this magnitude.",1
10,19,"A recent study by Travis et al. of 7,610 cases and 10,196 controls reported null results for interactions in breast cancer susceptibility between 9 of the same genetic loci and 10 risk factors, including age at menarche, parity, age at first birth and BMI [19]. Our null findings replicate the results from this prospective study of older women (over age 50 years), but in a study with more than twice the sample size in this age group, and confirm that they are also applicable to women under age 50 years. Our study also extends the genetic loci evaluated for interactions with a subset of established breast cancer risk factors to include 17q23rs6504950 and 3p24-rs4973768 [1] and ESR1-rs3020314 [7], which were not considered by Travis et al. [19]. Furthermore, with regard to the susceptibility locus at 5p12, we considered the more strongly associated SNP rs10941679 rather than rs981782 (which is only weakly correlated with rs10941679) [5]. Of note, Travis et al. found no evidence of interaction between 11p15rs3817198 (LSP1) and number of children (P = 0.9) [19].",1
10,20,"One of the strengths of the BCAC is the large combined sample size achieved through international collaboration. This has proven to be very effective in confirming or ruling out association with breast cancer for common SNPs identified through GWAS and candidate gene studies [1,2,6,14,20,21]. The BCAC has also been able to provide highly precise estimates of the ORs associated with susceptibility alleles, with very high consistency observed between the many studies that participate in the consortium, despite the range of study designs represented. The inclusion of multiple studies that recruited selected cases and/or volunteer controls means that the main effects for some risk factors cannot be appropriately evaluated across the whole consortium. However, this potential selection bias in estimating main effects should not influence the assessment of interactions [22]. Nevertheless, we carried out sensitivity analyses considering only data from population-based studies and only data from studies with at least 1,000 cases and 1,000 controls and observed no substantial change in the results obtained regarding interactions.",1
10,21,"A potential limitation of our study derives from heterogeneity in data collection methods across studies. All studies except two (neither population-based) used structured questionnaires administered by a variety of means, including in-person interviews, phone-interviews and self-administration. Nevertheless, the measurement of age at menarche, ever having had a live birth, number of live births and age at first birth seem likely to be robust to these differences in data collection method. Our results for BMI may be more likely to be affected by heterogeneity in data collection methods, although standardized measurement within studies and adjustment for study as a covariate should limit this to a loss of power, rather than any systematic bias. We repeated our primary analyses excluding cases interviewed before, or more than two years after, their breast cancer diagnosis and results were not substantially different. This suggests that between-study differences in the reference time at which BMI was reported did not influence the inference from our study. A further limitation of our study was that we did not collate information on hormone therapy (HT) use from the majority of participating studies and so were unable evaluate interactions between SNPs and BMI by HT use in older women.",1
10,22,"In summary, in the largest collaborative analyses of gene-environment interactions carried out to date, we have observed no conclusive evidence for modification of the per-allele relative risk associated with common breast cancer susceptibility variants by age at menarche, parity, age at first birth or BMI. This finding is consistent with those from a recently published smaller prospective study. These results imply that the combined effects of these common susceptibility alleles and other established risk factors can be assumed to multiplicative in risk predicted models for breast cancer.",1
11,1,"Anopheles funestus is the major malaria vector in southern Africa. Early records of its involvement in malaria transmission give Plasmodium falciparum parasite rates as high as 22% in South Africa [1]. More recently, in Tanzania 11% infection rate was recorded [2] and 5% in southern Mozambique [3].",1
11,2,"South Africa eradicated An. funestus in the 1950’s when an extensive indoor residual spraying (IRS) campaign using DDT was rolled out. In the next 50 years, this vector species was recorded only once during a small malaria outbreak in the northern part of the country [4]. In 1999/2000, however, South Africa experienced its worst malaria outbreak since the introduction of IRS in the 1950’s and An. funestus was found once again in northern KwaZulu/ Natal, just south of Mozambique [5,6]. The P. falciparum parasite rate in An. funestus was 5.4% and the mosquitoes were found to be resistant to both pyrethroids and carbamates.",1
11,3,"Subsequent research in southern Mozambique showed that the insecticide resistant population of An. funestus extended north of the capital, Maputo [7-9]. Most recently, resistance was found in An. funestus from Chokwe [10], approximately 200 km north of the capital, where previously this population was found to be susceptible [8].",1
11,4,The present study provides evidence of insecticide resistance in An. funestus from an island in Lake Malawi that is considerably further north than any previous records of resistance.,1
11,5,"The mosquito survey was carried out on Likoma Island in Lake Malawi (12°04’S, 34°44’E) from 10 - 14 May 2010 (Figure 1). The island is a series of outcrops and the housing on the island consists mainly of scattered homesteads with residents engaged in fishing and smallscale subsistence farming. Many houses were searched for mosquitoes mostly without success, but a substantial An. funestus population was found in a few houses close to a small area being used for rice cultivation.",1
11,6,Mosquitoes were collected resting inside houses using a hand aspirator. Some samples were used immediately for WHO susceptibility tests while others were packaged and returned to Johannesburg where egg batches were obtained and larvae reared through to F-1 adults.,1
11,7,Species identification was carried out using the methods of Koekemoer et al. [11] for the An. funestus group and Scott et al. [12] for the An. gambiae complex. Wild females were screened for malaria parasite infection using ELISA [13].,1
11,8,"Insecticide susceptibility tests were carried out using the WHO [14] standard test kits and treated papers from the WHO Collaborating Centre in Penang, Malaysia. The insecticides tested and their discriminating doses are given in Table 1 and 2.",1
11,9,"One hundred and eleven wild An. funestus females of unknown age were tested for insecticide resistance under field conditions with no temperature or humidity control. A total of 6 An. gambiae complex females and over 120 females and ± plusorminus90 males of An. funestus, together with a small collection of An. Gambiae larvae, were packaged and transported back to the laboratory in Johannesburg.",1
11,10,"A total of 223 An. funestus were subjected to molecular assays including all the wild adults used in the susceptibility tests (n = 111) as well as the live females brought back to the laboratory for egg laying (n = 112). 97.3% were successfully identified as An. funestus s.s. (five specimens did not amplify a PCR product and one specimen was identified as An. funestus-like). All males and females of the An. gambiae complex (wild adults and adults reared from larvae, n = 89) were identified as An. arabiensis.",1
11,11,"Of the 81 wild An. funestus females tested for parasite infection, 4.9% were positive for P. falciparum using the ELISA method.",1
11,12,"The results of the first insecticide susceptibility tests, carried out on the island using wild female An. funestus of unknown age, are given in Table 1. Since the controls gave >5% mortality, Abbott’s formula [14] was used to correct the results, giving 77.8% mortality on deltamethrin and 56.4% on bendiocarb. The papers used in the field were tested in the laboratory using a susceptible An. gambiae colony and gave 100% mortality for all samples and replicates (n = 100 for each insecticide).",1
11,13,The second round of insecticide susceptibility tests was carried out in the laboratory at 25°C and 85% RH using 1-5 day old An. funestus females pooled from approximately 120 egg batches. Nine different insecticides from all four classes were tested and the results are given in Table 2.,1
11,14,"Unfortunately, the An. arabiensis sample reared from larvae was too small (n = 42 females) to carry out meaningful susceptibility tests.",1
11,15,"The marked difference between the deltamethrin susceptibility tests carried out on wild females in the field and those on the laboratory reared, 1-5 day old F-1 progeny (p <0.005), can be explained in two ways. One, high temperatures are known to affect the survival of mosquitoes exposed to insecticides [15] and this may account for the high mortality in the field samples. Two, An. funestus susceptibility to this sub-class of pyrethroids may be age dependent [16]. Since the survey was carried out in May towards the end of the transmission season, it is likely that the wild-caught females tested in the field were an aging population and were therefore more susceptible to the insecticides. However, Hunt et al. [16] also report that blood fed, mated, females did not show any decrease in resistance over time, and aging wild populations would all be mated and have taken numerous blood meals.",1
11,16,"It is clear from the susceptibility results that a resistance management strategy will have to be devised and implemented in order to control malaria on the island. If pyrethroid treated bed nets are to be distributed widely on Likoma Island, then IRS must be carried out simultaneously with an organophosphate or DDT in order to manage the resistance. Carbamates are unfortunately not an option with such a high frequency of survival. The An. funestus population is fully susceptible to DDT, which raises the possibility of using DDT for IRS perhaps in a rotation with one of the organophosphates.",1
11,17,"There is already extensive use of bed nets on the island with an assortment of treated and untreated nets, old and new, damaged and intact. There is also obvious variation in usage. Frequently, nets were present in the house but not being used. If a combination of bed nets and IRS is under consideration, an important component of such a strategy must be education and monitoring of net use. When the mosquito populations decrease, either due to seasonal change or in response to control measures, many people will stop using the nets. It is also a reality that in a community where livelihood depends on fishing, some nets will be used for this purpose (Figure 2).",1
11,18,"The most worrying aspect of this survey is the discovery of pyrethroid and carbamate resistance in the An. funestus population approximately 1,500 km north (Figure 1) of its current known distribution at Chokwe in southern Mozambique [10]. The report by Casimiro et al. [9] on samples collected from central Mozambique in 2006 showed that An. funestus had >95% mortality to pyrethroids and carbamates. The WHO criteria recommend that this percentage of susceptibility requires further investigation, but operationally it is unlikely that a control programme would change its policy based on this frequency of resistance/susceptibility.",1
11,19,"Likoma Island in Lake Malawi is just a few kilometres away from Mozambique and presumably the mosquitoes are either blown over by the wind or brought on boats that ply their trade between the island and the mainland. One must assume, therefore, that the An. funestus population in northern Mozambique is also resistant and this has serious implications for current malaria control efforts being undertaken in this region. Since both pyrethroid and carbamate resistance has been found in the Likoma population, mirroring the resistance found in more southerly populations, it can be assumed that the resistance is spreading northwards through the An. funestus populations through gene flow, and not arising as separate genetic mutation events. There are no obvious geographical barriers to gene flow in this region of southern Africa and presumably we can expect the resistance to spread northwards into southern Tanzania and westwards into Zambia and Zimbabwe. The recently reported resistance in An. funestus from Uganda [17] is obviously different to that observed in southern African populations, based on both susceptibility tests and molecular characterization of the P450 genes [5,16,18,19].",1
11,20,This paper highlights the seriousness of the rapid spread of insecticide resistance in An. funestus in southern Africa and the urgent need for resistance management strategies within malaria vector control programmes within the region.,1
12,1,"Angiogenesis is a process by which new blood vessels are formed from pre-existing ones [1]. In physiological conditions, this process is strictly controlled by a set of molecules that can either activate the process (proangiogenic factors) or inhibit it (antiangiogenic factors) [2]. During the last decades, it has been widely established that solid tumors have abnormal hyperactivation of angiogenesis [2]. Among the factors that can trigger angiogenesis, the lack of oxygen (hypoxia) is of special importance. Virtually all solid tumors eventually activate angiogenesis in order to overcome lack of oxygen and nutrients after reaching a certain burden [3,4]. One of the most important mediators of hypoxia-activated angiogenesis is the Vascular Endothelial Growth Factor (VEGF-A), produced by tumor cells after sensing low oxygen levels [5,6]. VEGF-A expression can also be induced by non-hypoxia mediated activation, such as Ras signalling [7].",1
12,2,"VEGF-A is a key player in tumor-induced angiogenesis, and its overexpression has been found in most solid tumor types [6]. VEGF-A acts through its cognate receptors VEGFR1 (Flt-1) and VEGFR2 (Flk-1/KDR), in endothelial and bone marrow-derived cells [6,8]. The VEGF pathway has been used as a major target to block tumor angiogenesis. A set of molecules that bind and inhibit different components of the VEGF-A pathway have been developed during the past years. Some of them have already reached the clinical practice, such as bevacizumab (Avastin®, Genentech), a monoclonal antibody that binds and inactivates VEGF-A, or sunitinib (Sutent®, Pfizer), a tyrosine-kinase inhibitor that blocks phosphorylation of several tyrosine-kinase receptors including VEGFR1 and VEGFR2 [9,10].",1
12,3,"The VEGF-A gene contains 8 exons, which can give rise to 5 main alternatively spliced isoforms (VEGF121, VEGF145, VEGF165, VEGF189 and VEGF206) [6]. Alternative translation codons upstream of the canonical ATG codon can be used, so that longer isoforms can also be generated [11]. However, the relative importance of these members is still undetermined. Recently, a novel set of isoforms, the so-called “b-isoforms” or “VEGFxxxb” isoforms, have been described. These transcripts of the VEGF-A gene code for polypeptides with the same length as the classical ones, because exon 8 (present in all the formerly known isoforms) is substituted by an alternatively spliced exon of the same size (exon 8b) [12]. These isoforms were therefore named VEGF121b, VEGF165b, VEGF189b etc. In the classically studied isoforms, exon 8 is known to be important for receptor activation [13]. Thus, the “b-isoforms”, where exon 8 is substituted by another peptide sequence, were hypothesized to act as potential antagonists of VEGF-A receptors [14]. Several reports have indeed shown that VEGF165b may have anti-angiogenic properties [14,15], while others cast some doubts about such activities, suggesting that it may act as a VEGF-A receptor agonist [16,17].",1
12,4,"Another interesting issue is the possible differential expression between “angiogenic” vs. “antiangiogenic” isoforms in pathologies where development of aberrant vasculature is involved, including cancer. Previous studies have shown in a limited number of samples, using semiquantitative RT-PCR, that VEGFxxxb isoforms are highly expressed in normal prostate, colon and kidney compared to their malignant counterparts [14,18,19]. It was proposed that formation of neovasculature in pathological conditions would modify alternative splicing of VEGFA, thus promoting the expression of the “b-isoforms” (supposedly anti-angiogenic) at the expense of the classical angiogenic family of isoforms. This would also be extremely interesting because expression of the ratio VEGFxxxb/VEGF could be utilized as a biomarker of angiogenic disease [13].",1
12,5,"Since a therapeutic approach using recombinant VEGFxxxb proteins is very attractive, but the biological activity of such transcripts is not yet clear, we sought to produce recombinant VEGF121b and VEGF165b proteins in the yeast Pichia pastoris, and constructed expression vectors to overexpress these isoforms, in order to further elucidate their role in cancer models. In addition, we analyzed protein expression of VEGFxxxb and total VEGF in normal mammary glands and 50 breast cancer samples, using specific antibodies previously characterized.",1
12,6,"Oligonucleotides were purchased to Sigma-GenoSys (Sigma, St. Louis, MO, USA). The primers VF (5’GAAACCATGAACTTTCTGCTGTCTT3’) and V121bR (5’ TTAAGCTTTCAGTCTTTCCTGGTGAGAGATTTTTCTTGTCTTGCTCTATC3’) were used to clone the VEGF121b isoform by PCR into pCR2.1 vector (Invitrogen). VF and V165bR (5’ TTAAGCTTTCAGTC-TTTCCTGGTGAGAGATCTGCAAGTACGTTCGTTTAACTC 3’) were used to clone VEGF165b. Note that initiation codon is underlined in VF and both reverse oligonucleotides contain HindIII restriction sites (bold). VEGF121b and VEGF165 b coding sequences were then subcloned into the pCDNA3.1(-)Neo expression plasmid. The primer VPPF (5’ GGTCTCGAGAAAAGAGAGGCTGAAGCTGCACCCATGGCAGAAGG 3’), together with V121bR or V165bR, was used to clone VEGF121b and VEGF165b coding sequences lacking the signal peptide (ΔPSVEGFxxxb) into the pPICZalphaC vector (Invitrogen) for production of recombinant proteins in the yeast Pichia pastoris, where the alpha-factor signal peptide is used to achieve extracellular expression of the VEGFxxxb sequences.",1
12,7,"The pPICZalphaC plasmids carrying the ΔPS-VEGFxxxb sequences were linearized, gel-purified, and measured for concentration. 80 μL of Pichia pastoris cells were mixed with 5 μg of linearized-plasmid in 1 mm-wide electroporation cuvettes (Bio-Rad). Electroporation was carried out in a Gene-pulser II (Bio-Rad) using the preset yeast conditions. After electroporation, 1 mL of 1 M sorbitol was added to the cuvettes and the electroporated cells were transferred to sterile microtubes. Yeasts were incubated at 30°C for 2 h and then spread in YPDSZ plates (1% yeast extract, 2% peptone, 2% sorbitol, 2% agar and 100 μg/mL zeocin) and incubated for 9 days at 29°C. Zeocin-resistant colonies were picked and grown in YPD medium. Yeast clones were transferred to BMGY medium (1% yeast extract, 2% peptone, 100 mM potassium phosphate pH 6.0, 1.34% yeast nitrogen base, 0.00004% Biotin, 1 U/mL gentamycin sulphate, and 1% glycerol) to allow cells to grow exponentially for 30 h at 29°C and thorough shaking. Yeasts were then centrifuged and resuspended in BMMY medium (thesame composition as BMGY but containing 1% methanol instead of glycerol) to induce protein production.",1
12,8,"Supernatants were collected 24 hours after incubation at 29°C and thorough shaking, and analyzed by SDS-PAGE to determine the best clone producing each of the VEGF121/165b isoforms. Selected clones were grown at 29°C in 2 L of BMGY for 2 days and then changed to BMMY inducing medium, in order to produce large amounts of recombinant products. For purification, nickel-affinity chromatography was used. A Hi-Trap chelating column (Amersham) was connected to an AKTÄ High Pressure Liquid Chromatography (HPLC) device (Amersham). Pichia pastoris supernatants containing recombinant VEGF121/165b proteins were diluted in binding buffer (0.02 M sodium phosphate, 1 M NaCl, pH 7.2; all reagents from Sigma) and loaded into the HPLC device. Elution buffer (0.02 M sodium phosphate, 1 M NH4Cl, 500 mM Imidazole, pH 7.2; all reagents from Sigma, except for imidazole, purchased from Merck) was loaded, and gradually mixed with binding buffer with an increasing proportion of elution buffer. Fractions of 1 mL were collected throughout the process.",1
12,9,"Purified proteins after affinity chromatography were depleted from eluting medium and changed to PBS through dialysis, using Slide-A-lyzer cassettes (Pierce) with a 10 KDa threshold pore. Cassettes were filled with eluted protein and drawn in 3L of PBS, overnight. This step was repeated with new PBS for 6 more hours. Dialyzed proteins were extracted from the cassettes with syringes and snap frozen.",1
12,10,"For protein extraction, cultured cells were lysed for 30 min at 4°C in RIPA buffer (50 mM Tris pH 7.4, 150 mM NaCl, 1 mM PMSF, 1 mM EDTA, 1% sodium deoxycholate and 0.1% sodium dodecyl sulphate; all reagents from Sigma) plus a protease inhibitor cocktail (Roche, Switzerland). Samples were then centrifuged at 13000 rpm. Protein concentration was determined by the bicinchoninic acid protein assay (Pierce, Rockford, IL). In the case of conditioned culture media, supernatants were centrifuged to get rid of any cell debris and 20-fold concentrated by centrifugation for 45 min, using 15-KDa Amicon Ultra centricons (Millipore, Billerica, MA, USA).",1
12,11,"Proteins were electrophoresed in Bis-Tris buffered gels (Novex gels, Invitrogen) in either reducing or non-reducing conditions, following standard procedures. 20 μg protein solution (in RIPA buffer) were mixed with Laemmli sample buffer and boiled for 5 min. Electrophoresis was carried out in 1X running buffer for 90 min at 130V and room temperature. Proteins were directly stained in the gel with Coomassie blue or transferred to PVDF membranes for immunodetection. Deglycosylation analysis of VEGFxxxb proteins (90 μM) was treated with 0.8 mM Endo F1 and incubated for 1 h at 37°C; cleavage was monitored by SDS-PAGE.",1
12,12,"Membranes for western blots were rinsed twice with PBS-tween, blocked with PBST plus 5% skim milk for 30 min at room temperature, and incubated with primary antibodies. Antibodies against VEGF (MAB293, R&D; and sc-152, Santa Cruz), VEGFxxxb (MAB3045, R&D), pKDR, total KDR, pERK1/2, total ERK1/2, and GAPDH (all of these latter ones from Cell Signalling) were used. Then, horseradish peroxidase-labelled secondary antibodies (GE Healthcare) against the corresponding primary antibodies were added. Immunoreactive bands were visualized by a chemoluminescent method using the Lumi-lightPLUS kit (Roche).",1
12,13,"HUVECs, PC3 and A549 cell lines were obtained from the American Type Culture Collection (ATCC, Manassas, VA, USA). PC3 and A549 cells were maintained in complete medium, consisting of: RPMI-1640 growth medium (Invitrogen) with Glutamax®, supplemented with 10% heat-inactivated FBS, 100 U/mL penicillin and 100 μg/mL streptomycin (both antibiotics from Invitrogen). HUVECs were maintained in EGM-MV2 medium (Lonza) containing human recombinant EGF, VEGF, FGF, IGF-1, hydrocortisone, ascorbic acid and 2% FBS. Cell culture medium with 1% serum was used to analyze cells supernatants by western blot.",1
12,14,"Purified plasmidic DNA was introduced into mammalian cells through cationic lipid-based transfection with the reagent Lipofectamine 2000, according to manufacturer’s recommendations. Transfected cells were selected and maintained with complete medium plus 300 μg/mL (PC3) or 500 μg/mL (A549) G418.",1
12,15,"Two different methods were used to assess cell proliferation. The first method consisted of the MTT (SigmaAldrich, Italy) assay. Cells were seeded in 50 μL 2% FBS-containing growth medium in 96-well culture plates and allowed to attach overnight. Two-fold concentrated recombinant human VEGF165 (rhVEGF165, Apollo Cytokine Research), recombinant human VEGF 121 b and VEGF 165 b produced in Pichia pastoris (VEGF 121 b(pp) and VEGF165b(pp)), recombinant human VEGF165b produced in CHO cells (VEGF165b(hs)), kindly provided by Dr. David O. Bates (Microvascular Research Laboratories, Department of Physiology, University of Bristol, UK), or the VEGFRs inhibitor GW654652 (GlaxoSmithKline) were added. In each time point, 10 μL 5% MTT solution was added to each well. Plates were incubated for additional 3 h at 37°C. The resulting formazan crystals were finally solubilized by administration of 100 μl 10% SDS in 50% N-N-Dimethylformamide to each microplate well. Absorbance at 550 nm was measured using a TECAN Sunrise microplate reader. Wells containing only complete medium were used as controls. Each experiment was performed three times using six replicates for each drug concentration.",1
12,16,"The second method consisted of analysis of DNA synthesis by incorporation of the modified nucleotide EdU, using the Click-it reaction according to the manufacture’s instructions (Invitrogen). Briefly, cells were plated at 50% confluence and treated with 50 or 100 ng/mL of rhVEGF 165 , VEGF 121 b(pp), VEGF 165 b(pp), or bFGF overnight. Cells were then incubated for 1h with 5mM EdU solution, washed, trypsinized, fixed, permeabilized, and incubated with Alexa-Fluor-647 dye in the presence of copper for catalysis of the Click-it reaction. Cells were analyzed with a FACScalibur flow cytometer to determine EdU incorporation.",1
12,17,"Nu/Nu mutant athymic mice (Balb/C genetic background) were purchased from Harlan Laboratories (Barcelona, Spain) and maintained in SPF (Specific Pathogen Free) standard conditions. One million PC3 or five million A549 cells and their corresponding transfectants in exponential growth phase were resuspended in 200 μL PBS and injected subcutaneously in the flanks of Nu/Nu mice. Tumor measurements were done with precision callipers and animals were sacrificed before tumors reached 1.7 cm in diameter. Experiments were conducted according to the guidelines for ethical use of animals of our Institution (CIMA-University of Navarra) under an approved protocol. Tumors were harvested and fixed overnight in 10% buffered formalin, embedded in paraffin, and sectioned. Primary tumor volumes were calculated with the formula: V = length × (width)^2/2.",1
12,18,"For Matrigel plug assays, 400 μL Growth Factor Reduced Matrigel (BD) were mixed with 100 ng of rhVEGF165, VEGF121b(pp), VEGF165b(pp), or bFGF (as positive control) in 100 μL PBS and injected subcutaneously in Nu/Nu mice. One week after cell inoculation, mice were injected retro-orbitally with 100 mL Fluorescein-labelled dextran (3 mg/mL) or with Alexa-647labelled isolectin B4 (100 μg/mL). After 15 min, mice were sacrifized, and the Matrigel plugs were explanted and analyzed under a Zeiss Axiovert confocal microscope.",1
12,19,"Tissues (xenografted tumors or matrigel plugs) were obtained from the in vivo experiments, fixed in 10% buffered formalin and embedded in paraffin. Tissue Microarray (TMA) slides were obtained from AccuMax (Seoul, Korea; catalogue # A202(I)). This TMA contains 100 breast tissue cores from 50 patients and 8 tissue cores from 4 normal breast tissue obtained by mammoplasty. Breast cancer types include 33 infiltrating ductal carcinomas, 7 papillary carcinomas, 3 phyllodes tumors, 4 infiltrating lobular carcinomas, and 3 samples corresponding to other breast cancer tumor types.",1
12,20,"For immunohistochemistry, slides were deparaffinized, hydrated, and incubated for 10 min with 3% H 2 O 2 in water to quench the endogenous peroxidase activity. An antigen retrieval method was used for detection of the antibodies. Dilutions of primary antibodies were as follows: 1:200 for Caspase 3 (Cleaved Caspase-3 Asp 175, Cell Signaling); 1:20 for CD-31 (Dianova); 1:100 for PDGFRb (Cell Signaling); 1:200 for VEGF (Santa Cruz); 1:50 for VEGFxxxb (R&D). Primary antibodies were incubated at 4°C overnight or for 1 h at RT in the case of CD31. Tissues were washed in TBS and incubated with the appropriate secondary antibody. Afterwards, slides were incubated for 30 min with the EnVision™ antirabbit detection system (Dako). Peroxidase activity was carried out with DAB (Dako). Finally, slides were counterstained with hematoxylin, dehydrated, and mounted. For quantifications of immunohistochemistry in xenografted tumor sections, 10 random images (200×) per mouse were captured with a microscope (Leica, Wetzlar, Germany) equipped with the Analysis™ software. Positive cells were quantified with Image J (NIH, Bethesda, MD, USA).",1
12,21,"For quantification of FITC-dextran and Alexa-647 Isolectin B4 in sections of Matrigel plugs, slides were analyzed with an Axiovert (Carl Zeiss, Germany) epifluorescence microscope and 10 random pictures of each Matrigel were taken. Labelled area was measured with the ImageJ software.",1
12,22,"Data sets were tested for normal distribution with Shapiro-Wilks and Kolgomorov-Smirnoff tests. Levene’s test was also performed to verify homogeneity of variances. In those cases where tests displayed normal distribution, ANOVA was performed to test for possible differences among groups. Bonferroni correction was used for post-hoc comparison in the case of variance homogeneity, whereas Tamhane’s correction was the choice in the case of Levene’s positive test. For non-normal distributed data sets, non-parametric tests were applied: Kruskal-Wallis for multiple comparisons and Mann-Whitney’s U-test with significance correction for double comparisons of independent samples. Wilcoxon’s test was carried out for dependent sample data. To run these tests, The SPSS software was used. Results with a pvalue < 0.05 were considered significant (*), and those with a p-value < 0.01 (**), or <0.001 (***), very significant.",1
12,23,"Figure 1 shows a scheme of the different exons included in each of the “classical” VEGF-A isoforms and the “VEGFxxxb” isoforms. The coding sequence for both VEGF121b and VEGF165b, lacking the native human signal peptide, was cloned into the pPICZalphaC plasmid. The native human signal peptide sequence was substituted by the yeast alpha-factor signal peptide in these constructs, which is known to be very efficient for secretion in Pichia pastoris. To obtain top-quality recombinant proteins, VEGFxxxb was purified from Pichia pastoris culture supernatants through nickel-affinity chromatography. Figure 2A shows a chromatographic image of the procedure. Recombinant VEGF 121 b was eluted in a gradient of 20% imidazole. Peak 1 corresponds to all unbound substances, which run through the column. Peak 2 corresponds to proteins eluted with approximately 12.5% of imidazole (Figure 2A). Similar results were found for VEGF165b (not shown). Figure 2B shows Coomasie blue staining of different aliquots taken during elution of VEGF121b around peak 2, where the bands correspond to the expected size of VEGF 121 b. These results show that nickel-affinity is an efficient method to purify VEGFxxxb proteins from Pichia pastoris culture supernatants.",1
12,24,"Electrophoresed culture media from Pichia pastoris clones obtained after electroporation with the linearized VEGF 121b or VEGF 165 b sequence containing pPICZaphaC plasmids and selection with zeocin for one week is shown in Figure 2C. Bands of the expected molecular masses were detected in supernatants from Pichia pastoris clones. The amount of ectopic protein was clearly visible among the total secreted proteins by this yeast. The clones overexpressing higher amounts of recombinant VEGFxxxb proteins were chosen for large-scale production. Importantly, Pichia pastoris-derived recombinant proteins were immunoreactive to the currently available (and previously validated) commercial antibody (R&D) against VEGFxxxb (Figure 2D).",1
12,25,"The band pattern of recombinant human VEGF121/165b isoforms expressed in Pichia pastoris was similar to that of the native VEGFxxx isoforms, as previously described [20]. VEGF121b forms dimers that can be detected in the gel as three bands under non-reducing conditions (Figure 2C). The three bands probably correspond to dimers of glycosylated-glycosylated, glycosylated-non-glycosylated and non-glycosylated-non-glycosylated proteins, as described for the VEGF-A classic isoforms [20]. The same culture supernatants run under reducing conditions showed only two bands (Figure 2C), which would be concordant with the ability of these proteins to dimerize. The same pattern can be seen for VEGF165b (Figure 2C), although the bands are not as clearly seen as for VEGF 121 b. Recombinant VEGFxxxb proteins also formed larger complexes, such as tetramers and octamers, especially in the case of VEGF165b (Figure 2D).",1
12,26,"To assess the glycosylation status of the VEGFxxxb recombinant proteins produced in Picha pastoris, endoglycosidase F1 was used both in reducing and non-reducing conditions (Additional file 1 Figure S1). VEGF121/165 b deglycosylation produced an electrophoretic shift for both isoforms. Molecular weights for both glycosylated and deglycosylated proteins are compatible with those observed for VEGF121 and VEGF165 [20,21].",1
12,27,"The effect of VEGF121/165b recombinant proteins produced in our laboratory (VEGF121b(pp) and VEGF165b (pp)) was first tested on endothelial cell proliferation in vitro. We also tested the effect of a VEGF165b recombinant protein (VEGF165b(hs)) produced in mammalian CHO cells to discard any possible yeast-glycosylationderived effect. A first experiment was conducted with the MTT assay. Addition of 100 ng/mL commercial VEGF165 (from R&D) induced HUVEC proliferation by 63% compared to untreated cells (Figure 3A). Coadministration of VEGF 165 and either VEGF 121 b(pp), VEGF 165 b(pp), or VEGF 165 b(hs) (at the same dose) caused a similar proliferative induction (Figure 3A). Exposure of HUVECs to each one of the recombinant “b-isoforms” alone resulted in ~40% increased proliferation. Administration of the VEGFR-targeting compound GW654652 alone or with VEGF165b(hs) produced similar rates of HUVECs proliferation than untreated control cells (Figure 3A). This result shows the specificity of VEGF165b in inducing VEGFR-mediated endothelial proliferation. Similar results using the VEGFR inhibitor were obtained for VEGF 121 b(pp) and VEGF 165 b(pp) (results not shown).",1
12,28,"To confirm our results on proliferation we used an alternative method, based on DNA incorporation into the cells. As shown in Figure 3B, administration of bFGF and VEGF 165 increased DNA incorporation into HUVECs by 3-fold (p < 0.001), compared to untreated controls. Exposure to VEGF165b(pp) and VEGF121b(pp) also increased significantly (p < 0.01) DNA incorporation into HUVECs by almost 2-fold as compared to controls. Therefore, these experiments parallel those obtained by MTT showing that VEGFxxxb isoforms increase proliferation, although less potently than VEGF165.",1
12,29,"Addition of all VEGF-A proteins to HUVECs induced phosphorylation of the VEGF-A receptor Flk-1/KDR (also known as VEGFR2) and the intracellular kinase ERK1/2 (Figure 4). As expected, VEGF165 caused phosphorylation of KDR and ERK1/2, 10 min after treatment in serum-free conditions (Figure 4). VEGF121/165b proteins induced KDR phosphorylation in HUVECs as well. VEGF121b and VEGF165b, either produced in mammalian cells or in Pichia pastoris stimulated similarly ERK1/2 phosphorylation. Co-administration of VEGF 165 and VEGF121/165b did not prevent VEGF165-induced KDR or ERK1/2 phosphorylation. VEGF165b(pp) failed to activate the KDR-ERK pathway in the presence of the VEGFRs inhibitor GW654652, thus indicating receptor specificity. Similar results were obtained with VEGF 121 b(pp) and VEGF165b (hs) (not shown).",1
12,30,"Matrigel plug assays were done in order to decipher the effect of VEGF121/165b isoforms on endothelial cell function in vivo. Matrigel was mixed with either bFGF, or VEGF165 (from R&D), or VEGF121b(pp), or VEGF165b(pp). Blood vessels within the Matrigel plugs were identified by the presence of Alexa-647-labelled isolectin B4 (Figure 5A), which was injected systemically into the mice before the sacrifize. No signal from the Alexa-647-labelled lectin was observed in control Matrigels, whereas plugs carrying any of the VEGFxxxb isoforms showed a strong signal, thus demonstrating angiogenesis in vivo (Figure 5A). To analyze vascular permeability, FITC-labelled-dextran was injected in another set of mice with Matrigel plugs under similar experimental conditions (Figure 5B). Whereas almost no fluorescent signal was seen in control plugs, in Matrigels that were pre-loaded with bFGF or especially with VEGF121b, a dramatic increase in the fluorescent signal was found. Matrigel plugs carrying either VEGF165 or VEGF 165 b displayed a similar degree of fluorescence, which was approximately 10-fold higher than that of controls.",1
12,31,"A cell line with high (PC-3) and another one with low (A549) endogenous total VEGF expression levels were selected for in vivo assays (Figure 6A). VEGF 121/165 b isoforms were overexpressed in both PC-3 and A549 xenograft models in order to assess the effect of these isoforms in tumor growth and angiogenesis. Western blot analyses showed a high expression of either VEGF121b or VEGF165b in cell pools that were selected with G418 over a period of 20 days (Figure 6A). No statistical differences in tumor growth were seen between controls and tumors overexpressing either VEGF121b, or VEGF165b, or a combination of both in PC3 xenografts (Figure 6B). Moreover, VEGF121b-overexpressing cells tended to form bigger tumors than the rest of the experimental conditions (Figure 6B). In the case of A549 xenografts, significant increases in tumor volumes were found when cells with either VEGF 121 b, or VEGF 165 b were injected, in comparison with controls (Figure 6C). Therefore, overexpression of the VEGF121/ 165 b isoforms does not cause tumor shrinkage but tumor growth in these models.",1
12,32,"Analysis of angiogenesis revealed that A549 tumors were less angiogenic than PC-3 tumors with no differences between controls and the experimental groups (Figure 7). In PC-3, VEGF121b-overexpressing tumors showed a significantly higher (p < 0.05) vascularization than the other experimental groups (Parental, Mock-transfected and VEGF165b). To analyze a possible mural recruitment to the vasculature, levels of PDGFRb were analyzed by immunhostochemistry and image analysis. PDGFRs are expressed in pericytes and bone-marrow-derived cells that participate in blood vessel formation and coverage (22). Therefore, if VEGFxxxb isoforms alter the vascular wall, a decrease in PDGFRb+ cells should be found in comparison with controls. However, no such decrease was observed in either PC-3 or A549 xenografted tumors (Additional File 2 Figure S2). We also quantified the number of apoptotic cells in these tumors, since an anti-angiogenic effect of the VEGFxxxb isoforms should be translated into an increase in apoptosis. In A549 xenografts, no changes were observed in the number of active caspase-3+ cells (Additional File 2 Figure S2). In PC-3 xenografted tumors, not an increase but a reduction in the number of apoptotic cells was observed when VEGFxxxboverexpressing cells were injected, as compared to controls (Additional File 2 Figure S2).",1
12,33,"Previous studies had suggested that VEGFxxxb isoforms can be differentially expressed in normal vs. pathological conditions [13]. To study if this was the case for breast cancer, we used a TMA containing core biopsies from breast cancer patients and normal breasts. To this end, we used a well validated antibody that recognizes total VEGF-A (including all VEGF-A isoforms) (R&D systems) and the only available and validated anti-VEGFxxxb antibody that recognizes all the VEGFxxxb proteins (R&D systems) [18]. No available antibody specific for the “non-b” isoforms (VEGFxxx) is currently available.",1
12,34,"Figures 8A and 8B show representative images of malignant and normal breast tissues stained with the anti-VEGFxxxb and anti-total VEGF-A antibodies. Strong staining for VEGFxxxb could be seen in tumor cells of infiltrating ductal carcinoma (IDC) samples. Staining was also found for other types of tumors, including papillary carcinoma (Pap), phyllodes (Phy), infiltrating lobular carcinomas (ILC), and ductal carcinoma in situ (DCIS). No VEGFxxxb was detected in any of the normal breast tissue (NBT) samples. All tissues analyzed were positive for total-VEGF-A, including the normal breast epithelium. Semiquantification of the staining showed that both total VEGF-A and VEGFxxxb protein levels were significantly higher (p < 0.05) in IDC than in normal breast tissues (Figures 8C and 8D). A significant (p = 0.033) positive correlation index (r = 0.404) between VEGFxxxb and total-VEGF-A was found, thus indicating the degree of co-staining. Therefore, we conclude that VEGFxxxb levels are not reduced in malignant breast cancer but, on the contrary, tend to increase in the tumor samples and are significantly higher in infiltrating ductal carcinomas.",1
12,35,"The importance of VEGF-A in normal and pathological angiogenesis has been widely explored and documented in the last decades [6]. VEGF-A has become a major target for cancer therapy in solid tumors, and VEGFtargeted drugs, such as bevacizumab or sunitinib are currently being used in patients [9,10]. The biology of VEGF-A spliced isoforms is, however, poorly understood yet. In particular, understanding how the different VEGF-A isoforms are generated through alternative splicing may be important to design more specific and effective molecular therapies.",1
12,36,"In 2002, a new family of VEGF-A isoforms generated by alternative splicing was reported [14,19], which were denominated VEGFxxxb isoforms. These transcripts incorporate a different exon (called exon 8b, sequence SLTRKD) from the classical exon 8a (sequence CDKPRR) found in the angiogenic transcripts [19]. Inclusion of exon 8b was thought to endow VEGFxxxb isoforms with the capacity to bind VEGF-A receptors without strong downstream signalling activation [14]. Because of this property, the VEGFxxxb proteins were hypothesized to be antiangiogenic [14]. Although results have to be interpreted carefully, it was shown that overexpression of VEGF 165 b or VEGF 121 b in tumor cells xenotransplanted into nude mice results in growth inhibition [14,18,23-25]. Another interesting finding that was reported is that VEGFxxxb isoforms may be differentially expressed in pathological tissues compared to normal tissues [13,25,26]. Changes in the natural splicing would favor the amount of the VEGFxxx transcripts in some aberrant angiogenesis-linked diseases, at the expense of reducing the amount of the VEGFxxxb isoforms (mainly expressed in normal tissues).",1
12,37,"Because of the great potential importance of these findings, we aimed in the present study to produce VEGF 121 b and VEGF165b recombinant proteins in the yeast Pichia pastoris, with the goal of testing their antiangiogenic/antitumor properties in vitro and in vivo. Generation of VEGF121/165b-overexpressing cancer cells using the PCDNA3.1 plasmid was also used for this purpose. The yeast expression system was chosen for several reasons. First, this system allows protein glycosylation, and purification with little secretion of yeasts-derived endogenous proteins that may contaminate the recombinant protein of interest. Another advantage is that protein production is easier, faster and cheaper than that generated in mammalian systems. In addition, we made sure with this expression system that no exon 8-containing VEGF-A contamination is present, since yeasts do not code for any form of VEGF. Producing VEGF-A in mammalian cells has the drawback of possible formation of exons 8 and 8b heterodimers. This may be of special importance, since VEGF-A is secreted and active in its dimeric form [6].",1
12,38,"We have successfully produced recombinant VEGF121b and VEGF165b proteins that share similar structural characteristics to those of the classical VEGF121 and VEGF165 proteins: Ability to form dimers or multimers, and reactivity with commercial antibodies that were raised against exons 1 to 5 (common to all VEGF-A isoforms). In addition, both recombinant VEGF121b and VEGF165b proteins were immunoreactive with a validated antibody that recognizes exon 8b (from R&D [18]).",1
12,39,"To test the functionality of these isoforms in vitro, HUVECs were treated with recombinant proteins produced in yeasts, VEGF 165 b produced in mammalian cells, or the “classical” VEGF165 angiogenic protein (as control). All treatments were carried out in serum-free media. We found that VEGF121/165b isoforms induced proliferation of HUVECs and phosphorylation of VEGFR2 and its downstream transducer ERK. The effect of VEGF121/165b isoforms was milder than that found for VEGF165: Proliferation of HUVECs was ~50% less stimulated with VEGF 121/165 b isoforms than that using recombinant VEGF165. However, the degree of ERK activation was similar for all the proteins tested, 10 min after stimulation. This intracellular effector was phosphorylated specifically by VEGFRs, as demonstrated by the inhibition of such process in the presence of the VEGFR1 and VEGFR2 tyrosine-kinase inhibitor GW654652.",1
12,40,"Kawamura et al. [16] have demonstrated that VEGF165b displays unique functional characteristics. They showed VEGF165b to be a weak agonist of VEGFR2 and to induce its phosphorylation in HUVECs with a similar potency as VEGF145. Similarly to VEGF121, VEGF165b does not bind neuropilin-1 (NRP1) and failed to induce complexes between NRP1 and VEGFR2. VEGF165 b promotes cell migration (in PAE cells transfected with VEGFR2), similar to VEGF165, VEGF145, and VEGF121 isoforms. Resembling the activity of VEGF121 and VEGF 145, but unlike VEGF165, VEGF165b does not induce endothelial sprout. But unlike the other isoforms, VEGF165b was unable to phosphorylate the mouse VEGFR2 at the Y1052 position. Unfortunately, downstream signalling activation was not tested in this study [16]. Authors hypothesized that VEGF165b is not able to fully rotate the receptor’s intracellular tail upon binding, thus blocking to some extent transphosphorylation [16]. In addition, Glass et al. [17] have shown that VEGF165b activates transiently VEGFR1 in order to elicit vascular permeability in the mesenteric vein. Collectively, these and our results suggest that VEGF 165 b may exert weak downstream signalling in endothelial cells.",1
12,41,"To further validate the observation of VEGF 121/165b angiogenic properties seen in classical in vitro assays, we conducted in vivo experiments with Growth Factor Reduced Matrigel, in which VEGF, among other angiogenic cytokines, have been significantly depleted. Addition of recombinant VEGF 121 b, or VEGF 165 b, or VEGF 165 caused recruitment of blood vessels to the Matrigel compared to PBS-loaded controls, thus demonstrating an angiogenic effect. It is worth mentioning that VEGF121b-containing Matrigels were highly enriched in dextran-FITC signal, which seemed to be within and out of the vessels (similar to results found for bFGF). This suggests an increase in vascular permeability, in keeping with vascular permeability described for VEGF121 [27].",1
12,42,"The ability to inhibit tumor growth in vivo was tested in our study by VEGF121/165b overexpression in xenograft models. We chose two different cancer cell lines: The low-VEGF-expressing lung adenocarcinoma A549 cell line (~1-5 pg/mL (28)) and PC-3, a prostate cancer cell line that secretes ~800 pg/mL; [29]. These cell types were chosen to ascertain possible differences in the VEGFxxxb behavior depending on the endogenous VEGF expression. Experiments were performed without any further exogenous VEGF stimulation, such as transfection of VEGF. In the PC3 xenografts, no statistical differences between controls and VEGF121/165b-expressing tumors were seen. However, a tendency of VEGF121boverexpressing tumors to grow at a faster rate than the other groups was found. In agreement with these results, vascular density for VEGF121 b-overexpressing PC-3 tumors was significantly higher than that observed for the rest of the groups, and apoptotic levels significantly lower. A549 xenografts grew slow and formed small tumors after subcutaneous implantation in nude mice, as previously described [30].",1
12,43,"These results are in conflict with previous reports showing that VEGF 165 b causes anti-tumor effects [14,15,23,24]. Our interpretation for these seemingly contradictory results is as follows: The in vivo models in which the VEGFxxxb isoforms have been proven to be efficacious in reducing tumor growth expressed high VEGF levels (either by the nature of the cells used or by transfection with VEGF-carrying plasmids). In these conditions, both VEGFxxx and VEGFxxxb proteins would compete equally for receptor binding. Because VEGFxxxb is only able to signal weakly, a reduced tumor volume will be observed when tumors overexpressing VEGFxxxb are compared to high VEGF-expressing tumors. However, in the case of tumors with low VEGF production, overexpression of VEGFxxxb would stimulate tumor growth to a certain extent. Thus, in CAKI cells, where endogenous total VEGF levels are ~900 pg/mL [23], when both parental and VEGF165b-overexpressing cells were injected into mice, no differences in tumor growth were found. Only when parental cells were transfected with VEGF 165 , a reduction in tumor volume was observed compared to VEGF165b-overexpressing tumors [23].",1
12,44,"It is possible then that therapies based on the administration of VEGFxxxb proteins are effective in tumors with high endogenous VEGF expression. However, the use of this therapy in tumors with low VEGF levels, which likely rely on other angiogenic factors for their growth (such as bFGF, IL-8, etc.) may worsen the evolution of the tumor. Therefore, therapy with VEGFxxxb casts some doubts about its possible use in unselected patients. Caution must be taken in defining which possible patient will benefit from VEGFxxxb-based therapies. Stratifying the patients based on the amount of VEGF production may be critical for future possible clinical trials.",1
12,45,"But before translating this type of therapy, many aspects of the VEGFxxxb biology should be clarified. For instance, it is quite surprising that VEGF121b, although found to inhibit endothelial cell migration, was cytoprotective for endothelial cells (in serum starvation experiments), in a similar way as VEGF 165 [15]. Such cytoprotection involved activation of VEGF receptors and downstream signalling [15]. Even more surprising is the fact that in some xenograft models (for instance using CAKI cells), co-overexpression of VEGF165 and VEGF165b results in tumors that are smaller in size than those generated by overexpression of just VEGF 165 b [23]. Other issues, such as whether or not VEGFxxxb proteins are able to heterodimerize with members of the VEGFxxx angiogenic family, should be clarified as well.",1
12,46,"We have also addressed in this study the issue of whether the VEGFxxxb isoforms may be differentially expressed in malignant tissues (human breast cancer) compared to healthy tissues (normal mammary gland). For our experiments we used immunohistochemistry with validated antibodies specific for all VEGFxxxb isoforms and antibodies that recognize all VEGF transcripts. Our results revealed that both total VEGF and VEGFxxxb levels tended to increase in breast cancer samples (n = 50) compared to normal breast tissues (n = 8). This increase was statistically significant for intraductal carcinomas (IDC). Expression of both total VEGF and VEGFxxxb were significantly correlated, thus suggesting that both families of VEGF (VEGFxxx and VEGFxxxb) follow a similar pattern of expression.",1
12,47,"Previous studies have analyzed, in a limited number of samples, expression of the VEGFxxxb isoforms. Whereas total VEGF mRNA levels were found significantly upregulated in colon carcinoma samples (n = 6) compared to controls, no changes were observed for VEGFxxxb mRNA levels [18]. This result shows that the increase in total VEGF is due to the VEGFxxx angiogenic isoforms [18]. A similar result was found analyzing protein levels by isoform-specific ELISAs [18]. RT-PCR analysis showed that VEGF165b was present in 17 of 18 normal kidney samples, but only in 4 of 18 matched malignant tissues [19]. Immunohistochemical analysis of 19 melanoma samples (9 metastatic and 10 nonmetastatic) using the VEGFxxxb specific antibody, found a decrease in VEGFxxxb expression in the neoplastic tissue (especially in metastasis) compared to the normal skin [25].",1
12,48,"The lack of appropriate antibodies specific for each of the VEGFxxx and VEGFxxxb proteins hinders the fine characterization of the pattern of expression in malignant and normal tissues. Future studies using larger number of samples, and quantitative real time RT-PCR and immunohistochemical analyses would be needed to assess whether VEGFxxxb expression could be used as a cancer biomarker.",1
12,49,"Our results demonstrate that VEGF121/165b are not antiangiogenic, but weakly angiogenic isoforms of VEGF-A that may foster tumor growth and angiogenesis in vivo. We also conclude that VEGFxxxb isoforms (as well as total VEGF levels) are up-regulated in breast cancer in comparison with non malignant breast tissues.",1
13,1,"Severe acute respiratory syndrome (SARS) is an emerging infectious disease [1]. In contrast to most other coronaviruses, which cause mild infection, the new SARS-CoV has a high mortality rate. Because the re-emergence of SARS is possible due to existence of SARS-CoV like strains in animal reservoir, development of safe and effective vaccines is highly desired. The SARS-CoV genome is composed of single positive stranded RNA and encodes four main structural proteins including spike protein (S), membrane protein (M), envelope protein (E) and nucleocapsid protein (N) [2]. The S protein is involved in not only receptor recognition but also in virus attachment and its entry into target cells [3].",1
13,2,"In attempts to develop vaccines against various pathogens, research on DNA vaccine has been widely carried out. Using DNA vaccines, both humoral and cellular immune responses are induced [4]. A few studies demonstrated that DNA-based vaccines can induce protective immune response against several viruses [5,6]. However, one of the problems with DNA-based vaccines is that they are incapable of inducing immune response in mice when injected through the intranasal (i.n.) route [7]. In light of the fact that the entry of most respiratory diseases is through the mucosal surface, it is obvious and ideal that a vaccine should induce both systemic and mucosal immune responses. Secretory IgA plays a major role in mediating mucosal immunity [8]. Mucosal immune responses take an important role as a first line of immune defense system against influenza virus infection although parenteral immunization is not enough to provoke protective immunity [9].",1
13,3,"Polyethylenimine (PEI) has been widely used as the nonviral vector in vitro and in vivo due to high transfection efficiency and buffering capacity [10]. It has been shown that mucosal administration with PEI could function as a potent mucosal immunostimulator [11]. It has been revealed that PEI is a very effective gene delivery vehicle for lung transfection producing high antibody titers against the encoded protein [12]. In the present study, the immune responses in BALB/c mice immunized with SARS DNA vaccine via i.n. route have been examined.",1
13,4,"It is well known that transfection efficiency of gene carrier depends upon its ability to condense DNA into nano-sized particles [13]. As expected, PEI condensed DNA into nano-sized particles, suggesting their endocytosis potential (Figure 1A).",1
13,5,"The formation of PEI/pci-S nanoparticles was further confirmed by morphology observation. Representative energy-filtering transmission electron microscopy (EF-TEM) images of the PEI/pci-S nanoparticles at N/P ratio 10 are shown in Figure 1B. The nanoparticles were observed as spherical shape with around 200 nm size, which are similar to those measured by dynamic light scattering. It is notable that cytotoxicity of PEI was measured in RAW 264.7 cells after transfection with PEI/pci-S complexes by using MTT assay. The cell viabilities decreased slightly when the N/P ratios of PEI/pci-S complexes increased. When the N/P ratio was 10, the cell viability was 87.5 ± 7.3% (data not shown). In order to confirm PEI/pci-S uptaken by RAW264.7 cells, rhodamine labeled pci-S DNA was used to form the nanoparticles with the PEI and the complex was visualized by confocal microscopy. As shown in Figure 1C, the labeled nanoparticles can be seen in the cells, near to the nucleus. RT-PCR analysis showed both pci-S DNA and PEI/pci-S nanoparticles can transfect the cells. In fact, the PEI/pci-S nanoparticles induced much stronger S mRNA expression than that of naked DNA (Figure 1D).",1
13,6,"To evaluate the influence of PEI on adaptive immunity to SARS-CoV S protein, specific antibody responses were examined in mice immunized i.n. with SARS-CoV DNA vaccine. Immunization with PEI/pci-S complexes elicited high level of SARS-CoV S-specific-serum IgG antibody but not in mice immunized with SARS-CoV S DNA alone (Figure 2A). To access the balance of Th1/ Th2 response, SARS S-specific IgG1 and IgG2 were evaluated in immunized mice. SARS S-specific IgG1 antibody was significantly (P < 0.01) increased in mice immunized with SARS-CoV S DNA vaccine plus PEI whereas little increase was observed on SARS-specific IgG2a antibody production (Figure 2A), indicating Th2 dominant response. To examine mucosal antibody production, lung wash, nasal wash, fecal extracts, saliva and vaginal wash of immunized mice were collected. The result showed that SARS S-specific IgA antibody response was significantly (P < 0.01) increased in lung wash from mice immunized with PEI/pci-S complexes (Figure 2B).",1
13,7,"To assess B lymphocyte proliferation against SARSCoV spike protein, the notion that antibody responses enhanced was further confirmed by proliferation ability of B220+ cells at 1 week after the last vaccination. B220+ cells from mice immunized with PEI/pci-S complexes were highly proliferated after in vitro re-stimulation with SARS-CoV S protein (Figure 2C).",1
13,8,"The maturation of DCs is accompanied with enhanced expression of surface markers, including co-stimulatory and MHC class molecules. To examine the effect of DNA vaccination on DC maturation in vivo, mice were immunized i.n. with PEI/pci-S complexes. The surface expression of CD80 and CD86 co-stimulatory molecules were significantly (P < 0.05) higher on DCs from mice treated with PEI/pci-S complexes than those from SARS-CoV DNA S vaccine alone (Figure 3). MHC class II, I-Ad, expression was also up-regulated significantly (P < 0.05) in PEI/pci-S complexes group as compared with that of SARS-CoV DNA alone (Figure 3).",1
13,9,"To examine T cell immunity to SARS-CoV S DNA vaccine, cytokine profiles were examined by using intracellular cytokine assays. The cells were harvested from the lung at 6 days after the immunization. It has been suggested that T cells producing IFN-g, IL-2, IL-17, and TNF-a are especially effective in protective immunity [14]. Amount of IFN-g-producing cells were increased in CD4+ and CD8+ T cells from mice immunized with PEI/pci-S whereas IL-17-producing cells were increased only in CD4 + , not CD8 + T cells. It is notable that IFN-g + , IL-2 + and IL-17 + cells were not detected in CD8 + T cells from the mice immunized with PEI/pci-S complexes (Figure 4A and 4B). Re-stimulation with SARS-CoV S peptide induced the activation of cytokineproducing CD4+ and CD8+ T cells with a predominant production of TNF-a as well as TNF-a and IL-2 double cytokine-producing T cells in mice immunized with PEI/pci-S complexes (Figure 4A and 4B). Furthermore, IFN-g and IL-17 double cytokine-producing cells were found more in the PEI/pci-S complexes group while it was not detectable in pci-S group. It is to note that IL4-producing cells were detectable neither in the lung nor spleen (data not shown).",1
13,10,"In the twenty first century, SARS was the first emerging infectious disease that has seriously threatened public health and the economy throughout the world [1]. Over 8,000 people from 26 countries were infected with SARScoronavirus, resulting 774 deaths [15]. It has been shown that SARS-CoV spike protein (S) plays an important role in receptor recognition, virus attachment and its entry [16]. It represented one of the most important targets for the development of SARS vaccine [6]. To prevent and control SARS outbreaks, several vaccine studies based on the spike protein of SARS have been done including S protein vaccine, fragment DNA vaccine, full-length DNA vaccines and receptor binding domain [17]. DNA vaccine encoding full-length S protein has shown to induce humoral, cellular and protective immune responses against SARS-CoV [6]. In the current study, we evaluated the immunogenicity of a PEI/pci-S in mice through intranasal immunization.",1
13,11,"There have been several reports that PEI/DNA complexes enhance transfection efficiency in mammalian cells and augment immunogenicity [18]. In the present study, we have adapted this PEI/pci-S complex for mucosal DNA vaccination. The size of PEI/pci-S complexes appeared to be about 200 nm. The effect of PEI/DNA complexes on transfection, and gene and protein expression in RAW 264.7 cells were evaluated by measuring the expression of the mRNA and protein, respectively. This result, thus, let us move ahead to in vivo studies for mouse immunization via intranasal route using PEI/pci-S complexes.",1
13,12,"A number of studies attempted to develop SARS DNA vaccines, exclusively via systemic routes including intramuscular injection [19]. As SARS is a respiratory pathogen, among the SARS vaccine candidates, targeting intranasal immunization was likely to be more effective to induce protective immune responses against infection when compared with other delivery routes. Intranasal immunization of PEI/pci-S complexes induced higher antigen-specific serum IgG responses than pci-S alone. Coincidently, antigen-specific IgG1 was also dramatically increased when compared to IgG2a, suggesting Th2 dominant response. Also the immunization enhanced antigen-specific IgA response in bronchoalveolar lavage fluid and B cell proliferation after in vitro re-stimulation with the spike protein. In Garzon’s study, antigen-specific antibody and T cell responses have been dose-dependently increased in mice immunized with DNA vaccine up to 100 μg [20]. However, in our study each mouse was immunized with only 20 μg of DNA. Despite the small amount of DNA, it has induced not only systemic but also mucosal immune responses.",1
13,13,"DCs play a pivotal role for the effective induction of antigen-specific immune responses. DCs are found throughout the body and are considered as one of the first-line sentinel cells [21]. When DCs recognize pathogen-associated molecular patterns from microorganisms, DCs became mature and acquired capacity for the antigen presentation, concomitantly augmented the expression of MHC proteins [22], cytokines [23] and number of co-stimulatory molecules including CD80, CD83, and CD86 [24]. Thus, the maturation of DCs is essential for appropriate initiation of the subsequent adaptive immune responses [22]. In the present study, we demonstrated that the PEI/pci-S complexes increase the co-stimulatory and MHC class II molecules on DCs from cervical lymph nodes after intranasal immunization.",1
13,14,"The cellular immune responses are mediated by both CD4+ and CD8+ T cells. Functional study indicated that antigen-specific T cells produce cytokines including IFN-g, TNF-a, IL-2, and IL-17 after in vitro re-stimulation with SARS spike peptides. IFN-g is an effector cytokine, critical for activating macrophages and DCs and inhibiting viral infection [25]. TNF-a is a cytokine that probably regulates immune cells and inhibits viral replication [26]. IL-2 mediates the expansion of T cells and maintains memory T cells [27]. IL-17 mediates the production of antimicrobial peptide and immunoglobulin for neutralizing viral infection [28]. In the current study, we have shown that antigen-specific CD4+ and CD8+ T cells secreted IFN-g, TNF-a, IL-2, and IL-17 in nonlymphoid tissues such as lung. Furthermore multiplecytokine producing cells are increased in mice immunized i.n. with PEI/pci-S. It is probable that these cells are likely responsible for the protection when host is infected with SARS-CoV after the vaccination. In fact, it has been suggested that multi-cytokine producing antigen-specific CD4+ T cells are functionally superior on protection to single-cytokine producing cells [29]. There are several reports that multi-cytokine producing T cells have shown to correlate with protection against Leishmania major infection [30].",1
13,15,"PEI is effective in delivering DNA onto the mucosal surface, in maturation of dendritic cells and in improving the immunogenicity of the DNA vaccine. Our results indicated that PEI can be used as a vector for the mucosal delivery of DNA vaccine and play an important role in B cell and T cell immunities.",1
13,16,"The gene encoding SARS-CoV spike (S) protein without transmembrane domain (amino acids 14-1154) was synthesized. The sequence was codon optimized for mammalian cell expression and the natural signal sequence was replaced with the leader sequence of human tissue plasminogen activator (tPA). The tPA-S gene and pci-neo (Promega, Madison, WI) were digested with Nhe I and Not I. Then, the plasmid expressing SARS-CoV S protein was generated by ligation.",1
13,17,"PEI/pci-S nanoparticles were prepared by mixing polymer and pci-S DNA in a solution form at N/P (PEI/pciS) ratio of 10. The size of PEI/pci-S nanoparticles was measured by an electrophoretic light scattering spectrophotometer (ELS8000, Otsuka Electronice, Osaka, Japan). Morphology of the PEI/pci-S nanoparticles was observed by EF-TEM (LIBRA 120, Carl Zeiss, Germany).",1
13,18,"For cell uptake observation, pci-S DNA was labeled with rhodamine by using Label IT® Tracker™ CX-Rhodamine kit (Mirus, WI). RAW 264.7 cells were seeded in the plate. PEI/Rhodamine-labeled pci-S DNA nanoparticles were incubated for 1 h and washed. Then, they were mounted using ProLong ® Gold antifade reagent with DAPI (Invitrogen, Carlsbad, CA). The cell uptake images were observed by confocal laser scanning microscope (Carl Zeiss-LSM510, Thornwood, NY).",1
13,19,"The expression of SARS-CoV S was examined in RAW 264.7 cells at both transcriptional and protein level. The cells were transfected with naked pci-S DNA or PEI/pciS nanoparticles at N/P ratio of 10. The cells were lysed with Trizol or cell lysis buffer [31]. Reverse transcription (RT) were performed using Superscript III reverse transcriptase (Invitrogen). The resulting cDNA was amplified by PCR. The sequence of primers were as following; for pci-S, forward (CGT CGT GAA AGG CGA TGA TG) and reverse (CGA TGG TGT TGT TGC TGT AGG); for glyceraldehyde 3-phosphate dehydrogenase (GAPDH), forward (ACCACAGTCCATGCCATCAC) and reverse (TCCACCACCCTGTTGCTGTA). The RT-PCR products were analyzed by electrophoresis.",1
13,20,"For Western blot assay, equal amount of lysates was separated by SDS-PAGE and subsequently transferred onto a nitrocellulose membrane (Amersham Biosciences, Piscataway, NY). Membranes were blocked with 5% non-fat milk. Spike protein primary antibody received from Chiron and horseradish peroxidase-conjugated secondary antibody (Santa Cruz Biotechnology, Inc., Santa Cruz, CA) were incubated with the membrane, in turn. Antigen-antibody interaction was detected with an ECL fluorescence system. b-actin was used as a control.",1
13,21,"Six- to eight-week old female BALB/c mice (Orient, Korea) were anesthetized. Five mice per group were immunized i.n. with 20 μg of pci-mock, pci-S, or PEI/pci-S complexes in total of 25 μl ultrapure water on days 0, 14, 28, and 42. All studies were approved by IACUC at International Vaccine Institute (Seoul, Korea).",1
13,22,"Sera and mucosal samples were collected on day 6 or 7 after the last immunization. Blood was collected from the retro-orbital plexus. Fecal extracts were dissolved in phosphate-buffered saline (PBS) containing 0.02% sodium azide. For other samples, mice were anesthetized and vaginal washes were collected by pipetting with PBS. Lung washes were performed by repeated flushing and aspiration with PBS into the lungs. Nasal washes were collected twice by flushing with PBS through the nasal cavity.",1
13,23,"Microtiter plates (Nunc, Denmark) were coated with 2 μg/ml of S protein (Protein Sciences Corporation, Meriden, CT). Plates were blocked with 5% skim milk. Serum (1:20) or mucosal samples (1:2) except lung wash (no dilution) were diluted in the blocking buffer. Each 100 μl samples were applied into separate wells. Goatanti-mouse IgG, IgG1, IgG2a or IgA conjugated with horseradish peroxidase (Santa Cruz Biotechnology, Inc) in the blocking buffer was added to each well. Color was developed with TMB solution (Sigma) in dark. The reaction was stopped by 0.5 N HCl. The absorbance at 450 nm was measured in a microplate reader (Molecular Devices Corp., Menlo Park, CA).",1
13,24,"Mice were sacrificed on day 7 after the last vaccination and spleens were collected. Splenocytes were labeled with Carboxyfluorescein succinimidyl ester (CFSE) (Invitrogen) and stimulated with 2 μg/ml SARS-S protein for 5 days. B cells were stained with anti-B220-PerCP (BD Biosciences). The degree of proliferation was detected using flow cytometry, FACSCalibur (BD Biosciences). All cytometric data were analyzed by using FlowJo software (Tree Star, San Carlos, CA).",1
13,25,"Cervical lymph nodes (CLN) were removed on day 3 after the last vaccination. Single cell suspension was stained with following antibodies: CD11c-APC and CD80-PE, CD83-PE, CD86-biotin, or I-A d -biotin (BD Biosciences). The degree of expression was detected using flow cytometry, FACSCalibur. All cytometric data were expressed as MFI (mean fluorescence intensity) and analyzed by using FlowJo software.",1
13,26,"Lungs, removed from mice on day 6 after the last vaccination, were disrupted into single-cell suspensions. The cells were seeded onto 96-well plate at 2 × 10^5 cells per well and re-stimulated with SARS peptide (Peptron) at 5 μg/ml for 12 hrs. Intracellular cytokine staining assay was followed by the manufacturer’s instruction. The cells were stained with anti-CD4-PerCP and anti-CD8FITC together with anti-IFN-g-APC and -IL-17-PE, or anti-TNF-a-APC and -IL-2-PE (all from BD Biosciences). The percentage of cells with associated fluorescence was determined by using a flow cytometry, FACSCalibur. All cytometric data were analyzed by using FlowJo software.",1
13,27,Statistical tests were performed by using Student’s t test. P value less than 0.05 was considered significant.,1
47,1,"This study is an assessment of economic knowledge among students who receive formal economic instruction in their senior year of high school. Our sample was drawn from seven high schools in two large school districts in Orange County, California. Students were enrolled in the compulsory, semester-long economics course, a state requirement for high school graduation. Our key performance measure is the Test of Economic Literacy (TEL). Using a pretest–post-test design, we find that initial knowledge of economics is not strong among the students. After one semester of formal economics instruction, TEL examination scores improve by 12.3 percentage points on average.",1
47,2,"The need for improving economic and financial literacy is now being frequently discussed in the media, a sign that policy makers and educators are more aware of the importance of economic literacy for children, teenagers, and young adults. Evidence of this increased awareness can be found in the public attention given to the second and third National Summit on Economic & Financial Literacy [NCEE, March 2005 and February 2008]. Likewise, the academic literature has long emphasized the importance of economics education in high school [Walstad 1992; Salemi and Siegfried 1999; Walstad and Rebeck 2000; Walstad 2001], and there is a growing body of literature that investigates issues related to the teaching and learning of economics at the high school and college level [e.g., Becker et al. 1990; Harris and Kerby 1997; Lopus 1997; Melican et al. 1997; Allgood and Walstad 1999; Walstad and Rebeck 2001a; Belfield and Levin 2004].",1
47,3,"This paper presents results from our investigation of economic literacy among high school students in Orange County, California. Since 1985, California high school graduation requirements have included one semester of economics. The course is taken by students in their senior year in high school, and it exposes them to the basics of microeconomic and macroeconomic analyses. California is one of only 17 states [NCEE June 2007] that require formal principles of economics instruction at the secondary level. To our knowledge, there is no empirical study to date that focuses specifically on the effectiveness of formal economics instruction in improving economic literacy of high school students in the state of California. This study partially fills that gap.",1
47,4,"Our work contributes to two important policy issues. The first regards the efficacy of high school economics in improving economic literacy. As we discuss below, evidence at the national level supports the view that a high school economics course improves students’ performances on standardized economics tests. We sharpen the focus on this issue by adopting a single state, single county research design that includes a rich set of control variables from a survey that we designed, and from school records. The second policy issue concerns the effects of gender and ethnicity/ race on economic literacy. The literature, again mainly at the national level, finds significant gender differences in economic knowledge before an economics course is taken, but is inconclusive regarding gender effects on the learning of economics. A relatively scant literature finds differences in economic knowledge by race and ethnicity. We use our research design to study both gender and ethnicity effects on economic literacy both before and after students take their high school economics course.",1
47,5,"Our focus on a single state and single county has a number of advantages for the empirical investigation. The reasons for variations in student achievement in economics are complex and are likely to be related to funding issues and administrative decisions regarding emphasis placed on economics instruction that vary considerable by state, and by counties within a state. Our research design effectively controls for many of these differences and allows us to better isolate the role of student characteristics on achievement.",1
47,6,"Although, as detailed in the section Study Methodology, Data, and Characteristics of the Sample, practical limitations were externally imposed on our research design, the demographics of Orange County are also important to this study. First, data from the California Department of Education (www.cde.ca.gov) for 2003–2004 show that Orange County had the second largest grade 12 enrollments in the state of California, accounting for over 8 percent of all high school seniors in the state. Second, whereas California is known for its diverse population, Orange County is one of the most racially and ethnically diverse populations in the state, with higher percentages of Asian and Hispanic students enrolled in 12th grade than the corresponding percentages for the state.",1
47,7,"Evidence from the literature supports the view that having students take an economics course is more effective in improving economic literacy than ‘‘infusing’’ economic content in the K-12 curriculum [Walstad 2001]. Using a sample of students from the second revision of the Test of Economic Literacy (TEL), Walstad and Soper [1989] report that students enrolled in an economics course scored higher on a post-test than students enrolled in social studies classes with no economic content, and scored higher than students enrolled in classes with some economic content. Becker and Walstad [1990], using the same data set, found that controlling for selection bias increased the marginal effect of the economics class on post-test performance. Walstad and Rebeck [2001a] and Lillydahl [1990], likewise, find that, nationwide, students enrolled in an economics course obtain the highest scores on the TEL multiple choice examination.",1
47,8,"Studies that explore differences in economic literacy by gender have also appeared in the literature. In a frequently cited article, Siegfried [1979] reviews the literature on a gender gap in students’ performance. He reports that in most cases there is a statistically significant, although often small, male advantage over females in the understanding of economics measured at a specific point in time. More recent works have largely confirmed that a gender gap favoring males exists in students’ point-intime measures of economic knowledge in high school [Watts 1987; Heath 1989; Walstad and Soper 1989; Evans 1992; Walstad and Robson 1997].",1
47,9,"Siegfried also suggests that strong evidence does not exist on the inferiority of women in learning economics, once other measurable factors affecting economic understanding and knowledge accumulation are considered. When a pretest–posttest design is used to measure improvements in economic knowledge, and therefore learning, often the female initial disadvantage does not increase overtime, implying that males and females learn at similar rates. Similar results emerge from more recent literature. Studies by Jackstadt and Grootaert [1980], Watts [1987], and Allgood and Walstad [1999] find insignificant effects of gender on learning economics. A different result concerning differentials in learning outcomes is obtained by Walstad and Soper [1989] and then replicated in a study by Becker and Walstad [1990]. The authors find that there are indeed statistically significant differences in learning rates favoring males.",1
47,10,"Less attention has been given to the effect of race and ethnicity on test scores. Evans [1992] and Harris and Kerby [1997] control for both students’ race and ethnicity in their analyses. Evans finds that black students score significantly lower than whites, while Hispanics are at no significant disadvantage. Harris and Kerby find that black students are at a significant disadvantage with respect to white students, and that both Hispanics and Filipinos have significantly lower test scores than whites. Asians students score higher than white students, but the difference is not statistically significant. Walstad and Soper [1989] find that black students perform worse than other students on the TEL. In 2007, the US Department of Education’s National Center for Education Statistics published results of their first national assessment of economic literacy in grade 12, reporting that a larger percentage of blacks and Hispanics performed below basic level than did whites.",1
47,11,"There are 15 school districts in Orange County, California, all under the auspices of a county superintendent. We contacted the county superintendent’s office and obtained a complete list of high schools in Orange County, along with contact information for each district’s superintendent. The assistant superintendent for the county sent a letter expressing support for our project to the offices of the districts’ superintendents.",1
47,12,"We made repeated appeals to the districts’ superintendents to enlist their support for the project. In the end, two large school districts, Fullerton and San Juan Capistrano, agreed to work with us. Seven schools from these districts participated in the study, and there were 1,343 students enrolled in the one-semester, senior year compulsory economics courses offered at these schools for Fall 2005. Virtually all the studies done on economic education at pre-college and college level suffer from similar limitations in their sampling procedures, regardless of the size of the sample or the financial resources available to the researchers [e.g., Walstad and Soper 1988, p. 28; 1989, p. 24]. It is also important to note that the 1,343 figure reported above represents the number of students enrolled in the classes surveyed as of the census date. As later explained, the actual number of students who attended classes and for whom we have complete data was smaller.",1
47,13,"Our key performance measures to assess initial economics knowledge and subsequent learning are students’ scores on the TEL, administered to the students in the sample in the first week of their semester of economics course work (pretest) and again in the last week of the course (post-test). The TEL is a nationally-normed, standardized test developed by the National Council on Economic Education [Walstad and Rebeck 2001b], and it is the accepted standard for testing pre-college economic literacy. The test consists of 40 multiple choice questions on basic core, micro, macro, and international economics concepts.",1
47,14,"To analyze students’ performance on the TEL examination, we needed information on students’ characteristics. We gathered demographic, family background, and academic performance characteristics from a student questionnaire that we designed [Appendix A] and from official school records. From the questionnaire we obtained information about students’ race, ethnicity, and gender, their primary language, hours they work per week at jobs outside of school, the number of hours per week they devote to their studies, and the educational background of their parents. From official schools’ records we obtained students’ academic (excluding physical education) grade point averages (GPAs) prior to the start of the Fall 2005 semester.2 From some schools we also obtained students’ standardized mathematics and reading scores. As mentioned, the pretest was administered to students prior to the start of their mandated economics course. No student had received formal economics instruction prior to taking the pretest. Our survey instrument was administered during the first two weeks of classes.",1
47,15,"Table 1 presents descriptive statistics. The descriptive statistics are based on a sample of 514 students for whom we had complete information on test scores and survey responses to carry out the multiple regression analysis of pretest and post-test scores presented in the section Analysis of Test Scores. The reduction in sample size is caused primarily by students never attending the class, withholding information on individual questions, or by students being absent from class on the day the pretest, post-test, or survey were administered.",1
47,16,"The first column of Table 1 lists students’ demographic characteristics, family background characteristics and academic performance and work effort characteristics, including pretest and post-test TEL scores. The second column of the table gives frequency distributions for the categorical variables and means and standard deviations for the continuous variables. As shown, our sample contains a larger proportion of females than males (53.9 percent vs 46.1 percent), with about 70 percent of the student population being white, 17.7 percent Hispanic, and 5.3 percent Asian. About 4 percent of the students in the sample report a language other than English for reading, writing, and speaking; 9 percent of our students are foreign born and 10.6 percent of them speak a language other than English at home. Our data indicate that a higher percentage of fathers are college educated than are mothers, and that 73 percent of the students in our sample live with both their mothers and fathers most of the time.",1
47,17,"The last part of Table 1 summarizes students’ characteristics on academic performance, work effort, and test scores. The mean academic GPA is 3.02, with 65.4 percent of students reporting they took at least one advanced placement or honors class in high school. In addition, 21.2 percent of the students were enrolled in an economics class taught at the advanced placement level. Mean mathematics and reading scores are 246 (out of a possible 300) and 230 (out of a possible 300), respectively.4 Students, on average, devoted a little less than 9 hours per week to their studies and about 10.4 hours per week to work for pay. Finally, the TEL scores indicate that students’ mean scores increased from 52.9 percent of questions answered correctly on the pretest to 65.2 percent of questions answered correctly on the post-test.",1
47,18,"Since both pretest scores and student characteristics’ determining pretest scores are included in the post-test regression, we interpret the coefficients for the student characteristics in the post-test regression as the marginal impacts of these characteristics on post-test scores, net of their effects on pretest scores. That is, we are interested in how these variables affect the value-added from economics instruction.",1
47,19,"Table 2 provides information on pretest scores and changes in test scores by race and ethnicity, gender, and academic performance. The first two rows of the table show sample means for students’ pretest scores and the difference between the pretest and post-test score organized by race and ethnicity. African-American students are excluded from this analysis because we lacked a sufficient number of observations to carry out our tests. Rows three and four, and rows five and six, respectively, provide the same information broken down by gender and by whether students had taken an advanced placement or honors class. Probability values for univariate tests of significance in each case are displayed in the table.",1
47,20,"Table 2 also shows that there are statistically significant, though small, gender differences in pretest scores. On average, male students outscore female students by about 3.5 percentage points. Walstad and Rebeck [2001b] report a 4 percentage point gender gap favoring males among students without formal economic education. Finally, students who reported taking at least one advanced placement or honors class performed better on the TEL than students who had not. Similar results are reported by Evans [1992] and Walstad and Rebeck [2001a, b].",1
47,21,"Turning first to the results on pretest scores in Column 1 of Table 3, we find, consistent with the univariate tests reported in Table 2, that Hispanic and Asian students’ pretest scores are significantly lower than the TEL scores for whites, the reference category. Yet, in the multiple regression analysis, the white–Hispanic gap in scores falls noticeably (from about 11 percentage points in Table 2 to about 7 percentage points in Table 3). Thus, it appears that the lower performance of Hispanic students compared to white students can be explained in part by differences between the groups in family background, performance and work effort characteristics. Our results show a large negative effect for African-American students (11.12 percentage points), but we view this result and the result for Asian students with caution, as our subsamples of African-American and Asian students are small.",1
47,22,"The gender effects reported in Table 3 tell a different story. Column 1 gives a gender effect of 6.4 percentage points favoring males. This is 83 percent higher than the gender differential reported in Table 2. A likely reason for this result is that males lag behind females in academic performance characteristics, yet despite this disadvantage they outperform females on the TEL. Therefore controlling for academic performance characteristics increases the male–female gap in test scores.",1
47,23,"Additional results indicate that students who report English as their primary language for writing and speaking score about 5 percentage points higher on the pretest, and students who report living with both parents score about 3 percentage points higher. Academic performance is, as expected, an important predictor of success on the pretest: a one-point increase in academic GPA is associated with 9.12 percentage point increase in pretest scores. In addition, students taking an advanced placement economics class score nearly 4 percentage points higher on the pretest. The variable controlling for whether students ever had an advanced placement or honors class is insignificant in the pretest regressions.",1
47,24,"Adding math and reading scores to the pretest regression (Table 3, Column 2) does little to change the estimated ethnicity and gender effects reported in Column 1. A ten point increase in reading scores increases pretest scores by a little over 4 percentage points. Including mathematics and reading scores reduces the impact of academic GPA from 9.12 percentage points to 7.42 percentage points. The impact of being currently enrolled in advanced placement economics, on the other hand, increases from 3.88 percentage points to 5.78 percentage points.",1
47,25,"Our results confirm previous findings on the determinants of student’s stock of economic knowledge in high school. As we indicated in the section The Literature, Watts [1987], Walstad and Soper [1989], Heath [1989], Evans [1992], all report statistically significant differences by gender favoring males, though, with the exception of Heath, our gender effects are larger. Previous studies also obtained results similar to ours for the effect of variables measuring academic ability, such as GPA or AP courses. Jackstadt and Grootaert [1980], for example, find that grade level, GPA, and holding a part-time job, are all variables that significantly affect students’ scores. As for the effect of ethnicity on students’ scores, Harris and Kerby find that both Hispanics and Filipinos have significantly lower test scores than whites (1.47 points and 2.34 points, respectively on multiple choice exams). If anything, our single county focus suggests even larger ethnicity and gender differences in pretest scores than those indicated in most of the previous studies, though we acknowledge that our results for Hispanic students, in particular, may be picking up an effect specific to Orange County.",1
47,26,"For the high school students in our sample, initial knowledge of economics is not strong. As indicated by descriptive statistics, white students obtained the highest pretest TEL scores (55.5 percent), followed by Asians (48.9 percent) and Hispanics (44.1 percent), and males outperformed females by about 3.5 percentage points (54.8 percent and 51.3 percent, respectively). When we analyze the determinants of pretest scores, we find significant differences by ethnicity and gender. For Hispanic students the gap with whites in pretest scores is reduced, but not eliminated, when we control for academic performance and family background characteristics.",1
47,27,"The gender differences we report on pretest scores are intriguing. The overall differences in initial economic literacy favoring males are small, yet the gap widens when we control for academic performance characteristics. Females seem to underachieve in economics relative to their performance in other subjects. One could speculate that more frequent exposure of young girls to the economic way of reasoning at younger ages could make a difference. In general, academic performance, as reflected in GPA and in standardized mathematics and reading scores, is an important determinant of pretest scores.",1
47,28,"Finally, we find evidence that teacher quality may be very important in determining students’ learning. We show that the teacher-specific effects are, for the most part, large and statistically significant. While we cannot rule out that there may be common unobservable (or observable) student characteristics by classroom that lead to peer effects, we believe that teacher quality plays a significant role in determining changes in students’ test scores.",1
47,29,"Our results by ethnicity and gender do suggest venues for effective policy intervention. The results indicate that raising the economic literacy of Hispanics to the level of whites has a lot to do with factors affecting the overall academic performance of Hispanics relative to whites. Thus, if the aim is to improve the economic literacy of Hispanics, attention should be given to improving learning for this group in all subjects, including economics, at younger ages. The fact that there is a white–Hispanic difference in pretest scores after controlling for academic performance characteristics leads us to speculate that there may be important differences between whites and Hispanics in early exposure to economic concepts, perhaps having to do with lower income and other background and community characteristics. Similarly, females enter 12th grade with less economic knowledge than their male peers, particularly relative to their overall academic performance.",1
47,30,"To conclude, our analysis of 12th graders’ entry-level knowledge of economics, although limited in geographical scope, suggests that more should be done throughout the K-11 school curriculum to foster basic economic literacy. Since 1998, the California History/Social Science Standards do include an Economics Strand across the K-12 curriculum, therefore requiring ‘‘infusion’’ of basic economic concepts and economic way of thinking over the course of 11 school years, culminating in the one-semester economics course required for high school graduation. Despite the ‘‘infusion’’ requirements, we find that economic literacy among young Californians is not strong upon entering 12th grade. On the other hand, we do find that 12th grade formal economic instruction does improve students’ economic literacy.",1
48,1,Classical economists attached dominant importance to issues of capital accumulation and growth. It may be no exaggeration to say that this emphasis on growth and accumulation dates from Adam Smith’s Nature and Causes of the Wealth of Nations. It has been widely observed that in the Wealth of Nations Smith has a highly formal account of economic development in which some economic forces interact and lead a commercial economy to move forward in the dynamic process.,1
48,2,"Yet, this is only part of the story with regard to the issues of economic evolution. In order to understand it we also need to look at the study of history. For Smith, the study of history also remains a basic necessity for the science of man and society. The historical study becomes a tool with which to construct a coherent system of social science. In this regard it should be recalled that Smith provides a historical account of social progress from the rise and fall of feudal society to the emergence of modern European states in Book III of the Wealth of Nations.",1
48,3,"In his essay on the history of astronomy, Smith notes that science seeks to identify mechanisms that give power to event regularities between phenomena. In Smith’s words, the mission of scientists is to find out ‘the connecting principles of nature’ or ‘the invisible chains which bind together all these disjointed objects’ (Smith 1980: 45). The same applies to moral philosophy. It is noted in the Wealth of Nations that moral philosophy is the ‘science which pretends to investigate and explain those connecting principles’ (Smith 1776: 769). Complying with the task of scientists thus defined, Smith tried to uncover the ‘chains and mechanisms’ or ‘connecting principles’ from which it would be possible to draw inferences on events in the social arena. This is why today Smith’s moral philosophy, which includes natural theology, ethics, jurisprudence, and economics, is often depicted as a system of social science.",1
48,4,"Indeed, this has led a number of commentators to support the view that Smith’s historical account is to be understood, not as a form of idiographic approach but rather as that of nomothetic approach to history. This means that history is considered less as a body of work that deals with a narrative description based on the collection and arrangement of past events, and more as that which starts from a theoretical framework established in the beginning by which systematic examination may be made of main issues in history. It has been therefore pointed out that Smith’s historical discourse proceeded ‘from the system to the facts,’ not vice versa, and the use of historical evidence was made to illustrate and sustain his theory.",1
48,5,"What has been so interesting to Smithian scholars is that this led Smith to state strikingly that the actual course of economic development in Europe was ‘entirely inverted’ (Smith 1776: 380). Indeed, Smith devoted the remaining chapters from two to four of Book III to accounting for why that divergence happened. This has led some of commentators to argue that Smith failed to reconcile historical experience with his theoretical argument in history.",1
48,6,"However, it is now important for the present purpose to observe that the theoretical history of progress depicted in the first chapter of Book III is built upon a kind of economic theoretical modeling with a set of institutional, legal and political conditions given or assumed as constant.",1
48,7,"There may be another, rather extended dimension to Smith’s theoretical history of economic progress. That is to say, we may suppose that the nomothetic mode grounded in an economic modeling may be extended to a politico-economic modeling, in which the set of principles (such as the structure of legal rules and incentives) to be considered at the level of the polity can be introduced, thus allowing the interplay with economic forces. In our view, this is what Smith attempts through most of Book III and Book IV of the Wealth of Nations, although at a glance such a story of the theoretical history of economic change does not clearly come into view.",1
48,8,"Firstly, it needs to be recalled that, for Smith, political economy is not a subject that concentrates on purely economic questions with no political activities working on them. According to him, it was ‘a branch of the science of a statesman or legislator’ (Smith 1776: 428) or the theory of natural jurisprudence that may be named today as a theory of the state. Natural jurisprudence was thought to be ‘a theory of the general principles which ought to run through and be the foundation of the laws of nations’ (Smith 1759: 341).",1
48,9,"This observation implies that Smith may have a politico-economic model in economic history, where Smith’s theories of the state and positive economics act as a subtheory respectively. As Smith’s historical account of the actual progress in Europe shows, the politico-economic model tells us that while the polity and the economy interact in the system, any governmental actions, and legal institutions set up by public policy will surely affect economic performance, whether or not favorable or unfavorable.",1
48,10,"It should be borne in mind that Smith was well aware that there are a number of forces at work that will have effects on the stagnation and progress of wealth in the real historical process. Therefore, he often indicates that defense, culture, climate, terrain, and even chance might be factors that influence economic performance and social change.",1
48,11,"As it is well known, the principle of self-love or ‘the desire of bettering our condition’ is especially noted as ‘a desire which, though generally calm and dispassionate, comes with us from the womb, and never leaves us till we go into the grave’ (Smith 1776: 341). Smith therefore argues that this principle of human nature is the engine driving humans to bring about savings at the individual level and capital accumulation at the aggregate level, so that it helps lead to the higher employment and national income.",1
48,12,"Second, it ought to be observed that Smith incorporates into his account of economic history an analysis of institutional factors such as political rules, property rights and contracts, which are altogether run and enforced by the state. Actually, human institutions managed by the state are formal constraints to everyday life and so act as a primary agent of human interaction. For instance, a type of polity and a structure of property rights positioned in a just and proper way may allow individual actors to enjoy security for industry or have an incentive to economic activities, and thus seek a more productive use of limited resources.",1
48,13,"From Book III, Chapter 2 of the Wealth of Nations onwards, Smith describes the progress of wealth and the transition to the modern economy, which really happened in Europe after the fall of the Roman Empire. Smith states that what happened at that time was to see an agricultural stage. Therefore Smith’s historical description starts from the evolutionary process of agriculture.",1
49,1,"This study aims at assessing to what extent institutional environment is responsible for worldwide differences in economic growth and economic development. To answer this question, we use an innovative approach based on a?new concept of the institutionsaugmented Solow model which is then estimated empirically using regression equations. The analysis covers 180 countries during the 1993–2012 period. The empirical analysis confirms a?large positive impact of the quality of institutional environment on the level of economic development. The positive link has been evidenced for all five institutional indicators: two indices of economic freedom (Heritage Foundation and Fraser Institute), the governance indicator (World Bank), the democracy index (Freedom House), and the EBRD transition indicator for post-socialist countries. Differences in physical capital, human capital, and institutional environment explain about 70–75% of the worldwide differences in economic development. The institutions-augmented Solow model, however, performs slightly poorer in explaining differences in the rates of economic growth: only one institutional variable (index of economic freedom) has a?statistically significant impact on economic growth.",1
49,2,"There are many factors that affect the pace of economic growth and the level of economic development, both from the theoretical and empirical perspective. Using one of the classifications, the factors can be divided into two groups: the demand-side and the supply-side determinants. The first group encompasses the components of aggregate demand, i.e. investment expenditures, government spending on goods and services, and net exports (consumption may be omitted because it is not an autonomous factor due to its direct dependence on output). The second group of factors includes the supplyside determinants which affect potential output; among these variables one may include physical capital, human capital, labor, and technology. Of course, both demand-side and supply-side variables can be more disaggregated, including various types of investments or government spending, or many more types of capital. All these factors (both demandside and supply-side) can be called direct ones because they immediately transform expenditures or inputs into output.",1
49,3,"Economic growth and economic development both depend, however, not only on these direct determinants but also on deep factors of production. Deep factors affect direct determinants and in this way they influence macroeconomic performance. Deep determinants are institutions that allow for interactions between output and measurable inputs.",1
49,4,"The role of institutions in the process of economic growth and economic development is enormous. However, when assessing the impact of institutions on economic growth, the following questions or problems arise: first, which institutions are the most important growth factors; and second, how to measure institutions quantitatively in order to include them in empirical studies. The difficulty in answering these questions implies that there is still much room for theoretical and empirical studies that examine the relationship between institutions and economic growth.",1
49,5,"The term ‘institution’ is very broad. There are a? huge (perhaps almost infinite) number of variables that represent some kinds of institutions. For example, Sulejewicz [2009] provides many different concepts of institutions. Persson [2010] states that institutions are the rules of the game; some are upheld by law, others by mutual and spontaneous consent and a?few by the (brute) force of privileged elites. Some institutions are informal, such as trust and commitment, while others—the limited liability corporation for example—needed coordinated action by lawmakers to get established. Rodrik [2007] points out that markets require institutions such as property rights, regulatory institutions (regulating conduct in goods, services, labor, assets, and financial markets), fiscal and monetary institutions for macroeconomic stabilization, institutions for social insurance, and institutions of conflict management (e.g. rule of law, a?highquality judiciary, representative political institutions, free elections, independent trade unions, social partnerships, and institutionalized representation of minority groups).",1
49,6,"Research hypotheses and the objectives of the paper refer to the following aspects. The first aim of the paper is to extend the neoclassical growth model to include institutions. Second, the study aims at assessing empirically the impact of institutions on economic development of the countries in the world. Third, the paper examines the empirical impact of institutions on the worldwide level of economic growth. Our fourth goal is to estimate the production function based on these results.",1
49,7,"Since it is impossible to include in one empirical analysis all the possible types of institutions, it is necessary to introduce some constraints as to the number and the type of institutional indicators. Hence, the study focuses on the following indices that represent various areas of institutional environment: index of economic freedom, governance indicator, democracy index, and transition indicator. Economic development is measured by the level of GDP per capita at PPP while economic growth is its growth rate. Our study covers 180 countries but the particular models may be estimated based on a?lower number of countries, depending on data availability.",1
49,8,"The paper is composed of five points. In the following point, which appears after the introduction, we present the methodology by providing a?concise description of the Mankiw-Romer-Weil model and the institutions-augmented Solow model, and we review the literature, describing other selected empirical studies on institutions-growth nexus. The next section describes the data used. Then, the results of the analysis are presented and discussed. The last point is the conclusion.",1
49,9,"In this section we compare the Solow model extended for human capital, i.e. the Mankiw-Romer-Weil (MRW) model, with our own concept of the institutions-augmented Solow model. For the sake of conciseness, only the most important assumptions and implications are presented here; some issues are examined more deeply by Próchniak [2013].",1
49,10,"Equation (21) shows that, according to the institutions-augmented Solow model, economic growth depends on institutions as well as standard factors. The better institutions are, the more rapid is economic growth. Estimating equation (21) using linear regression allows us to check empirically the impact of institutions on economic growth. Of course, some assumptions as to the specification of the regression model and the methods of estimation have to be imposed. For example, Bia?owolski, Kuszewski, and Witkowski [2010] assume that all the macroeconomic relationships are linear.",1
49,11,"This way of finding economic growth determinants, namely the estimation of the regression equation, is not the only way of finding the variables that affect economic growth. Another type of research aiming at verifying growth determinants is the growth accounting exercise. Growth accounting is an empirical exercise aimed at calculating how much economic growth is caused by changes in measurable factor inputs (such as labor, physical capital, or human capital) and in the level of technology. The unexplained part of economic growth, measured as a?residual, is called the Solow residual and it is interpreted as the proxy of technical progress or the increase in total factor productivity (TFP). Estimation of the regression equation and carrying out the growth accounting framework involve different econometric methodology and they cannot be directly compared because based on this study, we cannot easily state which portion of the Solow residual is attributed to institutions and which to elements other than institutions. For the studies in which a?growth accounting exercise is carried out, see e.g. Rapacki and Próchniak [2006].",1
49,12,"Since there is no unique method to measure institutions, in the literature we find a?lot of empirical studies that analyze the relationship between institutions and economic growth (or economic development). There number of these studies is too high to discuss even a?small portion of them in one paper. For the sake of conciseness, we limit ourselves to presenting a?brief comparison of selected empirical studies in Table 1. In the quoted studies, the authors analyze the impact of institutional environment on macroeconomic performance. Most of the institutional indicators are related to economic freedom, the level of democracy, and political stability.",1
49,13,"The literature review shows a?huge diversity of the methods of analysis, including various theoretical models, various institutional indicators, various samples of countries and time periods, as well as various ways of econometric modeling. Despite the fact that some clear tendencies appear (such as the positive impact of economic freedom on economic growth), some other questions are not yet resolved (e.g., whether the impact of institutions on growth is linear or nonlinear). Hence, there is still much room for the empirical studies on the relationship between institutions and economic growth. In this paper we would like to test the appropriateness of the institutions-augmented Solow model in explaining differences in the rates of economic growth and in the levels of economic development and, based on these results, to estimate the macroeconomic production function.",1
49,14,"In this section, we verify the validity of the institutions-augmented Solow model to explain the differences in economic development and economic growth between the countries. We begin the analysis with the determinants of economic development. Then we switch to the analysis of economic growth determinants.",1
49,15,"The data in Table 2 indicate that the institutions-augmented Solow model performs extraordinarily well in explaining worldwide differences in income levels. Regardless of the institutional indicator, all the regression equations have very high R-squares while estimated coefficients, in terms of their sign and significance, correspond to our expectations and the theoretical analysis. For example, variant A?indicates that differences in physical capital accumulation, human capital accumulation, population growth, and the scope of economic freedom (measured by the Heritage Foundation index of economic freedom) explain about three-fourths of worldwide differences in economic development. All the explanatory variables are statistically significant (but the sign for population growth is, contrary to the theory, positive). If we use another index of economic freedom as the institutional indicator, compiled by Fraser Institute, the results are similar in terms of explaining worldwide income level differences (R-square is about three-fourths); physical capital, however, becomes an insignificant variable, but human capital and institutions retain their significance. In variant C, in which the institutional variable is the world governance indicator compiled by World Bank, the results are similar to those in variant B (high R-square, significant explanatory variables except physical capital which is completely insignificant).",1
49,16,"According to the theoretical analysis, the relationship between the rate of economic growth and the initial GDP per capita level should be negative. Such a? phenomenon confirms the existence of convergence. The appearance of the catching-up effect leads to diminishing income differences between countries. As regards the other economic growth determinants, the impact of physical capital and human capital accumulation as well as that of institutions on the rate of economic growth is positive while the relationship between population growth and output dynamics should be rather negative.",1
49,17,"Hence, our analysis shows that the Solow model extended for institutional variables is better in explaining worldwide differences in economic development than differences in economic growth rates. This results from the fact that the institutional environment as well as the other two variables representing inputs (investment rate and human capital accumulation) are related to the supply side of the economy and influence potential output to a? large extent. Indeed, the theoretical analysis of the Solow model associates output with potential output. Meanwhile, economic growth rates of the countries in the world, in our opinion, are influenced by many demandside factors as well as the other forces implying that they do not well reflect fluctuations in potential output. Hence, our institutions-augmented Solow model better explains differences in economic development than in the rates of economics growth. Another explanation refers to the fact that institutional variables exhibit rather long run effects. The current level of economic development is the result of a? long run behavior of a? given economy and that is why institutional variables may explain it well. Conversely, economic growth, even averaged over a?number of years, does not reveal long-run tendencies and that is why institutional variables may provide a?weak explanation.",1
49,18,"When interpreting the results, the theoretical causal relationship between explanatory variables and the level of economic development is assumed to be as follows: past values of explanatory variables affect the current state of development. In reality, many macroeconomic relationships have mutual causality, which is partly caused by the fact that some variables are endogenous by nature. For example, rich countries may also have greater opportunities to save, to invest in human capital, and to have friendly regulations and institutions just because they are rich. An endogenic approach requires, however, more in-depth analysis, with more advanced econometric techniques, which could be a?subject for further research.",1
49,19,"The above formulas seem to yield slightly contradictory results. The first one emphasizes a?significant role of human capital in the process of economic development while the latter one gives more importance to physical capital accumulation. This outcome may be explained by the fact that the former formula was obtained based on the determinants of economic development. In explaining differences in economic development, human capital is more important. The level of economic well-being is the result of the long-term process of economic growth which depends to a?large extent on human capital accumulation over the past decades. Therefore, the countries which are human capital abundant achieve higher levels of economic development.",1
49,20,"On the other hand, in the process of medium-term economic growth physical capital seems to be more important. It is investment in physical capital rather than investment in human capital which leads to an immediate acceleration of economic growth. The effects of human capital accumulation take more time and that is why in the process of economic growth physical capital is a?more significant variable. This view is also shared by some models of economic growth (e.g. the Uzawa-Lucas model) which states that the pace of economic growth of a?given less-developed country depends on whether this country is physical capital scarce or human capital scarce.",1
49,21,Our results imply that institutions are important in forming GDP regardless of the model. Institutional elasticity of output equals 0.55 or 1.05 on average indicating that institutions are one of the most important factors determining output. Most of the individual models also confirm this view.,1
50,1,"An economic man, i.e., the leading role in economic ethics, has been deeply investigated in our study considering a human being’s economic behavior and the hypotheses for an economic man in traditional economics based on M. Weber’s and S. N. Bulgakov’s Christian economic man. Among various channels to study business ethics and economic ethics, we chose the definition of an economic man given by Weber and Bulgakov to review a hypothesis about a rational economic man in economics and discussed L. von Mises’s and A. Sen’s contentions for an economic man’s substantive freedom and innermost being. The issue deserved to be further investigated by scholars who concern business ethics and economic ethics consists in reconciling egotism and altruism commonly embedded in an economic man’s heart and boosting more altruistic economic men.",1
50,2,"In the late 19th century, China faced the capitalist powers of Europe and America and the challenge of Western civilization. China first took note of the West when it was unable to counter its military might in the form of ships and guns. It then observed the advantages of laws and institutions of the Western capitalist countries, and finally started to realize how it would affect its own cultural heritage and civilization. Therefore, Neo-Confucianism reinvents the concept of ‘‘external enrichment’’ of traditional Confucianism, and by understanding its transitional process from the ‘‘internal tradition’’ to ‘‘external enrichment’’ proposed by Confucianism, it hopes to harmoniously blend Confucianism, capitalism, and democracy. Similarly, when Peter the Great westernized Russia, the amalgamation of Russian and Western civilizations was an important issue for the Russian educated circles. In the early 20th century, Russia chose the path paved by Lenin’s Bolsheviks, and the issues of the ‘‘westernized’’ 21st century Russia (how to properly reconcile Western civilization and the inherent Russian culture and thus create a more efficient and moral capitalist market economy) and the mature and incorruptible democracy had yet to be proposed by Russia. Such a study is well worth the attention of academia.",1
50,3,"In 1950s, Pye (1982), Mead (2001), Almond and Verba (1963), Lipset (2001), McClelland (1987), and others had made significant contributions to the foregoing research approaches. From 1970 to 1980, several Asian countries became influenced by Confucian culture, especially after the economic take-off of the Four Asian Tigers (i.e., Hong Kong, Singapore, South Korea, and Taiwan). Confucian ethics and culture in economic development played an important role in national schools and attracted scholars such as Landes (1998), Fukuyama (1995), Huntington (1993), Porter (1990), Radelet and Sachs (1998), and so on, resulting in the accumulation of considerable research data. Since the 1990s, culture and economic development and culture and political development have been topics of considerable research. As Confucian ethics is a major source of Chinese culture, Russian culture is also heavily influenced by religious culture and ethics of the Eastern Orthodox Church. However, there have not been many studies on the impact of and the interaction between the Russian Orthodox ethics culture and economic development. It is interesting and worthy of more research to observe the operation of Russian-style capitalism influenced by the Eastern Orthodox Church culture rooted in ethical considerations.",1
50,4,"Therefore, this study hopes to utilize Amartya Sen’s economic ethics theory as an analytical tool in order to develop Russia’s capitalist market economic ethics based on the comparative economic ethics of Protestantism and the Eastern Orthodox Church. The culture and tradition of the Russian Orthodox Church has in fact made a profound impact on the development of Russia. A. Leroy-Beaulieu devoted a third of his classic ‘‘The Empire of the Tsars and the Russians’’ to the influence of the Eastern Orthodox Church on Russian history (Leroy-Beaulieu 2000). J. F. Hecker spoke about the ‘‘soul’’ of Russian people in his ‘‘ Religion under the Soviets’’ where he called Russians the ‘‘apostles of God’’ (Bogonostzy) and ‘‘those who yearn for God’’ (Bogoiskately) (Hecker 1994, p. 30).",1
50,5,"Furthermore, this study mainly focuses on the economic system of the Russian capitalist market and the Eastern Orthodox Church’s ethical considerations in business management. It also extends Max Weber’s ethical reflections on the capitalist economic system in his masterpiece ‘‘ The Protestant Ethics and the Spirit of Capitalism’’ , a s well as examines the relationship between the religiousrooted cultural phenomenon, economic development, and business operations.",1
50,6,"In addition, Bulgakov mentioned in his ‘‘Eastern Orthodox Church—The Orthodox Dogma’’ the inevitable branding of ‘‘economic man’’ in religions, where an internal relation within religions and economic activities exist in the human soul, and that such relations are indeed the most interesting topic in Economics. He furthermore pointed out that the types of economic man in Christianity can be divided into Puritan economic man, Lutheran economic man, Reformed economic man, the Quakers, and other innovative types of economic man, as well as discusses about the Eastern Orthodox Church type of economic man. Therefore, it is essential in this study to examine the relationship between the Eastern Orthodox Church economic man and the development in the capitalist market economy, and the differences to the other types of economic man.",1
50,7,"In ‘‘The Development of Economic Ethics and Sen’s Claim of Economic Ethics’’ section, economic ethics and economic system are reflected from perspectives of Sen’s human substantive freedom, capability development, and lifestyle options. There among Sen’s words are implied meanings of an economic man based on his statement of freedom an economic man based on his statement of freedom. As the concept economic man links up the paper, it is discussed again in the concluding section.",1
50,8,"In contrast to other theologians, Bulgakov was not only a contemporary well-known Russian Orthodox theologian but an economist having taught in both the Lomonosov Moscow State University and the Taras Shevchenko National University of Kyiv and specialized in Marxist economics but gradually inclined Orthodox theology and become an Orthodox priest in 1918. In 1922, Bulgakov expelled by the Soviet government was exiled to Paris, France, founded the Institute Saint-Serge, and served as a professor teaching dogmatics until 1944 when he passed away. As an economist and a theologian, Bulgakov investigated various issues such as Orthodox ethics, alternative economic system, and economic development based on M. Weber’s Christian economic ethics. His ideology enlightened modern business ethics and capitalist economic ethics. In this course for capitalist economic ethics, we will present Bulgakov’s lifetime, academic courses, and ideological and theoretical contributions hereinafter.",1
50,9,"As a pious Orthodox Christian since childhood, Bulgakov who was born in a hereditary Russian Orthodox priest’s family gradually became an atheist and a Marxist in an ordinary high school after leaving the original missionary school. He was generally recognized as a typical specialist of Marxism because of his monograph, ‘‘Production in a Capitalist Market’’, published in 1896. In virtue of effects of I. Kant and F. W. J. von Schelling, Bulgakov returning from Western Europe in 1901 had profoundly reviewed Marxist economics, investigated the issue that the rule of concentrated production in Marxist economics contradicted the rural production in his Master’s thesis, ‘‘Capitalism and Agriculture’’, and further proselytized himself that the human life or a society was based on absolute values, i.e., true, good, and beautiful, rather than material. Accordingly, he published the monograph, ‘‘From Marxism to Idealism’’ to elaborate his ideological change in 1903. In this book, Bulgakov confessed he was a pure social scientist in the beginning of his academic career but had no choice but to explore righteousness and truth in the human society and further existence of the God during investigating foundation of the social system. Against this background, the relationship between Christian ethics and economy or society became one major issue in his research (Lossky 1952, pp. 192–195).",1
50,10,"Bulgakov continued the concept of man-God and investigated properties of pseudo-Christianity in materialistic atheism and Marx’s socialism, for example, the prophecy for development of socialism and destiny of capitalism appeared to be eschatology in Christian theology, the called proletariat on a special mission was like the God’s chosen people possessing vocations, and the capital was Satan, in his two assays, ‘‘Pristine Christianity and Last Socialism’’ in 1909 and ‘‘Apocalypse and Socialism’’ in 1910 (Lossky 1952, pp. 200–202). In the purport of economic ethics, Bulgakov argued Marx’s socialism or the so-called atheist pseudo-religion was based on self-righteous man-God, who analogized oneself to the Christ or a saint but was hostile to Christianity as well as God-man saints, and this man-God was contrary to Christian economic man with unique personality and soul.",1
50,11,"The human economic behaviors were also investigated in Bulgakov’s dissertation, ‘‘Philosophy of Economy: the World as Household’’, in addition to the concept of an economic man. Bulgakov considered correlation between labor and the realistic world as the object of economic activities: economy was one bridge rigidly joining a person and the realistic world in which a living person consumed and was involved but not reached by a dead who lost capability to communicate with the world; a person’s renaissance and immortality in Christian view implied resumption of capability to consume in the realistic world; production was labor rights and responsibilities fulfilled by one person in the realistic world (Bulgakov 2000; Valliere 2000, pp. 253–278).",1
50,12,"In terms of discussions about economic ethics for the whole economic system and operation following the concept of Christian economic man, those issues hereinbefore were further elaborated by Bulgakov in assays, e.g., ‘‘The Soul of Socialism’’ (1932–1933) and ‘‘Social Teaching in Modern Russian Orthodox Theology’’ (1934) and the monograph, ‘‘The Orthodox Church’’ i n ‘‘ Orthodox Church and Economic Life’’ for the doctrine of the Russian Orthodox Church (1935). With the identity of an economist and a Russian Orthodox theologian, Bulgakov was known as a Christian socialist investigating correlation between Christianity and socialism and devoting himself to Orthodox Action by cooperating with Berdyaev in Paris and contended socialism was soulless (Williams 1999, pp. 229–236). In Bulgakov’s thinking pattern of a Christian economic man, an economic man’s properties in Christian implications followed by the Orthodox style and then the foundation of economic ethics in socialist as well as capitalist economic systems by Christian view were discussed sequentially.",1
50,13,"The examination of economic growth in Economics in fact stems from Adam Smith’s ‘‘An Inquiry into the Nature and Cause of the Wealth of Nations’’, and J. M. Keynes’ ‘‘The General Theory of Employment, Interest and the Money’’ further inspired and intensified academia’s reexamination of economic growth. R. F. Harrod, E. D. Domar, R. M. Solow, N. Kaldor, J. Tobin et al. examine economic growth based on labor production, capital increase, and advances in production technology.",1
50,14,"On the other hand, the Supply-Side School emphasizes on the lifting of government control, lowering of taxes, and the curbing of inflation to improve the aggregate supply function in order to enhance economic growth rate. However, the research on economic growth has shifted after Amartya Sen won the Nobel Prize for Economics in 1998, and further attracted academic attention to the ethical and moral factors associated with economic development.",1
50,15,"Sen stressed that economic development was based on the elevated state of substantive freedom entitled to man, so economic development could only be possible when any factors that jeopardized free will were eliminated (Sen 2000, pp. 3–4). He also advocated critical thinking in the nature of Economics, for it’s the contributions of economists such as Sir William Petty, Leon Walras, Francois Quesnay, David Ricardo, Augustine Cournot, etc., who tackled Economics with logics and engineering awareness that kindled the beginning of engineering analysis. Similarly, the association between Economics and ethics was only established when ethical issues were heavily weighted in the economic works of people like Adam Smith, John Stuart Mill, Karl Marx, and Francis Edgeworth (Sen 1987; Evensky 2007, pp. 253–282).",1
50,16,"The issue of man’s ‘‘freedom’’ has been greatly valued by Christianity and its various divisions, namely the Eastern Orthodox Church, Catholicism, Protestantism, and others. Questions such as ‘‘who is man?’’ and ‘‘what is the relationship between man and God?’’ surface whenever human freedom comes to mind. Christianity usually uses ‘‘Imago Dei’’ from Chap. 1 verses 26–27 in ‘‘Genesis’’ of the Old Testament to explain who man is (Ott and Otte 2005, p. 145). So some of human’s inherent characteristics, such as rationale, free will, and morality, are used to explain man’s mirror image of God and the special relationship between man and his creator. In this case, man is the reflection, interlocutor, and contracting agent of God (Ott and Otte 2005, p. 145). Catholic theologian Karl Rahner considered man the receiver of Word of God ‘‘Ho ?rer des Wortes’’ as to describe the relationship between man and God (Rahner 1969; Rahner and Rahner 1962). However, can man’s mirror image of God, after it was destroyed by Adam, only be restored through salvation? Or although man is a sinner, can man’s mirror image of God remain intact and still be used as a link to God’s grace through salvation? Or did man’s mirror image of God only come into existence after the Original Sin, parts damaged, and parts intact?",1
50,17,"Under the uncertainty and dilemma of such ‘‘limited freedom’’, Luther talked about Christians’ virtue in having faith. Their faith leads to Christians believing in their own salvation, and thus having the freedom to complete what they supposedly need to do within their environment without coercion in performing sacred deeds for the mere purpose of pleasing God or gaining his recognition. Those without faith are deemed worrisome, troubled, and unhappy (Althaus and Schultz 1972, pp. 37–39). Therefore, salvation is only achieved by waiting for God wholeheartedly and completely trusting in God, as well as abandoning all self-directed activities (Althaus and Schultz 1972, p. 55; Brendler 1991; Hummel 2003). It is thus at the end of his life and after he is redeemed that man can be free to serve God.",1
50,18,"The uniqueness of Eastern Orthodox Theology lies in the fact that Orthodox theologians are constantly reminding the West that a large number of Christian religious rites and beliefs are derived from the East, because most of the early churches were located in the East, ‘‘Ex Oriente Lux’’ ! Second, the Greek language accurately expresses Christian doctrine, and they believe that the Latin terminology cannot master the subtle differences in concepts expressed in Greek theology (Pelikan 1974, pp. 19–25; Geanakoplos 1966, pp. 1–2; Rogosh 1948, pp. 24–26; Baum and Dietmar 2003, pp. 7–10).",1
50,19,"Sen developed a theory of economic development that embarks upon the relationship between human freedom and development. When man is in possession of true freedom, he is able to access and develop his talents in order to become a member of a certain group, profession or status, such as doctors, soldiers, volunteers, and so on. Sen defined this status and identity as ‘‘being’’ (Dai 2008, p. 53) which is different from the extensive religious concepts of ‘‘calling’’ or ‘‘Beruf’’ proposed by Weber. Weber mentioned the desire of Calvinist Puritans to become Berufsmenschen in order to reach the Kingdom of God, with which they answer God’s calling by following asceticism and re-shaping the world. Weber believed that when an employer faces these voluntary workers with such high productivity, he can effectively put to use this capitalist ‘‘labor productivity’’. However, after the capitalist mode of production has replaced humans with machines, and the Enlightenment has inherited asceticism, the concept of Calling (Beruf) was translated into economic impulses and the pursuit of wealth, without ethical religious implications or spiritual associations (Weber 1958, p. 124). Therefore, after asceticism had given birth to capitalism, it collapsed itself slowly again in capitalism.",1
50,20,"Since Bulgakov considered man the Logos and the creator of this economic world, and that Christian religion holds the characteristics of asceticism, he proposed a merger between the role of Logos man plays in this world and asceticism, as well as between the responsibility of governing and abandoning the world. The new economic man motivated by this new labor mechanism could increase labor productivity (Bulgakov 1995, pp. 111–116). So, the distinction between Bulgakov’s ‘‘homo economicus’’ (economic man) and Calvinist ‘‘Berufsmench’’ (man work in a calling) is evident. While ‘‘homo economicus’’ possesses ascetic nature, the man of ‘‘homo economicus’’ exists only in the identity of Logos, who collaborates and bonds with the Holy Spirit to help with the deification of the world. Man is an intimate partner of God, he assists the sacrament of God and governs the world after Creation. The ‘‘Berufsmensch’’ assumes the profession of ‘‘Beruf’’ (calling), he is dedicated and hardworking, and believes himself to be the chosen one who will be rewarded with an eternal life. He believes labor and diligence are his duties to God, and regards his work as a lifetime mission bestowed by God upon him.",1
50,21,"The Eastern Orthodox concept of the new economic man defines man as the Logos of the economic world. Man is assigned by God to govern and to create, he is endowed with labor rights and obligations to participate in God’s mission of world divinization. In this scenario, the ‘‘instrumental freedoms’’ which give way to economic convenience and freedom, as well as basic human rights and economic rights to free trade in the market seems advantageous. So, if the Russian government can fully utilize the development strategy proposed by Sen’s five ‘‘instrumental freedoms’’ to create a good environment and safeguard our freedom, etc., it should be most beneficial to Russia, including to its overall economic development.",1
50,22,"Referring to Bulgakov’s Christian economic man, we studied the correlation between human substantive freedom or human economic behavior and an economic system in Sen’s arguments. In addition, we investigated other concepts such as human freedom in theology; the God’s calling to human beings, predestination, justification, mysticism, deification, and economic ethics of one economic system while researching Weber’s man working in a calling under Lutheranism and Calvinism.",1
50,23,"As to Weber’s ‘‘The Protestant Ethic and the Spirit of Capitalism’’ published in ‘‘Archiv f ? ur Sozialwissenschaft und Sozialpolitik’’ from 1904 to 1905 (Parsons 1958, p. ix), Williams (1997, p. 501) argued that Bulgakov’s attitude to reject Marxism was elaborated in his statements for the economic man from 1903 to 1911. In fact, Bulgakov’s dissertation, ‘‘Philosophy of Economy: the World as Household’’ (1912) and other essays including ‘‘The Unfading Light’’ (1917) and ‘‘The Soul of Socialism’’ , ‘‘ Social Teaching in Modern Russian Orthodox Theology’’ , and ‘‘The Orthodox Church’’ (1932–1935) referred to the concept of an economic man, particularly his concept of a Christian economic man undoubtedly inspired by Weber. In this regard, Bulgakov also gave ideas of various Christian economic men as regards Catholicism, Orthodox Church, Puritan, Lutheranism, Calvinism, and Quakers. Weber’s man working in a calling could be referred as to Bulgakov’s Christian economic man. However, this viewpoint categorized in theology did not attract much attention in contrast to the economic man defined in traditional economics. As such, it can be said that a new research domain is activated because of this new concept about the economic man defined with new significance.",1
50,24,"Sen’s research transiting a rational and self-interested economic man to a free economic man still did not reach an economic man’s soul or innermost being which was specified in von Mises’s analyses for a human being’s economic behavior at Chap. 1 and free will at Chap. 3 and considered as an essential ingredient in analyses of a human being’s economic behavior (von Mises 2006). In this regard, von Mises’s economic man got close to Bulgakov’s Christian economic man or Weber’s man working in a calling which was referred to as a Calvinist economic man from Bulgakov’s viewpoint.",1
50,25,"The correlation between an economic man in an economic system and religious ethics attracted much attention from Bulgakov and Weber: Weber emphasized effects of Calvinist economic ethics on an economic man, which was further upgraded to an economic man in Christianity by Bulgakov. Both Bulgakov and Weber referred to the soulless economic man: Bulgakov believed a materialist economic man in Marxism would be soulless; Weber argued there was no man working in a calling except soulless ones losing Protestant ethics in the last stage of capitalism.",1
51,1,The purpose of this paper is to clarify the presuppositions implied in a recent debate about the possibility of economic planning using computing models and to provide additional arguments relevant to the economic calculation debate.,1
51,2,"The paper provides additional arguments supporting the thesis that computation in a planned economy implies computation with infinite uncountable domains. In addition, this paper rejects the objections raised by some earlier researchers in 2007 in response to Murphy’s theses.",1
51,3,"The possibility of computation and calculation in an economic system is of great practical importance. Institutional settlements and policies are not indifferent to the economic calculation problem. Different institutional settings can hinder the very possibility of economic calculation and rational allocation of resources. From this perspective, the conclusions of economic calculation debate are crucial. The economist’s and philosopher’s criteria used to define institutions and policies must take into account this important question of the possibility of computation and calculation in an economic system.",1
51,4,"Computability in an economic system deals primarily with the question whether economic problem can be solved in the framework of the computability theory. Modern computing devices often seem to possess infinite capacity for calculation, and sometimes we assume that, given enough time and resources, we might use computers to solve any problem, including the economic problem.",1
51,5,"The economic problem can be briefly described as the problem of the rational allocation of resources in an economic system. Each person, even if he/she has autarchic existence, has to deal with the problem of the rational allocation of the resources, mostly because in almost all cases there are much more needs or desires than resources available to satisfy these needs or desires. The most suggestive example is the problem of the rational allocation of time. The time is a scarce resource for all of us and the rational allocation of this resource means to allocate the time according to the importance of the objectives we have.",1
51,6,"In his argument, von Mises sustains that in an economic system based on collective forms of property, even if the planner has all the relevant information[2], the economic calculation is still impossible. For the sake of the argument, von Mises presupposes that the planner holds all the technological knowledge available in his period and a complete inventory of the production factors. Also, a number of experts give him reports with complete information, and, miraculously, all the individuals from the society agreed upon their ultimate common ends. But even in these conditions, the planner has an insoluble problem: how to decide between the infinite variety of projects and means that can be employed for the fulfillment of the chosen ends in the most advantageous manner[3]. For example, if the planner wants to build a house, there are multiple methods to do that, and each of these methods has advantages and disadvantages regarding the final result, the consumed resources, and the period of production. How to choose the appropriate method? In order to do that, he/she has to compare very different things, such as the time for production, the consumed resources (possibly more useful for other alternative projects), the productivity of the different tools and machines, the quality of the building materials, labor, and so on.",1
51,7,"In a complex economy, the production methods are extremely varied. The means of production are neither completely specific, nor absolutely non-specific. If all the means of production were either specific, either non-specific, the decision about the method of production and about the means to be utilized would be a purely technological problem, not an economic problem (von Mises, 1998, pp. 207-8). From this point of view, even in a simple economy, a rational choice between heterogonous means and methods of production would be possible only with some limits[4]. In the case of a complex economy, the main difficulty is not to decide about the final goods to be produced. Even in a socialist economy, this problem is not so complicated. It can be decided approximately if 1,000 hl of wine are better then 800 hl of wine or if, instead of 500 hl of oil, 1,000 hl are to be preferred. After this decision is taken, from this point onward, the real, insoluble problem (for the planned economy) occurs: choosing the most advantageous means and methods of production in order to fulfill the ends (von Mises, 1990, p. 13).",1
51,8,"The importance of the market prices (i.e. the expression of the goods value in terms of a common exchange medium) is that they make possible the rational decision regarding the means and methods of production, given the multitude of available variants. Therefore, the monetary calculation based on market prices formed in a system of private property, where entrepreneurs bids for the goods they need (final goods and intermediate goods) is finally, from this perspective, the solution of the economic problem of the rational allocation of resources.",1
51,9,"Abba Lerner and Oskar Lange recognized that market prices are very important in economic calculation, but they rejected the idea that free market based on private property is a necessary condition for economic calculation and sustained that planners could mimic any market outcome. Lange (1936, 1937) developed an argument in favor of market socialism. He stated that there are three kinds of data, necessary for calculation: individual preferences, prices and knowledge about available resources. An important difference between von Mises and Lange is the conception about prices. For Lange, the determination of the prices is possible knowing the preferences of the individuals and the amount of available resources. He sustains a trial and error procedure or a t? atonnement solution for finding “correct”, equilibrium prices of goods. For von Mises, the determination of the prices can take place only in a private property based system, in a market economy.",1
51,10,"According to the revised version sustained for example by Lavoie (1981), von Mises’s critique of socialism is not invalidated by the advocates of the market socialism. Basically, Lange presupposed, when settled down his solution, the Walrasian model of static general equilibrium. Instead, von Mises and Austrian outlined the entire problem of economic calculation in a different framework: the dynamic adjustment and discovery in the face of continuously changing conditions (technologies, preferences). According to Lavoie, von Mises never denied that in static conditions the economic calculation in socialism could work, but this is irrelevant for the real world. From this perspective, economic calculation in an economy based on collective forms of properties is not possible in principle and the computation argument is downplayed. The problem is not that there are too many equations to be solved, but that the equations could not be set up from the beginning (Lavoie, 1981, 1985).",1
51,11,"In the next section, we will analyze a recent debate about the limits of computability in an economic system based on central planning and collective forms of property. Robert Murphy, that adopted the revised version position in economic calculation debate, formulated a new argument in order to support the thesis that, in principle, economic problem cannot be solved using computational models (Murphy, 2006). Cottrell et al. (2007a, b) adopted the standard version position concerning economic calculation debate and contested Murphy’s argument.",1
51,12,"Murphy’s argument is not formulated in one stroke. First, he stresses the fact that, in the market process, entrepreneurs innovate continuously. Therefore, the list of goods to be produced is always an open one. So, if the central planning unit has to mimic the market processes, it is necessary to take into account all possible future goods and commodities that can appear on the market (all possible fiction books, movies, services and also all the intermediate goods). Therefore, the central planner must have the corresponding lists of the prices of all final goods and also implicitly of all intermediate goods necessary for producing the consumer goods.",1
51,13,"In order to show why the number of prices is uncountably infinite, it is useful to consider beforehand an application of Cantor’s diagonal argument in proving the existence of an uncountable set (Hunter, 1996).",1
51,14,"Cottrell et al. (2007a, b) that R. Murphy does not succeed to prove nor that the set of market prices is uncountable, neither that it is infinite. Their thesis is that the number of all commodities is necessarily countable, because “every commodity is produced from a discrete and finite amount of other commodities, and base commodities (typically raw materials) are composed of finite numbers of atoms.” Every commodity could be represented by some archetype, giving it a unique integer identifier, based on aG ? odel number composed from the number of atoms of each element it contains. Finally, they concluded that since there are only a finite number of elements, all possible finite combinations and also all possible commodities can be enumerated. It follows that the set of the commodities is finite and countable. Therefore, if the set of commodities is countable, so is the set of corresponding prices (Cottrell et al., 2007a, b).",1
51,15,"However, Cottrell et al. (2007a, b, p. 3) raised an interesting question: even if the number of prices is infinite uncountable, in the market economy individuals do not work on an infinite domain: they do not need to take into account all possible prices when they act; otherwise, they will not be able to solve the problem of economic calculation either. So, why Murphy insists that the central planning unit must take into account all possible prices, all possible goods and services, even if they were not invented yet?",1
51,16,"Murphy’s possible answer could be that this requirement of taking into account all possible prices is not motivated only by the innovation problem per se. In a private property regime, that is in a market economy, the individuals express their preferences in relation with the properties they posses. The preferences of the individuals are expressed in the exchanges they make on the market. But they cannot make an infinite number of exchanges, because they posses only a definite amount of things that can be exchanged. From this perspective, the set of preferences of the individuals on the market is a finite set. In a society based on collective forms of property, the preferences of the individuals are not really limited. They may express how many preferences they want to, and central planning unit must take into account all these preferences, because, from the hypothesis, its role is to deduce the prices from the two kinds of data available: individual preferences and the total amount of resources. Therefore, if the planner or central planning unit is to mimic the market processes, it is bound to take into account all the preferences of individuals (which are virtually infinite). Thus, assuming the theory of subjective value, it follows that the resulting set of prices is also infinite.",1
51,17,"There is one remaining problem: we did not give a straight answer to the first question. Is it really an infinite uncountable list of prices? We only stressed the fact that the potential set of individual preferences is infinite, because there is no limitation for individuals in simply uttering their preferences.",1
51,18,"Using Cantor’s diagonal argument it is possible to demonstrate that the set of the prices which the planner must take into account is really uncountable, not only infinite. First, suppose that each good and its price are defined in equations using a set or a subset of preferences. Second, we already assumed that the set of all potential preferences of the individuals is an infinite set (p1,p2 ...pn). Given these two premises, it is possible to define a subset of preferences that differ from all other existing or future subsets of preferences (using the same method of changing on the diagonal each “Yes” to “No” and each “No” to “Yes”). If somebody is trying to write down the new subset of preferences, on the diagonal will arise a new subset of preferences never listed before and so on. Thus, there is an one-to-one correspondence between the set of all possible preferences and the set of natural numbers but there is not an one-to-one correspondence between the set of all subsets of preferences and the set of natural numbers. Therefore, the number of subsets of preferences by which we assumed to define prices of the goods is an uncountable infinite set (Table III).",1
51,19,"Indeed, the consumer goods market alone cannot solve the general problem of the infinite uncountable set of preferences. Even if we admit that the set of consumer preferences is finite, the problem is not solved, because the set of managers and entrepreneurs’ preferences is still an infinite uncountable set. On the market, managers and entrepreneurs often supply products that are not specifically requested by consumers. For example, when the Wachowski brothers wrote The Matrix, they were not responding to “given” consumer demand (Murphy, 2006). Entrepreneurs’ investment preferences are limited on the market, because they can invest only the capital they posses. In a planned economy, a central planning unit still has the problem of defining the prices of intermediate goods, and it still must work taking into account an infinite uncountable set of prices for the intermediate goods.",1
51,20,"In the classical debate on economic calculation, Lange (1936, 1937) assumed that the planner must ultimately rely on the market prices for consumer goods. On this basis, he believed that it is possible for central planner to deduce the prices of intermediate goods. von Mises’s response was that this fact will not solve the problem, because the planner will encounter the same problem at the level of intermediate goods. von Mises (1990) argued that the prices of intermediate goods are not established on the market using a technical method. The production factors are nor entirely specific, neither entirely non-specific. Technically, there are many possible ways to produce final goods using intermediate goods. Even if the prices of intermediate goods are partially relying on the preferences of individuals for final goods, they are ultimately established by entrepreneurs that bid for different amounts of intermediate goods. Market prices for intermediate goods help entrepreneurs to find the most profitable solution. Thus, the planner will encounter the same problem at the level of intermediate goods as encountered at the level of consumer goods.",1
51,21,"In this paper, we refined and reformulated Murphy’s arguments, using Cantor’s theorem from the set theories[6]. On this ground, we sustained the thesis that, in a planned economy, a computational model must take into account an uncountably infinite set of equations and prices. If this is correct, the real problem of the central planner would be the impossibility of setting up in the first place all the equations necessary in calculus, rather than the huge number of equations that must be computed. Given these premises of the problem, we sustain the thesis that computational models cannot mimic the market process.",1
51,22,"The conception regarding price formation is fundamental for economic calculation debate. Different theories of value lead to different theories of prices and for this reason the presuppositions regarding value are very important in economic calculation debate. Cottrell et al. raised their objection totally disregarding the real conception of Austrian School of Economics about value and price formation. On this basis, we rejected all important objections formulated by them in response to Murphy’s (2006) theses.",1
52,1,"The 2008–2009 worldwide economic crisis serves as a backdrop to this study of the dynamics of citizens’ economic expectations. Economic expectations are identified as crucial for a range of political attitudes. This study is the first to consider how information affects evaluations in times of a severe crisis, as prior research of information effects on economic evaluations took place in more stable economic times. It links citizens’ news exposure and the content of economic news coverage with changes in prospective economic assessments. Drawing on a three-wave panel study and on a media content analysis between the panel waves, we thus provide a dynamic assessment of media influences on changes in economic evaluations. The results demonstrate that media exposure strongly affected expectations regarding the future development of the national economic situation, while being largely unrelated to personal economic expectations. We furthermore show that media dependency increases the magnitude of the media effect. We discuss the disconnect between personal and national economic evaluations with regard to mass-mediated economic information.",1
52,2,"Citizens’ economic expectations are (partly) based on information about the economy (Kiewiet, 1983). There are (at least) three ways in which citizens’ economic expectations may be affected – through personal experience, interpersonal communication and through the mass media (Mutz, 1992). In this article, we focus on the latter, information about the economy from the media. We assess to what degree media coverage of economic prospects has an impact on changing economic expectations in times of crisis. We furthermore address the question of which kinds of economic expectations are affected by the mass media. Does new information influence perceptions of one’s own economic situation or only that of the entire country? (Mutz, 1992; see also, for example, Kinder and Sears (1981) for different outcomes of these types of economic assessments) As the media mostly cover the economic health of a nation or of sizable social groups within the nation, we follow prior studies by focussing on the influence of the media on assessments of the national economy (Mutz, 1992; Shah et al, 1999). We proceed by comparing this to media influence on assessments of personal economic expectations. We pose that evaluations of the national economy are largely influenced by mediated information.",1
52,3,"The study explains changes in evaluations, thereby conservatively estimating the influence of information between two points in time. Finally, we take from literature in political communication that media effects are likely to differ in strength for different segments of the audience (see, McLeod et al, 2002). By closely linking indicators of media coverage to different types of economic assessments through an integration of media content and survey data, and by considering a potential moderation of media effects through news dependency, this study refines the understanding of the relationship between economic media coverage and citizens’ evaluations.",1
52,4,"The literature on citizens’ economic expectations in established democracies is mostly based on data collected at times when economic developments were relatively stable. Thus, this study is among the first to deal with economic perceptions at times when economic prospects rapidly and unequivocally deteriorated. Talk about the economic crisis is likely to make people uncertain about their economic prospects, and to alleviate this uncertainty they engage in information-seeking behaviour (Berger and Calabrese, 1975). This, in combination with heightened media attention for economically bad times (Fogarty, 2005), potentially renders mass-mediated economic information in times of crisis even more important.",1
52,5,"Rational choice theorists point out that it is not rational for citizens to be permanently fully informed about the state of the economy, just as they are ‘rationally ignorant’ about current affairs in general (Downs, 1957). Yet, there is empirical evidence that many citizens have, in fact, quite some knowledge on economic matters such as their country’s unemployment rate, in particular at election times (for example, Paldam and Nannestad, 2000). This is not to say that the perceptions or expectations that citizens have always accurately reflect the state of affairs. There are several reasons why citizens’ perceptions would deviate from reality (for example, Hetherington, 1996). A first explanation holds that different citizens use different criteria in their evaluation of how well the economy is doing (Kinder et al, 1989). A second explanation is associated with partisanship (for example, Kramer, 1983), holding that citizens perceive economic conditions as more favourable if their preferred party is in power than if it is not (Wlezien et al, 1997; Van der Eijk et al, 2007). A third explanation – at the core of this study – is that citizens receive varying information from different sources about the state of the economy and form their evaluations accordingly. The role of the mass media as central information providers is discussed next.",1
52,6,"The subjective economy, that is, citizens’ perceptions and evaluations of the economy, features prominently in studies on the political impact of the economy. Early interest in the mediating role of the mass media in the economic voting model (for an overview, see Key and Cummings, 1966; Lewis-Beck and Stegmaier, 2000) stems from the observation that subjective assessments of the economy rather than objective indicators were successful in explaining voting behaviour and/or election outcomes and that therefore there must be a distortion between the subjective and the real economy (for example, Sanders, 2000; Sanders et al, 2001). Hetherington (1996), for instance, showed the US economy to recover before the 1992 US Presidential elections, while mass-mediated information about the state of the economy was continuously negative. On the basis of this information, he argued that Clinton’s victory in this election was more based on a perceived economic situation than on reality. Similar observations have been made regarding the 2001 UK General election (Sanders et al, 2001) and the 1998 German Bundestag election (Donsbach, 1999).",1
52,7,"Research about media influences on economic assessments is mostly based on macro-level analyses. In his time-series study, Mosley (1984) finds media estimates of the economic situation to be a far better predictor of economic assessments than official economic indicators. Relying on a similar design, Sanders et al (1993) and Goidel and Langley (1995) find the tone of economic news coverage to be affecting public assessments, in addition to the impact of real-world factors, in the United Kingdom and United States, respectively. The latter, however, show that only negative news coverage affects public evaluations, which is in line with Soroka’s (2006) more recent analysis (see also Ju, 2008). Others come to different conclusions based on macro-level analyses, such as Haller and Norpoth (1997) who find little, or Wu et al (2000) who find no impact of economic news on assessments.",1
52,8,"We proceed to argue that these media effects are only likely to occur for assessments of the national economy (sociotropic evaluations), and not for assessments of the personal economic situation (egocentric evaluations). The economy is partly an obtrusive subject (Zucker, 1978) – a doorstep issue (Haller and Norpoth, 1997) – in that citizens may notice that others in the immediate surrounding lose their jobs, that the cost of living increases, that they themselves lose their job, or that shops in their neighbourhood go bankrupt. However, most developments of national economic scope are not all that easy to observe first-hand; here the economy is an unobtrusive issue. Apart from via the media or from talking to others, how should citizens learn about, for instance, changes in the GDP? Mutz (1992) considers how problem perceptions of unemployment are influenced by media coverage. Distinguishing different information sources and different types of problem assessments, she finds that personal experience with unemployment significantly contributed to perceptions of unemployment as a personal problem, whereas exposure to newspaper coverage about unemployment ‘uniquely identifies perceptions of unemployment as a social problem’ (p. 496).",1
52,9,"Finally, we focus on differences in the potential effects of positive versus negative economic news coverage. Psychological studies have repeatedly shown that people pay greater attention to negative information as compared to positive information (for example, Fiske, 1980; Pratto and John, 1991), which makes them more likely to draw on this information when forming an opinion. In fact, prior research in the field of political communication confirms that negative information (also in the form of threat or risk frames) tends to have stronger effects on public opinion dynamics compared to positive information (for example, Schuck and de Vreese, 2006; de Vreese et al, 2011). These observations square well with the prevalence of threats and negativity in classic persuasion studies (for example, Hovland et al, 1953). Accordingly, and paying tribute to recent studies in the field of media and the economy (for example, Soroka, 2006) that argue that people are more likely to pick up negative information about the economy, we expect the impact of negative economic news to weigh stronger than that of positive news.",1
52,10,"The assumption that mass media content affects all citizens equally is somewhat na? ? ve (for example, Delli Carpini, 2004) and political communication research pays increasing attention to the contingency of media effects (McLeod et al, 2002; Walgrave and Van Aelst, 2006). We pursue this approach in our study of media effects on economic assessments. The degree to which individuals rely on the media for understanding and interpreting their surroundings is a key component of understanding the media’s impact on opinions and evaluations. Media system dependency theory (Loges and Ball-Rokeach, 1993), abbreviated as MD, argues that the degree to which people depend on the news for informational goals matters for whether news coverage affects their perceptions (Morton and Duck, 2001). MD theory thus takes its starting point in the observation that the impact of media messages on audiences is a function of how dependent audiences are on (mass) media: the higher the dependency, the larger the effects. Initial support for the theory (for example, Ball-Rokeach et al, 1984) has been corroborated by experimental research on health communication effects. Morton and Duck (2001) found that the impact of mass communication on both personal and impersonal perceptions was moderated by self-reported dependency on mass-mediated information.",1
52,11,"This study focuses on media influences on changes in citizens’ economic assessments. We are in particular interested, following the existing literature (for example, Soroka, 2006), in the potential impact of the tone of reporting, in this case mass-mediated future economic expectations, on prospective, sociotropic economic assessments.",1
52,12,"We rely on three-wave panel survey data and a news content analysis between the panel waves to address the expectations formulated above. Respondents reported whether and to what degree they were exposed to outlets that were subject to the content analysis, and media content and survey data were integrated. Relying on such a design allows assessing what kind of economic information respondents were exposed to between different time points and how this information exposure affects changes in their economic outlook.",1
52,13,"Owing to practical constraints, we relied on a more limited selection of media outlets for the second period. However, descriptive results demonstrate considerable similarity across outlets for that period. For instance, two of the three initially most negative outlets remain most negative in the second period (Metro period 1: 2, NRC Handelsblad period 1: 1.78, Metro period 2: 2, NRC Handelsblad period 2: 1.69). Moreover, in the first period nine of the eleven outlets range between 1 and 2 in terms of national economic evaluations, and this goes for seven out of the eight outlets analysed in the second period. Furthermore, a replication of the analyses for the first period that incorporates only those outlets that were also available in the second period yields highly similar results. This makes us confident that our (still broad, but more confined) selection of outlets for the second period suffices.",1
52,14,"We test the hypotheses on the basis of data from a three-wave panel survey of Dutch citizens eligible to vote. From an online panel of 143 809 citizens, 2400 persons over 17 years old were randomly selected, and invited to fill out an online questionnaire. Of these persons, 1394 completed the questionnaire,7 which yields a response rate (RR1) of 58 per cent. When compared to the census data from the Dutch electorate, groups underrepresented in our sample are men (47.0 per cent versus 49.4 per cent), young citizens (30.8 per cent versus 34.2 per cent), and those who had intermediate vocational education (31.3 per cent versus 48.0 per cent).",1
52,15,"In order to assess the hypotheses, we perform multiple OLS regression analyses. We present four models for sociotropic and four models for egocentric expectations, regressing economic expectations at t2 (second wave) and t3 (third wave) on the variables introduced above, while controlling for economic expectations at t1 (first wave) or t2 (second wave), respectively. The use of a lagged variable puts a focus on change of the dependent variable between two panel waves (for example, Markus, 1979). Moreover, controlling for prior economic assessments decreases the likelihood of our models being underspecified, as predictors of static economic evaluations are taken account of by including the lagged term.",1
52,16,"Furthermore, and interestingly, our results show that whereas personal economic circumstances did not affect changes in sociotropic expectations, household income was to some degree related to changes in egocentric expectations. Household income can be considered a proxy measure for information about peoples’ personal economic situation. The findings thus provide some suggestive evidence that citizens rely on different information sources (personal experience versus the mass media) when forming the different types of economic expectations.",1
52,17,"The egocentric expectations on the aggregate level did not significantly change during the time of our study. In the midst of the worst crisis in over half a century, people’s outlook on their personal financial situations was, on average, unaffected. Most people still believed that their personal financial situation would not be endangered, even if they predicted that the national economy would go down the drain within the coming year. We do not only see such a pattern for the Dutch case, but also more generally. All over Europe it seems that assessments of personal and national economics have diverged (Eurobarometer 71). Perhaps, this is a result of a lack of experience with a severe economic crisis. Perhaps, this is a more general psychological phenomenon of people’s disbelief that any major misfortune might happen to them. Perhaps, this is because the crisis takes time to eventually affect a mass of individuals. Especially the latter explanation might have extra mileage because economists agree that it takes time from national economic developments to translate into individual pocket book considerations. In any case, it seems that citizens generally do not link the abstract world of macroeconomic figures to their personal situation.",1
52,18,"Whereas prior studies established a negativity bias in media effects on economic perceptions (for example, Soroka, 2006; Ju, 2008), our data did not confirm such a bias (not supporting H2). This is likely due to the fact that news coverage was univocally negative in our research period, whereby a heavier weighting of negative news did not change much of the variance in the independent variable. We, however, also note that the negativity bias was so far only established in macro-level time-series studies, and not at the level of the individual. It might be that micro-level dynamics work differently than those at a macro-level, in particular in times of economic crisis when the news environment may be unusually negative. Furthermore, we cannot empirically assess how our findings compare to a situation in which the economy is flourishing and characterized by an overall positive economic news climate. Prior macro-level research suggests that news effects are stronger in times of economic crisis (Wu et al, 2000), but future studies on the individual level should address this potential difference in the strength of media effects on economic assessments.",1
52,19,"This study further adds to existing research by taking into account the conditionality of news effects. Our findings corroborate research showing that media dependency is an important moderator of media influences. We indeed find that the more people depend on the news, the stronger the impact of exposure to positive versus negative economic information in the news on economic expectations becomes (supporting H3).These outcomes square well with the research by Ball-Rokeach et al (1984), who found that the strongest effects of media on attitudes and behaviours were among those individuals whose dependencies were more intense. Future research should focus on factors exogenous to the current model, so as to better chart the antecedents of motivations and dependency on the media for information. The fact that the interaction term was only significant in the first period, and that in the second period media dependency had a direct effect on changing expectations suggests that outlet-specific exposure was less important for those who heavily depend on the media in the second period.",1
52,20,"Notwithstanding these shortcomings, we believe to have added to the understanding of the dynamics of economic evaluations, in part as a function of economic news coverage. Knowing that media coverage can drive changes in economic evaluations bears implications for politics. If a positive economic outlook results in a higher likelihood of voting for a government party (for example, Lewis-Beck and Paldam, 2000) and vice versa, then media-induced negativity in economic expectations can be risky for those in power. Moreover, one can envision a spiral effect on economic conditions, if people who are more negative about future economic developments are likely to consume less (for example, Van Raaij, 1989) and thereby affect economic conditions. Although this study was conducted in a unique economic context, the dynamics bear relevance beyond the economic crisis under investigation.",1
52,21,"Joost van Spanje is an Assistant Professor of Political Communication and Quantitative Methods at the Amsterdam School of Communication Research and the Department of Communication at the University of Amsterdam. His research deals with political behaviour, electoral studies and the media, particularly anti-immigrant parties and voting in European elections.",1
53,1,"A knowledge economy still produces goods and services, although by the important use of knowledge. Therefore, economic models are relevant to understanding how a knowledge economy should properly work, particularly the financial system in a knowledge economy. When finance fails, all knowledge stops. Cross-disciplinary approaches to societal models of a knowledge economy are necessary and useful, because societies are more complex than can be seen by any single social science discipline. This was dramatically demonstrated in the first decade of the twenty-first century by the major failure of mainstream economic theory, as a basis for financial regulation. The surprising thing was that the economic discipline as a whole did not take this empirical opportunity to rethink economic theory, to build together a new and valid theory. Instead, the schools of economics continued to argue with one another. We take this historical case of scholastic conflict to reexamine economic theory, but within a cross-disciplinary framework. We use the modeling that had been accomplished in the two conflicting economic schools—exogenous and endogenous schools. Each modeled parts of an economic system, production subsystem (exogenous school) and financial subsystem (endogenous school).",1
53,2,"Going back in time from 2012 to 2010 to 2009 (the recent years following the financial crisis of 2008), one can find the historical evidence of theory failure and also of a continuing failure of the discipline to agree upon how to construct valid theory. In science, of course, when theory fails to explain empirical reality, then theory is changed. But matters were not so straightforward in the recent history of the economics discipline. Instead of immediately rushing to change economic theory, there continued a contentious debate among economists. Was a market empirically perfect or only ideally perfect? Mainstream economic theory had constructed an economic model of supply–demand–price equilibrium, which was based upon the assumption of a perfect market. But fact was that the financial market had been far from perfect. For example in 2012, one economist, Howard Davies, then a professor at Sciences Po in Paris wrote: “In an exasperated outburst, just before he left the presidency of the European Central Bank, Jean-Claude Trichet complained that: ‘as a policymaker during the crisis. I found the available models of limited help; in fact, I would go further. In the face of the crisis, we felt abandoned by conventional tools.’” (Davies 2012).",1
53,3,"Previously Davies had been the Director of the London School of Economics and earlier was the Chairman of Britain’s Financial Services Authority and even earlier the Deputy Director of the Bank of England. Professionally as an economist, Davies was both an economic academician and practiced as a banking authority. His view about the how contemporary economic theory had been useful to practice was negative: “Our approach to regulation in the past was based on the assumption that financial markets could to a large extent be left to themselves, and that financial institution and their boards were best placed to control risk and defend their firms. These assumptions took a hard hit in the crisis, causing an abrupt shift to far more intrusive regulation. Finding a new and stable relationship between the financial authorities and private firms will depend crucially on a reworking of our intellectual models.” (Davies 2012).",1
53,4,"Earlier in 2010, Chris Giles had reported: “Many of the world’s top academic economists agreed on Friday (April 9, 2010) that the financial and economic crisis had exposed fatal flaws in their subject and ideas were urgently needed to keep economics relevant. While this represented an unusual consensus, the eminent economic brains lived up to their stereotype by disagreeing on what policies, if any, should be adopted to prevent a repetition.... The participants were speaking at the inaugural conference of the Institute for New Economic Thinking, a think-tank sponsored by George Soros, the billionaire financier. They included five Nobel prize-winners (in economics). Held at King’s College, Cambridge... the conference participants could neither agree on the cause of the crisis nor the necessary remedies. One disagreement hinged on whether asset price bubbles lay at the heart of the crisis. Those who thought so argued for tighter regulation... (Others, such as) Michael Goldberg, of the University of New Hampshire, said it was wrong to suggest the price swings were necessarily a bubble and that they were more likely to be fundamental to the beneficial forces of capitalism.” (Giles 2010).",1
53,5,"Another economist, Charles J. Whalen, had written: “The financial crisis that ran from late 2007 through early 2009 did more than traumatize the world economy; it drew widespread attention to some major shortcomings of conventional economics. Paul Krugman pointed out those weaknesses in a number of public lectures and in the pages of The New York Times, but he was not alone. Forced to confront the reality of the Great Recession, a number of prominent scholars and policymakers also joined the chorus.” (Whalen 2012).",1
53,6,"Back in 2009, Paul Krugman (a Noble prize economist) analyzed his discipline: “It’s hard to believe now, but not long ago economists were congratulating themselves over the success of their field. Those successes—or so they believed—were both theoretical and practical, leading to a golden era for the profession. On the theoretical side, they thought that they had resolved their internal disputes.... And in the real world, economists believed they had things under control: the ‘central problem of depression-prevention has been solved’, declared Robert Lucas of the University of Chicago in his 2003 presidential address to the American Economic Association. In 2004, Ben Bernanke, a former Princeton professor who is now the chairman of the Federal Reserve Board, celebrated the Great Moderation in economic performance over the previous two decades, which he attributed in part to improved economic policy making. (But) last year (2008), everything came apart. ... Few economists saw our current crisis coming, but this predictive failure was the least of the field’s problems. More important was the profession’s blindness to the very possibility of catastrophic failures in a market economy. ... During the golden years, financial economists came to believe that markets were inherently stable—indeed, that stocks and other assets were always priced just right.",1
53,7,"Krugman wrote about this division among economists: “Meanwhile, macroeconomists (remain) divided in their views. But the main division was between those who insisted that free-market economies never go astray and those who believed that economies may stray now and then (but that any major deviations from the path of prosperity could and would be corrected by the all-powerful Fed). Neither side was prepared to cope with an economy that went off the rails despite the Fed’s best efforts. ... And in the wake of the crisis, the fault lines in the economics profession have yawned wider than ever.” (Krugman 2009).",1
53,8,"Why did this fault line persist? Krugman explained this as due to “aesthetics”: “As I (Krugman) see it, the economics profession went astray because economists, as a group, mistook beauty, clad in impressive-looking mathematics, for truth. Until the (1930s) Great Depression, most economists clung to a vision of capitalism as a perfect or nearly perfect system. That vision wasn’t sustainable in the face of mass unemployment. But as memories of the Depression faded, economists fell back in love with the old, idealized vision of an economy in which rational individuals interact in perfect markets; this time gussied up with fancy equations. ... Unfortunately, this romanticized and sanitized vision of the economy led most economists to ignore all the things that can go wrong. They turned a blind eye to the limitations of human rationality that often lead to bubbles and busts; to the problems of institutions that run amok; to the imperfections of markets—especially financial markets—that can cause the economy’s operating system to undergo sudden, unpredictable crashes; and to the dangers created when regulators don’t believe in regulation.” (Krugman 2009).",1
53,9,"When the price of a commodity is charted as the quantity of the supply of the product (dotted line) then the price will decrease in an economy as the supply increases. Because of business competition, more goods flooding a market will force prices down. Also, if the demand for a product (solid line) increases, then the price will increase (as more consumers buy a limited amount of product). The optimal pricing of a product (commodity) in an economy will occur when supply equals demand. This is the equilibrium price, as supply and demand meet in quantity. If a market behaves like this, it is perfect. No control over pricing is necessary, as a supply–demand equilibrium in the market sets the optimal price.",1
53,10,"Neo-Keynesians argued that the Neo-Classical Synthesis School economists had too narrowly viewed an economy as only a production system. Ben Bernanke wrote: “Economists have not always fully appreciated the importance of a healthy financial system for economic growth or the role of financial conditions in short-term economic dynamics. ... During the first few decades after World War II, economic theorists emphasized the development of general equilibrium models of the economy with complete markets; that is, in their analyses, economists generally abstracted from market ‘frictions’ such as imperfect information or transaction costs. But without such frictions, financial markets have little reason to exist.”",1
53,11,"Minsky argued that a time dimension was important to a model of an economy. In 1936, John Marnard Keynes had introduced a time dimension in an economy—in order to include “finance” as a part of the economic model. “In the General Theory, Keynes sought to create a model of the economy in which money is never neutral (to pricing). He did this by creating a model... in which the price level of financial... assets is determined in (financial) markets where... the price of money... is an asset whose value is derived from its liquidity. For Keynes, each capital and financial asset yields an income stream, (which) has carrying costs and possessing some degree of liquidity... The price level of assets is determined by the relative value... (of) income... and liquidity...” (Minsky 1993)",1
53,12,Time dependence in a Keynes model of a financial system lies in the concepts of: a “present-income” and a “future liquidity” of a “capital asset.” A capital asset is an investment which creates income and can later be sold. A capital asset produces an income stream (present-income) but also can be sold in the future (future liquidity) (Minsky 1975). The time dimension is from (T1) of a present-income to (T2) of future liquidity. This present-to-future (T1 to T2) temporal process occurs in a financial system as a transaction of “credit-debt.” Minsky wrote: “Every capitalist economy is characterized by a system of borrowing and lending... The fundamental borrowing and lending act... is an exchange of ‘money-now’ for ‘money-in-the-future’. This exchange takes place... in a negotiation in which the borrower demonstrates to the satisfaction of the lender—that the money of the future part of the contract will be forthcoming.... The money in the future is to cover both the interest and the repayment of the principle of the contract.” (Minsky 1993).,1
53,13,"This is the time dimension of any financial system—the yesterday of credit, the today of interest payment, and the tomorrow of paying off the debt. Credit and debt as a financial process is essentially temporal; and this is why models of economic systems must have a time dimension for Keynesians.And a financial market provides liquidity through valuing capital assets: “In the General Theory, Keynes... created a model... in which the price level of financial... assets is determined in (financial) markets... where ... the price of money... is an asset whose value is derived from its liquidity... For Keynes, each capital and financial asset yields an income stream, (which) has carrying costs and possessing some degree of liquidity... The price level of assets is determined by the relative value... (of) income in the future and liquidity now.” (Minsky 1993). A financial market makes the credit-debt contracts sellable in the future, as future liquidity. A capital asset must have two temporal features of a current-income and a future liquidity. A financial market provides the capability of future liquidity for a capital asset.",1
53,14,"The Neo-Classical Synthesis School focused upon the production subsystem; in which the present price of a commodity is the key factor of control in a production subsystem. The Neo-Keynesian School focused upon a financial subsystem, in which future price of a capital asset is the key factor of control in a financial subsystem. The modeling challenge is to use both these economic models (theories) in a complementary framework. For this, one can methodologically use a “meta-framework,” such as in societal dynamics theory. In the meta-framework for economic system modeling, we use a topological systems model of a society, in which an economy is an economic subsystem; and in the economic subsystem are production and financial sub-subsystems. The development of this societal systems model can be found in (Betz 2011).",1
53,15,"In a societal dynamics topological model of the stasis of a society, the major systems in an industrialized society can be classified into four kinds of subsystems (economic, cultural, political, and technological; and these can be topologically presented as stacked planes, as in Fig. 4). Also traditionally in economics, an economy is composed of production, distribution, and consumption of goods and services. The production subsystem produces the goods and services from material/energy resources and financed by a financial system. These goods/services are consumed within a market. Thus any economic system can be partitioned into four subsystems of production, market, finance, and resources. Therein, we can now place the exogenous school’s model of an economy (as a production system) within this larger societal context—as the production subsystem of the economic system. Also, one can place the endogenous school’s model of an economy (as a financial system) within this larger societal context—as the financial subsystem of the economic plane.",1
53,16,"To understand how to connect the partial economic models from the endogenous and exogenous schools, we will next draw upon other models from other social science disciplines, aiming toward a connectable model of a societal economic subsystem—a cross-disciplinary economic system.",1
53,17,"Because the economics discipline distinguishes micro for macroeconomics, we first add cross-disciplinary partial models for microeconomics. For this we turn to management science for a model of a productive economic agent, which is to say, a business that produces goods or services. This is a standard model in management science, called an “enterprise model,” and first popularized by Michael Porter (Porter 1985; Fig. 6). A productive organization can be depicted as adding value to resources and labor obtained from its environment by transforming these into products sold back to the environment as customers. This is an open system model of a firm, receiving inputs of resources and labor from its environment and transforming this into value-added products sold back into the organization’s environment.",1
53,18,Thus the equilibrium pricing model of supply–demand is applicable only to a specific set of productions (commodity) within a specific sector of an industrial value chain. The first arrow indicates that a firm model belongs functionally to a specific industrial sector; and the second arrow indicates that the commodity supply–demand curve is functionally specific to an industrial sector.,1
53,19,This placement of the exogenous school’s supply–demand model upon a societalmodel topological plane shows that data must be specific to an industrial chain for the supply–demand model to be empirically real (real supply–demand data in and valid price information out).,1
53,20,"The data for such an aggregate account comes from revenue data reported each firm and grouped by commodities produced. Again, we note that in each partial model, data does not flow necessarily from one model to another but must be gathered independently.",1
54,1,"This paper examines the relative impact of economic freedom, civil liberties, and political rights on growth. A system of three simultaneous equations is used to unearth the channels through which these institutional dimensions affect economic growth. These include greater efficiency and enlarged investment in physical and human capital. The sample contains 79 countries and six periods covering the years from 1976 to 2005. The results show that the three dimensions of institutional quality are important for economic growth either through a better allocation of resources or, indirectly, through the stimulation of investment in physical and human capital.",1
54,2,"The factors that determine the economic growth of nations and account for crossnational differences in per-capita real incomes are a main concern of economists. The literature on this matter is abundant, but the empirical research has only been moderately successful at showing what is behind the growth processes and the observed inequalities. For this reason, evermore explanatory variables have been incorporated into growth models until, at the end of the twentieth century, institutional factors were included, complementing the more traditional variables such as labor, physical and human capital, and technology used in neoclassical and endogenous growth models (Olson 1982, 1996).",1
54,3,"In recent years, the incorporation of institutions into growth models has become a habitual practice among researchers (Ak?omak and Weel 2009; Barro 1996; Easterly and Levine 2003; Hall and Jones 1999; Mauro 1995; Rigobon and Rodrik 2005; Stroup 2007; Yang 2008). Most of them have found a positive and significant effect of institutional quality on economic growth, even though the results cannot be considered conclusive. With respect to the different dimensions encompassed by the concept of institutional quality, economic freedom, followed by political freedom, have generated the most interest in the empirical literature (Aixalá and Fabro 2009). For this reason, we select these two aspects with the view to analyze their respective impacts on growth.",1
54,4,"Civil liberties and political rights have frequently been conflated under the heading of political freedom, notwithstanding the fact that they are different concepts and, thus, have different implications for economic growth. Civil liberties allow for the freedom of expression and belief, freedom of the press, associational and organizational rights, as well as for the rule of law and personal autonomy. Political rights enable people to participate freely in the political process, including through the rights to vote freely, to compete for public office, to join political parties and organizations, and to elect representatives who have a decisive impact on public policies and are accountable to the electorate.",1
54,5,"In regard to the different concepts of freedom, Milton Friedman (2002) points out the necessity of using three classifications, instead of two, such as economic, civil, and political freedom. Political freedom must be understood as the way the political structure is configured, the right to vote, and the definition of democracy as a society where civil servants are elected through citizens’ votes. By civil freedom he means freedom of speech, freedom of assembly, and freedom of expression; in short, what is termed human rights. Hong Kong constitutes an example of such a distinction. Under British rule, while citizens lacked political freedom, as Freedom House would understand it, they did enjoy a high level of civil freedom (i.e., freedom of speech and assembly). Therefore, a country can have a high level of civil and economic liberties without having political freedom. However, it seems difficult to have political freedom without economic freedom. For example, in China the spread of economic freedom should bring about more political freedom.",1
54,6,"Ariel Benyishay and Roger Betancourt (2010) argue that the protection of human rights through the provision of civil liberties is one of the most fundamental indicators of the prevalence of the rule of law in a society. Violation of human rights (through loss of life, imprisonment, or other less dramatic restrictions of capabilities to make choices and enjoy one’s liberties) deprives individuals of property rights. They believe that civil liberties are important for markets to function at a high level due to their socially contrived nature, suggesting a causal mechanism between civil liberties and long- term economic development.",1
54,7,"With the aim of clarifying the channels through which institutional quality affects economic growth, a second contribution of this paper is the use of a system of three simultaneous equations. In order to analyze both the direct (greater efficiency) and indirect (greater investment) impact on growth, we added one equation of investment in physical capital and another of investment in human capital to the growth equation. We assessed the system using panel data techniques and weighted two-stage least squares. This technique overcomes the problems of heteroskedasticity and endogeneity typically found in studies of institutional quality and economic growth. Research in this line has generally not accounted for possible time that elapses between institutional changes and their impact on growth. With the object of capturing this effect, the third contribution of this paper is to use lags of the institutional variables.",1
54,8,"Growth theoreticians who share ideas of the property rights school as well as some of North’s contributions point out that economic freedom increases productivity by reducing transaction costs, thereby encouraging accumulation of human and physical capital stocks, strengthening specialization and economies of scale, promoting more efficient organizations, and fomenting business innovation (Kirzner 1973, 1997; Schumpeter 1912). In order for the market to work efficiently, precise and well-defined property rights are necessary since, without them, the costs of negotiation involved in the allocation and distribution of resources would be prohibitive (Tornell 1997). Moreover, the lack of transparent information and the entry barriers for new competitors, as well as for international competition, impose transaction costs on the economy that limit market opportunities. In fact, economic freedom is the institutional characteristic for which the highest consensus has been achieved with respect to its positive and significant impact on growth (Azman-Saini, Baharumshah and Law 2010; Carlsson and Lunsdtr?m 2002; Dawson 2003; De Vanssay and Spindler 1994; Easton and Walker 1997; International Monetary Fund 2003; Justesen 2008; Stroup 2007).",1
54,9,"One of the aspects of economic freedom that has gained special attention in recent years is regulation. Several empirical studies analyze the impact of regulation on growth and conclude that it is negative. In particular, Harold Cole et al. (2005) argue that international and domestic competition barriers are the key to understanding Latin America’s low total factor productivity (TFP). Stagnant relative TFP is the main determinant of Latin America’s relative income and labor productivity stagnation. John W. Dawson (2006) argues that reducing regulation has a positive impact on growth through both the investment channel (the indirect effect) and the total factor productivity channel (the direct effect). Enedina Licerio, Thomas Fullerton, and Don Clark (2010) quantify the potential income gains associated with deregulation and conclude that reducing regulatory burdens leads to increases in per capita incomes.",1
54,10,"Robert Barro (1996) promotes the existence of a non-linear relationship between democracy and growth, so that higher levels of democracy encourage growth in countries with lower levels of political freedom mainly because government abuse is limited. At the same time, these high levels of democracy hinder growth when a moderate level of political freedom exists. According to Barro, widening political freedom could slow down growth when a certain threshold is reached. This is partly due to the appearance of redistributive pressures.",1
54,11,"Because of the interconnectedness of all these freedoms, as well as their role as “instrumental freedoms,” Amartya Sen (1999) proposes that a satisfactory conception of freedom must be fairly broad, and that its virtues are both intrinsic and instrumental. In general, he argues that political and social freedoms are inherently desirable and conducive to economic growth. Sen further stresses the importance of focusing on economic development as an integrated process of expanding substantive freedoms that encompass economic, social, and political considerations. This broad approach allows the simultaneous appreciation for the vital roles in the development process of many different institutions, including markets and market-related organizations, governments and local authorities, political parties and civic institutions, education programs and forums, and many others.",1
54,12,"The fact that economic freedom fosters growth has been widely acknowledged. Nevertheless, importance must not only be attributed to markets, but also to the role that economic, social, and political freedoms play in improving and enriching people’s general capacities. Sen identifies five types of freedom, as viewed from an instrumental perspective: political freedom, economic freedom, social opportunities, transparency guarantees, and security networks. The promotion of such diverse but interrelated instrumental freedoms can contribute to the success of public policy intended to foster human capacities and substantive freedoms. While development analysis, on the one hand, pursues objectives that would consequently enhance these instrumental freedoms, it must also take into account the empirical connections existing between the various freedoms in order to reinforce their joint importance. In fact, these connections are of vital importance to a wider understanding of the instrumental role of freedom.",1
54,13,"Some empirical papers (Giavazzi and Tabellini 2005; Persson and Tabellini 2006) maintain that liberalizing the economy is an essential first step before the extension of political rights can generate growth. Inchoate democracies operating in closed economies face conflicts of redistribution, while established democracies in open economies are forced to pay more attention to economic efficiency. Furthermore, economic liberalization stimulates the rule of law and better protection of property rights, two prerequisites for democracy to generate growth (Giavazzi and Tabellini 2005).",1
54,14,"Empirical research, as stated earlier, frequently takes civil liberties and political rights globally as indicators of political freedom (Farr, Lord and Wolfenbarger 1998; Helliwell 1994; Wu and Davis 1999). This empirical research also provides results that are diverse and less robust than those obtained in the case of economic freedom, showing the conflict between costs and benefits pointed out by the theory. Some find an overall beneficial effect of democracy on economic growth (Gwartney, Lawson and Block 1996; Hanke and Walters 1997; Rigobon and Rodrik 2005; Rodrik 1999a; Scully 1988; Varsakelis 2006). Others, however, find that this relationship is neither significant nor robust (Alesina et al. 1996; Ali and Crain 2002; Barro and Sala-iMartin 1995; De Haan and Siermann 1995, 1996; Mulligan, Gil and Sala-i-Martin 2004), and even, in some cases, slightly negative (Helliwell 1994; Tavares and Wacziarg 2001).",1
54,15,"An often ignored question in empirical research is the timing of complex causal relations between institutional factors and economic results. Although some of the generated effects may be contemporaneous, others present a lagged structure. For example, economic freedom frequently requires a certain lapse of time before it produces a tangible effect. Credibility then becomes a vitally important factor in growth processes. This is especially true in countries that have historically suffered from unstable and changing policies, and where there is a strong opposition to liberalization policies.",1
54,16,"Further, this paper stresses the necessity to consider the difference between the direct and indirect effects of institutional quality on growth. This difference has often been ignored and, when taken into account, has led to a remarkable lack of consensus. In the case of economic freedom, for some authors (Hall and Jones 1999), the effect is greater on productivity than on the accumulation of productive factors. For others (Ayal and Karras 1998), economic freedom promotes growth by improving both the total factor productivity and the accumulation of human and physical capital. Some believe that growth is encouraged only through greater efficiency in the allocation of resources (Ali and Crain 2002; De Haan and Siermann 1998; De Haan and Sturm 2000), while others emphasize the role of investment (Dawson 2003; Eicher, García-Pe?alosa and Teksoz 2006; P??kk?nen 2010).",1
54,17,"In the case of political freedom, some authors claim that democracy could promote growth while fostering human capital accumulation (Mariscal and Sokoloff 2000). For physical capital, the evidence is less conclusive. Authors like José Tavares and Romain Wacziarg (2001), Philipp Harms and Heinrich Ursprung (2002), and Matthias Busse (2004) find that democratic countries attract direct foreign investment, while Adam and Filippaios (2007) argue that democracy may reduce private investment. José Aixalá and Gema Fabro (2009), for their part, point out that while in the case of physical capital investment only economic freedom matters, for human capital investment economic and political freedoms are relevant.",1
54,18,"It is desirable to clarify these channels in order to have a better knowledge of the processes of economic growth. Furthermore, if these indirect channels (accumulation of human and physical capital) are included as explanatory variables in the regressions, it has to be born in mind that the coefficient of the institutional variable does not reflect the total effect on economic growth, and could lead to erroneous conclusions. For this reason, the estimation of models of simultaneous equations is a good option, although it has been rarely used (Alesina et al. 1996; Faruk, Kamel and Véganzonès-Varoudakis 2006; Leite and Weidman 2002; Rigobon and Rodrik 2005; are some exceptions).",1
54,19,"Institutional change is often a difficult and slow process, because the institutions of a country may be deeply rooted in its history and culture. In addition, it is very likely that those who wish to maintain the status quo will be against comprehensive reforms. Nevertheless, it is sometimes important to incorporate the temporal dimension because the institutional changes occur with remarkable speed, especially in developing countries. For example, the IMF (2003) demonstrated that important rule-of-law progress has occurred worldwide since the mid-1980s, and especially during the early 1990s. Similarly, it pointed to the political and economic reforms in the formerly centrally planned economies of Central and Eastern Europe, where they have caused a generalized institutional strengthening. The IMF also noted the radical changes that have occurred in such “post-conflict” states as Kosovo and Afghanistan.",1
54,20,"In this paper we use as institutional data the indices of civil liberties and political rights published annually by Freedom House since the early 1970s. These indices are based on the strict evaluations of regional experts, human rights specialists, academics, journalists, and even political figures. Additionally, we refer to the index of world economic freedom published by the Fraser Institute since the 1970s. This index mainly incorporates quantifiable, objective data, although some of its components are subjectively evaluated by various researchers and experts (see Appendix 1, p. 1077).",1
54,21,"The main reason we chose these indices for economic freedom, civil liberties and political rights, instead of others, is the prestige of the organizations that publish them. In addition, they are good proxies for the concepts they are intended to measure. Moreover, their broad coverage in terms of time and countries is especially appropriate both for the use of panel data techniques and for the introduction of lags in the variable to examine the delay with which these freedoms sometimes affect growth. For the other variables — growth of per capita GDP (PPP), investment in physical capital, rates of enrolment in primary and secondary education (as investment in human capital), trade and initial income — we refer to the World Development Indicators database of the World Bank.",1
54,22,"When institutional dimensions are considered individually, all the traditional variables exhibit the expected signs and are generally significant. In the growth equation, as predicted by neoclassical theory, the initial income shows a negative sign that is significant in eight of the nine estimations carried out, thereby confirming the hypothesis of convergence. The investment in physical and human capital variables have positive and statistically significant coefficients, except for human capital which, in spite of presenting the expected sign in all cases, is not significant in three of the nine equations. For the investment in physical and human capital equations, all the explanatory variables (rate of enrollment in primary education and openness in the first equation, and the lagged rate of enrollment in primary education and initial income in the second) have the expected positive sign and a high level of significance in all the estimations.",1
54,23,"With respect to the institutional variables under study, the most outstanding results give rise to the following considerations: Economic freedom (Table 1) has a significant impact on growth not only by improving the allocation of resources, but also by encouraging investment in physical and human capital, given that in the three equations of the system it has a high level of significance (systems 1 and 2). When two lags are introduced in the analysis (system 3), economic freedom retains its significance in the equation of physical capital investment and the explanatory power of the model improves.",1
54,24,"These empirical results support the ideas of the property rights school as well as some contributions by North (1990) and Olson (1982), which would later be incorporated by growth theory, about the role of economic freedom in promoting the accumulation of physical and human capital and in increasing productivity by reducing transaction costs. Civil liberties (Table 2) and political rights (Table 3) are important for growth because they improve the allocation of resources and investment in physical and human capital (systems 1, 2, and 3). When two lags of the variables are included, civil liberties and political rights retain their significance in the three equations and the explanatory power of the models improves.",1
54,25,"Other research (Gwartney, Lawson and Holcombe 1999; Hanke and Walters 1997; Stroup 2007) supports the view that economic freedom has greater impact on growth than civil liberties and political rights. As seen in Table 4, when current values are used, the results show superior coefficients for this institutional dimension. It is true, however, that in the case of human capital the coefficient for civil liberties is almost as large and when lags are included in the variables economic freedom loses its supremacy.",1
54,26,"This paper endeavored to uncover the relative importance of institutional dimensions like economic freedom, civil liberties, and political rights for economic growth. Furthermore, its objective was to differentiate between the direct and indirect effects of these dimensions. First, the results showed that the three dimensions of institutional quality are important for the economic growth of countries either through stimulating a better allocation of resources or, indirectly, by encouraging investment in physical and human capital. Second, with respect to the relative importance of the three dimensions of institutional quality, the results suggest a greater impact of the contemporaneous values of economic freedom although, in the case of investment in human capital, it is closely followed by civil liberties. When lags are introduced, civil liberties and political rights retain their high level of significance, but economic freedom is no longer the most relevant dimension.",1
55,1,"The study aims to examine the short and long term impacts of economic liberalization on economic growth in case of Pakistan from 1971 to 2011. Economic liberalization consists of reforms in both trade liberalization and financial liberalization. This study contributes to the existing literature by constructing an economic liberalization index using principal component analysis. Our results show, firstly, that economic liberalization reforms have a positive impact on economic growth in the short run. However, trade liberalization is negatively associated with economic growth in the long-run. Secondly, the estimated coefficients through rolling window show that impact of economic liberalization on real GDP is unstable during the selected period of sample. This study recommends to policy makers to enhance human capital by having more expenditure on education sector. In addition, financial reforms by way of a sectoral credit allocation should be introduced to further promote the economic growth.",1
55,2,"The link between economic liberalization (EL) and economic growth (EG) has drawn significant attention from researchers after the emergence of new growth theories. In 1980s, many developing countries have put into practice the endogenous growth theory model and started the process of liberalization in order to achieve EG. The complete liberalization of economy means the liberalization of financial sector and trade sector. However, empirical evidence on the results of financial and trade liberalization are inconclusive.",1
55,3,"Pakistan started the process of financial sector liberalization in late 1980s. The objectives were to improve the efficiency of financial markets, to formulate the market-based and relatively more efficient monetary and credit policies, and lastly to strengthen the capital and market based financial institutions.",1
55,4,"This study aims to examine the short and long run impacts of EL on EG in the case of Pakistan by using the data from 1971 to 2011. This study contributes to the literature by developing an economic liberalization index (ELI). The short run and long run relationship are estimated by using the error correction model, JJ cointegration and full modified OLS method. The paper is organized as follows: the Sect. 2 presents a literature review of the topic. It is followed by a presentation of our methodology and various estimations. The empirical results are presented in Sect. 4. The final part concludes with some policy recommendation.",1
55,5,"The empirical literature indicates that most of studies have used the following three proxies to test the impact trade openness on EG: export divided by GDP, import divided by GDP, and export plus import divided by GDP. The advantage of these three proxy indicators are that the data is easily available. It is assumed that a lower value of these trade indicators are representing the higher degree of policy intervention in trade sector.",1
55,6,"The vital weights are calculated by using the principal component analysis (PCA). The eigenvalues show that the first principal component accounts for about 65 % cumulative proportion of variation (See Table 2). The second component explains another 35 % and last principal component demonstrates 0.00 % standardized variation. It is the first principal component that shows greater variation as compared to other combination of variables. The first eigenvector values as a weight is used in our study to construct a composite measure of trade openness and denoted as TLI. The separate contribution of TD; M and X in standardized variance of the first principal component, i.e. 71.6, 54 and 44.2 % respectively.",1
55,7,"Since the JJ Cointegration approach is very sensitive to the lag order employed, this study uses the SBC method to determine the optimal lag order earlier to estimate cointegration tests. In Table 5, the results of trace test indicate the same conclusion that there is cointegration relationship exist in 1–12 models. But the cointegration vector is different, in Model-1, 3, 4, 9 and 10 there is one cointegrating vector. The two cointegrating vectors are found in Model-2, 5, 6, 7, 11 and 12, only in model-8 the three cointegrating vector are found.",1
55,8,"The rolling window regression is used to check the stability of coefficients of the variables in the selected data period. The available cointegration econometric techinques assume that coefficients of the estimate model remain constant throughout the sample. In the reality, economy cannot continue in similar manner, and, economic indicators thus oscillated. Consequently, the estimated coefficients of economic indicators cannot remain the same throughout sample.",1
55,9,"In this paper, we have constructed a FLI, trade openness index, and ELI for Pakistan for the period of 1971–2011. The augmented Dickey–Fuller unit root tests has been employed to determine the order of integration. The JJ cointegration, Fully Modified Least Squares and error correction model were used to estimate the long run and short run relationship. The stability of the cofficients was checked by using the rolling window regression method.",1
56,1,"The relationship between stock market and economic growth is tested for Portugal (1993–2011), which is a small open economy dependent on bank financing. The relationship between economic growth and bank financing is also appraised. Using Vector Autoregressive (VAR) modeling, Granger causality, variance decomposition and impulse response function are discussed. The physical replacement of the currency, as a consequence of the integration in the European Monetary Union, proves to be an economic regime change. The effect of the subprime crisis was also proved. There is evidence of Granger bidirectional causality between the stock market and economic growth. Meanwhile, there was no evidence of causality running from bank financing to economic growth.",1
56,2,"The relationship between economic growth and the financial system, whose components are stock markets and the banking system, has received considerable attention for decades (e.g. Beck and Levine, 2004; Capasso, 2008; Goldsmith, 1969; Keynes, 1973; Levine, 1991; Schumpeter, 1982). Traditionally, Anglo-Saxon countries use mainly the capital market for corporate financing, while in non-Anglo-Saxon countries the banking system predominates (e.g. Marini, 2005; Lee, 2012).",1
56,3,"The use of long series as well as the control of structural changes might be important in determining the relationship between the financial system and growth. Given that structural changes may have the strongest impacts on a small economy, we will focus on Portugal. This exercise will allow us to verify the interaction of variables during the 1990s and 2000s, a period full of both economic and political change. Considering that Portugal is a non-Anglo-Saxon country, the banking system is expected to play a more significant role in the economy than the stock market.",1
56,4,"Results suggest that the stock market Granger-causes economic growth. However, this Granger causality is not verified from banking system to economic growth. This study allows us to better understand how to act in terms of economic policy for the financial system, focusing on the stock market segment or banking segment.",1
56,5,"Nonetheless, the concept of stock market development is not clearly defined. As a result, four indicators can be used to study stock market development (e.g. Demirgu?-Kunt and Levine, 1996): (i) market capitalization; (ii) volatility measured by standard deviation of stock market; (iii) indicators of institutional development; and (iv) regulation indicators. Since the banking system must be included, it can be measured by the ratio of domestic credit to GDP or the ratio of nominal money supply (monetary aggregate M2) to nominal GDP. Other variables are often used for robustness of the model. The most common is inflation (e.g. Bassanini et al., 2001).",1
56,6,"Studies dealing with the financial system and economic growth have been discussed mostly in quantitative terms, through crosscountry (e.g. King and Levine, 1993; Levine and Zervos, 1998)panel data (e.g. Luintel and Khan, 1999; Zang and Kim, 2007)andtimeseries (e.g. Gries et al., 2009; Masih et al., 2009; Wolde-Rufael, 2009). Causal relationships between stock markets and economic growth have been shown (e.g. Adamopoulos, 2010; Nieuwerburgh et al., 2006). Causality could be from stock market to economic growth, from economic growth to stock market (e.g. Shahbaz et al., 2008)orbidirectional(e.gCapasso, 2008; Hondroyiannis et al., 2005; Ndako, 2010; Tsouma, 2009). On the other hand, causality may not be present. The analysis of causality was extended to combine the short and long run, as well as strong causality (Bangake and Eggoh, 2011). The direction of causality could be central for economic policy decision making.",1
56,7,"Financial development, as a result of endogenous growth process, is far from new in the literature (e.g. Bose and Cothren, 1997; Greenwood and Jovanovic, 1990). Indeed, it is expected that all variables will interact with each other causing an effect of an endogenous adjustment, and therefore the use of VAR technique is required. This technique treats the variables as potentially endogenous, evaluating the relationships without the prior need to distinguish endogenous from exogenous variables, as required by the simultaneous equations model. In the analysis of the relationship between developed stock markets and economic growth, this technique was used, for example by Caporale et al. (2004), and Tsouma (2009).",1
56,8,"The results show that, for the analysis of the contribution of stock market on economic growth, the appropriate VAR specification requires considering as exogenous the variables: constant, seasonal dummies, one impulse dummy at second quarter of 2000, and two shift dummies. On the one hand, it is necessary to control for the physical introduction of euro notes and coins/integration in Euronext and, on the other hand, to control for the evidence of the subprime crisis in Portugal (since the last quarter of 2008). Moreover, the results of VAR also indicate the prevalence of the physical introduction of the euro over the integration in Euronext. Indeed, the shift dummy is highly statistically significant in the GDP equation, with a negative signal, and it is equally negative and statistically significant in the stock market equation.",1
56,9,"To carry out the VAR estimation, we proceed by testing the optimal lag structure through the sequential modified LR test, the final prediction error, and the Akaike information criterion. All tests indicate three lags. This short optimal number of lags reveals a parsimonious model, and could be a sign of absence of the omission variable bias. The validity of the estimated VAR model was evaluated through diagnostic tests (see Table 3), namely: normality, by using the Jarque Bera test, autocorrelation through the LM test, and heteroskedasticity by performing the White test (without cross terms).",1
56,10,"This paper focuses on the contribution of two competing systems of financing the economy, stock markets and bank financing, towards economic growth. In designing economic policy for growth, it is crucial to understand this fully. In fact, if economic growth responds differently in face of an innovation in the two systems, then policy makers should focus their action preferentially on the most responsive one.",1
56,11,"The competing systems are proved different in terms of Granger causality, variance decomposition and impulse response function. Actually, an innovation in one brings, as expected, a decrease in the relative weight of the other in the system, as can be seen in Fig. 3. The response of bank financing to an innovation in the stock market is more pronounced and faster than the reverse. In general, bank financing is closed in on itself more than the stock market is. This result is largely unexpected. Indeed, as a non-Anglo-Saxon country, in Portugal the use of bank financing by corporations should be widespread. Accordingly, bank lending ought to play a major role in Portuguese economic growth.",1
56,12,"The results from Table 5 are in line with those obtained from the exogeneity tests. Indeed, all variables reveal dynamic behavior which is a requirement of endogeneity (see Table 5 and Fig. 3). With regard to DLY, after a two-quarter lag, shocks to DLY explain around 85% of the forecast error variance. This impact is reduced to around 59% at the end of the ten-quarter. When comparing the shocks to DLS and shocks to DLB, the shocks to DLS explain a substantially larger percentage of the forecast error variance than the shocks to DLB, i.e., about 15.5% and 3%, respectively at the end of ten-quarter. Shocks to DLI gain strength consistently, and jump from about 2.5% to 5.8% in the explanation of the forecast error variance. As expected, when the focus is on models incorporating financial variables, then the control for nominal effects reveals to be necessary. Indeed, at the end of ten-quarters, shocks to DLP explain around 16.6% of the forecast error variance.",1
56,13,"The effect of the stock market development on economic growth in Portugal (1993–2011), which is a small economy subject to strong impacts caused by structural changes, is analyzed. A comparison of the effects of the two competing systems of financing the economy – stock market and bank financing – on economic growth is also provided. No cointegration relationship was detected. A VAR model, with exogenous both impulse and shift dummies, was estimated. The VAR model proved to be suitable for handling the analysis of the relative contributions of the stock market and bank financing on economic growth. However, this analysis requires the inspection and posterior inclusion of the Portuguese idiosyncrasies. The absence of these controls could mask relevant causal relationships among variables, leading to erroneous conclusions.",1
56,14,"Regarding the two components of the financial system, two behaviors are observed. On the one hand, a positive causal relationship between stock market development and economic growth was detected, and it is, in fact, bidirectional. On the other hand, it appears that the banking system is not driving economic growth, but is a net beneficiary of that growth. In view of this, economic policies ought to be aware that it is stock market development, and not bank financing, that promotes economic growth. The different nature of these two components of the financial system deserves to be the object of further research, including understanding the transmission channels through which financial markets and their segments interact with economic growth.",1
56,15,"The control variables enabled facts often associated with the Portuguese reality to be proved. On the one hand, investment did not produce significant multiplier effects. On the other hand, the loss of economic price competitiveness is notorious. Also considered were the Portuguese idiosyncrasies, namely: (i) the break in the GDP series in the third quarter of 2000; (ii) the physical change in currency, from the escudo to the euro, which constitutes an economic regime change; and (iii) the subprime crisis. These facts prove to be mandatory for a full understanding of the transmission channels from finance to the economy.",1
57,1,"We look at economic voting during times of financial crisis using individual-level survey data from the 2008 and 2011 Canadian Election Studies. We posit that in times of crisis, the economy’s impact on incumbent voting can be twofold. There is first an impact that is more traditional in nature and based on retrospective assessments of national economic conditions (which are necessarily bad given the crisis context). There is also an impact that is based on perceptions of the parties’ competence at managing the economy. Depending on these perceptions, the competence effect can compensate for incumbent vote losses that might be incurred from bad economic times (traditional effect). In more general terms, looking at competence-based issue ownership allows us to add a neglected valence component to the economic voting model.",1
57,2,"From the viewpoint of voting behavior theory, the economy is a classic valence issue (Stokes, 1963). In democratic societies, basically all parties and voters agree that economic growth is a desirable goal. Put differently, neither parties nor voters really differ in their position on this issue since there is a virtual consensus about what should be achieved economically for the society as a whole. What really matters for voters, then, is whether the government actually delivers on that goal. If it does, it stands a greater chance of being reelected at election time. If it does not, then it seriously runs the risk of being voted out of office.",1
57,3,"The latter phenomenon has come to be known as the ‘traditional economic voting’ expectation (Lewis-Beck, 1988). It forms the core of what can be called a valence model of economic voting (Lewis-Beck and Nadeau, 2011). Voters form a judgment on the government’s past economic performance and cast their ballot based on that judgment. In other words, they hold the government accountable for the recent evolution of their country’s economic situation.",1
57,4,"The valence model of economic voting, in its current formulation, is thus mostly concerned with voters’ retrospective evaluations of economic conditions. While it makes sense to expect voters to react to recent changes in economic circumstances, it seems reasonable as well to assume that voters also take into account the issuehandling capabilities of the different political parties that are competing for their votes. The parties’ reputation as competent political actors is an important component of the valence model of political choice (for example, Trilling, 1976; Petrocik, 1996; Clarke et al, 2004; Bélanger and Meguid, 2008; Pope and Woon, 2009; Green and Jennings, 2012; Egan, 2013). Following these insights, a growing body of work has started to examine the impact on vote choice of perceptions of party competence at managing the economy (for example, Sanders, 1999; Bellucci, 2006; Butt, 2006; Smith, 2007; Bélanger and Gélineau, 2010).",1
57,5,"In this article, we wish to integrate these two valence dimensions of economic voting into a single incumbent vote model. So far, the valence model of economic voting has focused almost exclusively on the impact of retrospective economic evaluations, mostly ignoring the second dimension highlighted above, which involves issue ownership (the only exceptions in this regard are: Martinsson, 2009; Bélanger and Gélineau, 2011). Taking both of these components of economic voting into account seems particularly relevant in the context of an economic crisis. In times of crisis, the economy’s impact on incumbent voting can be expected to be twofold. There is first an impact that is more traditional in nature and based on retrospective assessments of national economic conditions (which are necessarily bad given the crisis context). There is also an impact that is based on perceptions of the parties’ competence at managing the economy. Depending on the state of these perceptions, the competence effect can compensate for incumbent vote losses that might be incurred from bad economic times (traditional effect).",1
57,6,"We empirically demonstrate these dual effects with survey-based analyses of the vote for/against the incumbent Conservative Party of Canada in the 2008 and 2011 federal elections. In both of these elections, the Conservatives were reelected despite the economic crisis context, which suggests that the traditional economic voting hypothesis may not be sufficient for explaining the role of the economy as a valence issue in these election outcomes.",1
57,7,"For example, five federal elections have been held in Canada at times when the country was going through, or was still recovering from, a serious economic crisis. In three of these elections (1974, 2008, 2011) the incumbent party managed to get reelected. In the other two elections (1984, 1993) the incumbents experienced crushing defeats. How can we reconcile these different outcomes with the classic economic voting theory that would predict the incumbent’s defeat in all of these five elections? In this article we offer an explanation that rests on the distinction between two valence dimensions of economic voting, the classic dimension and the issue ownership dimension, and we test it by examining two of these five Canadian elections more in depth. The next two sections present a more elaborate discussion of our theoretical considerations and expectations.",1
57,8,"The hypothesis of a link between the economy and incumbent voting rests on the principle of government accountability: governments are held responsible, at least in part, for the evolution of economic conditions and citizens reward (punish) the governing party if this evolution is positive (negative). The impact of economic conditions on support for incumbent governments has mainly been studied in the United States (Key, 1966; Kramer, 1971; Fiorina, 1981; Kiewiet, 1983; Lewis-Beck, 1988) but a similar relationship has been uncovered in most other Western democracies (for recent comparative studies, see Duch and Stevenson, 2008; Nadeau et al, 2013) with some of this literature having emphasized the conditionality of the relationship between the economy and the vote by taking into account either the role of institutional arrangements or voters’ level of sophistication (see, in particular, Powell and Whitten, 1993; Anderson, 2007).",1
57,9,"This basic expectation forms the core of what Lewis-Beck and Nadeau (2011) refer to as the ‘valence’ model of economic voting. They distinguish this type of economic voting from two other models: policy-oriented economic voting (Kiewiet, 1983; Lewis-Beck et al, 2013) where the economy acts as a positional issue (that is, voters have diverging views about economic policy outcomes and parties are associated with specific economic policies); and patrimonial economic voting (Nadeau et al, 2010; Lewis-Beck et al, 2013) where a person’s patrimony (in terms of financial assets) influences his/her vote preferences. We agree with Lewis-Beck and Nadeau (2011) that economic voting can be viewed as a multidimensional phenomenon. What we wish to argue in this article is that the valence model of economic voting can itself be understood as being multidimensional if we integrate a second valence dimension to it, namely that of party competence.",1
57,10,"According to the current valence interpretation of economic voting, when casting their ballot citizens are mostly concerned with the incumbent party’s economic record over the past year or so. Valence models of political choice (for example, Clarke et al, 2004, 2009) suggest that voters can very much consider the incumbent’s comparative performance and reputation as well when making up their mind about which party to vote for. In fact, in recent years a growing number of studies about the impact of the economy on the vote have highlighted another dimension of economic voting that is related to the political parties’ image of competence at dealing with the economy (Sanders, 1999; Bellucci, 2006; Butt, 2006; Smith, 2007; Martinsson, 2009; Bélanger and Gélineau, 2010, 2011).",1
57,11,"In a context of financial crisis, when the state of the economy does not really give an electoral advantage to the incumbent party, we can expect that the incumbent may try to campaign on an issue other than the economy (Vavreck, 2009) or that it may still campaign on the economy – but by framing that issue in a more favorable way, that is, in a way that would allow the incumbent party to project an image of itself that is more positive than that of its opponents (Nadeau et al, 2010). A party’s economic competence can thus become a key component of its campaign message.",1
57,12,"This second valence dimension of the economy is retrospective in nature. But it differs from the traditional valence dimension in one important respect. While the traditional dimension is solely concerned with the incumbent party’s economic record, the competence dimension is more comparative in nature. It involves assessments of the incumbent’s economic performance as compared with other economies. The question that the voter asks becomes: Does the nation’s economy, despite its difficult situation, nonetheless show a better performance than comparable (for example, neighboring) economies? If it does, then the voter concludes that the incumbent party did relatively well under the difficult circumstances and may decide to support it despite the crisis context and its impact on the national economy. Kayser and Peress (2012) refer to this cognitive process as ‘benchmarking’ while Duch and Stevenson (2010) conceptualize it as the extraction by voters of signals about the government’s relative economic competence.",1
57,13,"This dimension thus relates to the competence-based component of issue ownership, which rests on the parties’ performance at handling specific issues and can be assessed via comparison, and especially via benchmarking in the case of the economy. It must be distinguished from the ‘associative’ component of issue ownership that mainly involves the history of attention given to specific issues by parties through their policy priorities, and which has less to do with performance per se (on this crucial distinction, see Walgrave et al, 2012). This distinction between valence and policy dimensions of issue ownership mirrors the one that we drew in the previous section between the traditional economic voting hypothesis and Kiewiet’s (1983) policy-oriented view of economic voting.",1
57,14,"Together with Martinsson (2009, p. 230), we argue that issue ownership constitutes an important factor that helps to account for why incumbents might not be punished for objectively poor economic performances. Other studies having tried to account for this phenomenon have tended to highlight various institutional and contextual factors (see the review in Anderson, 2007); but they have not looked at the parties’ image of economic manager. We believe issue ownership to be another significant factor of economic voting.",1
57,15,"We expect that such a competence dimension influenced incumbent voting in the 2008 and 2011 Canadian federal elections: perceptions of the incumbent party as being the most competent at managing the economy should increase the likelihood of voters supporting the Conservative Party while perceptions of an opposition party as being the most competent should decrease it. Bélanger and Gélineau (2011) examined similar effects in the context of a single subnational election (the 2008 Quebec one). Martinsson’s (2009) study looked at six Swedish national elections, but focused on the specific issue of unemployment. Our own study looks at competence on the economy more broadly defined, for two consecutive Canadian national elections.",1
57,16,"As indicators of retrospective sociotropic economic assessments, we use two measures in turn. We first use the classic measure based on the usual question: ‘Over the past year, has Canada’s economy gotten better, gotten worse or stayed about the same?’ (better = +1, same = 0, worse = ?1). This indicator should allow us to capture the traditional economic voting effect. That said, in their own investigation of economic voting in the 2008 Canadian election, Gidengil et al (2012, p. 77) report only a weak effect when using this measure. They go on to argue that the reason for such a modest economic voting effect is that many voters did not blame the Conservative government for the country’s economic downturn, since the financial crisis had mainly erupted in the United States (Gidengil et al, 2012, pp. 79–82). For this reason, we develop a second measure of retrospective economic evaluations that takes into account responsibility attribution. This ‘economic responsibility’ measure weights the original variable of economic perceptions on the basis of whether the respondent actually attributes responsibility for good (or bad) national economic conditions to the government’s policies.",1
57,17,"Our indicator of political parties’ image as competent economic managers is based on answers to the following question: ‘In your view, which party would be best at dealing with the economy?’2 Since our dependent variable is dichotomous (voted for the Conservative Party or for another party) we code the competence variable as follows: Conservatives named as competent = +1, another party named as competent = ?1; none are competent, all about the same, don’t know = 0. (For a similar three-category coding of party competence, see Bélanger and Meguid (2008); Bélanger and Gélineau (2011)). This question is available in both surveys. However, in 2008 it is asked only to one half of the sample (random split-sample experiment). The question asked to respondents from the other half of the sample refers instead to job creation (‘... would be best at creating jobs?’). Since the issue of job creation is relevant to the economic crisis context, we also consider this second aspect of economic competence in our analysis as additional evidence of economic voting on the basis of competence assessments.",1
57,18,"The 2008 Canadian federal election was called by Prime Minister Stephen Harper right before the economic crisis erupted in the American housing and financial markets. Canadians went to the polls on 14 October, having in mind this crisis context and being aware that the Canadian economy had started to slow down and was possibly about to collapse, to some extent, over the coming months. According to the CES data, 81 per cent of respondents outside Quebec stated that the issue of the economy was very important for them in that election, with an additional 17 per cent saying that it was somewhat important.3 Not surprisingly given the start of the economic downturn, 46 per cent of respondents thought that Canada’s economy had deteriorated over the past year, 39 per cent thought that it had stayed the same, while only 14 per cent said that it had improved. The traditional economic voting hypothesis would lead us to expect these negative economic evaluations to have hurt the incumbent Conservatives.",1
57,19,"The regression model presented in Column 2 of Table 1 substitutes the traditional 3-point measure of past economic assessments for this 5-point economic responsibility measure (although keep in mind that both indicators have been standardized to run from ?1 to +1). The results are clear. Economic voting appears as substantial as in the first model when one uses the economic responsibility indicator. This result is in line with Gidengil et al’s (2012) intuition about the nature of economic voting within the context of the 2008 Canadian election. Certainly, in times of global economic crisis, an incumbent government cannot be held entirely accountable for a country’s worsening economic conditions; only those voters who blame its policies can be expected to cast a vote against it, which is what the economic responsibility indicator attempts to capture. To be clear, economic voting did occur in 2008 and it hurt the incumbent party since most Canadian voters thought that economic conditions had deteriorated, or at least had not improved. It is simply that it occurred most strongly among the smaller group of people who attributed credit or blame to the government’s policies, everything else being equal.",1
57,20,"That said, we note that the difference between the two models of Table 1 in terms of model fit is extremely small. This suggests that the contribution of responsibility attributions to the traditional economic voting effect is rather modest. Responsibility attributions do add an important nuance to the effect, but they do not increase the explanatory power of the model by much. As we have argued at the outset of this article, it seems that a focus on retrospective economic perceptions alone can only offer an incomplete account of economic voting, especially in times of financial crisis. As hypothesized, during hard times, perceptions of party competence at managing the economy can have either a counteracting effect or a reinforcing effect.",1
57,21,"How much of an effect do these two valence dimensions of economic voting actually have on the probability to support the incumbent party, everything else being equal? To illustrate this impact in more concrete ways, we convert the results into marginal effects based on our logistic regression results. We do so for the enhanced valence model of economic voting as estimated for 2008 (first column of Table 4) but the results are very similar if one uses instead the 2011 regression results of Table 7 as a basis, or those of the jobs creation model of 2008 (second column of Table 4). We keep all the other independent variables at their mean values while we change the values of retrospective national economic evaluations (the version weighted by responsibility attribution) and party competence on the economy and compute the corresponding change in the predicted probability to vote for the incumbent party. These simulation results appear in Table 8.",1
58,1,"The standard neoclassical approach to economic theorizing excludes, by definition, economic emergence and the related phenomenon of entrepreneurship. We explore how the most economic of human behaviours, entrepreneurship, came to be largely excluded from mainstream economic theory. In contrast, we report that evolutionary economists have acknowledged the importance of understanding emergence and we explore the advances that have been made in this regard. We go on to argue that evolutionary economics can make further progress by taking a more ‘naturalistic’ approach to economic evolution. This requires that economic analysis be fully embedded in complex economic system theory and that associated understandings as to how humans react to states of uncertainty be explicitly dealt with. We argue that ‘knowledge,’ because of the existence of uncertainty is, to a large degree ‘conjectural’ and, thus, is closely linked to our emotional states. Our economic behaviour is also influenced by the reality that we, and the systems that we create, are dissipative structures. Thus, we introduce the notions of ‘energy gradients’ and ‘knowledge gradients’ as essential concepts in understanding economic emergence and resultant economic growth.",1
58,2,"Conventional neoclassical economics has at its core the presumption that economic decision making is a matter of cold logic, namely, the application of a constrained optimisation rule. Over the past three decades, this rule has become set, increasingly, in the context of strategic interactions although much of macroeconomics continues to apply it in the context of a single ‘representative agent.’ Despite the analytical precision that such a rule provides, it can only approximate actual behaviour in historical time when there is either certainty or quantifiable risk, i.e., in ‘simplistic’ contexts (Foster (2005)). It can only be used to calculate from calculable information. It cannot approximate economic decision-making when there is uncertainty, i.e., the absence of knowledge of the full set of events faced and the probabilities associated with them. Significant technological, organizational or institutional changes occur in states of uncertainty and, furthermore, these changes, in turn, can create new uncertainties in an economic system. This uncertainty does not prevent economic behaviour from occurring. On the contrary, we observe much creative and cooperative behaviour in states of uncertainty and the result is ‘economic emergence’ whereby new network structures form with characteristics that are irreducible to the elements of which they are composed.",1
58,3,"The school of thought in which economic emergence has been addressed most directly is evolutionary economics. This has been possible because evolutionary economists are concerned with how economic systems are transformed from within; evolutionary theory is inherently a theory of change that reflects not one, but a range of behavioural rules that are adopted and applied by economic decision-makers. For example, Nelson and Winter (1982) stressed the centrality of behavioural routines once it is accepted that decisionmakers have to operate in the reality of historical time, with all its attendant uncertainties. In evolutionary economics, economic agents are viewed as reducing the uncertainty that they face and achieving economic goals by adhering to bundles of rules. Economic emergence occurs as radically new bundles of rules form into capital goods (technological rules), productive networks (organisational rules), contracting systems (institutional rules) and human skills (procedural rules). This is a process of ‘selforganization’ and it is honed by a process of ‘competitive selection’ whereby particular technologies, organisational structures, institutions and procedures come to dominate.",1
58,4,"This perspective on economic emergence requires an understanding of both the genetic and culturally acquired drivers of human behaviour, honed in our anthropological history, and how these interface with the energetic requirements of living, dissipative systems. Correspondingly, the institutional rules that humans adopt in their various cultures, and how these change as circumstances change, have to be understood before we can analyse economic behaviour. This does not imply that conventional economic analysis should be rejected since humans clearly attempt to do the best they can within the circumstances that they face. Thus, the issue is not optimisation per se but rather the limits to calculative behaviour and the different ways in which individuals can respond to the information at their disposal. Thus, all evolutionary theories place the diversity of behaviours, rather than uniformity of behaviour, at their cores. So, whether or not behaviour is ‘optimal,’ by some logical criterion, is very much a secondary question. .",1
58,5,"The remainder of the article is organised as follows. In Section 2 we provide a historical overview of why economists have found it so difficult to capture emergence in economic analysis. For the heterodox economist, this overview is likely to cover material that is familiar but, for the benefit of younger mainstream readers, it seems worthwhile to provide some motivation for what follows. In Section 3, we discuss how evolutionary economists have dealt with economic emergence over the years. Again, this is in the style of an overview of the main points of differentiation with the mainstream rather than a comprehensive review. Section 4 focuses on the key catalyst of economic emergence, widely regarded as pivotal by evolutionary economists inspired by Joseph Schumpeter, namely, entrepreneurship. In Section 5 we seek to grasp why people are impelled to take large entrepreneurial risks in the face of radical uncertainty and to assess how this kind of behaviour can be captured using complex adaptive systems theory Section 6 contains some concluding remarks.",1
58,6,"So economics in the 1950s moved inexorably towards a body of logic in which emergent phenomena could not be accommodated. From a scientific perspective, this was a quite remarkable trend because it meant that what are patently core drivers of economic evolution and growth, came to be ignored in favour of the mathematics of constrained optimisation, cast in a ‘force field’ representation of a fully connected network system imported from 19th Century physics (Mirowski (1989) and Potts (2000)). Back in the 1950s, it did not look like this kind of economic analysis would come to dominate. The ‘Keynesian revolution’ had raised fundamental questions concerning the validity of neoclassical economics as an adequate representation of economic behaviour. Although, microeconomics remained firmly in the neoclassical tradition, short, medium and long term macroeconomics took on a distinctly non-neoclassical flavour. For example, the medium term multiplier-accelerator representation of the business cycle became popular and Harrod’s theory (Harrod (1948)) became the baseline in the field of economic growth, with the related Harrod-Domar representation the preferred analytical basis of development planning.",1
58,7,"Instead of trying to find ways of dealing with technological change in their growth models, neoclassical economists argued that what were required were better ‘microfoundations’ for macroeconomics. This view had already gained a foothold after Keynes’ death through the widespread acceptance of the ‘neoclassical synthesis’ interpretation of the Keynesian model, originally promulgated by John Hicks (Hicks (1937)). So, neoclassical economists found it relatively easy to advance into the fields of business cycle and growth theory in the following decades. The dynamical mathematical representations of the cycle and growth that had emerged were messy, complex, often did not have equilibrium solutions and were very difficult to verify empirically. Neoclassical economists sought to circumvent these difficulties with simple ‘representative optimizing agent’ analytical foundations that were easy to understand and apply if suitably strong ‘simplifying’ assumptions were made. In no sense could these advancing theories deal with economic emergence because the representative agent is a uniform agent, so there can be no possible connection to Schumpeter’s entrepreneur or the ‘Marshallian flux’ and the differentiated firm (Metcalfe (2007)).",1
58,8,"The economics discipline consolidated its constrained optimisation core in the second half of the 20th century partly because of an anxiety to be recognisably ‘scientific.’ Samuelson, Arrow and Debreu replaced Veblen, Marshall and Schumpeter at the intellectual core and not only did this disconnect economics from economic emergence but it also made economists reluctant to accept the importance of behavioural traits beyond narrow neoclassical definitions of rationality. This was amply demonstrated recently in the blindness of the majority of economists to the impending global financial crisis in the first decade of the 21st Century (Akerlof and Shiller (2009)). Decades previously, John Maynard Keynes, very perceptively, had argued that business investment was driven by ‘animal spirits’ and that the resultant waves of optimism and pessimism caused fluctuations in economic growth. But the neoclassical synthesis had eliminated this attempt by Keynes to capture a particular kind of emergence. Instead, the Keynesian story became depicted as one of labour market failure in an otherwise wellfunctioning neoclassical (non-) world.",1
58,9,"By the early 1990s, endogenous growth theorists would claim that Solow’s unexplained residual could be explained by introducing ‘knowledge’ as an additional factor of production with unusual characteristics that yield economies of scale or spill-over externalities. In this neoclassically-based theory, a ‘stock’ of knowledge is generated by R&D, involving researchers incentivised to discover inventions that can be innovated into new capital equipment to sell to consumer goods producers. As usual, some clever assumptions and functional forms are required to make the theory work and what did it tell us? Only general things we already knew: investment in education and training matters, it is important to promote and facilitate innovation, patents are socially beneficial but mustn’t be over-protective. By definition, equilibrium endogenous growth theory lacks any explanation of the process of economic emergence, yet it aspires to be explanatory. Most notably, the key agent of economic progress, entrepreneurship is virtually ignored.",1
58,10,"However, the mathematical representation of processes such as competition and innovation does not wholly eliminate their emergent character. In the contemporary lexicon of emergence, they capture ‘weak’ emergence not the ‘strong’ emergence that we associate with, for example, Schumpeterian radical innovation and associated entrepreneurship (see Corning (2002)). All emergent processes and the economic growth trajectories that they shadow, must have a deterministic component because of the fact that economic systems are dissipative structures and, as such, have to remain structurally coherent and, to some degree, be irreversible over historical time (Foster and Wild (1999a)). This structural persistence has a mathematical structure that can be estimated parametrically using econometrics. But such quantitative modelling of a growth trajectory remains, necessarily, an incomplete representation of an evolutionary process that involves structural change. By implication, the statistical residuals in a logistic diffusion model that has been estimated econometrically must contain all the nondeterministic components of an emergence process, in addition to normal Gaussian stochasticity (see Foster and Wild, 1999b).",1
58,11,"Thus, there is little doubt that evolutionary economists have been successful in dealing with weak emergence in both their theorising and in empirical applications. They have also understood the importance of strong emergence and recognised that it is the source of economic evolution and growth. Since the seminal contributions of Joseph Schumpeter, it has been accepted that the generation of novelty via entrepreneurship is the pivotal catalyst in economic emergence. But this has been very difficult for evolutionary economists to deal with analytically (Witt (2009b)). Clearly, this is a field in evolutionary economics that requires further development before a full treatment of economic emergence can be delivered.",1
58,12,"Emergence involves, among other things (Harper and Endres (2011), wholes being more than the sum of their parts. This is, of course an old idea (Lewes (1875)) and is recognised in mainstream economics in the context of economies of scale and scope and learning, or experience, curves. However, as noted, these are generally kept outside the constrained optimization body of theory. In contrast, both in evolutionary economics and in business strategy, analysis of these processes is central and tends to centre on the operation of entrepreneurship. Entrepreneurial individuals or groups in organizations take on the difficult task of: setting up networks of connections between elements, such as machines (embodying physical technologies) and people (embodying skills); using sets of organizational rules (social technologies); and accessing appropriate and affordable energy sources. There have been a number of contributions in this field by evolutionary economists generally adopting either a case study methodology, agent-based simulation or some combination of both (see, for example, Malerba et al (2001) and Foster and Potts (2009)).",1
58,13,"Historical lock in, because of the complexity of physical, cultural, conceptual and organisational structure that has been built up successfully, is always present and this limits the firm’s room for manoeuvre. Here there is an evolutionary dilemma - increased efficiency tends to be achieved by creating tighter specialised connections in networks, but specialised organizations are generally less flexible than loose groups of unspecialized individuals, making adaptation in maturity more difficult to achieve. There is always far more adaptive potential in an industry than there is in any individual firm and far more adaptive potential in the economy as a whole. So, again, being overly rational in the neoclassical sense can be a handicap. A common case cited in the field of business strategy is that of IBM which achieved high levels of organisational efficiency but became incapable of adaptation (Foster and Kaplan (2001)). So an entirely separate branch had to be created to innovate and create the personal computer. In complexity theory, it has been long recognised that the optimisation of a whole system generally involves suboptimal behaviour in its individual components.",1
59,1,"The recent moves of the Indian economy towards further opening up of the economy with less government control has brought about changes in its policy structure. The objective of this study is to test the hypothesis that greater economic freedom leads to higher levels of economic growth in a federal system like India where business regulations, taxation, and government spending differ widely across states. Pooled linear regression model is applied to categorical data containing economic freedom and its three components as independent variables, and growth rates of income per capita and gross state domestic product as dependent variable, for a panel of twenty states for three time periods, 2004/2005, 2006/2007 and 2009/2010. While examining this relationship, the variables like initial income per capita, initial literacy rate, sectoral composition, and inflation rate are taken as control. The results tend to establish the fundamental effects of economic freedom in fostering economic growth. Three individual dimensions of economic freedom namely size of government, strong rule of law, and flexible regulations governing credit, labour, and product markets are likely to exert beneficial impacts on income growth.",1
59,2,"It is widely established that market-driven reforms foster economic development (Berggren 2003). Market liberalization and building institutions for market are considered as crucial elements of Washington-consensus (World Bank 2002) under which adjustment programmes of international organizations like the International Monetary Fund (IMF) and the World Bank are designed to help free an economy from excessive government intervention. According to the World Bank (2002), market-based institutions help transmit information efficiently, enforce property rights and contracts, and secure competition, thereby influencing economic development (De Vanssay and Spindler 1994; Alesina 1998; De Haan and Siermann 1998; Nelson and Singh 1998). These institutions tend to promote economic freedom and have the credibility to make the growth-enhancing incentives available through low taxation, independent legal system and protection of private property (Murphy et al. 1991; Gwartney 2009). They encourage dynamic and organised economies, where free and fair competitions exist, thanks to effective regulations. Government enterprises are less in number in such economies (Johansson 2001).",1
59,3,"As early as in the late 1980s, the Indian economy evidently witnessed a gradual transformation with trade liberalization, slow but steady deregulation of investment along with output control. Since 1991, with the adoption of new economic reform programmes, the economy has made a clear-cut transition from a state-led development model to a neoliberal paradigm. Consequently, the country has registered a great deal of changes, both internally and externally, while ensuring greater visibility of ‘invisible hands’ of free and competitive market economy (Ghosh and Chandrasekhar 2007). Growth rates of India’s national and per capita incomes have been quite impressive during the period of economic liberalization. Subsequent measures towards further opening up of the economy with less government control seem to have brought about changes in the policy structure with respect to the size of government—expenditures, taxes and enterprises—, legal structure and security of property rights as well as regulation of labour and business (Debroy et al. 2011).",1
59,4,"Economic freedom implies the degree to which a market economy is in place, where the central components are voluntary exchange, free competition, and protection of persons and property (Gwartney et al. 1996). The primary goal is to characterize the institutional structure as central to economic policy (North 1990). The incentives economic actors (entrepreneurs, innovators, financiers, industrialists, and others) achieve are determined, in large part, by the existence of institutions (North 1990), which may or may not be efficient.",1
59,5,"Economic freedom, as originally defined by Fraser Institute, entails five important components viz. (a) size of government (b) legal structure and security of property rights (c) access to sound money, (d) freedom to trade internationally, and (e) regulation of credit, labour and business (Gwartney et al. 2010). Within these broad components lie many sub-components and 42 distinct variables, each having its own implications. In ‘Economic Freedom of the World Report’ of Fraser Institute, each component and sub-component is placed on a scale of 0–10 reflecting the distribution of the underlying data. Each sub-component and component is averaged to derive the ratings and economic freedom of each country. A separate index of economic freedom is also brought out annually by the Heritage Foundation in partnership with the Wall Street Journal. However, the philosophical underpinnings, by and large, remain the same in both the indices (Debroy et al. 2011).",1
59,6,"Since the time of Adam Smith, there has been a line of reasoning that economic freedom—understood in Hayek’s sense as ‘absence of coercion’—has the ability to promote growth and affluence (Prokopijevic 2002). There are strong evidences of a close statistical correlation between economic freedom and growth (Hanke and Walters 1997). As economic freedom entails competition, there can be potent reasons to expect that free economies grow faster than those that are less free (Gwartney et al. 2010). In general, competition leads to higher economic growth. A liberal economy provides greater opportunities for entrepreneurial discoveries and helps channelize private investments toward the areas experiencing higher rate of return (Parente and Prescott 2000). While economic freedom per se is a critical indicator, its individual components are likely to exert varied impacts on the health of the economy (Ayal and Karras 1998; Heckelman and Stroup 2000; Carlsson and Lundstrom 2002; Dawson 2003; Berggren and Jordahl 2006) (Fig. 1).",1
59,7,"There seems to be a broad consensus that security of property rights is crucial for economic growth (Parente and Prescott 2000). Secure and transferable rights over assets and contracts are investment-generating and hence growth-enhancing, as owners are assured of receiving the benefits of their investments. With security of property rights, the allocation of assets also becomes efficient and hence, it becomes growth-promoting (World Bank 2002). Savings can be transferred to activities with the highest expected profits. Security of property rights with a well functioning legal structure may act as a necessary complementary institution to other components of economic freedom (Rodrik 2000).",1
59,8,"Access to sound money is yet another area of economic freedom, which puts thrust primarily on the costs of inflation. There are ample reasons why especially high and volatile inflation will have a negative impact on growth (Briault 1995). However, Akerlof et al. (1996) argue that a moderate level of inflation provides ‘grease’ to the price and wage setting processes. The economic adjustment of relative prices to shocks can become sluggish in the presence of downward nominal rigidities in wages and prices. A moderate level of inflation provides some real wage flexibility, which reduces the natural or long run rate of unemployment (Loboguerrero and Panizza 2003). The empirical evidences on the inflation-growth nexus is thus somewhat mixed.",1
59,9,"Freedom to trade internationally may indicate that there are efficiency effects from trade liberalization. The interaction with global market through trade liberalization may bring about diffusion of technology. With international competition in the background, free trade enhances the productivity of the domestic firms, if exchange is done according to comparative advantages (Greenaway et al. 2002). The debate on the relationship between trade liberalization and economic growth is, however, still inconclusive (Sachs and Warner 1995; Rodriguez and Rodrik 2001). Some studies (Greenaway et al. 2002) report evidences in support of a positive linkage, while others are skeptical (Yanikkaya 2003).",1
59,10,"Regulation of labour, credit, and business is yet another dimension of economic freedom. There is a broad consensus that less regulation, in general, becomes beneficial to growth (Calmfors and Driffill 1988; Baumol et al. 2007). Unfriendly labour laws and concomitant labour strikes and industrial disputes hamper the business. Lack of adequate infrastructure and raw materials may also hinder control over the business. Higher transaction costs impose constraints on carrying out trade and economic activities, thereby serving as restraints on economic freedom of agents (Debroy et al. 2011).",1
59,11,"For undertaking state-wise analysis in India, economic freedom indices considered are taken from Economic Freedom of Indian states, 2011 (Debroy et al. 2011) for the year 2005, 2007 and 2009. The Indian economic freedom index is based on only three important parameters namely size of government, legal structure and security of property rights, and regulation of business and labour. It considers 20 states for which relevant data are available.",1
59,12,"It may be noted here that the areas for which the India’s economic freedom index is constructed are derived from the Economic Freedom of the World Report constructed by the Fraser Institute. This ensures that the economic freedom rating for Indian states has measures that are somewhat comparable with those for other countries. However, given Indian conditions and the nature of the sharing of responsibilities between the states and the centre, only above-mentioned three dimensions are found to be appropriate. Evidently, in these dimensions, state governments have been given powers to directly affect conditions and institutions (Table 6). These three areas are designed in a way to measure almost all the major aspects of economic freedom of the respective states of the country. The rating scale of the economic freedom index ranges from 0 to 1, with 0 representing the lowest degree of economic freedom and 1 the highest. In order to find out the impact of economic freedom on economic growth, growth of per capita gross state domestic product (GSDP) and growth rate of GSDP are considered and the data pertaining to that were collected from the Central Statistical Office (CSO), Government of India.",1
59,13,"The present study considers the level of economic freedom index rather than its change, though the letter could have been more useful. Since data pertaining to freedom index in Indian context is available only for 3 years, estimation of changes would reduce the data period to two only, thus reducing the number of observations. It may be noted that studies in the past have also considered the level rather than the change (Ayal and Karras 1998; Heckelman 2000). On the basis of earlier empirical evidences, the present study assumes a priori that economic freedom influences growth, but not the other way round (De Vanssay and Spindler 1994; Ayal and Karras 1998; Heckelman 2000; Dawson 2003). Consequently, the model is not tested for endogeneity and only linear multiple regression model is proposed.",1
59,14,"It may be recapitulated that higher degrees of economic freedom are associated with higher rates of economic growth. The (direct) channel of such association could be the ‘productivity effect’. Since many of the freedom index variables amount to measures of price distortion, leading to effects on efficiency in the allocation of resources, it is likely that economic freedom exerts positive effects on economic growth (Cole 2005).",1
59,15,"With regard to individual components, it may be hypothesized that a smaller sized government, better legal provisions and security of property rights, and higher flexibility and state intervention in credit and labour market, and business will ensure higher economic growth in India. In the neoclassical growth models of Solow–Swan and Ramsey, an exogenously higher value of the rule of law indicator tends to raise the steady-state level of output per effective worker. Similarly, a higher ratio of (nonproductive) government consumption to GDP seems to depress the steady-state level of output per effective worker, thereby reducing the growth rate. In the former case, the growth rate increases, while in the latter, it decreases, for given values (Barro and Sala-i-Martin 2004).",1
59,16,"Interference of the government in the functioning of the economy or a larger role of the government as a producer and a provider of goods and services or as a redistributor of resources reduces the level of economic freedom (Debroy et al. 2011). Rise in size of government in terms of expenditure, for instance, may entail distortion of private decisions. These distortions can affect governmental activities themselves and also involve the adverse effects from the associated public finance (Barro and Sala-i-Martin 2004). This dimension of freedom is intended to capture the idea that the role of the government in a free economy is to provide functions that are protective and productive. Government expenditures beyond these basic functions and transferring the resources between tax payers are considered as impinging on economic freedom (Compton et al. 2011). In essence, small government size is needed for raising economic freedom, while large size reflects more resource reallocation and intrusion into the private market which may lower freedom. In the formulation of freedom index, such non-linear relationship between size of government and economic freedom seems to have been considered in the background.",1
59,17,Flexibility in labour market is the key to the success of any business. It may indicate capacity of the entrepreneurs to adopt changes needed for their enterprises to grow (Altman 2007). Freedom to entrepreneurs to rationalize the labour base and exit market may enhance business capabilities. Entrepreneurs may also fail if there are constraints in terms of infrastructure and raw materials (Debroy et al. 2011).,1
59,18,"Volatility in the money market may lead to uncertainties. Inflation is an indicator of such volatility and it also reflects macroeconomic instability. There are, however, conflicting views on the role of inflation in output growth. Inflation can create two kinds of effects namely ‘grease effect’ (Tobin 1972) and ‘sand effect’ (Friedman 1977). While grease effect indicates that inflation can speed up the adjustment to long-run equilibrium, sand effect speculates the possibility of resource misallocation, leading to deceleration in growth. In the empirical literature on developed countries, grease effect plays a predominant role, while in developing countries, sand effect assumes significance (Loboguerrero and Panizza 2003). One point of argument is that high inflation rates tend to distort price signals and relative prices due to inefficient allocation of resources (Akerlof et al. 1996). Real net return on investment seems to decrease in higher inflationary environment. Consequently, investment and economic growth are likely to decline in the long run. Contrarily, it may be argued that as money could act as a substitute for capital, favourable impact of inflation cannot be ruled out (Tobin 1980). With these inconclusive findings, the impact of inflation on economic growth remains an empirical question.",1
59,19,"Structure of an economy also assumes significance in the context of economic growth. In this respect, sectoral composition, reflecting industry mix, may be considered as a useful indicator. It may be ascertained that structural change in favour of fast-growing sectors may lead to improvement in growth and per capita income (Mourre 2006). While most of the earlier studies have incorporated the share of services into the model to find out the role of such compositional effects, in the context of the Indian economy, the role of manufacturing as an employmentgenerating sector can be considered as crucial as the fast-growing service sector (Padalino and Vivarelli 1997; Kapsos 2005). In order to understand the compositional effects, shares of employment for the secondary and tertiary sectors are taken as two independent factors. The expected sign of each variable is not clear (Garrett and Rhine 2011) and it may depend on the relative size of each sector and the employment dynamics in all other sectors (Elhorst 2003). Hence, the possible impact of shares of industry and services on growth in India remains an empirical question.",1
59,20,"Yet another important determinant of growth is the level of human capital. If more investment is made in human capital, economic growth rates are likely to be higher, at least until the steady state is reached (Galor and Zeira 1993; Piketty 1997). The presence of human capital may relax the constraint of diminishing returns to physical capital and can lead thereby to long-term per capita growth in the absence of exogenous technological progress. Hence, the production of human capital may act as an alternative to improvements in technology and in turn, as a mechanism to generate long-term growth. The growth rates tend to rise with the amount of the imbalance between human and physical capital if human capital is abundant relative to physical capital, but they tend to fall with the amount of the imbalance if human capital is relatively scarce. Accordingly, it may be argued that an economy can recover faster in response to a war that destroys mainly physical capital than to an epidemic that destroys mainly human capital (Barro and Sala-iMartin 2004). Greater availability of human capital can reduce a country’s costs of adopting sophisticated techniques or, equivalently, raises the return to this adoption (Caselli and Coleman 2001).",1
59,21,"Since 1991, India has introduced several liberalization measures, both internally and externally. The period since then has witnessed two phases of reforms, often termed in academic circle as first and second generation reforms (Jha 2009; Debroy et al. 2011). First generation reforms put more emphasis on the external sector (where the first flush of reforms was introduced), while second generation reforms pertain more to the domestic economy. Besides, first generation reforms often refer to agendas that are under the purview of the central government (viz. product markets), whereas second generation reforms primarily emphasize on issues falling under the purview of the states (viz. markets for land and labour).",1
59,22,"It is interesting to note that these reforms, in course of time, have brought about significant improvements in the scores of economic freedom, with the values rising from 5.1 in 1990 to 6.4 in 2008 (Table 1). Commensurately, all the individual indicators of economic freedom except ‘access to sound money’ have shown constant improvements. The individual indices measure the extent of freedom from restrictions imposed by government (Debroy et al. 2011) on different pertinent aspects.",1
59,23,"India is a large country encompassing perceptible differences across its constituent states, possibly due to differences in their socio-political and institutional arrangements. Therefore, the national scenario may not truly represent the scenarios of the states. Moreover, economic reform programmes have not made equal dent across all the states of the country. While some states have been more pro-active towards adopting reforms agendas, some others have been laggards consistently. Consequently, some states are found to be economically freer than others and some states have grown faster than others. The study on economic freedom and growth thus needs to focus on these inter-state differences.",1
59,24,"The key variables of interest in this study are economic freedom and economic freedom indices. The results regarding the effects of overall economic freedom on economic growth are presented in column 1 of Table 2. The coefficient of the overall economic freedom index is positive and significant, indicating thereby that higher levels of economic freedom tend to achieve higher economic growth across the states.",1
59,25,"The results of the economic freedom indices for three different components are shown in columns 2, 3 and 4 of Table 2 respectively. Considering economic freedom index for the size of government, the fundamental assertion is that lesser government intervention, indicating high economic freedom, may lead to higher economic growth. The coefficient of this index is positive and significant, revealing thereby that states with lower government spending as a share of the total, smaller government enterprise sector and lower marginal tax rates are likely to accomplish greater economic growth. The coefficient of legal structure and security of property rights is positive and significant. The primary assertion could be that ensuring law and order, and protecting property is a core governance area. Regulation of labour and business exerts direct impact on economic growth. This area of economic freedom reflects state intervention in labour markets, and bureaucratic and procedural costs, including physical infrastructure. It may be stated that high flexibility in labour market tends to enhance output growth. All the three areas of economic freedom indices are also taken simultaneously to check the robustness of the model (Table 2, column 5) and the results, by and large, remain the same.",1
59,26,"Share of tertiary sector employment directly affects India’s per capita income growth. However, secondary sector’s share does not seem to be relevant. The primary motive behind the introduction of tertiary and secondary sector’s share into the growth model is to examine the net compositional effects on account of shifts of people from low productive agriculture to high productive secondary and tertiary sector (Barro and Sala-i-Martin 1991). Currently, India’s growth story is attributed, in large part, to the growth of the tertiary sector, which is evident from the rising share of the tertiary sector to the country’s GDP. As the tertiary sector’s growth and employment therein are led by information and communication technology (ICT), the result also indicates the predominant role of ICT in propelling growth in India.",1
59,27,"Literacy rate, considered as a proxy for human capital, also stands out to be an important determinant of economic growth. The coefficient of the initial literacy rate is positive, indicating thereby that the states with higher amount of human capital at the starting point are likely to achieve higher growth. This may signify that human capital may act as complementary to physical capital and hence, it may have the ability to postpone the occurrence of diminishing returns to reproducible capital (Barro and Sala-i-Martin 1991).",1
59,28,"Interestingly, the growth rate of per capita income of the Indian states is found to be positively related to their initial levels of per capita incomes. This tends to suggest that states with initially high per capita incomes tend to grow faster than their counterparts with low per capita incomes, hence corroborating Rao et al. (1999). This finding is contrary to the predication of the neoclassical growth theory based on a critical assumption of diminishing returns to reproducible capital (Solow 1956). The result rather suggests increasing returns to the reproducible capital and divergence in economic growth across the states of India (Rao et al. 1999).",1
59,29,"The results clearly support the proposition that economic freedom enhances economic growth in India. What is interesting to find out is that all the three dimensions of economic freedom assume significance for the Indian states. It is thus prudent on the part of the nation and its constituent states to diminish the size of government and minimize government intervention in the free play of market forces. Flexible regulations governing credit, labour, and product markets are equally indispensable. The legal structure needs to be strengthened so that a better business-friendly environment is created across the states of India, which, in turn, is likely to foster growth.",1
60,1,"How do economic freedom and culture impact economic growth? This paper argues that culture, as measured by the World Values Surveys, and economic institutions associated with economic freedom are both independently important for economic prosperity, but the strength of their impact can be better understood only when both are included in the growth regression. Our results indicate that economic freedom is more important than culture for growth outcomes, suggesting substitutability between the two. We posit that culture is important for growth when economic freedom is absent, diminishing in significance once economic freedom is established.",1
60,2,"Economic institutions, such as private property, rule of law, and contract enforcement are extremely important for economic growth and development. As defined by North (1990), institutions can be thought of as the “rules of the game,” both formal and informal, which govern actions through incentives. Formal institutions are codified structures or written rules, whereas informal institutions are inclusive of cultures, norms, and conventions enforced by social custom. Economists independently link both formal and informal institutions to growth and development, but the relative effects of the two remain to be seen. Following this logic, we argue that economic institutions and culture both need to be accounted for when analyzing economic growth.",1
60,3,"The main goal of this study is to incorporate ‘cultural capital’ into the freedom-growth framework. More generally, the analysis can be viewed as contributing to the literature attempting to understand how institutions matter for economic development. By controlling for both economic institutions and economic culture, we disentangle the relative effects of each and determine empirically the significances of their impacts on economic outcomes. This analysis can be viewed as providing insight into whether economic freedom and culture are complements or substitutes. Our main focus is on relative effects, not the interaction or feedback between culture and freedom, as a way of first uncovering how economic freedom and culture may affect economic prosperity.",1
60,4,"To do so, we use a fixed effects model from 1970 to 2004 and include several robustness checks. Our results suggest that, independently, both culture and economic freedom contribute to economic prosperity. However, once we control for both culture and economic freedom simultaneously, the strong association between culture and growth becomes much weaker, while, overwhelmingly, economic freedom retains a positive and highly significant relationship with economic growth. We view these results as suggesting that culture and economic freedom may act as substitutes where, in the absence of economic freedom, culture provides the core institutional functions such as protecting property rights and enforcing contracts; however, once the institutions associated with economic freedom are credible, there is less need to rely on the informal mechanisms of culture.",1
60,5,"As mentioned above, the direct link between economic freedom and growth is robustly discussed in previous literature. The theoretical underpinning regarding this link is also well established. As De Haan and Sturm (2000: 3) note, “since the time of Adam Smith, if not before, economists and economic historians have argued that the freedom to choose and supply resources, competition in business, trade with others and secure property rights are central ingredients for economic progress.”",1
60,6,"In order to further understand how culture may affect economic growth, we narrow the concept to focus on several specific indicators of culture that are identified as being relevant for economic interaction and exchange. One can think of this subset as ‘economic culture,’ defined by Porter (2000: 14) as “the beliefs, attitudes, and values that bear on economic activities of individuals, organizations, and other institutions. This narrowing process enables us to provide a more in-depth analysis of the connection between culture and economic growth” (Patterson 2000).",1
60,7,"Our economic culture variable is based on the methodology found in Tabellini (2008a, 2009) and is constructed by identifying four distinct categories of culture that should shape behavior related to social and economic interaction and, thus, economic growth and development. These four components are trust, respect, individual self-determination, and obedience, which serve as rules governing interaction between individuals, including market production and entrepreneurship. In general, trust, respect, and individual self-determination are thought to stimulate social and economic interaction, whereas obedience is thought to limit economic interaction and development by decreasing risk-taking, a trait essential to entrepreneurship",1
60,8,"Self-determination is a quantitative measure of the amount of control individuals feel they have over individual choices and their lives. If individuals view economic success or failure as a result of their own efforts (i.e., high levels of self-determination), they will work harder in order to earn a greater payoff for their productivity and increase their welfare. According to this line of reasoning, the greater an individual’s ‘locus of control,’ the greater the overall level of economic development in their country (Banfield 1958).",1
60,9,"Theoretically, the relationship between economic freedom and culture could reasonably be expected to go either way—they may be substitutes or complements. As discussed above, both culture and economic freedom independently affect economic growth. Once both are included in the same regression, if either culture or freedom dominates the other, this suggests that the two are substitutes. However, if both remain significant, culture and freedom are complementing one another in supporting economic growth.",1
60,10,"For example, a culture conducive to economic growth may choose to formalize the informal institutions into institutions associated with economic freedom. Once the formal rules are credible, the informal norms and mechanisms once relied upon for economic interaction and exchange, such as trust networks, may be rendered much less important. If this is the case, economic freedom should dominate culture in the growth regression, suggesting a substitution effect.",1
60,11,"On the other hand, there also are ample reasons for thinking that these two key variables are complements and should both be significant in the growth regression. Culture or economic freedom may, independently, contribute to economic growth, but their independent effects might be far weaker than the impact of having both formal and informal institutions of freedom. For example, a culture rich in trust prompts some exchanges, yet the combination of a trusting culture and a government that enforces laws against predation and honoring private property rights is the key to sustained and large-scale economic growth. Several studies show that culture enhances economic freedom and vice versa (for example, see Berggren and Jordahl 2006; Heinemann and Tanz 2008; Tabellini 2008b; Aghion et al. 2009).",1
60,12,"To measure economic freedom, we utilize the well-cited and established Economic Freedom of the World Index compiled by the Fraser Institute (Gwartney et al. 2008). The index measures the level of economic freedom, utilizing 42 different components, on a scale from zero to ten, with ten representing a greater degree of freedom. These components can be grouped into five broad categories: size of government, monetary policy and price stability, legal structure and security of private ownership, freedom to trade with foreigners, and regulation of credit, labor, and business. Each of these categories represents a subset of the variables used to construct the broader index of economic freedom.",1
60,13,"We include the investment share as one of our standard control variables because of the well-documented positive relationship between the rate of investment in physical capital and the rate of growth (Levine and Renelt 1992). However, we acknowledge a potential endogeneity problem, as highlighted by De Haan et al. (2006), of including both economic freedom and the investment rate in the same regression. Several studies show that economic freedom influences growth directly through a productivity-enhancing channel and indirectly through an investment effect (Dawson 1998; Bengoa and Sanchez-Robles 2003;Gwartney et al. 2004). We include investment in our main specification but address the endogeneity concern in a later section.",1
60,14,"In column (3) we combine culture and economic freedom in the regressions to start disentangling the substitutability versus complementarity between economic freedom and culture. When controlling for economic freedom, culture is insignificant in the OLS regression but is significant at the 10% level in the fixed effects regression. Economic freedom retains its positive and highly significant (at the 99% level) relationship with growth in both specifications. For example, column (3) for the fixed effects model shows that a one standard deviation increase in culture and freedom increases growth by 0.65 percentage points and 1.93 percentage points, respectively. Also, in the fixed effects model, the joint significance of the F -statistics from columns (1), (2), and (3) are 8.74, 53.78, and 10.09, respectively, and are significant at the 99% level. This suggests that we explain more of the variation in growth when controlling for both culture and freedom than when controlling for culture alone. These results suggest that economic freedom is a strong contributor to economic performance, while culture displays a positive but milder effect on growth, lending support to the substitution hypothesis.",1
60,15,"In all five regression specifications, culture is insignificant, while economic freedom is positive and significant at the 99% level, lending further support for the substitution theory. Regression (1) suggests that a one unit increase in the freedom index increases growth by 1.40 percentage points. To gain a different perspective, if a country improves from the lowest score on the freedom index to the highest, it would experience an increase in growth by almost 10 percentage points, tripling the sample average. Freedom’s coefficient is similar in all five regressions except when controlling for educational attainment. Once education is included in the regression, the coefficient on freedom almost doubles, and the R-squareds go from an average of 0.28 to 0.93, suggesting that this specification suffers from severe endogeneity. As expected, education has a strong positive and significant relationship with growth. Also, all other variables, except for culture, are significant in this specification. This is the only regression where investment, population growth, and area are significant.14 Urban population is significant in three out of four regressions, although it switches signs. Geography and legal origin are insignificant.",1
60,16,"Although the additional control variables do not add much explanatory power to the model, as suggested by the similar R-squareds from the baseline specification (except when education is included), we do acknowledge that our model is only explaining approximately 25% of the variation in growth. We believe this is due to our cautious approach with our control variables.",1
60,17,"Overall, we view our benchmark and core analysis as providing evidence that culture and economic freedom may actually behave as substitutes. The results suggest that economic institutions supporting private property rights, rule of law, and enforcement of contracts are a strong determinant of economic growth. This result holds in both models and across a variety of regression specifications. Our results show a mild, positive, and significant direct relationship between culture and economic growth; however, when controlling for economic freedom, culture is significant only in one out of seven regressions, a result consistent with the substitution hypothesis. We view this as suggesting that culture’s connection with economic growth may be more complicated than previously suggested (for example, see Tabellini 2008a).",1
60,18,"In order to provide a more ‘direct’ test for reverse causality, we provide a simple check where we utilize both lagged and future values of changes in freedom, changes in culture, and our growth rate. If reverse causality is driving our results, we expect that changes in income, i.e., the growth rate, will subsequently change freedom and, culture, or both; however, if freedom or culture is causing growth, then we expect changes in these variables to be associated with growth in the following period. Therefore, we analyze changes in these variables, as opposed to levels, for this specification only.",1
61,1,"To social workers, extreme economic inequality is primarily a violation of social justice, but this article shows how growing economic inequality since the mid-1970s was not only unjust, but also dysfunctional to the U.S. economy and linked to the recent economic crisis with its devastating effects, particularly on the social work clientele. The article identifies interrelated changes in ideology, the market economy, and government policies since the mid-1970s; contrasts the political economy of this period with the preceding post–World War II decades when the trend was toward a “shared prosperity”; and shows how increased economic inequality and political consequences that undermined democracy itself contributed to the economic meltdown. The analysis has implications for the direction of social reform and for broadening the constituency of social movements in pursuit of the social work mission of social justice. How social workers can contribute to such movements and to a reduction of economic and political inequality is explored.",1
61,2,"From the perspective of economic inequality, the 65 years since World War II can be divided into two periods: (1) the first three decades when inequality, though ever present, was diminishing and (2) the subsequent 30 years when its rise culminated in economic crisis. The article begins by contrasting the two periods with respect to the distribution of income and wealth, wages, unemployment, and poverty. It then describes the political economy of the first period or the relationship between the democratic system of government and the capitalist economy. Although inequality remained a fact of American life in the first period, it was during this time that according to the British economist Andrew Shonfield (1965),a“new capitalism” emerged, one in which the advance in national income benefitedpeopleunabletogaina share of prosperity through their earnings. Shonfield also called attention to “the conscious pursuit of full employment” (p. 63), a policy that enabled more people to earn higher incomes. In retrospect, this era may have been an anomaly in the history of capitalism, owing, in the case of the United States, to the federal government’s more active role in the economy in response to the highly unusual conditions that preceded it: the Great Depression and World War II.",1
61,3,"Escalating economic inequality in the past 30 years comes as no surprise. Yet even those who are cognizant of the economic divide can be shocked by how wide it has become. We encounter egregious inequality wherever we look—at wages, income, wealth, poverty, and unemployment.",1
61,4,"Particularly egregious are the enormous and disproportionate income gains of the top 1 percent of households. According to a report of the U.S. Congressional Budget Office (CBO) (2010), the average after-tax income of these richest Americans in 2007—just prior to the financial collapse—was $1,319,700. This was an increase of $976,120 over the 1979 average, compared with increases of only $11,200 and $2,400 for the middle and bottom quintiles, respectively (in 2007 constant dollars). Analyzing these data from the CBO, Sherman and Stone (2010) of the Center on Budget and Policy Priorities pointed out that the gaps in after-tax income between the richest 1 percent and the middle and poorest fifth of the country more than tripled between 1979 and 2007. Sherman and Stone concluded that the new data, along with prior research, “suggest greater income concentration at the top of the income scale than at any time since 1928” (p. 2)the eve of our prior, disastrous financial crash.",1
61,5,"Wealth is even more top heavy than income, and it has become increasingly concentrated in recent years. In one short interval—1995 to 2004 —when aggregate household net wealth nearly doubled, almost all the net gains went to the top quartile of the income distribution (Di, 2007). By 2004, the richest one-tenth owned 71 percent of private wealth (Wolff, 2007). Top Heavy is the apt title of a study of the increasing inequality of wealth in this country by Edward Wolff (1995),a leading scholar of the subject.",1
61,6,"During the period of shared prosperity, unemployment, though not low, was less than it was in ensuing decades, averaging 4.8 percent from 1949 to 1973, compared with 6.5 percent from 1974 to 2008 (Council of Economic Advisors, 1962, 2010). Unemployment not only spells lost income for workers and increasing inequality; it also means loss of potential output to the economy (Ginsburg, 1995). Moreover, years of relatively high unemployment have contributed to stagnating wages. (When unemployment is high and there are many more jobseekers than available jobs, employers can hire the workers they need without raising wages or providing attractive benefits and working conditions.) The converse is true when the labor market tightens. When unemployment dipped slightly below 4 percent in the 1990s—hardly full employment, particularly for minority men—wages and benefits rose, especially for low-wage workers, and this occurred despite counter-pressures from globalization (Bernstein & Baker, 2003; Pollin, 2007). Unemployment, of course, reduces incomes and tax revenues and increases government outlays to benefit jobless workers, thus contributing to budget deficits.",1
61,7,"To meet the severe challenges of the Great Depression and World War II, the federal government exerted more control over the economy. As a result, the American people became accustomed to a government that was larger and more active than it was prior to the Depression. Government spending and taxing policies reduced the severity of recessions and mildly redistributed income. Social welfare measures enacted in the 1930s, particularly unemployment compensation, served as economic stabilizers, expanding during recessions and thereby reducing the contraction of consumer spending that would otherwise have worsened a downturn. New Deal regulatory policies, meant to reduce the disastrous financial speculation that led to the stock market crash of 1929, were maintained in the first postwar era. The progressive, higher tax rates of World War II were continued in peacetime, and rising real wages were the quid pro quo for relative labor peace. “Say what you want about the violations of free-market economics” ( p. 64), wrote progressive economist Robert Kuttner (2007), “a system that produced nearly three decades of egalitarian economic growth at an average annual growth rate of 3.8% cannot be all bad” ( p. 64).",1
61,8,"In an effort to reduce its competitive disadvantage, business could have stepped up investment to increase productivity and innovation. Instead, most businesses adopted alternative strategies that increased inequality (Harrison & Bluestone, 1985). In response to the profit squeeze, business squeezed labor—through wage freezes and new work arrangements that increased the flexibility with which workers could be hired, fired, and scheduled. Globalization—transfer of capital and business operations to lower-wage areas of the world—was another strategy that followed rather than preceded the U-turn, and it was encouraged both by federal tax policies that give more favorable treatment to income earned abroad than stateside and government financing of overseas manufacturing plants. Still another strategy was to abandon production for paper profits, again resulting in manufacturing job losses. For example, General Electric sold off its consumer appliance manufacturing division and concentrated on its more profitable credit corporation (Phillips, 2002). Similarly, General Motors emphasized financial services over auto production (Wolff, 2009). Still another strategy was to lobby government to reduce taxes and regulations.",1
61,9,"In 1980, Republicans succeeded in uniting the interests of their fiscally conservative, pro-business base with a portion of the Democrats’ New Deal coalition. As Edsall (1991) observed, such issues as affirmative action, the welfare expansion, school busing, women’s liberation, gay rights, abortion, and perceived high taxes had become offensive to numerous, former Democratic voters (1991). Many white people, including blue-collar workers, defected from the party they associated with these policies, particularly because it was no longer seen as the purveyor of prosperity.",1
61,10,"Democrat Bill Clinton, despite a progressive, populist persona, presided over the repeal of AFDC and the quintessential New Deal banking regulation, the Banking Act of 1933 (or the GlassSteagall Act) (P.L. 73–66). Repeal meant that commercial and investment banks were no longer separated and that the high-risk culture of the latter that traditionally managed rich people’s money would prevail. Globalization policies that largely ignored workers’ rights and environmental protection were also carried on by Clinton, virtually without change from his Republican predecessor George Walker Bush.",1
61,11,"The influence of the financial sector was exemplified by President-elect Bill Clinton’s abandonment of the populism of his presidential campaign. Candidate Clinton promised an economy that “put people first.” However, even before taking office, Clinton recognized that rich people were “running the economy” and that “we help the bond market [by lowering deficits] and we hurt the people who voted us in” (Woodward, as cited in Pollin, 2003, p. 91). Robert Rubin, co-senior partner of Wall Street giant Goldman Sachs, head of Clinton’s National Economic Council and later his treasury secretary, was only one of several advisors urging the president-elect to focus on deficit reduction (Rubin & Weisberg, 2003).",1
61,12,"In explaining the meltdown, economist Arthur MacEwan (2009) emphasized the “nexus of factors” that have been identified in this discussion: “growing concentration of political and social power in the hands of the wealthy; the ascendance of a perverse leave-it-to-the-market ideology which was an instrument of that power and rising inequality, which both resulted from and enhanced that power” ( p. 23). This perspective takes into account both the commanding heights of the economy and its lower reaches. Arising from this “nexus of factors” are developments proximate to the meltdown that will be discussed in detail later—the expanding role of credit, increased deregulation, and the housing bubble.",1
61,13,"Contributing to that limitation in the United States was increasing “media monopoly.” Between 1983 and 2004, the number of corporations controlling most of the newspapers, magazines, radio and television stations, book publishers, and movie companies shrank from 50 to five (Bagdikian, 2004). The media watchdog, Fairness and Accuracy in Reporting (FAIR) held that “mergers in the news industry have accelerated, further limiting the spectrum of viewpoints that have access to mass media” (FAIR, n.d.). The viewpoint of the media was largely that of their owners.",1
61,14,"The contrasting perspective—on agency and choice—is consistent with the view that the political economies of capitalist countries are not homogeneous. Others, for example, are less wary of “big government.” Cross-national study shows that wealthy capitalist countries differ substantially with respect to poverty prevention and the size and scope of their welfare states (EspingAndersen, 1999; Goldberg, 2002, 2010). Despite retrenchment in nearly all welfare states in recent years, the relative poverty rates ( percentage of the population with less than 50 percent of median income) in 2000 were 7.3 percent and 8.4 percent in France and Germany, respectively, compared with over twice these rates, or 17.0 percent, in the United States. Canada and the United Kingdom, though often compared to the United States in welfare state typologies (Esping-Andersen, 1999), had considerably lower poverty rates (12.4 percent and 13.7 percent, respectively). Lower rates, ranging from 5.4 percent to 6.6 percent, were found in the Netherlands, Denmark, Finland, Norway, and Sweden (Luxembourg Income Study, n.d.).",1
61,15,"Intended to minimize the risk of these subprime mortgages were the complex financial instruments known as derivatives. According to the editors of the New York Times, derivatives were “at the heart of the bubble, the bust, the bailouts.” (“Congress passes financial reform,” 2010, p. A26; see also Stiglitz, 2009). Credit-default swaps, a form of derivatives, are packages of mortgage loans for which banks that bought subprime mortgages sought insurance. Because insurance was regulated, the sellers of insurance on these loans called them “credit default swaps” to escape regulation. In 1998, the head of the Commodity Futures Trading Commission proposed regulating these derivatives but was roundly opposed by Bill Clinton’s Treasury Secretary Robert Rubin, his deputy Lawrence Summers (later head of the National Economic Council), and Federal Reserve chief Alan Greenspan (Johnson & Kwak, 2010; Kuttner, 2007; Stiglitz, 2009).",1
61,16,"The prescription for recovery and reform can be inferred from this analysis. Reregulation of the financial sector; measures to reduce control of politics by economic elites; and a stronger, more progressive labor movement are needed if we are to reduce the fundamental problem of economic inequality. Policies to reduce inequality include the following: increases in social welfare, both the range of needs covered and the level of benefits, and the assurance of living-wage jobs for all who want to work. With increased income; broader and more adequate coverage of health care, housing, and child care; and availability and affordability of public transportation, lower- and middle-income consumers could meet their needs without feeling obliged to borrow beyond their capacities.",1
61,17,"Such job creation resembles the New Deal work programs planned and administered by social workers Harry Hopkins and Aubrey Williams. Path breaking though they were, these work programs did not employ women and minorities in proportion to their need (Rose, 2010) We can improve on the New Deal model by emphasizing jobs in the social—child and elder care, education, health care—along with the physical infrastructure. A new industrial policy to revive U.S. manufacturing would create jobs, increase opportunities for productive investment outlets, and decrease dependence on the financial sector (Pollin & Baker, 2009). These changes would require a substantial involvement of the federal government.",1
61,18,"Is the ideology of the free or unregulated market and hands-off government in decline? The money changers, despite failures that nearly imploded the world economy, remain in the temple. In the view of some knowledgeable observers, the power of Wall Street has increased (Johnson & Kwak, 2010). So far, it has fared better than Main Street. The stock market recovered, but unemployment hit the double-digit mark in October 2009 and continued to hover near 10 percent for months. Financial interests are opposed to reregulation. By late 2009, lobbyists representing banks and other business interests working on financial regulation outnumbered consumer advocates 25 to one (Johnson & Kwak, 2010), and financial interests spent nearly $600 million to weaken regulatory reform (“Congress passes financial reform,” 2010). Yet Congress enacted the first regulatory legislation in a generation in July 2010. Although the legislation may not go far enough to limit the speculative practices that preceded the meltdown, it has a powerful consumer protection component. The real question is how effectively the new law will be implemented. Financial interests are preparing a “lobbying blitz” hoping to succeed in implementation where they fell short in blocking enactment (Lichtblau, 2010).",1
61,19,"Although some social workers were in the forefront of government job creation in the 1930s, the profession thereafter has been more concerned with welfare than with work. Unemployment, even at half the current rate, leaves millions jobless or marginally employed, not to mention the social and economic effects of loss of income and a valued social role. Social workers could contribute to the reduction of inequality by participating in organizations that advocate direct job creation by government. Successful living-wage campaigns and efforts to raise the minimum wage and the Earned Income Tax Credit would decrease inequality. A stronger labor movement would also contribute to this goal and be a powerful voice for the working class. A way to do this is to support the Employee Free Choice Act of 2009 (H.R. 1409) that would make it easier for workers to join unions and reduce firing and harassment of those who take part in union organizing. Another would be for more social workers to join unions and, as members, to advocate for labor’s commitment to reforms benefiting workers generally, not just union members.",1
61,20,"The high cost of meeting basic family needs shows that numerous families above the median income, including many social workers, are hardpressed and vulnerable to predatory lending. Who was protecting families against these predators? In earlier days, some settlements would have taken on that role, and they advocated as well for consumer protection and regulatory measures. In addition to consumer education, social workers should press for implementation of recently enacted consumer protection laws.",1
62,1,"Having joined the Eurozone in 2001, Greece experienced a short period of economic euphoria before confronting a major financial crisis some nine years later. In the period between joining the Eurozone and accepting the joint IMF/EU bailout package, the economic situation facing Greek voters changed dramatically. I use this setting to test the economic voting hypothesis. Using longitudinal aggregate data from 1981 to 2009, I investigate the relationship between macroeconomic indicators and vote share of the incumbent party to test the “grievance asymmetry” hypothesis. Moreover, by using individual-level data from 2004 to 2009, I investigate the extent to which retrospective sociotropic evaluations about the state of the economy are associated with support for the incumbent party. The results suggest that sociotropic economic evaluations are associated with government party support, but in a period when the economy is at its worst the incumbent has no real chance of winning and should expect support only from its longtime loyal supporters.",1
62,2,"2009 inaugurated the most difficult period for the Greek economy in recent times. For the past two years, the economic problems facing Greece have been making frontpage news around the world. For many who were impressed by the country’s achievements over the past decade this was an unexpected development (Kalaitzidis, 2010). Greece after all was among the first group of countries accepted into the Eurozone. By 2004 economic activity was booming in anticipation of the Olympic Games, while unemployment was falling (Kasimati and Dawson, 2009). In the March 2004 election, the conservative ND (New Democracy) party had won a decisive victory, ending eleven years of rule by the Panhellenic Socialist Move (PASOK) (Panagopoulos and Marantzidis, 2006). PASOK’s historical defeat at the 2004 election was at to increasing signs of corruption in the government. The conservative opposition leader, Kostas Karamanlis presented himself as a modest politician who would fight corruption and proceed with the necessary reforms (Dinas, 2010).",1
62,3,"By 2009, however, Greece’s debt and budget deficit had risen to alarming levels. On September 2, 2009, Prime Minister Karamanlis announced a snap election. This decision was due to the difficulties facing the New Democracy (ND) government regarding reforms that would help handle the effects of the global recession, but also due to a series of scandals that led to the resignation of three ND ministers within less than a year (Gemenis, 2010). During the electoral campaign, Karamanlis presented ND as the only party refraining from making promises regarding the economic policy it would follow after the elections. Furthermore, he claimed credit for being sincere about the actual economic situation of the country, which he portrayed as a product of the global financial crisis (Dinas, 2010). Despite Karamanlis’ efforts, PASOK won the election with a comfortable majority (43.9% of votes and 160 of 300 Parliamentary seats), on the premise that the economy was not doing well because of the poor management by the conservative government.",1
62,4,"In its simplest form, the idea behind economic voting is that voters are not “fools” but make rational judgments about what happened to the economy in the past (Key, 1966). Although prospective evaluations can also be relevant, foreseeing is not as easy as reminiscing. “Voters, or at least a large number of them”,Key(1966, 150) argued, “are moved by their perceptions and appraisals of policy and performance”. Building on Key (1966) andDowns (1957) , Fiorina (1981) further substantiated the point about retrospective evaluations by arguing that even uninformed voters “have one comparatively hard bit of data: they know what life has been like during the incumbent’s administration.” Based on such evaluations, the voter can hold the government accountable and “toss the rascals out”. Hence, it is relatively straightforward to reward and re-elect the government or to punish it and vote for the opposition.",1
62,5,"Due to the lack of systematic analyses of economic voting on Greece, the scarce knowledge we have in this respect is based on the comparative study by Freire and Costa Lobo (2005) and on a case study analysis by. Freire and Costa Lobo (2005) examined the effect of objective indicators and subjective individual perceptions of the economy on voting behavior in Greece, Portugal and Spain between 1984 and 1999 and found that in Greece there is a correlation between the perceptions of personal finances and the annual changes in the GDP. Using Eurobarometer data, the authors tested for the importance of the economy on the vote between 1985 and 2000 and found that the most important single factor determining party choice was ideology. However, the argument about the importance of economic evaluations and their relationship to party choice has not yet been tested empirically for recent elections. Before turning to individual-level data, however, I first examine economic voting at the aggregate level.",1
62,6,"The main argument which links macroeconomic performance to support for the incumbent party is the reward-punishment hypothesis. From this perspective, voters evaluate governments’ performance on major economic indicators, such as inflation or unemployment. Then they reward or punish the incumbent based on its performance on keeping these macroeconomic indicators at the desirable levels (Sanders, 2000). In other words the government is accountable over the economic policymaking. In addition, political parties at the opposition can hope for voters’ support when the performance of the party in government is considered inadequate (Lewis-Beck, 1988; Powell and Whitten, 1993).",1
62,7,"Studies on German and British data support Mueller’s hypotheses that the electorate responds to economic conditions only when the latter deteriorate sharply (see Nannestad and Paldam, 1997, 85). Does the same holds for the individual-level analysis? Attempts to verify the “grievance hypothesis” at the individual level have not been successful (Kiewiet, 1983;Lewis-Beck, 1988 ) with the exception of the Danish electorate (Nannestad and Paldam, 1997). Conversely, van der Brug et al. (2007) have found support for the “grievance asymmetry” hypothesis in their cross-national assessment of economic voting. These positive findings may be related to the fact that the authors took a more permissive view on what constitutes an asymmetry. Instead of expecting the coefficients on improving economic conditions to be near zero (LewisBeck, 1988, 78), they reported some substantial differences in the magnitude of the impact between improving and deteriorating economic conditions (van der Brug et al., 2007,142–159).",1
62,8,"Previous individual-level simulations on the electoral consequences of changing economic conditions (van der Brug et al., 2007,142–159) suggested that in Greece, voters responded to the improvements of the economy by rewarding the governing party in terms of vote intentions and that the rewards were slightly stronger than the punishments. The lack of coalition governments, makes it a high-clarity country as it is very easy for voters to identify the party accountable for government policies. The Greek party system has been characterized by stable single-party governments, largely due to the disproportional electoral system (called “reinforced proportional representation” in Greek political parlance) which has been amended several times since the restoration of democracy in 1974. With the exception of the quasicaretaker coalition governments of 1989–1990 (Verney, 1990), ND and PASOK have been alternating in government, while all other parties remained in opposition.",1
62,9,"The scatterplots in Fig. 1 (bandwidth ? 0.7) show a rather mixed picture but there is some evidence suggesting that there is an asymmetry between fluctuations at the state of the economy and vote share for the governing party. When we examine each macroeconomic indicator separately we see that decreases in the GDP are associated with decreases in the vote for the incumbent party and vice versa but there is evidence for a threshold at 2.5% change. After this point it seems that incumbents are not rewarded for improving the indicator for growth. Turning to inflation it seems that increases in the rate of inflation up to about 17% are not associated with decreases in the vote for the incumbent. To the contrary, it seems that the voters are slightly rewarding the party. After this threshold, however, there is a steep decrease in the vote for the incumbent, although the number of observations after this threshold is very small to make definite judgments. Finally, changes in the unemployment rate between 1% and 1% are not associated with changes in the vote for the governing party as evident by the near flat curve. Similarly, to inflation, we observe a steep trend after the threshold indicating a punishment for the incumbents although the number of observations is very small.",1
62,10,"Since I am interested on the impact of the economic variables on the support for the incumbent party I perform a logistic regression analysis where the dependent variable is coded 1 if the respondent intends to vote for the incumbent and 0 for the intention to vote for any other party at the opposition (Lewis-Beck and Nadeau, 2000; Evans and Andersen, 2006). The logistic regression models allow us to estimate the probability that the voter will select the incumbent versus other parties and to examine how this distribution of probabilities changes when perceptions of the economy change. Yet as in most studies, vote choice is considered a function of temporary effects as the economic evaluations, long-term effects as party identification and ideology and demographics such as age and gender (Clarke et al., 2004).",1
62,11,"Fig. 2 suggests that comparing the 2004 to the 2009 election (the latter taking place a few months before Greece agreed to a bailout package with the IMF/EU), the percentage of voters who negatively evaluated the economy increased by almost 20 percent. In 2004, five years before the economic crisis, the percentage of those who evaluated the economy as a lot worse was 24.4% while in 2009 it increased to 43.9%. Nevertheless, if economic considerations are to play an important role in voters’ minds, the economy has to be a salient issue for them (Whiteley et al., 2005). In both surveys, issue salience was measured by an open-ended questions asking responders to name the most important problem facing the country. Respondents were asked to mention up to two issues in 2004 and three in 2009. In both elections, economic issues were by far the most important in voters’ minds. For both elections the Greek public mentioned the economy in general and inflation and unemployment in particular as the most important problems facing the country, far ahead of issues such as health, immigration, education or the environment. As we move from 2004 to 2009 two important changes occurred: the importance of the economy as the most important problem is raised by almost 20%, followed by a decline on the importance of unemployment as an issue.",1
62,12,"Table 1 displays the empirical results. As hypothesized, the coefficients for the economic variable turn out to be statistically significant and in the expected direction. In the 2004 national election, voters on the left side of the ideological spectrum were more likely to support the socialist governing party, PASOK. This also holds for voters who believed that the economic situation had been positive the year before the national election as well as those who identified with the incumbent. Furthermore, none of the sociodemographic variables are statistically significant. Moving to the 2009 estimates the pattern is repeated. Voters who positively evaluated the economy were more likely to vote for the incumbent. Since the incumbent at the 2009 national elections was the conservative ND, those who placed themselves at the right side of the ideological spectrum also tended to vote for ND. The analysis so far suggests that economic evaluations by the Greek electorate are associated with support for the incumbent party. Even though in 2004 the macroeconomic measures indicated that the economy was performing quite well, and one may assume that the salience of the economy as an issue during the electoral campaign would be of less importance, retrospective evaluations about the economy exhibit a substantive association with support for the incumbent party.",1
62,13,"Unfortunately, it is difficult to address this endogeneity in a regression model based on cross-sectional data as we lack suitable exogenous instruments. Instead, I offer a counterfactual argument. If we think of endogeneity in terms of an omitted variable problem (Clarke, 2009,5758), we would need to think how big the effect of this omitted variable would have to be in order to invalidate the findings presented in Table 1. With the most powerful predictors included in the model (party identification and left–right self-placement) it is hard to think of an additional explanatory variable which could predict vote for the incumbent party with an odds ratio of at least 1.8.3 Therefore it seems safe to conclude that although we might be overestimating the impact of economic evaluations on support for the incumbent, such an effect probably exists.",1
62,14,"In this article I set out to examine the relationship between the economy and voting behavior in Greece for the 2004 and 2009 election years. More specifically, I examined the implications regarding support for incumbent parties. The aggregate level analysis focusing on the relation between macroeconomic indicators and support for the incumbent party showed the existence of thresholds which provided some evidence for the “grievance asymmetry” theory. As in other countries, the Greek electorate seems to be punishing the party in government when economic conditions deteriorate rather than rewarding it when economic conditions improve. Nevertheless, the non-parametric techniques used to study the relationship do not allow for making inferences and drawing definite conclusions. A multilevel analysis of economic voting which included Greece showed that, when individual-level covariates are taken into account, rewards become as likely as punishments in the Greek context (van der Brug et al., 2007, 166). Despite the existing scarcity of Greek electoral data, future studies need to explore the question of “grievance asymmetry”.",1
62,15,"Figs. 4 and 5 show that as we move from negative to positive evaluations about the economy the probability to vote for the incumbent party increases. Nevertheless, the confidence intervals between the adjacent plots for different levels of evaluation about the economy are overlapping. This means that if the mean evaluations among the electorate would change one level upwards or downwards we do not observe any substantive differences in the probability to vote for the incumbent party. Substantial changes (indicated by non-overlapping confidence intervals) are only observed in 2004 when we move from “much worse” to “much better” evaluations. Moreover, the figures hint that the position of the party on the Left–Right scale might make a difference for how much gain is to be expected from positive evaluations about the economy. The centrist position of PASOK (indicated by the vertical line) enables it to make gains across the ideological spectrum whereas for right-wing ND the gains on the left are associated with much uncertainty. At this point, however, It comes from expert surveys: for the 2004 election, the 2003 Benoit and Laver (2006) expert survey and for the 2009 election the Vowles and Xezonakis (2009) expert survey (Vowles et al., 2010).",1
62,16,"Do these results imply that there was no economic voting in 2009? On the contrary, the results in Table 1 confirm that economic evaluations played an important role in both elections but when we take the evidence in Figs. 4 and 5 into account, we can conclude that this “important role” could not have a substantial impact in terms of electoral returns for the party in government. The latter finding is particularly true for 2009. The high odds ratio (about 23.7) for party identification in Table 1 indicates that, in June 2009, only the most loyal supporters of the conservatives intended to vote for the incumbent ND. This was confirmed about four months later at the parliamentary election of October 2009 where ND had the worst electoral result in its 35-year history (Gemenis, 2010, 358).",1
63,1,"The economic voting literature shows that good economic performance bolsters the electoral prospects of incumbents. However, disagreement persists as to whether voters in vulnerable economic conditions are more likely to engage in economic voting. It is argued in this article that a crucial factor in explaining individual-level variation in economic voting is the degree of exposure to economic risks, because risk exposure affects the saliency of the economy in voting decisions. In particular, the focus is on job insecurity and employability as key determinants of economic voting patterns. The article hypothesises that the extent of economic voting is greater in voters who are more vulnerable to unemployment and less employable in case of job loss. Support for these hypotheses is found in a test with a dataset that combines survey data on incumbent support with occupational unemployment rates and other measures of exposure to economic risks.",1
63,2,"A vast literature in political science explores the nexus between economic factors and electoral outcomes. Despite the persistence of various areas of contention in the economic voting literature (Lewis-Beck & Paldam 2000), the idea of the decisiveness of macroeconomic performance in democratic elections has consolidated to the extent that it is now widely accepted among the non-specialist public and the popular press. In recent years, however, this body of knowledge has been challenged on two main empirical and theoretical dimensions (Anderson 2007). On the one hand, several studies have highlighted the existence of considerable individual constraints to economic voting as individuals differ greatly in their ability and willingness to acquire information about the economy (Gomez & Wilson 2006). On the other hand, the institutional environment in which political behaviour takes place can affect economic voting decisively, because political institutions may shape the extent to which voters hold incumbents responsible for economic performance (Duch & Stevenson 2008).",1
63,3,"This article contributes to recent efforts in the economic voting literature to identify individual-level differences in voting behaviour (Duch et al. 2000; Hellwig 2001; Dorussen & Taylor 2002; Gomez & Wilson 2006; Kayser & Wlezien 2011; Singer 2013) in two main ways. First, it draws on the theoretical insights of a well-known but separate literature in political science to investigate the factors that mediate the relationship between macroeconomic performance and incumbent support. Although several studies have ascertained the importance of ‘skills’ and professional job insecurity as a source of social policy preferences and welfare state arrangements (Iversen & Soskice 2001; Estevez-Abe et al. 2001; Rehm 2009, 2011a), the significance of such factors for economic voting is still largely unexplored.2 This article integrates these two threads of research by showing that macroeconomic performance is more decisive among individuals with more specific professional skills and among those employed in professions more vulnerable to unemployment. Second, this article offers new empirical evidence suggesting that voters respond to variations in macroeconomic performance according to their position in the labour market.",1
63,4,"The remainder of the article proceeds as follows. In the next section, I review the recent literature on economic voting, with particular emphasis on the study of individual-level variation in exposure to economic risk. I then outline a model of economic voting, showing the specific role that the degree of exposure to the economic cycle plays in shaping voting behaviour. Following this, I present the data used in this study and the strategies I follow for the empirical test. Finally, I discuss the results of the regression analysis and conclude with some remarks on the main avenues for further research.",1
63,5,"Many studies of economic voting have been reluctant to study this question. Following seminal work by Stokes (1963), the economy has often been considered as a ‘valence issue’, as all voters arguably prefer a good economy to a bad one. As Stokes himself observes, in debates over valence issues, ‘the argument turns on where the credit or blame ought to be assigned’ or, in electoral competitions, on ‘which party, given possession of the government, is the more likely to bring it about’ (Stokes 1963: 373). Since this paradigm has been preponderant in the economic voting literature, most scholars have focused on the process of responsibility attribution, assuming lack of variation in the salience of economic performance (see, e.g., Van der Brug et al. 2007; Wlezien 2005; McAvoy 2006). Yet some classic studies of economic voting have laid the theoretical foundations for conceptualising the role of individual economic conditions in shaping economic voting patterns. Hibbs (1977), in particular, famously showed that there are differences across groups within the electorate in responsiveness to signals of macroeconomic performance such as inflation and unemployment.",1
63,6,"This article offers two main contributions to this debate. First, it calls for close integration between work on economic voting and the literature on social policy preferences. It argues that an individual’s position in the labour market is a pivotal factor not only in determining their preferences over social insurance, but also in shaping economic voting patterns. At the macro-level, such disparities in risk exposure result in significant differences in voting behaviour across occupational groups. Second, this article performs the first empirical test of this argument using data on occupational unemployment, which is a key concept in the debate on social policy preferences and the origins of the welfare state. Furthermore, it offers a range of alternative measures of the idea of ‘risk exposure’ to test the robustness of its results to different operationalisation strategies.",1
63,7,"The findings from these seminal articles call for a closer integration between the economic voting literature and the insights of another well-known, although separate body of work in political science. Scholarly studies of the determinants of social policy preferences have presented ample evidence that there are deep inequalities in the distribution of economic risks across the electorate, and that such disparities are a source of variation both in preferences over redistribution (Iversen & Soskice 2001; Rehm 2009) and in macro-level welfare state arrangements (Estevez-Abe et al. 2001; Rehm 2011a). In particular, it is possible to identify two classes of individual-level factors that determine the exposure to the economic cycle of individual voters. According to one line of analysis, the specificity of professional skills developed through education and professionalisation practices is positively related to the degree of risk exposure because workers with non-transferable skills are more likely to suffer from protracted unemployment in case of job loss (Iversen & Soskice 2001). From another angle, risk exposure is a function of job insecurity rather than employability. On the one hand, industry affiliation shapes job security through various channels (Frieden & Rogowski 1996; Mayda & Rodrik 2005; Iversen & Cusack 2000).",1
63,8,"These core tenets of the economic voting model suggest that there are two main reasons why voters may care about macroeconomic performance. On the one hand, the prosperity of the economy may be considered as a good in itself, and economic voting may follow a ‘sociotropic’ pattern in which voters support incumbents only if they have furthered the material well-being of their country as a whole (Kinder & Kiewiet 1981). On the other hand, economic performance also matters because the future financial flows that individual voters receive depend, at least in part, from the health of the national economy. For the argument advanced here, it is crucial to assume that, at least to some extent, economic voting takes place due to ‘pocketbook’ concerns about future repercussions of economic performance on an individual’s personal finances. If voters did not care about how aggregate economic performance affects future developments in their own personal finances, exposure to economic risk would not be a relevant factor in economic voting.",1
63,9,"To understand why this is the case, we need to consider a factor largely understudied in literature on economic voting – namely the salience of the economy and its variation across the electorate. In particular, two fundamental assumptions are made in this article about the relationship between salience of the economy and voting behaviour. First, it assumes substantial cognitive limits in the way voters receive and process information about specific political issues. Following foundational work by Herbert Simon on ‘bounded rationality’ (Simon 1982), empirical research in behavioural economics and social psychology has shown that individuals, acting under various forms of constraints, tend to consider only a few items from their broader spectrum of preferences when taking decisions.8 In voting behaviour, this means that most voters do not evaluate candidates based on their performance in all policy areas, but only on their performance in some areas they consider of particular interest (Rabinowitz et al. 1982; Krosnick 1988; McGraw et al. 1990; Lavine et al. 1996; Belanger & Meguid 2008). This insight is important for economic voting because, although all voters may prefer a more competent economic manager to a bad one, some of them might care less about this attribute of the candidate than about others.",1
63,10,"Recent developments in the literature on economic voting have been instrumental in refining our understanding of the link between macroeconomic performance and voting behaviour. Most of the recently published studies acknowledge the importance of economic voting while qualifying its extent, showing substantial differences both across individuals and countries. In particular, many have focused on the idea of responsibility attribution and on individual-level characteristics that shape the cognitive processes involved in the economic voting model. I have observed in this article that there is another, equally important and understudied dimension in the process of economic voting. I have argued, in particular, that the study of economic voting should take into account the valuable insights provided by the scholarship on social policy preferences and welfare state development. Specifically, I have proposed in this article that voters be categorised in different groups according to their vulnerability to economic fluctuations, and hypothesised that economic voting occurs more extensively in voters who are more directly exposed to the economic cycle. The analysis performed in the previous section has found important empirical regularities consistent with this hypothesis: voters facing higher degrees of job insecurity and lower employability in case of job loss are more likely to condition their support for incumbent governments to good macroeconomic performance.",1
63,11,"The positive findings reported here, however, should be qualified by some limitations of the research design adopted for this study, and indeed such shortcomings offer potentially fruitful avenues for further research on the nexus between economic voting and economic risk. First, the argument outlined in this article should be tested with actual voting data as the response variable adopted here is a measure of public opinion rather than voting behaviour. To be sure, the analysis has been restricted to respondents who expressed the intention to vote, but discrepancies between such intentions and actual voting choices, including non-voting, are not controlled for in this study. Second, the sample is limited to a small group of advanced economies. The inclusion of a larger number of clusters in the sample could address potential methodological shortcomings in the estimations of standard errors for macro-level variables, and it could allow the exploration of interaction effects between cluster-level covariates. Furthermore, campaign-specific dynamics and political communication strategies, while not studied here, are important factors in determining the saliency of the economy in electoral contests. Finally, this article has not tested the causal mechanism postulated.",1
63,12,"Figure 3 offers a graphic representation of the difference between the two groups, plotting two distinct curves of predicted probabilities of incumbent support as a function of GDP growth. As the chart shows, the curve for low-skill respondents (solid curve) is substantially steeper than the high-skill curve (dashed curve) as incumbent support for low-skill respondents is more sensitive to macroeconomic fluctuations. For illustration purposes, consider the difference in predicted probabilities of incumbent support between a bad economic conjuncture (e.g., – 1 per cent growth) and a very good one (e.g., 3 per cent growth). For low-skill respondents, the difference is sharp: poor economic performance decreases support for the incumbent by about 0.21, as it drops from 0.45 to 0.24. For the high-skill group, however, the difference is only about 0.08 (from 0.39 to 0.31). The chart also suggests that the divergence is more marked during economic crises than in times of economic booms – perhaps an indication that the two groups differ more in their willingness to punish incumbents for bad economic management than in their willingness to reward them for good performance.",1
63,13,"Models 3–5 estimate the model in Eqn 3 using alternative measures of job insecurity. Model 3 interacts macroeconomic growth with a dummy variable that measures whether the respondent is unemployed. As unemployed respondents are in particularly vulnerable economic conditions, we should expect the coefficient for the interaction term to be positive. The estimation reported in Table 2 shows that this is indeed the case, although the coefficient is not significant at the 0.05 level in either the simple logistic or the random effect model. The role of employment in the public sector as an indicator of job security is explored in model 4. The results reported show that the significance of public sector employment is very sensitive to model specification as it is barely significant in the random effect model (model 4r) and not significant in the simple regression model. Furthermore, contrary to expectations, the coefficient is positively signed and of modest magnitude. Therefore, there does not seem to be a discernible difference in economic voting patterns between respondents employed in the private sector and those employed in the public sector. Finally, estimations for models 5 and 5r offer empirical evidence that being a union member is an important factor in economic voting behaviour.",1
64,1,"The paper analyses transformation process in Hungary between 1989 and 2004. The goal of this paper is to analyze and evaluate the transformation process in Hungary. The structure of the paper follows this general goal. First of all, an analysis of economic development of the country before the fall of the communist regime is carried out because this determined the whole process which followed. Then we shortly mention political development that had a significant impact on the transformation process and its results. In the next part we concentrate on the main steps in the economic transformation, and consequently we devote space to specific aspects privatization, for example. The main economic indicators of this period are analyzed in the final part. We conclude that the transformation process achieved its main economic goal and the economy’s ability to grow increased. At the same time, however, the transformation process created environment for the subsequent economic problems.",1
64,2,"The goal of this paper is to analyze and evaluate the transformation process in Hungary. In the author’s opinion, the main goal of the transformation process was a shift in the paradigm of the economy from the centrally planned system to a form of a market economy. In our view, this goal was generally reached with the accession to the EU. This is why we limit our paper to the period ending with 2004. We consider it an indirect proof that the environment reached a well-functioning market economy (formally it is a condition of the accession). The interesting question is how this state was achieved. We should not take it for granted because we can see several transforming countries that are still quite far from the state of a well-functioning market economy (for example Belarus). A shift in the overall trend of the economic development was the second goal of the transformation process, a more specific one, in our view. The centrally planned economy was doomed to fail – economic growth was declining and in fact negligible in the 1980s. As a consequence, the Hungarian economy was lagging behind the market economies. Any change of the pattern of the economy without improving its growth ability would be worthless. The paper tries to evaluate the progress from this point of view.",1
64,3,"We will start by describing the long-run political development in Hungary, which had an impact on the state of the Hungarian economy at the end of the 1980s, which is analyzed in the second chapter. In the next step we will concentrate on the political development during the transformation era, for which we consider the period between 1990 and 2004 (the accession to the EU). We believe that the accession to the EU can be seen as a proof of the state of the Hungarian economy. The main economic development is analyzed in the 3 following chapters. We concentrate on the sequence of the reforms first of all. Then the privatization development is examined in a stand-alone block. These two chapters describe the main economic steps. Then, in the last chapter, we sum up economic results in the studied period. In specific subchapters, economic growth, structure of the economy, inflation, unemployment and external relationship are analyzed.",1
64,4,"We would like to point out that while working on the paper, we were confronted with troubles regarding data. Primarily, there were problems with length of consistent data series because it was highly difficult to find relevant and homogenous data that would cover the whole transformation period. As a consequence, we were forced to use shorter series. The data that we use are in our view the best that could be obtained.",1
64,5,"This text focuses on development during the transformation process but it is necessary to see Hungary in a broader prospect to understand it better. The long-run economic development has deep roots in our point of view. The key event was the consequence of the First World War. Hungary lost important part of its land to successor states of the Austro-Hungarian Empire and large Hungarian minorities found themselves in the neighboring countries – Czechoslovakia, Romania and Yugoslavia. It was deemed by Hungarians as totally unjust. The main goal of Hungarian diplomacy in the interwar period was unifying all Hungarians into a single state, or in other words to recreate large Hungary. The way to achieve this goal was in cooperation with fascist Germany in the 1930s – and Hungary became Germany’s ally during the war.",1
64,6,"Political relaxing deepened during the time and led even to the forming of an opposition in the middle of the 1980s. Negotiations around the round table took place in 1989, resulting in a change of the constitution that guaranteed transition to democracy, market economy, human rights and explicit ban of a single party government (even in the situation when the party has majority in the parliament). This change was approved on October, 23, 1989, and it is considered to be the beginning of new democratic Hungary. This way, the country “jumped” directly into democracy with free elections in March 1990. Hungarians avoided any form of pseudo-democracy or government of national unity.",1
64,7,Political development had an immediate impact on the development of the Hungarian economy. The centrally planned system had been established in the country after the Second World War. There were of course differences to other centrally planned systems in the region but the basis of the system was similar. The Hungarian system was generally never as tough as in Czechoslovakia but even bigger differences started to appear as they introduced reforms after 1968.,1
64,8,"Hungary was the first country of Central Europe to have incorporated value added tax into the tax system, which occurred in 1988. Furthermore 63% of all prices were liberalized already in 1989.3 There were continuous devaluations of the forint – from 45.8 to USD in 1986 to 63.2 in 1990 (Vintrová, 1992).",1
64,9,"Bethkenhagen (1989) wrote that private sector had created 3% of national product in 1970. In 1989 it created already more than one quarter (Holman, 2000) and two thirds of Hungarians had an income from private activity in addition to their main jobs in a state company or a cooperative. These numbers are several times higher compared to Czechoslovakia ?s numbers but are of course far from any market economy.",1
64,10,"How the reforms and changes during the communist reign reflected in the economy? As we can see in the following figure, the overall trend in Hungary was similar to other countries of the Eastern Block after the Second World War, but the growth was affected by more significant fluctuations than in Czechoslovakia. The economy was able to achieve strong growth during the 1950s but this ability declined in the following decades to very low growth during the 1980s (the average was only 0.7% per a year Maddison, 2010). The general trend is clearly visible in the following figure. Economic reforms generally did not lead to improvement in the trend of economic growth. On the contrary, economic results were worsening.",1
64,11,"We have already mentioned that the first free elections took place in March/April of 1990. The first post-communist government was created by Jozsef Antall (1932-1993). The government was central-right and based on Christian and national parties. It had a strong majority of 60% in the parliament, which gave the government a stable position. One of its achievements was that Soviet troops left Hungary in the middle of 1991. In the same year, the association agreement with the European Community was signed as well.",1
64,12,The MSZP post-communist left wing party won the next elections in 1994 by landslide. Due to the economic situation they were forced to introduce tough economic measures (of which more later). A right wing coalition government (Fidesz was the main party) was created after the elections in 1998. Hungary joined NATO during its regime. Fidesz won the next elections in 2002 as well but was not able to assemble a government that was formed by left wing parties instead.,1
64,13,"Generally, the country adhered to democratic principles for the whole period and became a member of the European Union in 2004. But there has been a lasting dissatisfaction with the transformation process and life in general in Hungary. The results of one of the surveys (2006) are depicted in the following table.4 Personally, I do not have any reasonable explanation for this attitude. We can consider high expectations of the Hungarians at the end of the 1980s and a possibility that they were generally content with the semi-capitalist system of the goulash communism.",1
64,14,"The sequence of the reforms in Hungary was under similar discussion as in other countries at the beginning of the transformation period. Hungary was specific in the fact that its communist party had started reforms before the fall of the regime already. Hungarians therefore naturally believed that it was not necessary (or it was de facto impossible) to follow radical reforms. There was a general belief that slower reforms can bring the same results with lower costs. On the other hand, proponents of a shock therapy did not trust government ability to establish market economy. As a consequence, the first period of Hungarian transformation is often described as gradualist but there are always troubles with the definition of gradualism. Some of the Hungarian measures especially bankruptcy law – can be seen as extremely radical. The second subchapter deals with reforms which took place in the middle of the 1990s, and the last, third subchapter concentrates on the period after the turn of the century.",1
64,15,"We have already mentioned that Hungarian economy had suffered from macroeconomic imbalances. Laki (1993) wrote that the Antall government had had three main tasks – to keep creditworthiness of the country, reduce inflation and the growing public deficit. The last of these tasks was the most demanding one because after the communist regime had collapsed, problems with public finance worsened. With the fall of the regime the state income declined but the cabinet was not able to simultaneously decrease its expenditures. On the contrary, the government quite often took on responsibilities for late state companies that had provided social services to the public and it led to another increase in spending (Allen, Hass, 2001).",1
64,16,"However, Hungarian government proceeded with reforms of the business and the financial sectors at the same time. Steps were taken to improve the legal system, to privatize, to improve antitrust policy, and foremost in the field of bankruptcy. Hungarian gradualism is highly questionable if we take into account the bankruptcy legislation. A very tough new code was in effect from the beginning of 1992. If a company was not capable of paying its debts within 90 days, it had to call to start bankruptcy proceeding itself. The law was in force for 18 months, and 5,000 subjects went bankrupt (Holman, 2000). These subjects together had created 10% of Hungarian GDP (Nestor, Thomas, 1995). This bankruptcy proceeding was in fact a privatization method at the same time because around 500 large companies that had gone bankrupt were transferred into private ownership (Nestor, Thomas, 1995). The process had a negative impact on the banks that were affected by the growing number of classified credits. We should recall that in comparison to that, bankruptcy legislation was very weak in the Czech Republic – in the same period considered, the very first law was approved in 1993 only and it could not been applied against companies waiting to be privatized.",1
64,17,"The economic results in Hungary in this period were not positive. If the country represents a case of a gradual reform, then gradualism turned out incapable of avoiding transformation recession. Hungary suffered similar (or deeper) decline as other countries in Central Europe. Unemployment rate was relatively high. Inflation development did not embrace the typical jump after the price liberalization (that took place in other countries) but there was a continuously higher inflation rate. On the positive side, a relatively high level of foreign capital was flowing into the country. It had again its roots in the previous liberalization because foreign investors were familiar with situation in Hungary. At the same time, deficit of the current account appeared.",1
64,18,"The goal of these steps was obvious. The government wanted to reduce deficits of the public finance and the trade balance and increase competition in the economy. The consequences of the measures were harsh – government expenditure declined by 10% of GDP (Stojanov, 2004); real wages decreased by 12% in 1995 and 4% in 1996 (Holman, 2000), and economic growth slowed down to just 1% in both 1995 and 1996. At the same time, the main imbalances in the economy narrowed – the trade deficit declined between 1994 and 1996. The government deficit (without incomes from privatization) diminished from 8.4% to 3% in the same period as well (see the previous table). Overall development of public finance during the first decade can be seen in the following figure. We can see that average deficit was relatively high – between 1990 and 2004 5.5% of GDP (EBRD, 26. 11. 2007). These results were generally the worst from the CentralEuropean countries.",1
64,19,"The economic development after applying of the Bokros package is generally deemed to be positive. Unfortunately, this prosperous period lasted only for a few years. And Hungary had to face growing problems at the beginning of the new century. Foremost, Hungarian government created notorious problems in fiscal field, for which government expenditures were to blame. Gabrisch and H?lscher (2006), for example, state that wages in the public sector increased by 12-13% only in 2002. Growing deficit of the public finance can be seen in the previous chart. Trade was another source of instability because its deficit was getting larger. The trade deficit reached between 6-8% of GDP at the beginning of the new century, being partly caused by slowing down of European economies, but mostly by the decline of competitiveness that resulted from growth of wages.",1
64,20,"The central bank was worried about lasting inflation pressures and responded by a monetary restriction, widening the fluctuation band from ±2.25 to ±15 in May 2001 as well. In the summer, the system of inflation targeting was introduced, and the currency became fully convertible. That year in October, crawling peg was abandoned and central parity of the forint was fixed. Generally, the central bank shifted its emphasis from controlling exchange rate to inflation targeting, but the central parity and the fluctuation zone were still valid. It meant that the central bank tried to hit two targets (inflation and exchange rate) by a single tool – interest rates. This task was made even more complicated by free movement of capital. On the other hand, Hungarian authorities decided to fix the currency when inflation was declining and pressures on the nominal exchange rate were expected to be lower.",1
64,21,But the problem with higher inflation that we have mentioned previously caused a negative trend of growing indebtedness in foreign currencies that continued in the following years. This development was important especially for households that often obtained mortgages in Swiss francs or euros. The share and growth of this kind of debt can be seen in the following chart. This development was obviously caused mainly by higher inflation and the fact that interest rates in Hungary were consequently higher than in the developed countries. This dangerous borrowing trend was not creating problems only if the exchange rate was stable or appreciating.,1
64,22,We should notice that high government deficits mentioned above (see Figure 2) were not expressed in growing government debt (in our period) – see the following chart. But both of these negative trends – indebtedness in foreign currencies and growing government debt – caused serious problems to Hungarian economy in the second half of the 2000s.,1
64,23,"We have mentioned differences among the central European countries at the beginning of the transformation process. As far as ownership is concerned, the biggest difference was in the role of managers of state companies. In Hungary, their role was much more accepted than in Czechoslovakia, where they were deemed as foremost high-ranking communists. As a consequence, the managers were allowed to gain control over thousands of companies in Hungary already at the end of the 1980s. This process is sometimes called a spontaneous privatization.",1
64,24,"As we can see in the following survey, the attitude of the public towards privatization was definitely not unambiguous. The numbers say that restitutions (re-privatization) had low support in Hungary, and that there was relatively high resistance to privatization as such – one of the highest numbers in the whole Eastern Europe. At the same time, however, we can notice the highest support for selling companies for the highest price offered. Laki (1993) wrote that in a survey from middle of 1991, 34% of the respondents were against privatization as such, but as many as 55-60% were against privatization of their own company. At the same time, there was strong sentiment against foreign investment and return of the previous landowners.",1
64,25,"We have already mentioned the act from 1988 that allowed transformation of the state companies into joint-stock companies in Hungary. This was a turning point that enabled managements to take control over the companies. Insiders kept playing a dominant role in Hungarian privatization at the beginning of the following decade – Earle and Estrin (1996) write that the government was not able to keep full ownership or sell a company to outsiders without insiders consenting of it. The important role of management and their abusing of the power was accompanied by scandals and embezzlement. The public turned against this form of privatization, which resulted in a slowdown of the whole privatization process (Srholec, 2001).",1
64,26,"Institutional environment was developed and state Property Fund (SPA) was founded in 1990. This organization became a central agency responsible for privatization. In 1990, SPA controlled 1,975 state companies (1,700 in industry and the rest in agriculture). According to Earle and Estrin (1996) it probably prevented even worse abuse of the situation because the Property Fund had the right to approve of all sales.",1
64,27,"The government launched the process of small privatization in the meantime. The first program was called pre-privatization and started in May 1990. It was targeted at retail, and the goal was, among others to stop spontaneous privatization. Roughly 10,000 units were sold or leased between 1991 and 1993. This way of privatization involved mostly small shops and restaurants, which were mainly auctioned. An important factor was that employees of the respective shops gained majority of the property. Changes in property ownership can be seen in the following table.",1
64,28,"Until the mid 1995, SPA divested itself of 75% of the previous ownership, which nevertheless represented only 35% of state property (Stojanov, 2004). The government still kept possession in gas distribution, railways, airlines, telecommunication, banks and chemical companies. This changed with the Bokros package, though. The government urgently needed to decrease fiscal deficits, and intensification of the privatization process was one of the ways to achieve this. It was decided that all stateowned property with the exception of railways, post office and national parks would be sold. The rest of the property for sale included The Savings Bank (OTP) and the main telecommunication company, among others. The amount of property for privatization reached HUF 1.3 trillion out of 1.6 trillion of the overall state ownership (Stojanov, 2004). A typical method was a direct sale to a foreign investor, which resulted in a huge inflow of foreign direct investment in this period. A growing role of foreign ownership can be seen in the following table. Until the end of 1997, the government sold property worth HUF 790 billion and its debt decreased from 86% of GDP in 1995 to 60% in 1998 (Stojanov, 2004).",1
64,29,"Economic growth can be seen in the following figure. We can notice that similarly to other countries in central Europe, Hungary too suffered from transformation recession. The slower pace of the reforms (gradualism) did not help avoid the recession, and a visible slowdown after 1995 occurred here, too. But the general trend is positive. We should compare the results of HP filter during the communist regime with results after 1990. Hungarian economy was able to achieve growth around 3 or 4 percent after having overcome the transformation recession.",1
64,30,"Hungary was not spared growth in unemployment in the first years of transformation even though the country was actually following a more gradual approach. Within several years, unemployment achieved its maximum – around 12% of the labor force, after which it gradually declined. It is in contrast with the development in the Czech Republic, where unemployment rate was minimal until 1997 and grew only with the currency and economic crises in 1997. At that time, however, unemployment rate in Hungary had already been declining steadily. We should stress that in both of these countries, unemployment rate was very low in comparison to other post-communist countries – Poland being one of the examples, as we can see in the following figure. On the other hand, there was deep decline in employment in Hungary and thus the numbers are affected by it.",1
65,1,Current economic literacy tests focus on theory while almost totally ignoring the economy itself. This study analyzes how well we are teaching students empirical facts. Most agree that economic literacy is a laudable goal and current literacy pedagogy is centered on teaching students how to “think like economists.” The authors do not intend to imply criticism to current literacy campaigns; rather this work is intended to open a discussion within the field about the need to also introduce students to some basic economic facts. This study is based upon surveys given to several hundred introductory economics students and tabulates some preliminary observations about their level of fact attainment.,1
65,2,"Fact based, objective economics, allows the learner to understand some of the realities of the economy they live in. From that starting point the student can go on to make decisions about where they envision the economy is going and also make normative suppositions about how the economy should be directed. In doing this instructors must serve two differing roles: 1) to offer the students the differing models that explain how the economy works; and 2) to give the students the basic, factual information about economic variables so students can then use the models appropriately. Issue number one, which models should be taught, is beyond the scope of this work. This study wishes to emphasize the second role. By offering students factual information about real economic variables students are going to be able to make better informed decisions about economic issues.",1
65,3,"There has been some discussion on the appropriateness of this direction in defining literacy. In 2002, Hansen, Salemi, and Siegfried presented a paper on potential ways to reorder college principle classes to improve literacy attainment at that level. They argue that current intro classes, with the heavy emphasis on technical literacy, ill serve the majority of students who are taking the classes who will never take further economics training. Hansen, Salemi and Siegfried mention a study where on a 15 point survey, “college economics course-takers scored 9, high-school economics course takers scored an 8, and those who took no economics scored a 7” (2002, 463). Hansen, Salemi and Siegfried suggest in their paper that a reorganization of the introductory series be attempted. That extra time could then be used to “focus on problems, issues, and puzzles” and “create more opportunities to practice economics” (468).",1
65,4,"It seems fair to suggest that the individuals putting forth the goal of “practicing economics” are honest in their desire to improve student understanding, yet what does this statement mean? Does this mean teaching the students to think in terms of utility maximization? If so, then doesn’t this suggest that utility maximization is not some natural state and instead, it must be learned? Does this simply mean introducing our students to the best models we currently have available and leave it at that? As stated in the opening paragraph, introducing the students to these models is of importance but simply introducing the models to the students without giving them a basic understanding of real economic variables has inevitable downfalls. Doing so would be the equivalent of helping students build a car but never telling them that in order for the car to run you must put gas into the tank. Given the rhetorical power of basic economic analysis it would seem reasonable that we have an obligation to give our students the facts from which these devices are derived and we have an obligation to teach the sound application of facts to whatever models we teach.",1
65,5,This current essay is part of an ongoing project being conducted by colleagues who are interested in exploring how well informed the U.S. population is with respect to actual economic variables. This project is based on the firm belief that more can be achieved by giving Americans factual information than can be achieved by simply giving people disembodied economic models with little grounding in empirics.,1
65,6,"The facts that are chosen for inclusion into the realm of “economics” are important since they will serve to define the scope of that which is considered part of the field. It is conceivable that it is for this reason that fact based economic instruction has become less emphasized. It is perhaps beyond question that most economists would agree that GDP, GDP/person, inflation, and unemployment are important macro topics. Other economists may take time to cover poverty, income distribution and the changing dynamics of these variables over time. Still others may emphasize the role of interest rates and banking. A few might cover issues such as how the tax system works or how social security works. Most economists are going to offer their students an emphasis that is directed by their personal interests. Yet in covering any of these topics do we offer the students real information about the actual empirical numbers that we are detailing? More importantly are we offering the students accurate information on the topics of great importance?",1
65,7,This working group wants to measure how well individuals in the economy understand actual economic variables. This is an ongoing project and as such our methods and procedures will be changing as we move forward. We surveyed 341 incoming introductory economics students on a battery of questions emphasizing variables we thought important. We now offer some preliminary findings we believe may be of interest to the discipline.,1
65,8,"To be fair, the members of this working group believe that the wording of the question may be such that some of the people may be misconstruing the concept of GDP with GDP/person. Efforts are being made to improve the survey mechanism. Yet even with the flawed question the current evidence suggests that numbers, such as GDP/person, can be taught and will be remembered. This is clearly demonstrated by the students who answered close to correct after taking the courses of the instructors who are part of this working group.",1
65,9,"In this survey we decided to look at the knowledge of the students with respect to income distributions in the United States. We asked the following questions on income distribution. What household income does it take to be in the top 20% and top 5% of income earning households in 2007? The actual numbers for 2007 were around $87,000 and $166,000 respectively. Figure 1 gives the breakdown of answers by percentage of student’s answers in the specific range for 5% and Figure 2 gives the breakdown for 20%.",1
65,10,"The average responses given by the students as a whole were an income of $20,056,314 to be in the top 5% and $887,906 to be in the top 20%. Looking at the overall observations, 80% of the respondents overestimated the income it took to be in the top 5% and 70% of the respondents overestimated the income it took to be in the top 20%. If we look at the percentages that overestimated the amount by at least double, we have 56% that offered an answer at least double the actual number for the top 5% and 35% of respondents answered at least double the actual number for the top 20%. Given these observations it should probably not be surprising that politicians are able to claim that raising taxes on households with over $250,000 in income is giving a tax increase to middle income households. This study suggests that most of the students have a severe misperception of income distributions in the United States.",1
65,11,"We can once again breakdown the responses based upon the formal training of the respondents, and get some interesting results. It seems to be the case that the more formal training the more accurate the average response becomes with respect to the 20% answers. However, with respect to the 5% level it looks as if there is no difference between “no high school” and “college” (see Table 1). High school classes seem to have a negative impact on actual understanding given this study’s data. (Please note that the instructors past students seem to have done remarkably better than the rest but their average responses are also far off from the real numbers.)",1
66,1,"In this paper, we investigate the systemic link between economic freedom, foreign direct investment (FDI) and economic growth in a panel of 85 countries. Our empirical results, based on the generalized method-ofmoment system estimator, reveal that FDI by itself has no direct (positive) effect on output growth. Instead, the effect of FDI is contingent on the level of economic freedom in the host countries. This means the countries promote greater freedom of economic activities gain significantly from the presence of multinational corporations (MNCs).",1
66,2,"The effect of foreign direct investment (FDI) on growth has been debated extensively in the economic literature. The rising interest in this area of research also coincides with the shift in emphasis among policymakers towards attracting more FDI inflows in recent years. Since the early 1980s, many countries (including the developing ones) have lifted many of the restrictions imposed on foreign capital flows.1 As a result, global FDI inflows rose sharply from $57 billion in 1982 to $1271 billion in 2000. In fact, over the past few decades the growth rate of world FDIs has exceeded the growth rates of both world trade and GDP (UNCTAD, 2001). The reason for the increased effort to attract more FDIs stems from the widespread belief that FDI has several positive effects, including productivity gains, transfers of new technology, the introduction of new processes, management techniques, and technical know-how in the local market, employee training, and international production networks.2 Additionally, FDI is not as volatile as other forms of capital (e.g., short-terms capital), and hence, is less destructive (World Bank, 1999).",1
66,3,"In an effort to further understand the nature of the FDI–growth nexus, this paper draws from recent literature that highlighted the importance of institutions in the growth process. In particular, our research emphasizes the importance of freedom of economic activities in mediating FDI spillovers to help answer these questions. Our argument is simply based on the fact that the lack of economic freedom can limit a firm's (or nation's) ability to absorb and internalize new technology from multinational corporations (MNCs) (i.e., foreign presence) and contribute to host country's economic growth. To date, the literature has emphasized the quality of institutions and economic freedom, but the focus has been primarily on the direct effect on economic growth. Hence, this is not the first article that examines the role of economic freedom in wealth creation.",1
66,4,"In this paper, we utilize the index of economic freedom (EF, hereafter) provided by the Fraser Institute to establish the potential link between EF and growth. The index is a measure of institutional quality that provides insight into the characteristics of an environment conducive to prosperity. A glance at the index components reveals several reasons to expect that countries with higher levels of EF will have greater absorptive capacity, and thus allow them to reap more benefits from FDI spillovers. First, there is broad agreement within the profession that, in general, less regulation would be good for economic progress. It is well known that a free and competitive market provides greater opportunities for entrepreneurs to try out new ideas. It also encourages firms to engage in risky ventures such as FDI-related activities, in search of higher returns for their investment. On the other hand, if the market is extensively regulated, it will not function well, and hence the allocation of resources would be adversely affected in such an environment. For example, if financial markets are extensively regulated, FDI-related activities will be affected as firms need external funds to finance the adoption of new technology (Alfaro et al., 2004).",1
66,5,"The provision of incentives (i.e., tax incentives and/or subsidies) and the adoption of FDI-stimulating policies stem from the expectation that FDI will bring tremendous benefits to the recipient countries. MNCs have been linked to superior technologies, patents, trade secrets, brand names, management techniques, and marketing strategies (Dunning, 1993). Besides that, MNCs are known to be among the most technologically advanced firms, as they are responsible for a large part of the world's R&D expenditures (Borensztein et al., 1998). They also hire a large number of technical and professional workers (Markusen, 1995). Through FDIs, the recipient countries are granted instant access to new technology that may benefit those receiving the foreign capital, and also other firms in the host country. To the extent that FDIs add to the existing capital stock, they may have growth effects similar to domestic investments, in addition to alleviating the balance-of-payment deficits. Besides labor augmentation, MNCs train managers and workers who may then later join local firms. FDIs (especially export-oriented FDIs) may promote export by setting up assembling plants and helping local firms to access international markets for exports (Aitken et al., 1997).",1
66,6,"It has also been argued that the adoption of new technologies requires labor that is able to understand and work with the new technology. On this issue, Borensztein et al. (1998) found that FDI inflows only had a marginal direct effect on growth, but in countries where human capital was above a certain threshold it did positively contribute to growth (i.e., when FDI was interacted with the level of education of a country's labor force). The same interaction effect was not significant in the case of domestic investment, which may reflect the nature of technological differences between FDI and domestic investment. This finding implies that because developed countries have a higher level of human capital, they are more likely to gain from FDIs than developing countries. This conjecture is further supported by Xu (2000) who found that technology transfer by U.S. MNCs contributed to the productivity growth in developed countries, but not in developing countries. Unlike the two articles mentioned above, Alfaro et al. (2004) found that human capital was not important for mediating FDI inflows. Instead, Alfaro et al. (2004) suggested that the development of the financial sector was more important than human capital for FDI spillovers.",1
66,7,"Although empirical evidence on the link between FDI and growth is mixed, evidence on the role of institutions in the development process is more compelling. North (1990), perhaps today's bestknown economic ‘institutionalist,’ defines institutions as the humanly devised constraints or rules of the game that structure political, economic, and social interaction. Important elements of these are formal rules (e.g., constitutions, laws, and property rights sustained through courts, and the police) and informal constraints (e.g., sanctions, taboos, customs, traditions, and codes of conduct). He further states that institutions provide the incentive structure of an economy. As the structure evolves, it shapes the direction of economic change towards growth. In short, institutions affect security of property rights, prevalence of corruption, distorted or extractive policies, and thereby affect the incentive to invest in human and physical capital, and hence economic growth.",1
66,8,"A number of recent papers empirically confirm the importance of institutions for economic development. Knack and Keefer (1995) pioneered the use of property right security indicators in the growth literature, with the International Country Risk Guide (ICRG) and Business Environment Risk Guide (BERI) indices as proxies for institutional quality. These institutional indicators include quality of bureaucracy, property rights, and the political stability of a country. Their cross-country estimation results indicate that all these factors have a positive statistically significant relationship with economic performance. On this point, Barro (2000) argues that secure property right improves growth performance by encouraging investments, and also by enhancing the productivity of investments. Meanwhile, Demetriades and Law (2006) find that stronger institutions are more important than financial developments in explaining output per capita in low-income countries. Rodrik et al. (2004) show that quality of institutions overrides geography and integration (i.e., international trade) in explaining cross-country income levels. Acemoglu et al. (2001) use the protection from the expropriation risk index constructed by the ICRG as a measure of efficiency of current institutions.",1
66,9,"In short, empirical studies on FDI–growth relationship remain limited particularly with respect to the effects of EF on FDI spillovers. Arguably, countries that promote greater freedom of economic activities are more likely to gain from the presence of MNCs. While this is a plausible conjecture, as of yet there is no hard empirical evidence to support the view that EF makes a difference to the way in which FDI affects economic growth. Such evidence is clearly the logical next step in the evolution of the literature on FDI and growth.",1
66,10,"The GMM estimators are typically applied in one- and two-step variants (Arellano and Bond, 1991). The one-step estimators use weighting matrices that are independent of estimated parameters, whereas the two-step GMM estimator uses the so-called optimal weighting matrices in which the moment conditions are weighted by a consistent estimate of their covariance matrix. This makes the twostep estimator asymptotically more efficient than the one-step estimator. However, the use of the two-step estimator in small samples, as in our study, has several problems. These problems result from the proliferation of instruments. In a simulation analysis, Windmeijer (2005) shows that the two-step GMM estimation with numerous instruments can lead to biased standard errors and parameter estimates. Moreover, Bowsher (2002) shows that numerous instruments may lead to a weakened over identification test. The author shows that the test is undersized and never rejects the null of joint validity at 0.05 or 0.10, rather than rejecting it 5% or 10% of the time as a well-sized test would. In order to alleviate the problems induced by the proliferation of instruments, Roodman (2009b) recommended reducing the dimensionality of the instrumental variable matrix.",1
66,11,"This section presents the empirical findings using the three different approaches discussed in Section 5. The empirical results are presented in Tables 1–5. Table 1 reports a preliminary analysis on the effects of FDI and EF on growth. Table 2 presents coefficient estimates obtained from the baseline specification, which used an interaction term constructed as a product of FDI and EF index. Table 3 reports the coefficients estimate from a specification that uses dummies to capture the contingency impact of FDI on growth at different levels of EF. Table 4 displays the estimated coefficient obtained using sample splitting under which linear growth–FDI relationships are estimated using two different subsamples. Finally, the results on the interaction specification using the components of EF index are displayed in Table 5. Our aim is to show whether the component of the EF index yields qualitatively similar results to that of the aggregate index.",1
66,12,"Numerous researchers have investigated the impact of FDI on economic growth. Unfortunately, the empirical literature has produced conflicting conclusions. In more recent studies, the absorptive capacity of the recipient countries appears to be the key explanation for this ambiguity. The main purpose of this paper is to investigate a new aspect of absorptive capacity, namely EF. Specifically, this paper assesses whether the marginal impact of FDI on growth depends on the freedom of economic activities in the host countries.",1
66,13,"Using a panel data for 85 countries over the 1975–2004 period, we draw three important conclusions from the empirical analysis. First, as in earlier studies, we find that FDI by itself has no direct impact on output growth. Second, EF is found to be an important driver for long-run growth for the countries considered. The positive correlation (direct link) between EF and growth is also consistent with the findings reported in de Haan and Sturm (2000) and Sturm and De Haan (2001), to mention two. Finally, as it is shown in the empirical evidence, the impact of FDI on growth is contingent on the level of EF. We find that the countries under review (including the developing countries) that promote freedom of economic activities gain significantly from the MNCs' presence. In these countries, firms can more easily absorb and adopt new technology and other benefits associated with FDI inflows. This also explains why the benefits accrued from acquisition FDI and their association with foreign multinationals with performance advantage is higher for some countries and not others. We consider this is an important result as it suggests that EF is an important element of the nation's absorptive capacity, but it has been somewhat ignored in earlier studies.",1
66,14,"Freedom of exchange across borders may help domestic firms penetrate international markets for exporting purposes. Among other aspects, export activity involves costs associated with the establishment of distribution networks, transport infrastructures, or knowledge of consumers' tastes in foreign markets, which MNCs are more able to afford. By following the export processes of foreign firms (through imitation or collaboration), domestic firms may reduce the entry costs into the foreign market. The gains obtained in this way may have favorable implications on the productive efficiency of domestic firms. Trade may also enhance the productivity of resources at home by enabling domestic firms to employ a larger variety of intermediate products and capital equipment (Romer, 1990).",1
66,15,"Reducing regulatory constraints (e.g., labor, business and credit) is also importance for FDI spillovers. For instance, fewer regulations in hiring and firing workers in the host country will encourage labor mobility across firms. Therefore, workers previously employed with MNCs are more able to transfer their knowledge and experience of new technologies to domestic firms. The level of regulations on business activities may affect FDI spillovers through its effects on market competition. MNCs may be more willing to transfer technology to domestic suppliers in order to secure intermediate goods at a competitive price if the level of competition in the industry in which they operate is high (i.e., high level of regulatory freedom). The importance of financial markets for FDI spillovers was documented by Alfaro et al. (2004) who emphasized that firms need external funds for technology upgrading. Therefore, any effort that improves access to external funds, such as reducing regulatory constraints, will have a positive implication on the success of domestic firms in acquiring new technology.",1
66,16,"In this respect, policymakers should weigh the cost of policies aimed at attracting FDI versus those that seek to improve the level of EF. Policy strategies directed towards attracting FDI should be in conjunction with, rather than precede, policies promoting better freedom of economic activities, because more freedom is likely to deliver greater benefits. Countries that have not done so will lose out in the race. Policymakers should create policies transparent enough for potential investors before using other measures for attracting higher levels of FDI. However, the reforms can be an arduous process and requires a long-term commitment. In some countries, they may be politically difficult in the short run but the long-run economic benefits can be tremendous.",1
66,17,"Despite these important findings, some caveats are in order. One limitation is that the interaction term in our main specification forces the impact of FDI on growth to increase (or decrease) monotonically with the level of EF. However, it may be the case that a certain level of EF is required before FDI can have any impact on host countries. As noted by World Bank (2001) and others, only countries with the greatest absorptive capacity are likely to benefit from the presence of foreign capital. In countries with low absorptive capacity, the benefits of FDI are muted or non-existent. This suggests the need for a more flexible specification that can accommodate different types of interactions between FDI, output growth, and economic freedom. One possible solution is to employ a regression model based on the concept of threshold effects to capture the presence of contingency effects (see for example Girma, 2005). We leave this possibility for future research.",1
1,1,"Extant research supports the hypothesis that biometric indicators of life history (LH) strategy, such as the timing of sexual debut, are calibrated in response to cues sampled early in development (before age 7). Herein, we theorize that the experience of sexual debut itself may further calibrate women’s LH-related behavioral phenotypes across adolescence by modulating subsequent investment in mating effort, which is associated with faster (vs. slower) LH speed. We tested this hypothesis using longitudinal data, which included Q-Sort LH scores at ages 14, 18, and 23, and a report of whether or not sexual debut occurred between ages 14 and 18. Results demonstrated that women (but not men) who experienced their sexual debut between the ages of 14 and 18 showed greater relative acceleration of LH speed during this period than women who had not debuted by age 18. However, these same effects had weakened by age 23—which underscores the broader idea that LH-related behavioral phenotypes exhibit substantial cue-based plasticity across adolescence and into adulthood. Although alternative explanations for the observed patterns remain unfalsified, these findings are consistent with the hypothesis that developmental LH trajectory is regulated in relation to the timing of sexual debut in adolescence. This possibility could be further investigated in future research",1
1,2,"Life history (LH) theory originated as an explanation for changes in organisms’ reproductive strategies under conditions of increasing environmental constraints (Pianka 1970) with a rapid or quantity reproductive strategy predominating with loose constraints and a more restrained quality reproductive strategy prevailing as constraints tightened. Promislow and Harvey (1990) proposed that these strategies accounted for a collation of differences between species, finding significant covariance amongst such indices as rate of maturation, litter size, and maternal investment in offspring. Similarly, LH theory was applied to human group (Rushton 1985) and individual differences (Draper and Harpending 1982) such that individual differences in rate of maturation, sexual debut, and parental investment covary forming LH strategies between people. Individual differences in LH strategy are now described as varying in speed along a fast to slow continuum. Faster LH strategies are defined by earlier maturation and sexual debut, higher frequency of sexual intercourse with less stable pair bonds, and reduced parental investment. Slow LH strategies are defined by later maturation and sexual debut, lower frequency of sexual intercourse with more stable pair bonds, and increased parental investment.",1
1,3,"The earliest models on the development of LH strategies stressed the critical influence of early childhood experiences that would have predicted LH-relevant environmental parameters across human ancestral environments (Belsky et al. 1991; Draper and  Harpending 1982; Ellis et al. 2003). For example, Belsky et al. (1991) proposed that the quality of parental attachment in childhood is the key determinant in calibrating developmental trajectories toward a fast or slow LH strategy. Secure parental attachment guides development down the path of a slow LH strategy, with the corresponding phenotypic traits geared toward investment in future reproduction via delayed maturation and sexual debut. Alternatively, insecure parental attachment leads to a fast LH strategy with early maturation and earlier sexual debut, unstable pair bonds, and low parental investment in offspring. At several points in their article, Belsky et al. (1991) reiterate Draper and Harpending's (1982) position that early childhood experiences (explicitly stated as occurring in the first 5–7 years of life) are critical in setting the fast (called Type I in the article) or slow (called Type II in the article) developmental trajectories. This position is summarized in the following quote from the article",1
1,4,"A central tenet of the theory we advance is that a principal evolutionary function of early experience—the first 5–7 years of life—is to induce in the child an understanding of the availability and predictability of resources (broadly defined) in the environment, of the trustworthiness of others, and of the enduringness of close interpersonal relationships, all of which will affect how the developing person apportions reproductive effort.",1
1,5,"The position that there is a critical period wherein LH strategy crystalizes in the middle of the first decade may be too strong. While recognizing a significant degree of heritability in LH strategy (Figueredo et al. 2004), additional research and advancing theory on the development of LH strategies in reaction to proximate somatic (Nettle et al. 2013; von Rueden et al. 2015) and environmental (e.g., Brumbach et al. 2009) cues both suggest that significant plasticity in LH strategies remains after the 5–7 years of age period identified by Belsky et al. (1991). On the other hand, the issue of the importance of early versus late developmental experience in helping shape LH strategy remains an open question with some findings pointing to the importance of early experiences relative to those experienced later in life. For example, Simpson et al. (2012) found that the level of environmental predictability experienced in the first 5 years of life had a significant effect on LH strategy at age 23, but the level of environmental predictability experienced in later childhood and adolescence did not.",1
1,6,"The most comprehensive model on how factors beyond the age of seven may impact LH strategies has been proposed by Del Giudice (2009), who suggested that early adolescence, specifically adrenarche, acts as an additional switch point in the development of LH strategies. This idea has been advanced further by Ellis et al. (2012) and Del Giudice and Belsky (2011), both of whom extended the putative period of cue-based plasticity through puberty and into later adolescence. In support of the idea that LH strategy may be continually adjusted across development, well past the age 5 to 7 period, Dunkel et al. (2015) recently found that maternal authoritative parenting received during adolescence uniquely predicted later LH strategy above and beyond the calibration effects of maternal behavior in early childhood.",1
1,7,"The current investigation further explores the idea of continued plasticity in the development of LH strategy in adolescence. To that end, we examined another possible contributing factor in developing LH strategies during adolescence: sexual debut (i.e., age of first sex). While sexual debut has most often been used as a type of dependent variable, the timing of which is indicative of LH strategy (see Ellis et al. 2003), there is precedence indicating that it may also serve as an LH cue acting to calibrate LH speed. For example, Vigil et al. (2005) tested the possibility that childhood sexual abuse accelerates LH speed. Vigil et al. (2005) surveyed over 600 women between the ages of 18 and 56 from the Midwestern and Southwestern USA concerning whether or not they experienced childhood sexual abuse, assessed by the single item “I was sexually abused before age 14,” and the subsequent ages at which they experienced a number of indicators of LH strategy (e.g., sexual debut). While, as recognized by Vigil et al. (2005), childhood sexual abuse differs from consensual intercourse later in life in many clear and important ways, the authors proposed that the act of intercourse itself may be one reason why childhood sexual abuse accelerates LH speed. Indeed, they found that women who reported being victims of childhood sexual abuse also reported earlier menarche, earlier timing of first consensual intercourse, and giving birth to their first child earlier in life.",1
1,8,"Thus, the primary hypothesis of the present study is that sexual debut accelerates LH speed. The general prediction that LH strategy is facultatively calibrated in ontogeny only holds to the degree that particular developmental cues were ancestrally valid predictors of variable world states (Frankenhius and Panchanathan 2011). Although certain aspects of early environment may contain some valid LH-relevant information, recent theoretical work suggests that internal (e.g., somatic) cues may in many cases have much higher cue validities than external cues (Nettle et al. 2013). This would be especially true for internal cues associated with sexual debut (e.g., psychological experience of having sex; “breaking” of the hymen), which provide highly valid information regarding one’s actual progression into a sexually active developmental stage wherein it would have been ancestrally functional to invest in reproductive effort (at the expense of investment in growth, etc.). If so, selection may have favored facultative adaptations designed to accelerate LH speed in response to sexual debut in adolescence, such that the loss of virginity promotes investment in current reproduction via increased allocation of resources toward mating effort.",1
1,9,"Given that the transition from virginity to sexual activity entails much greater potential costs for females than males (Trivers 1972), the tradeoff between growth and reproduction as a function of virginity loss would have been especially pronounced among ancestral women (Vigil et al. 2005). We correspondingly predict that sexual debut will accelerate LH speed to a greater degree in adolescent females than males. We examine these predictions using data from a longitudinal study conducted by Block and Block (2006a) which includes both repeated measures of LH strategy from adolescence and into adulthood based on the California Adult Q-sort (Block 1978; Sherman et al. 2013) and information concerning the timing of sexual debut.",1
1,10,"The Block and Block data (2006b) and documentation files were downloaded via the internet from the Henry A. Murray Research Archive. The Block and Block longitudinal study lasted 30 years with multiple waves of data collection and extensive testing taking place at each wave. Participants were initially recruited from two preschools in Berkeley, CA, when they were 3 to 4 years of age. Demographic information including participant sex, ethnicity, and socioeconomic status was obtained from data files in the first wave of data collection.",1
1,11,"Data from waves at ages 14, 18, and 23 were also used in the analyses. Because the investigation concerned the transition in LH strategy from age 14 to ages 18 and 23, age 14 serves as the base year for the analyses. At age 14, the sample included 106 participants, of which 54 were female (51 %). Of the 106 participants, 71 were White, 27 were Black, 5 were Asian-American, and 4 were classified as “Other.” Due to the small number of non-Black minorities, participants were grouped as White (67 %) and non-White (33 %).",1
1,12,"LH strategy was measured using the California Q-sort (CAQ; Block 1978). The CAQ includes a set of 100 items, and the items are to be Q-sorted or arranged in piles based upon the degree to which they describe an individual. Sherman et al. (2013) developed an LH strategy template allowing LH strategy to be measured using the CAQ, and this measure was recently validated and slightly modified by Dunkel et al. (2014) using the Block and Block data.",1
1,13,"At ages 14, 18, and 23 between four and six, trained raters independently used the CAQ to rate each participant’s personality. The aggregate of these ratings was then correlated with the LH strategy template. The correlation of the participants’sort with the template is their score. Higher scores (i.e., stronger correlations) represent a slower LH strategy. A sample item that is reflective of slow LH speed is “sympathetic/considerate.” A sample item reflective of fast LH speed is “unable to delay gratification.”",1
1,14,"At age 18, participants responded either in the affirmative or negative as to whether they had “lost their virginity” within the last 3 years. Forty-two participants indicated that they had “lost their virginity” in the last 3 years and 60 participants reported that they had not.",1
1,15,"Sex, ethnicity (dichotomized as White and nonWhite due to small sample size), and socioeconomic status (SES), measured by Warner’s Index of SES (1949) when participants were 4 years of age, were demographic covariates.",1
1,16,"In addition to the demographic covariates, we included four other covariates: intelligence, maternal and paternal parenting style, and the relationship to the person with whom the participants had intercourse for the first time. Intelligence was measured at age 18 by the Wechsler Adult Intelligence Scale (WAIS). Intelligence was included as a covariate to control for the influence of the participants’ cognitive ability, which could plausibly limit one’s ability to reason about the potential consequences of consenting to intercourse. Maternal and paternal authoritative parenting was measured by the Child Rearing Practices Report (CRPR; Block 1965; Kochanska et al. 1989). The CRPR is a 91-item Q-set that participants used at age 18 to rate both their mother’s and father’s parenting style. Authoritative parenting was included as a covariate because it has been found to influence the development of LH strategies during adolescence (Dunkel et al. 2015). The last covariate was the level of intimacy the participants had with whom they reported having lost their virginity (knew each other a little, friend, going steady, or engaged). This covariate was included to test the possibility that the level of partner intimacy played a role in the effect of losing one’s virginity.",1
1,17,"Descriptive statistics (means and standard deviations for the LH scores) by age, sex, and sexual debut are seen in Table 1. LH scores appeared to increase after age 14, which presumably reflects a normative developmental trajectory in the transition from adolescence to adulthood. In addition, males exhibit a faster LH strategy at all ages. These trends were confirmed in a repeated measures analysis of variance (ANOVA) with the within-subjects variable of LH strategy at ages (14, 18, and 23) and between subjects variable of participant sex. The within-subjects effect was significant, F(2,99)=9.16, p<0.001,ηp2=0.16,and so was the between-subjects effect for participant sex, F(1, 100)=5.52,p<.05,ηp2=.05.The interaction between variables was not significant and explained little variance, ηp2=0.005.Correlations between sexual debut and LH strategy at the three focal ages were as follows: age 14 rpb(102)=-.06;age 18 rpb(100)=-0.24,p<0.05;and age 23 rpb(99)=-.14",1
1,18,"To test the hypothesis that sexual debut occurring in adolescence accelerates LH speed and that this effect is more pronounced in females, a series of partial correlations was conducted looking at the association between sexual debut and LH strategy at ages 18 and 23. Note that partial correlation is used to control for variance in both the criterion (e.g., LH strategy at age 18) and the predictor variable (e.g., sexual debut). Thus, partial correlation is more fitting for testing the hypotheses than an alternatives such as repeated measures ANOVA or regression (i.e., semi-partial correlation) in which the criterion (e.g., LH strategy at age 18) is not altered.",1
1,19,"Initially, and most importantly, the partial correlations controlled for LH speed at age 14. Then, in succession, additional partial correlations were calculated; in each case, an additional covariate was added. After LH at age 14, the covariates were added in this order SES, ethnicity, IQ, maternal authoritative parenting, paternal authoritative parenting, and the intimacy level with the partner. The results can be seen in Table 2. For the full sample when controlling just for LH strategy at age 14, sexual debut was correlated with LH strategy at age 18, but not at age 23. Additionally, the relationship between sexual debut and LH strategy at age 18 fluctuated as covariates were added.",1
1,20,"When the sample was split by sex, for females, the relationship between sexual debut and LH strategy at age 18 remained as covariates were added. There was an additional trend; the addition of covariates led to the strengthening of the relationship between sexual debut and LH strategy at age 23. To further explore this trend in females, two change scores were computed by subtracting LH strategy scores at age 14 from LH strategy scores at age 18 and by subtracting LH strategy scores at age 14 from LH strategy scores at age 23. Thus, positive scores indicate change in which LH speed slowed. Between ages 14 and 18, those who had their sexual debut during adolescence had a mean change score of (M= 4.80, SD=16.72), while those who did not have intercourse during adolescence had a mean change score of (M=13.45, SD=25.32). Between the ages of 14 and 23, those who had their sexual debut during adolescence had a mean change score of (M=7.48, SD=29.05), while those who did not have intercourse during adolescence had a mean change score of (M=13.20, SD=28.03). While the differences in the change scores are not statistically significant given the limited statistical power of between-subjects change score comparisons relative to the partial correlation analyses described above, the change scores do assist in interpreting the statistically significant correlations.",1
1,21,"Recent research findings and theoretical advancements have led to the prediction that plasticity in the development of LH strategies extends beyond the period of early childhood as first envisioned by Belsky et al. (1991). Following these changes in the understanding of LH strategies, it was hypothesized that the timing of sexual debut may impact developing LH strategy, such that sexual debut accelerates LH speed in adolescence. Additionally, it was expected that this effect may be more pronounced in females. To test these hypotheses, the relationship between sexual debut between ages 14 and 18 and LH strategy at ages 14, 18, and 23 was examined.",1
1,22,"The results suggest several possibilities. The partial correlations show that, for females, sexual debut may calibrate the developmental trajectory of LH strategy. After controlling for LH strategy in early adolescence and a number of potential confounds, female participants who engaged in sexual intercourse during adolescence had a faster LH speed in late adolescence and possibly into young adulthood. These individual differences are embedded in developmental change wherein raw LH scores increased with age. As such, the difference scores may provide a clue to help interpret these findings. Specifically, the observed age-related increase in LH scores was greater for those who did not engage in intercourse during adolescence.",1
1,23,"Given that a fast LH strategy is defined in part by an individual’s degree of investment in mating effort, this pattern is consistent with the idea that sexual debut acts to upregulate women’s engagement in risky tactics of intrasexual competition and/or mate attraction. This facultative response makes functional sense under our hypothesis, which posits that experiencing sexual intercourse would have been an ancestrally valid cue of having progressed into a LH stage during which the acquisition of reproductive benefits (whether via behavioral investment or genetic quality) would have become an adaptive problem of immediate and crucial importance. However, this hypothesis leaves unclear whether we should expect a longer-lasting developmental shift toward a fast LH speed that persists into adulthood. The fact that women’s sexual debut experienced between 14 and 18 is not as strongly associated with LH acceleration by age 23 suggests that virginity loss initiates a shift toward investment in mating effort that is (potentially) temporary and subject to further recalibration as developmental events unfold. For example, some individuals who were temporarily calibrated toward a faster LH profile post-debut may later begin to invest heavily in future reproduction as they enter subsequent LH stages. Likewise, some women who remain abstinent between 14 and 18 may later become sexually active and consequently experience a temporary LH acceleration of their own. In either case, further life stage-linked shifts in LH after age 18 would be expected to attenuate the association of events in early adolescence with later outcomes.",1
1,24,"The main premise of the current study is that LH variation is regulated over ontogeny not only in response to early cues but also in relation to cues experienced later in development. With few exceptions (e.g., Vigil et al. 2005), “biometric” indices have been viewed as outcome measures that signify individual differences in developing LH strategies (for an overview of biometric measures, see Copping et al. 2014; Figueredo et al. 2014; Figueredo et al. 2015). Although our correlational findings are subject to alternative explanations, they support the hypothesis that the experience of sexual debut may act to calibrate subsequent LH speed via promotion of investment in mating effort. At the very least, the data indicate that the trajectory of LH development in adolescence and the timing sexual debut are correlated phenotypic components.",1
1,25,"However, some specific limitations should be noted. While a number of covariates were included, genetic influence on both the timing of sexual debut and LH strategy (e.g., Eisenberg et al. 2007) cannot be ruled out. On the other hand, given that one of the controls was LH strategy at age 14, genetic explanations for the findings must move away from basic additive models, and additive effects appear to account for most of the heritability in psychological traits (e.g., Polderman et al. 2015). Another limitation of the finding is that the effect of sexual debut on LH strategy speed appears to dissipate as participants move from late adolescence into adulthood. Data points in later adulthood might shed light on whether this trend continued, but Q-sort data was last collected at the age 23 wave of data collection in the Block and Block (2006a) longitudinal study. As such, we hope that this article stimulates future research that can disambiguate the associations of biometric and psychosocial events with the development of LH strategy from adolescence into later adulthood",1
1,26,"This project was made possible by the Henry A. Murray Research Archive which is housed by the Institute for Quantitative Social Science at Harvard University. The data employed in this study derive from a 30-year longitudinal study begun with 128 3-year-old girls and boys, planned and conducted by Jack and Jeanne H. Block, involving a sequence of nine independent assessments based on personality and cognitive life, observational, test, and self-report (LOTS) measures.",1
2,1,"Contact switches and touch screens are the state of the art for recording pigeons’ pecking behavior. Recording other behavior, however, requires a different sensor for each behavior, and some behaviors cannot easily be recorded. We present a flexible and inexpensive image-based approach to detecting and counting pigeon behaviors that is based on the Kinect sensor from Microsoft. Although the system is as easy to set up and use as the standard approaches, it is more flexible because it can record behaviors in addition to key pecking. In this article, we show how both the fast, fine motion of key pecking and the gross body activity of feeding can be measured. Five pigeons were trained to peck at a lighted contact switch, a pigeon key, to obtain food reward. The timing of the pecks and the food reward signals were recorded in a log file using standard equipment. The Kinect-based system, called BehaviorWatch, also measured the pecking and feeding behavior and generated a different log file. For key pecking, BehaviorWatch had an average sensitivity of 95 % and a precision of 91 %, which were very similar to the pecking measurements from the standard equipment. For detecting feeding activity, BehaviorWatch had a sensitivity of 95 % and a precision of 97 %. These results allow us to demonstrate that an advantage of the Kinect-based approach is that it can also be reliably used to measure activity other than key pecking.",1
2,2,"Recording pigeons’ key pecking using a contact switch, a pigeon key, is common in studying animal learning and behavior. Such measurements only record whether or not a peck occurred at a specific time and at a general location. More recently, touch sensitive screens, which can provide a precise location of the peck, have become increasingly popular. Additional information could be collected if a video were used, including:",1
2,3,"1. the initiation time, speed of motion, head pose at start and end of pecks, pecks on the wall adjacent to key, and pecks initiated but not completed.2. the global body and head pose: head position and orientation, body position, and foot position. 3. the subject behaviors relative to the stimulus area, turning around, flapping wings, and so forth.",1
2,4,"In addition, the noncontact nature of the sensing reduces issues of mechanical wear and allows sensing at a wide variety of locations that do not have specific instrumentation, which provides flexibility for experimental design. Although touch screens may reduce the issue of mechanical wear, there is not enough experience to claim that other issues related to wear would not occur, such as visible damage to the screen. Additional issues with touch screens are the cost of the screen and that no commercially available software is specifically written for controlling learning experiments. Along with developing the programs using, for example, Visual Basic or MATLAB, investigators must integrate interface equipment for delivering reinforcers, providing feedback clicks for pecking etc. Finally, pigeon keys and touch screen can only detect pecks and various investigators have been interested in studying other naturally occurring behaviors, such as in a behavior systems approach (Silva & Timberlake, 2005), or reinforcing topographically different responses like treadle pressing (Wheatley & Engberg, 1978) or head bobbing (Ortega, Stoppa, Güntürkün, & Troje 2013).",1
2,5,"Although it might seem that a video would provide data for counting behavior, it is extremely difficult to automate the extraction of this information using a standard video camera. Figure 1 illustrates the problem. When an image of a scene is viewed, through lens optics, on the imaging chip of a video camera, the depth information of the objects in the scene is lost. The intensity of each pixel in the image is created by light arriving along a single ray (e.g., the ray from the top of the head of the pigeon in Fig. 1), and there is no easy way to determine at which distance along that line the object rests. One approach is to use a carefully calibrated camera (Zhang, 2000). Careful measurements are made of the position and pose of the camera (called the extrinsic parameters), the lens optics, and the spatial relationship of the lens to the imaging chip (the intrinsic parameters). The quality of calibration of the extrinsic and intrinsic parameters heavily influences any measurements made using the camera. Loose animal hair or “pigeon dust” may affect these calibrations. Thus, calibrations may need to be repeated frequently.",1
2,6,"Nonetheless, some use has been made of automated video information extraction from a video camera: Pigeon behaviors, such as the “head-bobbing” and “foot-plant” components of courtship, have been monitored from motion capture data and automatic image recognition criteria identified using a conditional restricted Boltzmann machine by Zeiler, Taylor, Troje, and Hinton (2009). Image analysis has also been used to classify avian observations according to species (Song et al., 2008). However, it would be challenging to use image analysis to track the head and beak motions with sufficient accuracy and also be able to detect gross body motions within the full area of an experimental enclosure. Gomez-Martin, Partoune, Stephens, and Louis (2012) described a comprehensive computer vision package, Sensory Orientation Software (SOS), for automated measurements of animal posture and movement. However, they commented on the sensitivity to disturbances of camera pose during measurements. A more general and less expensive solution has recently been developed. The Kinect1 sensor (Freedman, Shpunt, Machline, & Arieli, 2008) is a combination of camera and distance sensor that generates both visual image and a depth image. The Kinect is a structured infrared (IR) distance sensor combined with a camera in such a way that the distance and visual images are registered—that is, that the pixel coordinate system relationship between the two images is known.",1
2,7,"A visual image can be represented by an intensity map I, where I(u, v) is the image intensity at row u and column v of the image. A depth image, obtained from the IR range sensor, can be represented by a map D, where D(u, v) is the depth (i.e., the distance along the ray in Fig. 1 to the closest object) of the object responsible for the intensity reading I(u, v). The Kinect depth image is 320 pixels wide by 240 pixels high, with a field of view of 57.8°. A point cloud, a set of 3-D points, can be generated from D(u, v) by using the camera focal length to project u and v into x and y scene coordinates, with z = D(u, v). The Kinect is an inexpensive and general-purpose sensor currently available for the consumer video-gaming field (Suma, Lange, Rizzo, Krum, & Bolas, 2011). Because of its popularity in the consumer game market, there is software support for the sensor both from Microsoft2 and in the open-source community (OpenNI3 and OpenKinect4 ). The sensor is designed for use in indoor, unstructured settings and can easily be mounted to a large experimental enclosure. That software support includes software for generating and tracking human body features using a skeletal model: a 3-D stick-figure model that represents the locations of the subject’s torso and limbs. Such skeletal models have been a topic of research for some time (Moeslund & Granum, 2001). Extracting skeletal models from point clouds generated by distance sensors such as the Kinect has been described by Sharf, Lewiner, Shamir, and Kobbelt (2007) and Suma et al. (2011), among others.",1
2,8,"In this article, we present a flexible method for using the Kinect for Windows sensor to extract 3-D body information, at video frame rates (i.e., at the same rate that images are taken in the video sequence), of a pigeon viewed within an experimental enclosure. The method is embodied in a program, BehaviorWatch. No special care need be taken, other than to approximately center the subject in the field of view and place the closest edge of the animal chamber no closer than 400 mm (300 mm, if the Kinect is equipped with a Nyko wide-angle lens; Draelos, 2012). The maximum distance to the farthest object should be less than 3.5 m. A simple skeletal model is used to represent key body locations. We go on to present an approach to estimate pecking behavior on the basis of the motion of these body measurements. Identifying “treadle pressing” or “head bobbing” could use a similar approach. Finally, we present a comparison of our approach with a standard contact-switch-based approach, with which we show that the approach produces measurements for key pecking that are very similar to the output of a standard contact-switch-based system. Additionally, we show that we can detect feeding behavior also, and that the timing of this detection matches very closely with time when the signal is sent to provide a food reward.",1
2,9,"It is well documented that mealtimes are anxiety provoking for patients with Anorexia Nervosa (AN) [1]. Eating and weight gain is associated with feelings of fear and anxiety amongst AN patients [2, 3]. Psychological and physical discomfort are often ex perienced after meals when patients can become preoccupied with thoughts of purging or feelings of guilt [4]. Support from staff or family during meal times is acknowledged as an important therapeutic activity for decreasing meal-related distress [5–8]. Supported mealtimes are typically facilitated by in patient staff but there is little research into effective interventions for reducing meal related anxiety in a ward setting",1
2,10,"Participation in music therapy can improve the quality of life, interpersonal relationships and social skills of people with mental illness [9–11]. Music therapy can help promote self-determination and collaboration with patients through focusing on strengths and resource-oriented practice [12]. Literature supports the relationship between music therapy practice in mental health recovery and emphasis on empower ment and patient led processes [12–14]. Use of music therapy to promote feelings of empowerment and equality are arguably expressly important in inpatient mental health settings that may otherwise provide little opportunity for self-determination [15, 16].",1
2,11,"Music therapy may offer motivation for recovery from eating disorders, distraction from negative thoughts and feelings, a sense of autonomy and creative ex pression [17–19]. Case studies derived from patient experiences have described feelings of renewed self confidence and empowerment through participation in music therapy [20]. In a qualitative study exploring the perceptions of group singing from eight people with eating disorders, participants reported several emotional and cognitive benefits including mental engagement and opportunity to distance themselves from life’s problems [21]. Despite these reports of positive experiences during music therapy, there is no published research examining the role of music therapy during sup ported meal times. This study aimed to address this gap by evaluating post-meal music therapy amongst a group of inpatients with AN.",1
2,12,"The study was conducted in a specialist five bed inpatient eating disorders program situated within an acute psychiatric unit. The program primarily caters for adults with severe anorexia nervosa who have been unable to recover through outpatient treatment. The average age of patients admitted to the inpatient pro gram is 22 years of age, predominately young women. A collaborative conceptualisation-based approach [22] is adopted which is patient-centred and focuses on indivi dualised treatment. The therapy program includes a sup ported meal time (meal support therapy) that involves a period of post meal distress tolerance and support pro vided by a team member every lunchtime.",1
2,13,"The aim of this study was to evaluate post-meal music therapy amongst a group of inpatients with AN. The study aimed to both determine if participation in music therapy decreased subjective distress during post-meal support and to understand how participants described their experiences of music therapy during this time. The interest in both understanding and measuring post-meal music therapy suggested a mixed method approach, using different modes of self-reporting on the phe nomenon [23]. An embedded mixed methods design was adopted where quantitative and qualitative data were collected within a quasi-experimental design [23]. The qualitative part of the study is not included in this article due to the authors’ desire to conduct a deeper ex ploration of the participants’ rich descriptions of their experience. The quantitative element which is presented in this article, was a non-randomised pre-post design comparing music therapy with treatment as usual fol lowing mealtime. This was considered a fitting design because the intention of the study was to evaluate an existing music therapy program and therefore acted as a pilot study, in an attempt to give indicators of the size of the effect of the clinical intervention and to check the feasibility for a possible larger scale study.",1
2,14,Quantitative data was collected using the Subjective Units of Distress (SUDS) scale which was administered pre and post each intervention and control condition. Participants attended the music therapy intervention twice per week for the duration of their admission. At all other times during the week participants continued with their usual ward program. This project was ap proved by Human Research Ethics Committee at Austin Health (HREC/14/Austin/75).,1
2,15,"Adults admitted to the eating disorders program within the acute psychiatric unit, Mental Health Clinical Service Unit at Austin Health were invited to participate in the study. The primary researcher (Bibb) distributed the plain language statement and consent form to patients upon their admission to hospital. Informed consent to participate in the study was obtained from 18 of a total of 32 patients. During this time 89 intervention and 84 control sessions were recorded.",1
2,16,"Participants were trained in the use of the Subjective Units of Distress Scale (SUDS) which is a self-report tool measuring the subjective intensity of distress or anxiety currently experienced by a participant [24]. Although originally used with a 0 to 100 rating scale, more recently scales of 0 to 10 have been adapted, with par ticipants rating their anxiety on a scale ranging from ‘0– totally relaxed’ to ‘10– highest distress/anxiety/ fear/discomfort you have ever felt.’ Avisualanaloguescale in the form of a ‘feelings thermometer’ aided in the visual representation of the SUDS ratings (see Fig. 1)",1
2,17,"Two one-hour music therapy group sessions were held directly after lunch each week. The group was facili tated by a university trained Registered Music Therapist (first author; RMT) in a meeting room on the psychiatric unit. During music therapy sessions participants were encouraged to participate in singing and listening to songs, talking about and sharing music with others and writing songs together. The goal for the group was focused on offering participants a distraction and opportunity to practice coping skills through music. A humanistic approach [26] was adopted where par ticipants were invited to collaborate together on the process of each session. The principles of humanism suggest that “all persons have innate capabilities for actualising their own unique potentials for health and wellbeing” (p.148). Thus, the music therapist main tained a perspective of unconditional positive regard instead of a more directive approach common to cog nitive behavioural therapy groups in inpatient eating disorder programs. Group members were encouraged to listen to one another and engage in discussion about song lyrics and their preferred musical tastes. Other topics also emerged in discussions within the group which were often related to eating disorder recovery.",1
2,18,"Structured post meal support therapy acted as a control condition (treatment as usual) involving a one hour group session after mealtime and occurred on the remaining three days of the working week. These ses sions included discussion of feelings, encouragement to focus on achieving the goals of admission and group ac tivities such as playing games or art activities. Nursing and allied health staff facilitated post meal support therapy on a rotating roster.",1
2,19,The statistical software SPSS was used to analyse the data. Mean differences between pre and post scores and the standard deviation were calculated for both interven tion and control group data. An unpaired t-test was then performed to explore statistical differences between the mean differences between the music therapy and control interventions.,1
2,20,"A total of 18 patients participated in the study, including 17 females and one male. Participant’s ages ranged be tween 20 and 58 years old. Length of admission ranged between 21 and 90 days. The 18 participants, attended 173 sessions in total for the music therapy (n=89) and the control conditions (n =84). Results can be seen in Table 1. The mean pre-test score for the intervention group was 8 and the mean post-test score was 5.6. The mean pre-test score for the control group was 8.1 and post-test was 7.1. Mean pre-post test difference for the intervention condition was 2.4 integers on the scale with a standard deviation of 1.9 integers. The mean pre-post test difference for the control condition was 0.93 inte gers on the scale with a standard deviation of 1.7 inte gers.",1
2,21,"An ANOVA score of f=28.5 and a highly statistically significant (p =< 0.0001) difference be tween the control and intervention conditions was found. The combined mean pre-test score for both con trol and intervention conditions was higher (8.1) than the mean post-test score for both conditions (6.3), meaning that across all 173 occasions participants rated their anxiety higher prior to participation in either con dition, than afterwards. Additionally, there was a statisti cally significant difference (p =< 0.0001) between the pre-test scores and post-test scores of all combined 173 occasions.",1
2,22,"The aim of this study was to compare the levels of dis tress and anxiety of patients with AN pre and post group music therapy provided after meals, with standard post meal support therapy. The results are strongly positive and offer support for the use of music therapy in AN inpatient care. Participants in both conditions reported decreased anxiety post-session compared with straight after lunch (pre-session). This supports previous re search suggesting that meal related distress and anxiety is a great concern for patients with AN [1]. Participants’ levels of anxiety significantly decreased after both condi tions which also aligns with previous research that sug gests therapist facilitated support after meals is helpful for patients with AN [5–8].",1
2,23,"Results from the current study also suggest that group music therapy is a more effective intervention for reducing meal related anxiety than standard post meal support therapy in an inpatient setting. The average age of eating disorder patients admitted to the inpatient pro gram is 22 years of age. It is well known that music is an engaging activity for young people and is a motivating factor for participating in therapy [27]. It is likely that participants considered music therapy as a non threatening and familiar activity in an often confronting medical setting [15, 16]. Participation in music therapy may have acted as a “cognitive divergence” (p. 111) for patients, allowing time for the body to digest food while the mind was attending to something else that was engaging for them [17].",1
2,24,"AN is associated with emotion avoidance and dys phoria [28]. Patients report that AN helps them to avoid and control their emotions [29, 30]. Participation in music therapy after meal times is a way for distressing emotions to be experienced through the music. Using music therapy as a distress tolerance technique empha sises the therapy that occurs during the music rather than through discussion [27]. In this instance, the ex perience of musical process is the therapy [31]. As such, there are broader implications for the use of music ther apy as an alternate coping technique for patients who are likely to avoid distressing emotions and often report feeling emotionally ‘numb’ [32].",1
2,25,"Participants’ anxiety decreased significantly pre-post the music therapy group compared with standard post meal support therapy. This is important knowledge for inpatient eating disorder programs. Previously it was known that support after mealtime was helpful but the kind of interventions that were effective in reducing anxiety during this time were not [5]. Incorporating music therapy into inpatient meal support programs can offer patients with AN an alternative distress tolerance technique, which they can translate into their external environments post discharge [33]. Previous music ther apy research has focused on participants’ experiences of music therapy sessions during their recovery from AN [17–19]. It is important to consider the heightened dis tress of patients with AN after meal times and the role music therapy can play in reducing anxiety during this time. The current study is the first to use music therapy post meal-time and offers support for further research into this area.",1
2,26,"The current study has positive implications for the use of music therapy in reducing meal related anxiety for patients with AN. However, the findings may be limited due to a number of factors. First, the research design was quasi-experimental and did not randomise participants to each condition. The same participants contributed to sev eral occasions (both intervention and control conditions) during their admission which meant randomisation was impossible. Second, participants were recruited from one site which may effect the generalisabiltiy of the results. Third, the same music therapist facilitated the inter vention group condition while a variety of therapists (allied health and nursing staff) facilitated the control group condition. The researchers attempted to reduce this potential bias by collecting a large number of occasions (173) over the 36 week period. A larger number of partici pants, randomisation to control and intervention condi tions and recruitment from different hospital sites would benefit future research in this area.",1
3,1,"The present study examined the relationship be tween attentional focus, perceived hole size, and radial putting error in a golf task. Twenty-five experienced golfers were asked to produce size estimates immediately after completing a putt. To assess their attentional focus, one of two secondary tasks (chosen randomly) was performed next. In the Hole task, participants were asked to indicate whether a sound played during their putting stroke was presented to the left or right of the hole. In the Club task, they were asked to indicate whether the sound occurred closer to the beginning or end of their back swing. Participants completed three phases: a no pressure pre test, a pressure phase, and a no pressure posttest. There were substantial individual differences in the effects of pressure on putting kinematics: 11 golfers (designated the Choke group) showed significant changes in kinematic variables and heart rate, and 14 golfers (designated the Clutch group) showed no significant change in these variables. For the Choke group, putting error and the accuracy on the Club task significantly increased during the pressure phase while size estimates and accuracy on the Hole task significantly decreased. There were no significant changes in any of these variables for the Clutch group. These findings provide further evidence for the atten tional accentuation hypothesis of action-specific effects.",1
3,2,"Recent research has demonstrated repeatedly that perfor mance of a skill that involves acting on a goal object (e.g., a ball to be hit) can influence ones perceptual judgments of that object. For example, Witt and Proffitt (2005) reported that softball players with a higher batting average in a recently completed set of games judge the balltobelargerthandoplayers with a lower average. Similar effects also have been reported for perceptual judgments of hole size in golf (Ca?al-Bruland et al. 2011;Wittetal.2008), upright size in field goal kicking in football (Witt and Dorsch 2009), target size in dart throwing (Ca?al-Bruland et al. 2010;Wespetal.2004), target size in archery (Lee et al. 2012), and estimates of runway size in avia tion (Gray et al. 2014). These Baction-specific effects are all examples of an individual’s ability to interact with goal objects in the environment (as indexed by their performance success) changing the way in which these objects are perceptually judged. These findings are consistent with the theoretical viewpoint that perception directly specifies the relationship between the per ceiver and the environment rather than solely being based on the physical properties of objects (Gibson 1950; Proffitt 2006).",1
3,3,"Despite the growing body of research demonstrating action-specific effects on perception, the underlying mecha nisms havenot beenclearly identified. Alternative accounts to the embodied perception explanation described above have been put forward including ones based on experimental de mands (Durgin et al. 2009) and memory effects (Cooper et al. 2012). In the present study, we focus on an additional alterna tive explanation for action-specific effects: namely attentional accentuation. Ca?al-Bruland and van der Kamp (2009)have proposed that these action-specific effects are consistent with the perceptual accentuation hypothesis (Bruner 1957), which claims that when a person intends to act on object and directs their attention to it, the task-relevant object becomes accentu ated so that it stands out from other task-irrelevant objects (Balcetis and Dunning 2010). Evidence to support this hypoth esis comes from a recent study by Ca?al-Bruland et al. (2011) in which it was demonstrated that action-specific changes in the perceived size of a golf hole do not occur when a golfer is prevented from focusing their attention on the hole (because it was occluded) or when golfers are required to shift attention between an intermediate object and the target object (due to a requirement to hit a ball through a gate on its way to the hole).",1
3,4,"Further support for this hypothesis comes from research that has examined action-specific perception under conditions of high anxiety (Ca?al-Bruland et al. 2010). In this study, participants threw darts at a target and produced a judgment of target size. Under conditions of low anxiety (throwing while standing on the ground), there was a significant positive correlation between judged size and throwing performance, whereas under conditions of high anxiety (throwing while suspended above the ground), there was no correlation. The authors argued that the lack of effect in the high anxiety con dition was due to the fact that the performer’s attention was drawn away from the target (and thus accentuation did not occur). A shift in attention of this type is consistent with both of the main theories of what is thought to occur to a performer under conditions of high anxiety/pressure: distraction theory and self-monitoring (reviewed in Beilock and Gray 2007).",1
3,5,"The goal of the present study was to further investigate the role of attention in action-specific perception by expanding on the anxi ety study conducted by Ca?al-Bruland et al. (2010). In this pre vious study, only perceived size and performance outcomes were measured. Thus, there was no direct evidence that the change in action-specific perception was due to a shift in the performer’s attentional focus. However, previous research has demonstrated direct links between performance success, attentional focus, and movement kinematics under pressure conditions. For example, using a baseball batting task with college players, Gray (2004) found that a combination of competitive and evaluation pressure resulted in poorer batting performance, an increase in skill focused (internal) attention (i.e., batters performed better in a sec ondary task that involved judging the direction of bat movement), and a significant change in kinematics (specifically, an increased amount of variability in the timing of the different stages of their swing).",1
3,6,"Similarly, in golf putting an increase in skill-focused at tention (produced either by pressure or the introduction of a sec ondary task that involves making judgments about the movement of the putter) can produce both an increase in putting error and a change in putting kinematics (Beilock and Gray 2012;Gray, Allsop & Williams, 2013). In this case, the kinematic changes were an increase in club-ball impact velocity, a decrease in the time to peak speed, and a change in the relationship between downswing amplitude and putting distance. It is notable that all of these kinematic characteristics are typical of novice golfers (Delay, et al. 1997). See also Lohse et al. (2010) and Cooke et al. (2010) for similar findings. To our knowledge, no previous studies have examined how these changes in movement kinemat ics are related to the perceived size of the target object. Furthermore, although links between attentional focus and per ceived size have been inferred through looking at fixation patterns (Wood et al. 2013;Grayetal.2014), to our knowledge no previ ous studies have directly manipulated attentional focus and mea sured the effect on perceived size.",1
3,7,"In the present study, we sought to investigate the link be tween perceived size, performance outcomes, attentional focus, and movement kinematics in a golf putting task by measuring each of these variables and assessing how they change under pressure. Specifically, in conjunction with performing a putting task, participants were asked to estimate the size of the golf hole under nonpressure pre- and posttests and a pressure condition. The pressure condition involved a combination of competitive (monetary incentive) and evaluative (performance recorded and results distributed) pressure. The attentional probe method ology was used to assess the extent to which participants were focusing their attention on the hole or the movement of their club-head (Gray 2004; Gray and Allsop 2013). Finally, time to peak speed (TTPS)wasusedastheprimarykinematicmeasure, because it has been shown to be related to skill level in golf and be influenced by pressure (Beilock and Gray 2012).",1
3,8,"A total of 25 (17M, 8F) right-handed, experienced golfers enrolled from the School of Sport, Exercise & Rehabilitation Science program atthe University ofBirmingham participated in the study. Their mean age, mean handicap, and mean number of years competitive playing experience were 20.1 (SE =0.4) years, 7.3 (SE = 0.6) strokes, and 6.2 (SE = 0.8) years respec tively. Ethical approval was granted by the Science, Technology, Mathematics and Engineering (STEM) Ethical Review Committee at The University of Birmingham.",1
3,9,"AMcGregorM220, 35-in (88.9 cm), right-handed putter and Wilson Ultra golf balls (size 1.68 in [4.27 cm]) were used. The artificial putting mat had a width of 1.4 m and a length of 4.6 m.The putting taskrequired participants to putt a golf ball towards a 16.5-cm diameter red circle placed on the surface of the green. Participants were instructed to Bstop the ball as close as possible to the centre of the target circle. All putts were made from a distance of 2.5 m. The x/y/z location and angle of the putter head was recorded by mounting a Fastrak (Polhemus) position tracker sensor weighing 10 g on the back side of the putter.",1
3,10,"Estimates of perceived hole size were obtained using the method used by Wood et al. (2013)byaskingparticipantsto draw(using a computermouse)life-sized replicas of the target circle on a monitor using PowerPoint presentation software. The monitor was positioned perpendicular to the target circle at a distance equal to the putting distance (2.5 m). Auditory stimuli for the attentional probes were presented via two speakers (Logitech Model X140) placed at the end of the putting surface at a distance of 3.5 m from the participant. The speakers were placed 10 cm on either side of the hole, a distance determined in pilot experiments.",1
3,11,"Heart rate served as an index of sympathetic nervous sys tem activity and was measured using a heart rate receiver unit (Polar Electro S625X, Polar CIC Inc., USA), which was con nected to a transmitter (Polar Electro coded 31, Polar CIC Inc.) with moistened electrodes positioned across the lower mid thorax. Average heart rate was calculated for the different phases described below.",1
3,12,"The experiment was divided into four phases all completed within one 1.5-hour session: practice, pretest, pressure, and posttest. Participants were given 10-minute breaks between each phase. In all test phases, participants saw the final posi tion of the ball on the green.",1
3,13,"During this phase, participants took 20 putts under normal, single-task conditions. These trials allowed par ticipants to become comfortable with the sensor mounted on the back of the putter as well as to familiarize themselves with our putting task. They were not required to perform the hole size estimate during this phase. Following each putt, the ex perimenter measured the radial distance between the center of the target and the final position of the ball (in cm).",1
3,14,"Position tracker data from these practice trials was used to measure the timing of the putting stroke for each participant (Beilock and Gray 2012). This timing information was later used to control stimulus presentation for one of the secondary tasks as described below. For each putting stroke, we deter mined the instant in time when the putter began moving (STARTt) and the instant in time when the top of the back stroke was reached (BACKt). We then calculated the mean values of these variables for each participant.",1
3,15,"During this phase, the hole size estimation task was first explained to each participant and was practiced five times (without putting). The two secondary tasks were next explained to the participant and practiced five times each (without making the hole size judgment). Both secondary tasks involved the presentation of auditory cues, which were pure tones witha frequency of500Hzanddurationof150ms. The tones were presented via one of the two speakers placed on either side of the hole. Position tracker data taken from the practice trials was used to present the cue at a random time during the participant’s backswing, i.e., interval between STARTt and BACKt. If the tone was not presented in this interval or occurred at the midpoint of the backswing, the data from that trial was discarded and the trial was re-run. The two secondary tasks were modelled after Beilock and Gray (2012) and were as follows:",1
3,16,"Hole task For this task, participants were required to make a twoalternative forced choice (2AFC) judgmentabout whether the tone presented was playedfromthe speaker tothe left or to the right or the hole. Responses were made verbally (by say ing Bleft or Bright) after the putt was complete (see below).",1
3,17,"Club task For this task, participants were required to make a 2AFC judgment about whether the tone occurred close to the start or the end or their backswing by saying Bstart or Bend after the putting stroke was complete. The tone was presented in the backswing, because our previous research has shown that this is the phase of the putting stroke that is most sensitive to attentional manipulations and golfers can perform this task with a relatively high degree of accuracy (Beilock and Gray 2012).",1
3,18,"After all of the practice trials were completed, participants completed 30 putts. For each putt, participants first completed the stroke and observed where the ball stopped. After each putt, they were then asked to perform the hole size estimation as described above. Finally, they were given a verbal prompt by the experimenter as to which secondary task response was required. The 30 putts were divided into 12 putts with a Hole Task prompt, 12 putts with a Club Task prompt, and 6 putts with a BNo Task prompt for which no secondary task re sponse was required. This ratio of prompt types was similar to that used in our previous study (Beilock and Gray 2012). The order of these prompts was chosen randomly (without replacement) on each trial for each participant. The speaker side on which the tone was presented also was chosen ran domly. Participants were not given any feedback about their hole estimation or the secondary task response.",1
3,19,"Note that we chose to have participants complete the sec ondary task after they made the hole size estimate to avoid the possibility that the former would influence the latter. The sec ondary task prompts were given after the putt was complete and 20 % of trials involved no secondary task judgment with the goal of measuring where the participant’s attention was focused rather than directing it to a specific location via the secondary task. Because the participant did not know before or during the putt whether they would be asked to make the hole or club judgment, there was no advantage to shifting their attentional focus to one or the other location (Beilock and Gray 2012;Gray 2004; Gray and Allsop 2013). These two secondary tasks were chosen to allow for direct comparison with our previous research. How they might directly interact with the hole size estimation task is discussed in more detail below.",1
3,20,"Pressure phase This phase was identical to the pretest phase except that participants were given instructions prior to put ting designed to increase competitive and evaluation pressure. Before beginning putting, participants read the following script:",1
3,21,"We’re now moving into a competition phase. Your ob jective in the competition is still to putt the ball as close to the marker as possible. However, throughout the ex periment you have so far accumulated 180 points. For every putt that finishes more than 5 cm from the marker, you will lose 10 points. Prize money of ?50, ?25, and ?10 is up for grabs, for 1st, 2nd, and 3rd place. How many points you manage to hold on to determines your position on the leader board. All the results will be e mailed to everyone who takes part in the study and will be displayed on the notice board in the school atrium. So, everyone will know how everyone else performs. No pressure then Bsaid sarcastically…good luck!",1
3,22,"Note, this procedure is identical to that used in our previous study on the effects of pressure on golf perfor mance and has proven to produce significant pressure effects (Gray et al. 2013).",1
3,23,The Immediate Anxiety Measures Scale (IAMS; Thomas et al. 2002) was used to assess participants’ intensity of cognitive and somatic anxiety. The questionnaire was com posed of two items measuring the extent to which partici pants felt cognitively anxious (I was cognitively anxious) and somatically anxious (I was somatically anxious). Responses were made on a 7-point Likert-type scale rang ing from 1 (not at all)to7(extremely). This scale was completed at the end of each phase of the experiment.,1
3,24,"Manipulation check To determine to what extent our pres sure manipulation had the desired effect, the cognitive and somatic anxiety ratings for the IAMS and the heart rate data were subjected to separate one-way repeated measures ANOVAwith phase (pretest, pressure, posttest) as the inde pendent variable",1
3,25,"Task performance There were four main dependent vari ables that were analyzed: mean radial error (MRE), mean perceived hole size (MPS), percentage correct for the Hole secondary task (%Hole), and percentage correct for the Club secondary task (%Club). Each of these variables was first analyzed using separate one-way repeated measures ANOVAwith phase as the independent variable.",1
3,26,"Figure 2 shows the MRE for the two groups across the differ ent phases of the experiment. These data were analyzed using a 2×3mixedANOVAwithgroup(Choke,Clutch) and phase as factors. This analysis revealed significant main effect of phase [F(2,46) = 22.4, p<0.001, ηp2=0.49] and a significant group x phase interaction [F(2,46)=3.4,p=0.04,ηp2=0.13].Post-hoc t tests revealed that MRE was significantly higher in the pressure phase for Choke group: t(23)=2.79,p=0.01.All other comparisons were not significant.",1
3,27,"Despite the abundant evidence demonstrating that the action capability of a performer can influence the perceived size of the object(s) that they are acting on, to date there is no clear agreement as to which specific mechanism underlies these effects (see Firestone 2013 vs. Proffitt 2013). One key ques tion that has remained unanswered is what the role is of atten tion in these effects? Do objects look bigger to performers of higher skill level (or performers that have recently been suc cessful), because they are better able to maintain their focus of attention on the target object and this attention serves to ac centuate perception? As discussed above, although previous studies are consistent with the proposal that action-specific effects are mediated by attention (Ca?al-Bruland and van der Kamp2009;Ca?al-Brulandetal.2011;Gray2013;Grayetal. 2014), a direct link has yet to be established.",1
3,28,"The primary goal of the present study was to further investigate this issue by taking advantage of an effect that has been reported in several previous studies on skilled motor performance (reviewed in Beilock andGray2007),namelychokingunderpressure.That is, the introduction of performance pressure often leads to an inward shift in a performer’s focus of attention. By assessing perceived hole size, performance outcome, and attentional focus in a golf putting task, we sought to es tablish a more direct link between these variables. A sec ondary goal of the present study was to investigate the relationship between movement kinematics and perceived target size. The vast majority of studies in this area have only looked at performance outcomes (Witt and Proffitt 2005; Ca?al-Bruland and van der Kamp 2009; Lee et al. 2012; Witt et al. 2008). It hence remained to be determined whether changestothewayinwhichaperformerisexecutinganaction are associated with changes in perceived size of the goal object.",1
3,29,"Consistent with previous research, the addition of pressure resulted in a significant change in the movement kinematics for some (but not all) golfers in the present study (Gray et al. 2013). Specifically, for 11 of25golfers, there was a significant decrease in TTPS (and increase in VI). A shorter TTPS typi cally occurs when a golfer has a very symmetrical putting stroke such that the maximum velocity occurs exactly at the point of ball-club contact: a technique commonly used by novice golfers (Delay et al. 1997). Expert golfers, on the other hand, typically use an asymmetrical putting stroke for which the club-head is still accelerating at the point of contact with the ball, and thus, TTPS (measured relative to start of the stroke) occurs a bit later (Delay et al. 1997).",1
3,30,"The advantage of using an asymmetric putting stroke with a longer TTPS is that the ball maintains contact with the club-head for a short period time after the moment of initial impact which results in the ball rolling more smoothly across the green (Pelz 2000). Therefore, the decrease in TTPS for the golfers in the Choke group in the present study is consistent with a regression to an earlier stage of skill acquisition as proposed by reinvestment theories of choking under pressure (Masters 1992). This idea is further supported by the finding (Fig. 2) that MRE was significantly higher in the pressure phase for the Choke group.",1
3,31,"Also consistent with previous research, this change in put ting kinematics in the pressure phase was associated with an inward shift of attentional focus, i.e., towards skill execution and away from the external environment (Baumeister 1984; Beilock and Gray 2012). As shown in Fig. 4, golfers in the Choke group had a significant decrease in accuracy for the external, secondary task that involved making a judgment relative to the hole location and a significant increase in the accuracy of the internal, skill-focused secondary task that in volved making a judgment about club movement. Together, these findings provide further support for explicit monitoring (and related) theories of choking under pressure in which it is proposed that pressure serves to cause inward shift in attention towards skill execution resulting a perceptual-motor control strategy typical of an earlier stage of skill acquisition (Baumeister 1984).",1
3,32,"There were some important design choices in the present study that could have influenced the pattern of results and should be examined further in future research. First, partici pants were allowed to see the final position of the ball after each putt. As proposed by Proffitt and Linkenauger (2013), this knowledge of results could have provided a scaling metric for the perceived hole size judgments (i.e., the size estimate was related to the variability of final ball locations). However, although there is some indirect evidence in support of this hypothesis (Ca?al-Bruland et al. 2012), in a more recent study we have shown that when performance variability was directly manipulated perceived target size remained stable independent of performance outcome variability (Foerster et al. 2015). Regardless, it will be important for future studies to examine whether the effects observed in the present study occur when performers are not given knowledge of results as has been done in previous studies (Wood et al. 2013).",1
3,33,"Another design-related issue concerns the timing of the secondary task. In the present study, the secondary taskstimuli used to assess attentional focus were presented during the putting stroke to allow for direct comparison with our previ ous research (Beilock and Gray 2012). Therefore, perfor mance on these tasks could not be used to assess directly the attentional focus before the initiation of the putt. It is possible that the judged size of the target was determined by the atten tional focus of the performer before movement initiation, which could have potentially been different than the focus during the stroke. However, we argue that this was likely not the case. First, previous research on golfer’s eye movements (which can be used as an in direct measure of attentional focus) has shown that fixation patterns are similar before, during, and after the putting stroke (Vickers 1992). Second, we have shown previously by using an analogous secondary task in a baseball batting experiment that attentional shifts that are induced during the movement can spill over into the be havior that occurs before and after movement (Gray 2006).",1
3,34,"In conclusion, the present study helps to advance under standing of the mechanisms underlying action-specific effects on perception. We provide direct evidence linking the per ceived size of a target with extent to which an actor focuses their attention on that object—a finding that supports the at tentional accentuation hypothesis. Finally, we show how the relationship between attentional focus and perceived size is accompanied by changes in putting kinematics.",1
4,1,"A basic assumption of Signal Detection Theory is that decisions are made on the basis of likelihood ratios. In a preceding paper, Glanzer, Hilford, and Maloney (Psychonomic Bulletin & Review, 16, 431–455, 2009) showed that the likelihood ratio assumption implies that three regularities will occur in recognition memory: (1) the Mirror Effect, (2) the Variance Effect, (3) the normalized Receiver Operating Characteristic (z-ROC) Length Effect. The paper offered formal proofs and computational demonstrations that decisions based on likelihood ratios produce the three regularities. A survey of data based on group ROCs from 36 studies validated the likelihood ratio assumption by showing that its three implied regularities are ubiquitous. The study noted, however, that bias, another basic factor in Signal Detection Theory, can obscure the Mirror Effect. In this paper we examine how bias affects the regularities at the theoretical level. The theoretical analysis shows: (1) how bias obscures the Mirror Effect, not the other two regularities, and (2) four ways to counter that obscuring. We then report the results of five experiments that support the theoretical analysis. The analyses and the experimental results also demonstrate: (1) that the three regularities govern individual, as well as group, performance, (2) alternative explanations of the regularities are ruled out, and (3) that Signal Detection Theory, correctly applied, gives a simple and unified explanation of recognition memory data",1
4,2,"In a preceding paper, Glanzer et al. (2009) demonstrated that recognition memory performance is consistent with normative Signal Detection Theory (Green & Swets, 1966/1974)1 based on likelihood ratios (LR). The demonstration consisted of three steps:",1
4,3,"Formal proofs that the LR assumption implies three regularities. These regularities, defined shortly, are the Mirror Effect, the Variance Effect, and the normalized Receiver Operating Characteristic (z-ROC) Length Effect, (2) computed examples showing how LR decisions generate the regularities, and (3) a survey of recognition memory data establishing the ubiquity of the three regularities.",1
4,4,"The 2009 paper also briefly discussed two other topics: how bias can obscure the Mirror Effect and also how that obscuring can be countered. Those two topics are developed in detail here. We show that the Mirror Effect – measured in the usual way – is obscured by bias. We then counter the bias effect in four different ways. (1) by using a more informative index of the Mirror Effect, (2) by canceling the bias with a pay-off arrangement, (3) by using a between-list design, and (4) by increasing the difference in accuracy between the two experimental conditions (familiar vs. unfamiliar names).",1
4,5,"With respect to the survey in Glanzer et al. (2009), the following objection can be made. The surveyed data consisted of pooled group data. It is possible that group data give a different picture of the underlying processes than do individual data. The possible disagreement of group and individual data is discussed at length by Estes (1956) and Estes and Maddox (2005). The results reported here answer that objection by demonstrating that the three regularities govern individuals’ performance.",1
4,6,"In a recognition memory experiment, participants are shown a study list of items and are later shown a test list consisting of items from the first list (“old”) and items which were not (“new”). They are then asked to judge whether each item is “old” (O) or “new” (N), a YES-NO task. Or they are asked to rate their confidence that each item is “old” or “new”",1
4,7,"There are many experiments in which individuals are presented with two different kinds of items (e.g., high vs. low frequency words) or two different study conditions (e.g., single vs. repeated presentation) that produce a difference in accuracy. These two-condition experiments are important because they show three regularities that are produced by LR decisions: (1) the Mirror Effect, (2) the Variance Effect, and (3) the z-ROC Length Effect",1
4,8,"When there are two sets of items or conditions in a recognition test that produce a difference in accuracy and the decisions are based on LR, then the superior condition (S) will give better recognition of old items as old and also better recognition of new items as new. In a yes/no recognition test the effect is seen in the mirror symmetric pattern of hits (H) and false alarms (FA):",1
4,9,"When there are two sets of items or conditions in a recognition test that produce a difference in accuracy, decisions based on LR will affect the relative variances of new distributions. SN, the new distribution of the superior condition, will have a larger variance than WN, the new distribution of the weaker, lower accuracy condition. This is a novel general effect, not previously noted in the literature. It is measured using the slope of the z-ROC that plots superior (S) new items ratings against weaker (W) new items ratings, the new/new z-ROC. If decisions are based on LR, the slope will be less than 1.0. Decisions based on LR also produce a parallel effect on the relative variances of the old distributions. SO, old distribution of the S condition, will have a larger variance than WO, the old distribution of the W condition. The effect is measured using the slope of the old/old z-ROC that plots the S old items ratings against the W old items ratings. Again, if decisions are based on LR , the slope will be less than 1.0.",1
4,10,"When decisions are made on the basis of LR, the length of the z-ROC contracts as a function of accuracy. The more accurate the condition, the shorter the z-ROC.",1
4,11,"From this point on we will use the log likelihood ratio, Λ, for convenience. Its use allows us to present simpler equations. The log likelihood ratio Λ=λ(X) is a function of a random variable X and is therefore a random variable itself with its own distribution, mean, and variance. The distribution of Λ is determined by the form of the distribution of X and the function λ().",1
4,12,We note that we used ordinary linear regression to estimate linear fits and obtain slopes for the computed examples of the following models. There is no issue with using linear regression in this way. The ROCs are plots of one theoretical distribution against another theoretical distribution. Neither axis is affected by random error,1
4,13,"We now present a simple example, a Normal Equal Variance Model that shows the regularities and how they are generated. In the example we assume a model of recognition memory based on normal equal variance distributions because the equations that govern the regularities are simple and the displays that show the regularities are also simple. We demonstrated in Glanzer et al. (2009) that the unequal variance normal model (which is a better fit to most recognition memory data) produces the same regularities as the equal variance case. The regularities seen in the example hold as well for models of recognition memory based on binomial and exponential distributions (see Glanzer et al., 2009). In this example we also convert LR to log LR, Λ. The conversion does not change any of the effects discussed but allows us to present simpler equations and simpler plots.",1
4,14,"For the current example, SN and WN are both Normal (0, 1), WO is Normal (1,1) and SO is Normal (1.75,1) (the first number in the parentheses is the mean, the second number is the standard deviation). The model also assumes decisions being made on the basis of LR.",1
4,15,"Figures 2A and B describe the model at the theoretical level. Figures 2C and D represent observable data based on the model. Figure 2A represents the initial distributions of raw information for SN, WN, WO, and SO usually referred to as “strength,” “familiarity,” or “amount of marking.” SO is placed to the right of WO, representing greater accuracy. SN and WN are not separated. It can be argued that new, unstudied items, because they have not been studied, cannot differ in strength.2 We do not separate the new distributions here; moreover, in order to show the effects of the LR transformation clearly – namely, that when SO moves above WO, SN will move in the opposite direction, below WN, on the LR decision axis.",1
4,16,"When the individual decides on the basis of LR, the densities in Fig. 2A are effectively redistributed on a log likelihood axis, as in Fig. 2B. The log likelihoods, are random variables whose distributions are also normal (see Glanzer et al, 2009). Figures 2B, C, and D illustrate the three regularities.",1
4,17,"Figure 2B shows that when the densities of Fig. 2A are re-plotted on a log likelihood decision axis, the new distributions SN and WN which were at the same position in Fig. 2A are now separated. The Mirror Effect appears with the distributions ordered",1
4,18,"Glanzer et al. (2009), however, demonstrated that H/FA Mirror Index functions poorly when there are bias effects. In such cases the index may indicate the absence of a Mirror Effect even when the underlying distributions are actually in mirror order. We consider this H/FA Mirror Index at length in this paper, however, because it is widely used.",1
4,19,"In recognition memory experiments, bias can result if the observer misperceives the prior probability that the item presented on a given trial is old or, for some reason, believes that different outcomes are not equally rewarded or punished. The possibility of changes in bias by likelihood ratio observers in responding to different test conditions has been discussed by Wickens (2002): “As a psychological model, the likelihoodratio procedure gives a simple description of how decisions are made. From past experience the observer has a feeling for the distribution of effects produced by stimuli from the two conditions…Bias can arise in this scheme in several ways.... Alternatives whose likelihoods are overestimated, perhaps because they are particularly salient, are more often chosen than those that are not.”",1
4,20,"The second term reflects the losses and gains associated with different correct and incorrect responses. If the penalty for a FA is increased, for example, the individual should increase his log likelihood criterion and be more hesitant to respond “Yes.”",1
4,21,"We now report the results of five experiments that show the three LR regularities and the effects of bias. In the first experiment, normative word frequency is the strength variable. In the four that follow familiarity of names is the strength variable",1
4,22,"All five experiments’ results show the three regularities. The second experiment, however, shows that bias can obscure the Mirror Effect when measured by the H/FA Index. The Distance Mirror Index, however, reveals the effect. The third,fourth, and fifth experiments demonstrate three other methods for countering those bias effects on the H/FA Index.",1
4,23,"We report experiment results in four stages. First, we report group, pooled results. All the individuals' confidence ratings are pooled to give a single ROC. These give a compact, general picture of the regularity results but do not permit standard statistical analyses. It will be seen, however, that the measures derived from the group results correspond closely to the measures obtained from the standard analyses that follow. Second, we give the H/FA Index of the Mirror Effect, the conventional analysis of the effect. Third, we report the three LR regularities based on ROCs computed for each individual. These give distributions of measures that can be subjected to statistical analysis. Fourth, we report a more detailed analysis of each individual's performance.",1
4,24,"To show the three LR regularities in a simple case without the complications of bias we review and reanalyze the data from a recognition experiment with normative word frequency as the variable: high frequency (H) versus low frequency (L) (Glanzer & Adams, 1990). Here L is the more accurate or strong (S) condition and H is the less accurate or weak (W) condition.",1
4,25,"The 16 undergraduate participants were first given a lexical decision task with 248 words, half H, half L, and 248 nonwords. They were then given an eight-level confidence rating recognition test with the 248 old words and 248 new (half H and half L). Further details on the procedure and method are given in the original publication.",1
4,26,"The four group z-ROCs, based on the pooled confidence ratings of all 16 participants, are shown in Fig. 4A and B. The regularities can be seen in the four z-ROCs as in the z-ROCs for the theoretical model discussed earlier (e.g., Fig. 2C and D). The examination is supplemented by sets of measures based on those z-ROCs. For the Mirror Effect, we measure the distances between the four underlying distributions. Those are obtained from the intercepts of the two z-ROCs in Fig. 4A and the two z-ROCs in Fig. 4B. For the Variance Effect, we measure the slopes of the old/old and new/new z-ROCs (see Fig. 4B). Here and in all subsequent analyses of group and individuals’ z-ROCs those measures are obtained by fitting each z-ROC with a linear function using the Wickens maximum likelihood program (Wickens, 2002) which furnishes intercepts and slopes. For the z-ROC Length Effect we compute the Euclidean distance between the end points of the standard z-ROCs in Fig. 4A.",1
4,27,"We now report the results of the statistical analyses of the participants’ responses in three stages. First, the conventional analysis of the H/FA Index of the Mirror Effect. Second, the analysis of the three LR regularities. Finally, a third analysis of individual responses with respect to the three LR regularities.",1
4,28,"The standard analysis of the Mirror Effect consists of a comparison of the accuracy of the two conditions (a difference is necessary for the effect to occur), and comparison of the hit and FA rate for each condition. The measures of interest are presented in Table 3. The table also includes measures of bias.",1
4,29,"We raised earlier the question of whether the regularities hold for individuals as well as for the pooled, group data. To answer that question we tabulated the presence of the regularities in each individual's data. The proportions of the 16 participants that show each of the three regularities are shown as ratios in the first row of Table 5. For example, all 16 participants showed SN < WN (dnn negative). All the regularities are evident and differ significantly from chance (.50) by a binomial test. These results fully support the analyses of the corresponding statistics in Table 4",1
4,30,"We next report four studies in which, instead of word frequency, familiarity of names is the variable. We switch to this variable primarily to document further the three regularities. The use of familiarity will, furthermore, permit us to evaluate an alternative explanation of the Mirror Effect, the twoprocess explanation, considered later. All four experiments evidence the three LR regularities. They show, moreover, how the bias effects that conceal the mirror effect as measured by the H/FA Index can be countered.",1
4,32,"Two main lists, one of F and one of U names, were used to construct the study and test list for each participant. The F list consisted of 120 names of well-known actors, actresses, athletes, and politicians. The U list consisted of names from a local telephone book. Examples of the F names were Drew Barrymore, Edward Koch, and Tom Hanks. Examples of the U names were Aaron Hutchings, Basil Madsen, and Dawn Wise. Preliminary testing was carried out with a group of 15 undergraduates who rated each of the names on a 6-point scale with 1 being “very familiar” and 6 being “very unfamiliar.” The F names had a mean rating of 1.14, σ = 0.15, with 98 % judged familiar. The U names had a mean rating of 4.83, σ = 1.01, with 21 % deemed familiar. An additional 18 U names were selected and used as practice and filler items. Twelve were used for a practice study and test list. Six were used as unscored filler items: two, at the beginning and two at the end of each study list, and two at the beginning of each test list. The filler names served to eliminate primacy and recency effects. List names were randomly selected and individually randomized for each participant.",1
4,33,"During study and test each name appeared in the center of the screen, in capital letters. During study each name appeared for 1250 ms, with a blank screen for 750 ms, separating successive items. The test list was presented immediately after the completion of the study list. The test list consisted of 120 F names and 120 U names, half of each studied and half new. The test was self-paced, each name remaining on the screen until the participant responded.",1
4,34,"Participants were instructed to decide, for each name, whether the item was “old” (had appeared in the study list) or “new” (had not) using a 6-point confidence rating scale. The confidence ratings were: (1) very sure old; (2) moderately sure old; (3) slightly sure old; (4) slightly sure new; (5) moderately sure new; and (6) very sure new. The numbers and their descriptions stayed on the monitor so that participants did not have to commit the scale to memory. The experiment began with a short practice session which consisted of a 6-item study list followed by a 12-item test list, six studied and six new items.",1
4,35,"The data for 38 undergraduates are reported (one individual’s data whose responses were below chance are not). The participants had all been speaking English since the age of 10 years or earlier. They participated to fulfill a class requirement. This description also holds for the participants in Experiments 3, 4, and 5.",1
4,36,"The second row of Table 3 displays some of the results for the experiment. The first two entries show dF = 2.11 > dU = 1.04, t(37) = 77.69, MSE = 0.28. The significant difference in accuracy indicates that the Mirror Effect should be present. The next two entries are the bias indices. The mean bias index cU = +0.38 (a strong conservative bias) for the unfamiliar items and cF -0.03 (a slight liberal bias) for the familiar names. They differ significantly, F( 1, 37)= 20.93, MSE= 0.15 .The difference reflects the fact that participants tended to say “yes” less often to the unfamiliar names, both new and old, than to the familiar names. This differential bias moves the two false alarm rates together. The pattern of hits and false alarms shows the effect of the differential bias, with FAFN and FAUN barely separate. The effect of the bias is severe on the H/FA Mirror Index. The statistical analysis of that index is the test of FAFN versus FAUN and HUO versus HFO. That statistical evaluation finds only HWO versus HSO significantly different, t(37) = 9.30, SE=0.03. The difference between FAFN versus FAUN, however, is not, t(37) = 0.45, SE = 0.03. If the H/FA Index was the only measure available, the conclusion would be that there was a failure of the Mirror Effect.",1
4,37,"The second row of Table 4, shows, however, that the Mirror Effect is present as shown by the significant dnn and doo Distance Index (entries 1 and 2). The mean distance between to two new distributions is negative, dnn = ?0.57, and with t(37) = ?4.41, SE = 0.13 is significantly below zero: FN < UN. The mean distance between two old distributions, doo = 1.28, is positive and with t(37) = 16.73, SE= 0.08 is significantly above zero: FO > UO. In sum, the Distance Index finds that the Mirror Effect holds. The distributions are in the order FN < UN < UO < FO. When there is differential bias, the H/FA Index, based on minimal distance information, fails to show the mirror pattern while the Distance Index reveals the pattern’s presence.",1
4,38,The proportions of individual participants that show each of the three regularities are presented in the second row of Table 5. All the regularities are again evident and statistically significant by a binomial test. These data fully support the analyses of the corresponding statistics in Table 4. The denominators of the ratios vary because the data of two participants did not permit the computation of all four z-ROCs (they did not use a sufficient number of confidence categories). For the following experiments this variation in the Table 5 denominators occurs for the same reason: participants' responses that do not permit computation of particular z-ROCs.,1
4,39,"In summary, we have again demonstrated the presence of the three regularities in the performance of individuals, this time for familiarity of names as the variable. We have furthermore demonstrated that the conventional H/FA Index for the Mirror Effect is inadequate when there is differential bias. In that case, the more informative Distance Index based on dnn and doo should be used. We develop this point further by showing how to cope with differential bias when the H/FA Index is used.",1
4,40,"In the preceding experiment the participants showed a differential bias. They tended to say “yes” less often to unfamiliar names than to familiar names. This bias concealed the Mirror Effect when measured by the H/FA Index. We now remove the differential bias directly by arranging differential payoffs for responses to the two classes of names. If our reasoning is correct then all three regularities should appear including a mirror pattern for the H/FA Index. We use the payoffs to induce a counter-bias canceling the observed bias. This experiment is particularly important because any apparent failure of the Mirror Effect is necessarily accompanied by differential bias. This accompaniment is seen in the data of Experiment 2 when the H/FA Index is used. Our interpretation of the relation between bias and Mirror Effect is that the bias conceals the effect, particularly with the H/FA Index. An alternative interpretation is that the differential bias is a by-product of the intrinsic failure of the Mirror Effect with the materials of Experiment 2.",1
4,41,"To test which interpretation is correct, we now repeat Experiment 2 but with a feedback operation,pay-offs, to remove the differential bias of Experiment 2. If our interpretation is correct, then the Mirror Effect should be evident, full-blown, even for the H/FA Index.",1
4,42,"The materials, procedure, and characteristics of participants were the same as in Experiment 2, except that, before the test, the participants were told that their responses would be scored with the following schedule: For each old, unfamiliar name correctly identified as “old”, +50 points would be assigned. For each old, unfamiliar name incorrectly identified as “new”, ?50 would be assigned. For all other correct responses, +10 and all other incorrect responses, ?10 would be assigned. Total scores were reported to the participants at the end of the test.",1
4,43,"The group z-ROCs are presented in Fig. 6. All three LR regularities can be seen. In Fig. 6A the z-ROC for F is above that for U with dF = 1.45 and dU = 0.77. The length of the F z-ROC, 1.60, is less than the length of U, 2.13: the zROC Length Effect. In Fig. 6B the old/old z-ROC lies above the main diagonal, with doo = 0.61: FO is above UO on the decision axis. The new/new z-ROC lies below the main diagonal, with dnn = -0.40: FN is below UN on the decision axis. Those two z-ROCs indicate the Mirror Effect. Also the slopes of both those z-ROCs are less than 1.0, slnn= 0.67 and sloo= 0.83: the Variance Effect.",1
4,45,"The first two entries are dF = 1.80 and dU = 0.91. These measures of sensitivity differ significantly, with F(1,33) = 109.06, MSE = 0.12. With a difference in accuracies across the two conditions, the regularities appear. The next two entries present the mean bias indices, cF = +0.04 and cU = +0.08. These indices do not differ, F(1, 41) = 0.58, MSE = 0.07. No disruption of the mirror regularity should be expected. The next four entries show the mirror pattern in the H/FA data: FAFN= 0.20 < FAUN= 0.30 < HUO = 0.64 < HFO = 0.78. Statistical evaluation of FAFN versus FAUN and HUO versus HFO find the values in each pair significantly different, t( 41) = 7.65, SE = 0.01, and t(41 ) = 9.29, SE = 0.01. The argument presented in the introduction to this experiment is supported. Differential bias in Experiment 2 caused the obscuring of the Mirror Effect as measured by the H/FA Index. Removal of that differential bias with a payoff schedule revealed the effect even when measured by the weaker H/FA index.",1
4,46,"Table 4 contains the z-ROC-based regularity measures. The first two means for the Distance Mirror Index, are dnn = ?0.46 and doo = 0.71. Both differ significantly from zero. The mean dnn is negative with t(33) = ?5.15, SE = 0.09: SN < WN. The mean doo is positive with t(33)= 7.14 , SE = 0.10 : WO < SO. The next two entries, the mean slopes of the new/new and old/old z-ROCs, indicate the Variance Effect regularity. Both are significantly less than 1.0. The mean of dnn = 0.75 with t(33) = 3.93, SE = 0.06. The mean of doo = 0.76 with t(33) = 3.00, SE = 0.08. The Variance Effect holds.",1
4,47,"The next two entries, the mean lengths of the standard zROCs for F = 2.75 and U = 3.60 are significantly different, F(1, 33 ) = 12.32, MSE = 0.60. The z-ROC Length Effect holds.",1
4,48,The proportions of individual participants that show each of the three regularities are presented as ratios in the third row of Table 5. All the regularities are evident and statistically significant by a binomial test. These data fully support the analyses of the corresponding statistics in Table 4.,1
4,49,"All three preceding experiments displayed the three regularities. In Experiment 2, however, sizable bias difference effects removed the Mirror Effect according to the H/FA Index. In Experiment 3 we removed that bias with a payoff schedule and recovered the H/FA Mirror Effect. Another way to accomplish that removal and thereby recover the H/FA Mirror Effect is by moving to a between-list rather than a within-list paradigm. In a within-list paradigm, the two conditions, e.g., F and U, are both present in a single study and a single test list as in the preceding experiments. In a between-list paradigm, the two conditions appear in separate study-test sequences.",1
4,50,"The effect of separate test lists on bias was discovered by Hoshino (1991). In a series of experiments, he tried to replicate the word frequency Mirror Effect using Japanese kanji (ideograms) with a yes/no procedure and the H/FA Mirror Index. His first two experiments failed to show the effect, with P(HO) > P(LO). He ascribed the failure to a differential bias, a difference in the tendency to say “old” more frequently to H versus L words. The c bias indices are significantly different. In a third experiment he tested two groups in different conditions. One was tested as in his Experiments 1 and 2, with a test list consisting of a mixture of L and H words. That group showed the same pattern of results as his preceding two experiments, differential bias and violation of the Mirror Effect with the H/FA Index.",1
4,51,"The group z-ROCs are presented in Fig. 7. All three LR regularities can be seen again. The standard z-ROCs in Fig. 7A have dF = 2.26 and dU = 1.02. They show the z-ROC Length Effect, with length F = 2.12, and length U = 3.26. In Fig. 7B the old/old z-ROC lies above the main diagonal with doo = 1.16 and the new/new z-ROC, lies below the main diagonal, dnn = - 0.80: the Mirror Effect. Also the slopes of both those z-ROCs are less than 1.0, 0.54 and 0.75, respectively: the Variance Effect.",1
4,52,"The first two entries in row 4 of Table 3, the accuracy means, are dF = 2.49 and dU = 1.21. They differ significantly, F(1,29) = 112.96, MSE = 0.21. The next two entries the mean bias indices, cF = +0.11, cU = +0.15 do not differ, F(1,29) = 0.21, MSE = 0.10. The bias difference seen in mixed-list Experiment 2 has disappeared. Moving to a between-list paradigm removes the bias difference. With the elimination of differential bias the H/FA Index again shows a clear Mirror Effect",1
4,53,"The fourth row of Table 4 lists the regularity measures. The first two entries for the Distance Mirror Index, dnn = ?0.80 and doo = 1.31, show a significant Mirror Effect with mean dnn < zero, t( 29 ) = ?6.24, SE = 0.13 and mean doo > zero, t( 29 ) = 9.75, SE = 0.13. The next two entries, the slopes of the new/new and old/old z-ROCs show a significant Variance Effect. Both are less than 1.0: slnn= 0.77, t(29 ) = 3.18, SE = 0.07 and sloo= 0.54, t( 29 ) = 9.25, SE = 0.05. The next two entries, mean length F = 2.55 < mean length U = 4.07 show a significant length difference, F(1, 29) = 40.51, MSE = 0.85. The z-ROC Length Effect holds.",1
4,54,The proportions of individual participants that show each of the three regularities are presented in the fourth row of Table 5. All the regularities are evident and significant by a binomial test. These data fully support the analysis of the corresponding statistics in Table 4.,1
4,55,"We will now counter the bias effect of Experiment 2 by increasing the accuracy for the familiar names vis-à-vis the unfamiliar names. We do that by decreasing the number of familiar names in the study and test lists. Experiments on list composition in which study lists are composed of items from different sub-lists (Dorfman & Glanzer, 1988; Malmberg & Murnane, 2002; Shiffrin, Huber, & Marinelli, 1995) have shown that decreasing the number of items drawn from one of the sub-lists increases recognition accuracy for those items.",1
4,56,"Experiment 5 was identical with Experiment 2 except that the number of familiar names was reduced by half in the study and test lists. The study lists consisted of 30 familiar and 60 unfamiliar names. The test lists consisted of 30 familiar old, 30 familiar new, 60 unfamiliar old, and 60 unfamiliar new. Except for the change in number of items the procedure in this experiment was the same as Experiment 2: construction of lists, presentation, and characteristics of participants.",1
4,57,"The group z-ROCs are presented in Fig. 8. All three LR regularities can be seen again. The standard z-ROCs in Fig. 8A have dF = 2.18 and dU = 0.83. They show the z-ROC Length Effect, with length F = 1.78, and length U = .3.55. In Fig. 8B, the old/old z-ROC lies above the Main Diagonal with doo = 1.61, and the new/new z-ROC, lies below the main diagonal, dnn = -1.12: the Mirror Effect holds. Also the slopes of both those z-ROCs are less than 1.0, 0.41 and 0.55, respectively: the Variance Effect holds.",1
4,58,"Row 5 of Table 4 gives the regularity means. The first two entries for the Distance Mirror Index, dnn = -0.22 and doo = +1.14, show a significant Mirror Effect with mean dnn < zero, t(40) = 14.93, SE = 0.09, and mean doo > zero, t(34) = 18.37, SE = 0.06. The next two entries, the slopes of the new/new, and old/old, z-ROCs show a significant Variance Effect with both slopes less than 1.0. For slnn = 0.55 t(40) = 3.18, SE = 0.07. For sloo = 0.44, t(34) = 13.75, SE = 0.04 are less than 1.0. The next two entries, mean length F = 1.97< mean length U = 3.81, show a significant length difference, F(1, 42) = 76.47, MSE = 0.76. The z-ROC Length Effect holds.",1
4,59,"Reducing the number of familiar names increased the accuracy of recognition for those items from d' = 2.11 in Experiment 2 to d' = 2.76 here. It thereby increased the difference in accuracy between the familiar and unfamiliar items. This had the expected effect of recovering the Mirror Effect according to the H/FA Index (see line 2 of Table 3.) It had the unexpected effect, however, of also increasing the bias difference by making the responses to the familiar names more liberal. This effect is of considerable interest. It indicated that an experimental operation may have a double effect: a change in accuracy and a change in bias. The reason for the bias change may be that familiar names generate relatively liberal responses initially (as in Experiment 2) because they are more salient for participants. When we reduced the number of familiar names in the present experiment, we increased their salience further and thus increased further the tendency for liberal responses (see Wickens, 2002, on the relation of salience to bias).",1
4,60,"Our contention is that SDT with its three basic concepts – sensitivity, bias, and LR decision axis explains the three regularities. It also explains when the mirror regularity does not appear. There are process models of recognition memory that incorporate SDT and its LR component (McClelland & Chappell, 1998; Shiffrin & Steyvers, 1997). There is no conflict between such models and the more general SDT model considered here. What is involved are two different levels of theory (Marr, 1982).",1
4,61,"LR decisions need not be invoked to explain the data of a simple one-condition memory experiment such as the one represented in Fig. 1. The assumption that decisions are made on the basis of unprocessed “strength” will do. When we move to two-condition experiments such as the one represented in Fig. 2 simple strengthbased decisions fail. This can be seen by taking the same parameters used there: SN and WN are Normal(μ=0,σ=1), WO is Normal(μ=1,σ=1) and SO is Normal(μ=1.75,σ=1). If we omit the LR conversion from the computations then none of the regularities appear. The initial new distributions do not move: doo = .75 but dnn = 0, no Mirror Effect. The slopeoo = slopenn = 1.0: no Variance Effect. And lenW = lenS = 5.66: no Length Effect.",1
4,62,"It is, of course, possible to hold on to strength decisions by adopting additional, ad hoc assumptions, to explain a regularity. To date, two such proposals have been made to explain the Mirror Effect: Criterion Shift and Two-Process. Their ad hoc assumptions are indicated below.",1
4,63,"There is ample evidence, however, that WN and SN do not stay fixed. Experiments on forced choice in which participants were required to choose WN versus SN items, called null choices, showed that the two new distributions are separated, SN < WN ( Glanzer et al., 1991, 1993; Hilford et al., 1997; Kim & Glanzer, 1995). In all five experiments reported here dnn is negative (see Table 3), indicating again that the two new distributions are separated, SN < WN with distance -dnn.",1
4,64,"A popular explanation of the Mirror Effect, is the two-process explanation, e.g., Balota, Burgess, Cortese, and Adams (2002). This explanation is limited to the word frequency Mirror Effect (seen in Experiment 1). It makes the following assumptions: (1) Individuals use a familiarity/ strength decision axis, unconverted; (2) process one: Low frequency new (LN) words start out situated lower on the familiarity/strength decision axis than high frequency new (HN) words because they are less familiar (ad hoc assumption). This gives one of the inequalities that define the Mirror Effect, LN < HN; (3) process two: Low frequency words are learned and recollected much more effectively than high frequency words, overcoming the initial position difference (ad hoc assumption). This gives the second inequality, HO < LO, of the Mirror Effect. The three assumptions in combination produce the Mirror Effect, LN < HN < HO < LO.",1
4,65,"To support the explanation, the Mirror Effect is first shown in a baseline condition. Then an operation is carried out, e.g., speeded presentation, that disrupts the Mirror Effect (using the H/FA Index). This is interpreted as a result of disruption of recollection. The two-process explanation is limited in two ways: (1) It explains only the word-frequency mirror effect, not, as will be shown, the name familiarity mirror effect (Experiments 2, 3, 4 and 5), and (2) it does not cover the other two regularities, the Variance Effect and the Length Effect",1
4,66,"The LR SDT interpretation of the mirror disruption as a result of speeding differs. L words require more processing time than H words (Glanzer & Adams, 1990; Wright, 1979). Speeding therefore has a differential effect on L versus H words. It decreases the accuracy for both L and H words but more so for L words. It therefore decreases the difference in accuracy, d’, between the two conditions. In Glanzer et al. (2009) and in Experiment 5 we showed that the size of the accuracy difference between conditions was critical for the H/ FA Index of the mirror effect. If there is any differential bias, the smaller the d’ difference, the less likely the H/FA Index (used in the two-factor mirror disruption studies) will show the mirror effect.",1
4,67,"SDT with its LR decision axis handles the data summoned to support the two-process explanation without postulating any additional processes such as familiarity and recollection. It is not, moreover restricted to the explanation of word frequency effects as is the two-process explanation",1
4,68,"Finally and more generally, Experiments 2, 3, 4, and 5 rule out a two-process explanation and, more generally, any explanation that assumes a strength/familiarity decision axis. Such explanations require that the unfamiliar new names (UN) should be lower than familiar new names (FN) on the decision axis, UN < FN. Therefore no mirror effect should occur. SDT with its LR decision axis predicts the reverse order, FN < UN, and a full Mirror Effect.",1
4,69,"Our finding that familiarity produces a Mirror Effect is supported by evidence from five other studies on recognition that have varied familiarity of words, names, faces, and tunes (B?ckman 1991; B?ckman & Herlitz, 1990; Bartlett, Halpern, & Dowling, 1995; Brown, Lewis, & Monk, 1977; Schulman, 1976). Those investigators use different names for the familiarity variable, e.g., prior knowledge, but it is clear that the two sets of items used in each study differ in initial familiarity.",1
4,70,"Rouder and his co-authors have raised questions about the legitimacy of statements about the relation of asymmetry of ROCs (slopes other than 1.0 of z-ROCs) to the variance of the underlying distributions. Rouder, Pratte, and Morey (2010) challenged results presented by Mickes, Wixted, and Wais (2007) in support of the relation between slopes and variance in the normal unequal variance SDT model. Rouder et al. presented z-ROCs from other models (e.g., log normal, inverse probit transforms of normal) with other variances that mimic the Mickes et al. findings. They concluded that “there is no principled method for assessing the relative variability of latent mnemonic strength distributions” (p. 427). The argument has, however, been rebutted in detail by Wixted and Mickes (2010). The controversy cannot be resolved here. It requires, at a minimum, a demonstration by Rouder et al. that the alternative models proposed do as good a job as the standard SDT normal models with a range of data. Wixted and Mickes (2010) present analyses that they do not.",1
4,71,"Pratte, Rouder, and Morey (2010) are concerned with a different presumed problem in interpreting ROC asymmetries (z-ROC slopes less than 1.0). Their concern is whether they are an artifact of “distortions due to averaging data over items” (p. 224). They conclude, however, that “Application of a hierarchical unequal-variance signal detection model reveals that asymmetries are in fact a real phenomenon and do not reflect distortions from averaging data” (p. 224).",1
5,1,"Interest has flourished in studying both the spatial and temporal aspects of eye movement behavior. This has sparked the development of a large number of new methods to compare scanpaths. In the present work, we present a detailed overview of common scanpath comparison measures. Each of these measures was developed to solve a specific problem, but quantifies different aspects of scanpath behavior and requires different data-processing techniques. To understand these differences, we applied each scanpath comparison method to data from an encoding and recognition experiment and compared their ability to reveal scanpath similarities within and between individuals looking at natural scenes. Results are discussed in terms of the unique aspects of scanpath behavior that the different methods quantify. We conclude by making recommendations for choosing an appropriate scanpath comparison measure.",1
5,2,"We describe the scanpath comparison methods that have been introduced in the literature. In each case, we give a short description, and the reader is advised to consult the original publications for further details. Additional mathematical details are provided in the Appendix.",1
5,3,"One successful way for comparing scanpaths is based on the string-edit distance (Bunke, 1992; Levenshtein, 1966; Wagner & Fischer, 1974), which is used to measure the dissimilarity of character strings. In this method, a sequence of transformations (insertions, deletions, and substitutions), is used to transform one string into the other and their similarity is represented as the number of transformation steps between the two strings. This method has been adapted for comparing the similarity of scanpaths (Brandt & Stark, 1997; Foulsham & Kingstone, 2013; Foulsham & Underwood, 2008; Harding & Bloj, 2010; Underwood, Foulsham, & Humphrey, 2009). To achieve this, a grid is overlaid on an image, and each cell in the grid is assigned a unique character. Fixation sequences are then transformed into a sequence of characters by replacing the fixation with the character corresponding to the grid cell the fixation falls in. The dissimilarity of two scanpaths can then be represented by the number of transformations required to convert the string corresponding to the first scanpath to the string corresponding to the second scanpath.",1
5,4,"The string-edit measure has been used on a similar dataset previously in Foulsham and Underwood (2008), where similarity was found to be highest for scanpaths generated from the same person looking at the same image. In addition, in Foulsham et al. (2012), similarity in shape was highest for the same person looking at the same image. Given that the stringedit distance measure is most sensitive to similarities in shape and sequential information, we expect that string edit similarity scores should be quite high between scanpaths of the same person looking at the same image for a second time, convergent with these earlier results.",1
5,5,"Cristino et al. (2010) proposed a generalized scanpath comparison method that addresses many of the deficiencies of the string-edit distance method. Their generalization aligns eye movement sequences based on the Needleman-Wunsch algorithm, which is used in bioinformatics to compare DNA sequences. In their method, scanpaths are spatially and temporally binned and then recoded to create a sequence of letters that retains fixation location, duration, and sequence information. The two character sequences are compared by maximizing the similarity score computed from a substitution matrix, which in turn provides the score for all letter pair substitutions and a gap penalty. Critically, the substitution matrix can encode information about the relationship between specific regions of interest, thus providing the opportunity to include semantic information in the similarity measure.",1
5,6,"Since ScanMatch quantifies spatial, sequential, and duration information together, we expect ScanMatch to do well in revealing within-participant scanpath similarity, and in particular, the strong similarity between observers viewing the same image twice (see Foulsham et al., 2012).",1
5,7,"Shepherd et al. (2010) introduced several measures for assessing the similarity of two scanpaths. For each of the measures, the scanpaths are first resampled uniformly in time (at 60Hz), and truncated to the shorter length. These measures are sample-based, in that they do not require pre-processing of eye-tracking data into discrete fixation-saccade sequences via saccade and velocity thresholds.",1
5,8,"The overlap between two scanpaths yields a similarity measure that is sensitive to temporal and spatial differences between fixation locations. It does not take into account fixation duration, rather it uses the resampling to capture aspects of temporal similarity. Thus, this method preserves temporal ordering but does not account for differences in fixation times. As a result, two scanpaths could have the same spatial positions but different fixation durations, and this method would then evaluate them as not overlapping and therefore being very different. For example, if one scanpath lagged behind another by one fixation but was otherwise spatially overlapped, this method would evaluate the two sequences as very different. One drawback of this method is that it uses an arbitrary, pre-defined radius threshold, with similar disadvantages to the grid-based quantization of string-edit and ScanMatch.",1
5,9,"Fixation overlap is extremely sensitive to differences in absolute timing between two scanpaths, but is slightly less sensitive to differences in position (due to the use of the radius). Given these sensitivities, it is reasonable to expect this measure to perform similarly to the ScanMatch measure, which is also sensitive to the spatial and temporal similarities between two scanpaths.",1
5,10,"This measure is very sensitive to temporal and spatial differences between the two scanpaths. The sensitivity to temporal differences can be advantageous when timing is important, e.g., when the stimuli change over time, such as in videos. The correlation measure is also sensitive to small differences in fixation positions, given that there is no spatial quantization of the fixations. A significant advantage of this method is its use of the straightforward and readily interpretable correlation analysis. This measure is more sensitive to similarities in position than the fixation overlap method, while also taking sequential information into account. However, this strong spatial-temporal sensitivity may be less robust to noisy data than other measures that employ a grid or radius.",1
5,11,"Shepherd and colleagues’ (2010) gaze-shift measure assesses how similar the saccade times and amplitudes are between two scanpaths. Gaze shift is computed as the correlation between the absolute values of the first derivative of each scanpath and is computed in the same manner as the temporal correlation, but using the first derivative instead of the position",1
5,12,"For smoothing and for computing the derivatives of the scanpaths, each scanpath is convolved with the derivative of a Gaussian filter. Gaze shift is sensitive to the amplitude of the saccade as well as to its temporal location. It reflects how similar two scanpaths are in terms of the sequence of large and small saccades. This captures some aspects of a global viewing strategy, as subjects who make small saccades within a localized region would have very different scanpaths than subjects who make large saccades within the entire visible area. This is also useful for comparing dynamic stimuli (e.g., video) to assess how subjects respond to temporal changes in the scene.",1
5,13,"The gaze-shift measure quantifies similarity in amplitudes, and might correspond well with the MultiMatch measure that quantifies similarity in scanpath length. In Foulsham et al. (2012), similarity in length was only consistent for the within/ between-image comparison. One might expect a similar result for the gaze-shift measure; however, prediction is difficult because it simultaneously quantifies, like the other samplebased measures, temporal similarity",1
5,14,"The most significant advantage of the linear distance method is that it does not need to be quantized as in the string-edit method. It simply compares each fixation in one scanpath with the fixations in another in terms of their spatial similarity. However, by comparing only nearest neighbor fixations in terms of distance, this method ignores sequential information. To address some of these issues, Mannan et al.’s (1995) method was modified by Henderson, Brockmole, Castelhano, & Mack (2007) to enforce a one-to-one mapping between two scanpaths, provided that they have the same length. The results for the two methods are very similar (Foulsham & Underwood, 2008), which is likely due to the fact that Mannan et al. average the distances from the first to the second and from the second to the first scanpath, hence clusters of fixations in one scanpath are averaged out. For this reason, we used only Mannan et al.’s (1995) original method in our analyses. Linear distance is a measure that specifically quantifies and compares the fixation positions in two scanpaths, regardless of the order of fixations. Given that scanpath position comparisons have previously revealed an advantage for within-participant similarity (Foulsham et al., 2012), we expect this method to perform well in comparing within- and between-participant scanpath similarity.",1
5,15,"Recently, Jarodzka, Holmqvist, and Nystr?m (2010), Dewhurst et al. (2012), and Foulsham et al. (2012) introduced the MultiMatch method for comparing scanpaths. The MultiMatch methods consists of five separate measures that capture the similarity between different characteristics of scanpaths, namely shape, direction, length, position, and duration. Computation of each MultiMatch measure begins with scanpath simplification, which involves combining iteratively successive fixations if they are within a given distance or within a given directional threshold of each other. This simplification process aids in reducing the complexity of the scanpaths while preserving their spatial and temporal structure",1
5,16,"Following this simplification, scanpaths are aligned based on their shape using a dynamic programming approach. The alignment is computed by optimizing the vector difference between the scanpaths (note, however, that scanpaths may be aligned on any number of dimensions in MultiMatch). This alignment reduces the comparison’s sensitivity to small temporal or spatial temporal variations, and allows the algorithm to find the best possible match between the pair of scanpaths. All subsequent similarity measures are computed on these simplified, aligned scanpaths. The MultiMatch similarity computations presented here follow the implementation described in Dewhurst et al. (2012).",1
5,17,"Vector similarity is computed as the vector difference between aligned saccade pairs, normalized by the screen diagonal and averaged over scanpaths. This measure is sensitive to spatial differences in fixation positions without relying on pre-defined quantization. It is a measure of the overall similarity in shape between two fixation-saccade sequences.",1
5,18,"Length similarity is computed as the absolute difference in the amplitude of aligned saccade vectors, normalized by the screen diagonal and averaged over scanpaths. This measure is sensitive to saccade amplitude only, not to the direction, location, or the duration of the fixations.",1
5,19,"Direction similarity is computed as the angular difference between aligned saccades, normalized by π and averaged over scanpaths. This measure is sensitive to saccade direction only, but not to amplitude or absolute fixation location.",1
5,20,"Position similarity is computed as the Euclidean distances between aligned fixations, normalized by the screen diagonal, and averaged over scanpaths. This measure is sensitive to both saccade amplitudes and directions.",1
5,21,"Duration similarity is computed as the absolute difference in fixation durations of aligned fixations, normalized by the maximum duration and averaged over scanpaths. This measure is insensitive to fixation position or saccade amplitude.",1
5,22,"The main advantage of the MultiMatch method is that it provides several measures to choose from for assessing scanpath similarity, and each measure on its own captures a unique component of scanpath similarity. Given the multiplicity of measures, it remains, however, difficult to assess which measure, or which set of measures, is most applicable in a given scenario. Furthermore, because each scanpath is initially simplified it is also not clear how robust each measure is to scanpath variations.",1
5,23,"Given that the MultiMatch measures have already been evaluated with a dataset similar to the one generated for the present work, we expect to essentially replicate those earlier results, where saccade direction, fixation position, fixation duration, and shape similarity were found to be higher for withinparticipant compared to between-participant comparisons.",1
5,24,"To characterize cross-recurrence patterns, we have developed several measures that are based on the recurrence quantification analysis (RQA) for characterizing gaze patterns of a single observer (Anderson et al., 2013). These measures are introduced briefly below and described in detail in the Appendix.",1
5,25,"Consider two fixation sequences f and g that have the same lengths. For sequences of unequal length, the longer sequence is truncated. Within these sequences, any two fixations fi and gj are cross-recurrent if they match or are close together, i.e., if their distance is below a given threshold. In the following, we introduce several measures that we have found useful for characterizing cross-recurrent patterns.",1
5,26,"The cross-recurrence measure of two fixation sequences represents the percentage of cross-recurrent fixations, i.e., the percentage of fixations that match between the two fixation sequences. Cross-recurrence is higher the more spatially similar two fixation sequences are and quantifies their similarity in shape. It is invariant to differences in fixation sequence order as fixations are considered recurrent only if they overlap in position. Given that cross-recurrence quantifies similarity in position, results should be most in line with the linear distance measure and the MultiMatch position measure.",1
5,27,"The determinism measure represents the percentage of cross-recurrent points that form diagonal lines in a recurrence plot and represents the percentage of fixation trajectories common to both fixation sequences. That is, it quantifies the overlap of a specific sequence of fixations, preserving their sequential information (see Fig. 5). An advantage of this measure is that it provides unique information about the type of similarity between two scanpaths. Although two scanpaths may be quite dissimilar in their overall shape or fixation positions, this measure may show whether certain smaller sequences of those scanpaths may be shared.",1
5,28,"Laminarity is a measure of repeated fixations on a particular region that are common to both scanpaths. Laminarity is closely related to determinism. If both laminarity and determinism are high, then in both scanpaths fixations tend to cluster on one or a few particular locations and remain there across several fixations. If laminarity is high, but determinism is low, then it quantifies the number of locations that were fixated in detail in one of the fixation sequences, but only fixated briefly in the other fixation sequence. It is a measure of the clustering of fixations across two sequences.",1
5,29,"Finally, the center of recurrence mass (CORM) is defined as the distance of the center of gravity of recurrences from the main diagonal in a recurrence plot (see Dale et al., 2011b for another method to quantify leading and following in cross-recurrence). The CORM measure indicates the dominant lag of cross-recurrences. Small CORM values indicate that the same fixations in both fixation sequences tend to occur close in time, whereas large CORM values indicate that cross-recurrences tend to occur with either a large positive or negative lag. This is a measure of whether one scanpath may lead (positive lag) or follow (negative lag) its paired scanpath. Their overall similarity in shape or position may be different, but offset, such that one sequence proceeds in a particular trajectory, and the other follows the same trajectory only later on in time (e.g., a few fixations later). In the present work, we use the absolute value of CORM rather than averaging over positive and negative values as we do not have any specific predictions about whether leading or following is more likely to happen in one particular condition or another. Overall, we might predict low corm values for within-image, within-participant comparisons if participants consistently lead or follow a similar scanpath closely (i.e., with a low positive or negative lag) on a later viewing of the same image.",1
5,30,"In the present work, we compared the ability of the scanpath measures reviewed above to reveal scanpath similarities within and between individuals looking at natural scenes. In a paradigm adopted from Foulsham and Underwood (2008) and Foulsham et al. (2012), participants performed a scene encoding and subsequent recognition task. This ensured that participants saw each image in the encoding phase for a second time during recognition, allowing for a comparison of scanpath similarity both within and between subjects and within and between images. The main prediction of these comparisons is that scanpaths are more similar for the same person viewing the same image, than for different people viewing different images. This observation has been verified by a handful of scanpath comparison techniques (see Foulsham & Underwood, 2008; Foulsham et al., 2012). We use it here in order to evaluate the ability of each scanpath comparison method to reveal the uniquely high similarity in the scanpath of the same observer viewing the same image twice, and its ability to capture any singular similarities between observers and images.",1
5,31,Stimuli were presented full-screen on a 19-in monitor operating at a 60-Hz refresh rate. Participants sat 60 cm from the screen with their head restrained in a chin rest. Thus the screen subtended approximately 32.7° × 25.7° of visual angle. Eye movements were recorded using the Eyelink 1000 eyetracker (SR-Research) and participants used a standard keyboard when responses were required.,1
5,32,"A total of 36 images at a resolution of 1024 × 768 pixels were selected from a dataset created by Foulsham and Underwood (2008). The images were pictures of buildings, interiors, and landscapes (see Foulsham & Underwood, 2008 for more information). Half of these images were shown during both the encoding and recognition phases of the experiment, while the other half were shown only during the recognition phase to act as “new” images",1
5,33,"For the sample-based methods, signals were re-sampled at 60 Hz. For the overlap method, two fixations were considered overlapping if their distance was less than 3.5° visual angle. For the gaze-shift measure, a temporal Gaussian filter with σ = 100 ms was used. For the string-edit distance, fixations were discretized on an 8 × 6 grid (approximately 4? × 4° per grid cell). For the ScanMatch measure, the substitution matrix was used to define similarity in distance between grid locations (as was done in the original manuscript). For the MultiMatch measure, scanpaths were simplified by combining fixations that were closer than 3.5° visual angle or by combining successive saccades whose direction differed by less than 45°. For the recurrence-based measures, two fixations were considered cross-recurrent if their distance was less than 1.9° visual angle. For the determinism and laminarity measures, a minimum line length of 2 was used.",1
5,34,"Rather than simply compare measures in terms of their ability to detect the main effects and interaction of the analysis of variance, we chose to use effect sizes for making comparisons across measures. For example, if the recurrence measure has a high effect size for the main effect of image, then this measure is sensitive to this factor in the similarity of scanpaths. We used generalized eta squared (η2 G ) for the comparisons (Bakeman, 2005; Olejnik & Algina, 2003; J. T. Richardson, 2011). In repeated-measures designs, η2 G is comparable across different within-participant and betweenparticipant variables (see J. T. Richardson, 2011, p. 142), but the same is not true for the partial eta squared (η2 p ). Thus η2 G allows for a direct comparison of the effects of participant and image. Bakeman (2005) suggests that similar guidelines should be used for assessing the size of the effect with η2 G as is the case for η2 p , i.e., an effect size of 0.02 is considered as small, 0.13 as medium, and 0.26 as a large effect size.",1
5,35,"For each scanpath measure, the F-ratio and p-values for the main effect of participant, the main effect of image, and the participant-by-image interaction are presented in Table 2 and mean scanpath similarity for each measure across the four conditions is presented in Table 3. The remainder of the results will focus on the resulting η2 G obtained for each term in the analysis of variance. The η2 G values for the main effect of participant is shown in Fig. 1, for the main effect of image in Fig. 2, and for the participant-by-image interaction in Fig. 3. The means of the significant participant-by-image interactions are shown in Fig. 4, and the corresponding post-hoc comparisons are reported in the participant-by-image paragraph below.",1
5,36,"In the present work, we performed multiple types of scanpath comparisons on the scanpaths generated from a foundational encoding and recognition experiment. Specifically, we compared sample-based measures (Shepherd et al., 2010), gridbased measures (Bunke, 1992; Cristino et al., 2010; Levenshtein, 1966; Wagner & Fischer, 1974), the direct linear distance measure (Mannan et al., 1995), the measures computed from the MultiMatch algorithms (Dewhurst et al., 2012), and recurrence-based measures (D. C. Richardson & Dale, 2005). This design allowed for the comparison of scanpath similarity across images and participants, focusing on the relative contribution of the individual generating the scanpath and the influence of the stimulus itself on resulting similarities. In addition, this study was designed for the more general comparison of the methods used to compute scanpath similarity, which we compared by computing generalized eta squared. In the following, we review the contributions of each measure to the understanding of scanpath similarity in terms of participant and image similarities and then discuss the performance of each group of measures, with particular emphasis on the type of information they quantify",1
5,37,"Our results support previous work using a similar paradigm where the same person looking at the same image is more likely to have a more similar scanpath (Foulsham & Underwood, 2008; Foulsham et al., 2012). This was borne out in the number of measures that revealed a significant interaction between participant and image, where the withinimage, within-participant comparison had the highest similarity scores (see Fig. 4 and Foulsham et al., 2012, Fig. 2). Interestingly, because each scanpath comparison technique differs in the characteristics that it captures, the different scanpath comparison measures may be revealing in terms of the aspects of scanpath similarity that result from withinparticipant or within-image similarity.",1
5,38,"The quantification methods that were most notable in revealing within-participant idiosyncrasies were those that quantified similarity in shape and position: overlap, linear distance, ScanMatch and recurrence. Interestingly, and similar to previous work (Foulsham et al., 2012), measures that also quantified some aspect of sequential order such as ScanMatch and determinism were particularly discriminatory. Beyond the overall similarity in shape and sequential order, the determinism measure revealed that scanpaths are repeated by particular individuals on a more local level, where a person may have an idiosyncratic strategy of repeating particular short sequences of scanpaths in a consistent manner, regardless of the image they are viewing. Taken together, individual differences in scanning behavior reveal themselves in terms of overall scanpath shape and to some extent, the order in which this shape unfolds.",1
5,39,"The image had a very strong influence on the similarity of scanpaths. Most measures were able to detect a main effect of image and the resulting η2 G values were quite high. Most notably, those measures that quantify shape, position and sequential order were again very discriminatory: overlap, linear distance, ScanMatch, recurrence, and determinism. Interestingly, most of the measures that performed well on the main effect of image were those with configurable grid or radius sizes. Although we used author-recommended or previously used radius/grid sizes, an interesting avenue of future research would be to examine to what extent the present results may vary with respect to the radius/grid size chosen.",1
5,40,"In the present work, we were concerned with how the measures compared when they were computed using author-recommended or previously-used parameters. However, the choice of radius size or granularity of grid is extremely important. As radius size increases, so does the chance that spatially sensitive scanpath measures are considered similar. As radius is reduced, the chances of an overlap are reduced. The Overlap method was an extremely successful scanpath comparer in this dataset, but uses a much larger radius compared to the recurrence-based measures, which also performed quite well. This could reflect the fact that the Overlap measure is reflecting some overlap in time that the recurrence-based measures are not, but it could also mean that the radius was simply bigger and therefore, overlaps in space were more likely to be found. It is our speculation that there may be a fine line between real scanpath similarity and spurious similarity due to radius size. One interesting avenue for future investigation would be to run scanpath comparisons on multiple radius and grid sizes and compare the results along with effect sizes. The general recommendation, based on previous work (Anderson et al., 2013; Dewhurst et al., 2012) is to choose a sensible radius size that reflects roughly the size of region of foveal or parafoveal vision. However, how the choice of radius and grid size impacts scanpath quantification and comparison is another fruitful avenue of future research.",1
5,41,"Second, it is important to keep in mind the various requirements of each method. For example, some methods, such as the recurrence-based measures, require that the scanpaths be trimmed to the shorter of the two scanpath lengths. This may result in a loss of some data. Certain methods, such as the sample-based methods and ScanMatch may require the data to be resampled. Thus, fixations and saccades are no longer relevant units. For example, the sample-based methods work directly on the sample-level data from the eye-tracker which are then re-sampled to 60 Hz. In comparing the resulting scanpaths, the specifics of fixations and saccades are lost. Some methods encourage the simplification of data, although this is not a requirement. For example, in our implementation of MultiMatch, angular differences between saccades smaller than 45° were collapsed. Simplification is typically performed in order to increase processing speed. This may be desirable when many comparisons need to be computed (especially for the computation-intensive scanpath comparison measures), but is by no means absolutely necessary. Investigating the effect of simplification on subsequent scanpath comparisons is a fruitful avenue of future research.",1
5,43,"Although, as outlined above, the choice of scanpath measure is highly dependent on the research question, we have a few general recommendations. Scanpath comparison has evolved over many decades of research in eye movement behavior, but perhaps the most striking improvements have occurred most recently. ScanMatch is a remarkable improvement on more simple methods such as string-edit and linear distance and, as mentioned previously, is one of the few methods that naturally includes semantic information as part of the scanpath similarity score. MultiMatch is an excellent example of a method that is robust, easy to use, highly intuitive and freely available. Although cross-recurrence has only recently been developed for eye movements, we feel that it provides exciting opportunities to understand eye movement behavior beyond a single similarity score. The results from many of the cross-recurrence measures, such as determinism, for example, are simple percentages of fixations that overlap in a trial and are thus directly interpretable. These most recent contributions represent, in our opinion, the state-of-the-art in scanpath comparison techniques. However, these and many other scanpath comparison techniques are still under active development.",1
5,44,"One impressive aspect of the methods considered in the present work is that they are freely available, either upon request from the authors or directly online. Some measures are even accompanied by excellent user interfaces along with tutorials for their use (most notably, ScanMatch and MultiMatch), reducing the barrier to using these methods. Below is a list of URL’s where, as of this writing, those methods that are available online can be found.",1
5,45,"In the present work, we compared some commonly available scanpath comparison measures by providing an overview of the each measure and then applying it to a single data set. We compared the measures based on the aspects of scanpaths that they quantify and on how well they performed in revealing differences in scanning behavior across participants and images. This analysis provides a framework with which other researchers can use to determine the most suitable comparison technique that is most appropriate for their application. We hope that this overview and these results will help those interested in studying both the spatial and sequential aspects of eye movement behavior navigate the myriad of scanpath comparison measures.",1
6,1,"This review provides a systematic analysis of studies that evaluated interventions for inappropriate sexual behavior(s) of children and adolescents with developmental disabilities. Searches of databases, reference lists, and journals yielded 12 studies that met the predetermined inclusion criteria. Each study was summarized in terms of (a) participant characteristics, (b) dependent variables, (c) research design, (d) measures and data collection procedures, (e) independent variables, (f) treatment integrity, (g) results, and (h) level of certainty. All of the 12 studies reported decreases in the target behavior as the result of intervention. The most common intervention involved the use of multi-component behavioral strategies. Clinical implications and suggestions for future research are discussed.",1
6,2,"Sexual experimentation and exploration fits within the normal spectrum of human sexual behavior in prepubescent years. In particular, masturbation behavior has been observed to occur in utero (Meizner 1987) and during early childhood (Friedrich et al. 1998). According to Leung et al. (1993), masturbation occurs throughout the lifespan and most commonly occurs at 4 years of age and then again during adolescence. When defining normal or abnormal sexual behavior, the social, cultural, and familial contexts, the setting in which the behavior is occurring, and developmental norms need to be considered. When masturbation behavior is conducted in a private setting and is not excessive in nature, it is considered to be a normal part of child development. This behavior, however, may be considered to be inappropriate when it occurs for a sustained period of time and/or in public spaces and thus may warrant the need for intervention.",1
6,3,"Children with ASD in particular are reported to frequently engage in public masturbation (Ruble and Dalrymple 1993; Stokes and Kaur 2005), inappropriate touching of others (Clements and Zarowska 2000; Stokes and Kaur 2005), and fetishistic behavior (Ruble and Dalrymple 1993). There are several plausible explanations for this behavior. Firstly, sex education is not always provided to individuals with disabilities and is an area that is often ignored due to the potential embarrassment it may cause parents. Secondly, it is suggested that the predisposition of those with ASD, to engage in selfstimulatory behavior, may contribute towards repeated, inappropriate sexual behavior (Dalldorf 1983; Realmuto and Ruble 1999). Thirdly, unlike typically developing children, those with intellectual disabilities, particularly ASD, often require adapted and intensive instructional practices in order to acquire an understanding of the social and behavioral skills that might be learnt incidentally by others (Barnhill 2007; Gerhardt 2006; Hatton and Tector 2010). Due to the specific social deficits associated with ASD, these children and young people may have difficulty discriminating between public and private settings and may have impaired Btheory of mind (Baron-Cohen 2001). As a result, these children may have difficulty developing prosocial friendships and intimate relationships, may misunderstand relationship boundaries, may have difficulty understanding those behaviors that are appropriate in public versus private settings (Gougeon 2010; Hellemans et al. 2007), and may be excluded from social groups that provide typically developing children with peer feedback (Sullivan and Caterino 2008). Ludlow (1991) further suggests that the attention provided in response to the ISB of people with disabilities may provide strong social reinforcement for this behavior.",1
6,4,"There is little agreement in the literature regarding what can be considered ISB. For the purpose of this review, and based upon the literature on this subject, the term ISB is used to refer to those sexual behaviors that could be deemed to be excessive, obsessive, occur in public, violate others, are aggressive in nature, and/or imitate adult acts that are considered to be socially inappropriate.",1
6,5,"When individuals engage in ISB, there are profound implications for their social and familial relationships, as well as their community and home life. In clinical practice, parents of children with disabilities will often voice concern about their child’s ISB and may seek advice in this regard (Mallants and Casteels 2008). To date, there is limited research that has investigated different approaches to the treatment of childhood masturbation and even fewer studies that have examined ISB among children with ASD or other types of developmental disabilities. As a result, there is little consensus among clinicians regarding best practice for treatment of ISB, and the services and supports that are provided in this area are often limited.",1
6,6,"Mallants and Casteels (2008) conducted a review of the literature which investigated assessment and treatment approaches for childhood masturbation among those with typical development. They developed recommended treatment guidelines as a product of this review. In these guidelines, it is suggested that the process should begin with an assessment that includes questions about the child’s development, including affect, behavior, and sleep; questions about potential genitourinary or other medical problems; and consideration of cultural, familial, historical, relationship, and environmental variables. The signs of sexual abuse and/or skin irritation also need to be eliminated. In terms of treatment for childhood masturbation (CM), the authors highlight the fact that evidence-based treatment of early CM is lacking. When the assessment identifies that there are no additional confounding factors, it is recommended that treatment should focus on parent education and support. Educational processes should aim to alter parent perceptions of CM so that it is not viewed as pathology but, rather, a typical part of child development. It is further recommended that occurrences of CM should either be ignored or redirected and not punished due to the potential reinforcement that can come from responding to this behavior. Finally, the authors concluded that developmentally appropriate sex education should be provided to children in order to help them to understand what socially appropriate sexual behavior is and what it is not.",1
6,7,"In addition to the procedures recommended by Tarnai (2006), there is further evidence in the literature to suggest that treatment for ISB among those with disabilities should include a focus on providing sex education, as well as individualized instructional strategies. For example, Koller (2000) suggests that sex education for individuals with ASD should include instruction that is brief, repetitive, and specific; inappropriate behaviors should be promptly responded to and redirected; individuals should be taught an appropriate setting and time during which they can engage in sexual behavior; and private time should be proactively scheduled.",1
6,8,"In spite of the suggested value in providing sex education to children with disabilities, it is evident that we need to enhance our understanding of evidence-based practice in this area. Schaafsma et al. (2013) explored the development of sex education programs for people with intellectual disabilities and found that in general, these programs did not have clear outcome objectives, lacked theoretical underpinnings, had not been systematically evaluated, and the development of such programs did not involve consultation with relevant groups.",1
6,9,"It is essential to understand the lifecourse trajectory of ISB. In early childhood and prepubescence, the occurrence of these behaviors can have a significant impact on the development of friendships, familial relationships, social participation, and the individual’s inclusion in regular education settings. If ISB persists or escalates into adulthood, this behavior can further impact on the formation of social relationships, intimate relationships, home living, and community integration. If appropriate treatments cannot be found, these children could be at at-risk of sexual abuse, particularly given the increased vulnerability and risk for sexual violence that children with disabilities can face (Jones et al. 2012; Koller 2000).",1
6,10,"A search of the electronic databases PsycINFO, Education Resources Information Centre (ERIC), Education Research Complete, and PubMed was conducted in March 2014 by both the first and second authors. The search terms Bmasturbation, Bsexual behavior, and Bgenital stimulation were individually combined with the terms Bautism, BASD, Bdisabilities, Bdevelopmental disabilities, and Bintellectual disabilities. Entering a combination of the terms Bautism and Bsexual behavior into PubMed yielded the greatest number of results, with 122 articles. The combination of search terms Bsexual behavior and Bintellectual disabilities and Bautism and Bsexual behavior into PsycINFO resulted in 115 and 98 articles, respectively. This was the second and third most productive combination of search terms. In addition to the database searches, ancestry searches were conducted using the reference list of each article that was found. Finally, a search of Google Scholar was conducted using the aforementioned search terms in order to identify any literature that may have been overlooked. No additional articles were found as the result of searching Google Scholar or ancestry searching. Each of the articles identified as a result of the collective searches were examined in order to determine whether they met criteria for inclusion in this review.",1
6,11,The literature search was updated in May 2015 by the fourth author. This did not result in any additional articles but did reveal two potentially relevant papers (Early et al. 2012; Mallika et al. 2013) that were later excluded as they did not meet inclusion criteria.,1
6,13,"Twelve articles met the above inclusion criteria. The remaining articles were excluded as they did not include people with developmental disabilities, did not investigate treatments for ISB, or included participants who were older than 18 years of age. The 12 studies retained were evaluated and summarized according to the following criteria: (a) participants, (b) research design, (c) dependent variables, (d) independent variables, (e) measures and data collection, (f) treatment integrity, (g) results (including measures of generalization and maintenance), and (h) level of certainty",1
6,14,"For the purpose of this review, generalization of outcomes is defined based on the occurrence or non-occurrence of the target behavior under non-teaching conditions or when these teaching conditions are varied. This is derived from Stokes and Baer’s (1977) definition.",1
6,15,"The term treatment integrity is used to capture methods that were applied to ensure the intervention was implemented in the way in which it was intended. This includes recording inter-observer agreement (IOA) data, the provision of preintervention training for those implementing treatment, direct observation and recording of target behaviors, checklists to evaluate fidelity of implementation, and social validity checklists. Table 1 presents a summary of this information for each of the studies included in this review",1
6,16,Conclusive evidence describes those studies in which treatment outcomes are almost certainly true. Studies that provide conclusive evidence possess all of the methodological features of the studies that provide preponderant levels of evidence and also attempt to control for extraneous variables that may also account for treatment effects.,1
6,17,"In alignment with the procedure outlined in the Mulloy et al. (2010) review, the studies in this paper were coded according to whether the effects of treatment were positive, negative, or mixed. A positive effect was used to describe those within-subject design studies where all participants had positive treatment outcomes or there were statistically significant differences between groups in the group design studies. Mixed effects refer to those outcomes in which some participants demonstrated positive treatment effects, while other participants did not, and/or positive outcomes were identified for some but not all dependent variables. Negative effects describe those studies in which no treatment effects were noted for any of the participants in a within-group design, or the difference between groups was not statistically significant for those studies that employed a between groups design.",1
6,18,"In total, 18 articles were identified as possibly meeting criteria for inclusion in this review. In order to ensure the accuracy of the database search procedure, the first and second authors reviewed each of the 18 studies against inclusion and exclusion criteria. This resulted in 100 % agreement that 12 studies met review criteria. The remaining six articles were primarily excluded as they did not report on the treatment of inappropriate sexual behavior or they did not include individuals with developmental disabilities.",1
6,19,"Collectively, a total of 50 participants were included across the 12 studies. Butler and Fontenelle-III (1995) conducted a between groups study which included 30 participants. Coskun et al. (2009) conducted a single-case AB design study that included 10 participants. The remaining 10 studies included one participant each. The participants in the 12 studies consisted of three females and 47 males and ranged between 5 and 16 years of age.",1
6,20,"Twelve of the 50 participants included in this review had a diagnosis of ASD (Albertini et al. 2006; Coskun and Mukaddes 2008; Coskun et al. 2009), one child had moderate spastic hemiplegia, microcephaly, and severe mental retardation (Cook et al. 1978), one child had fixed encephalopathy and severe psychomotor retardation (Czyzewski et al. 1982), one child had a traumatic brain injury and seizure disorder (Fyffe et al. 2004), one child had Down syndrome (Polvinale and Lutzker 1980), and one child had a mild learning disability (Withers and Gaskell 1998). In the remaining studies, participants were simply described as having a level of intellectual disability, but further diagnostic information was not provided.",1
6,21,"The IQ of the participants was reported in five of the 12 studies (Albertini et al. 2006; Barmann and Murray 1981; Butler and Fontenelle-III 1995; Foxx et al. 1986; Polvinale and Lutzker 1980). IQ scores ranged from severe intellectual disability to being in the normal range for one of the participants with ASD. As so few studies reported the IQ of the participants, it is difficult to draw any conclusions regarding potential relationships between IQ, ISB, and response to treatment.",1
6,23,"Six of the 12 studies included in this review used a single-case experimental design (Barmann and Murray 1981; Cook et al. 1978; Czyzewski et al. 1982; Foxx et al. 1986; Fyffe et al. 2004; Polvinale and Lutzker 1980). Two of these studies included a multiple baseline across settings (Barmann and Murray 1981; Cook et al. 1978), one across time of day (Foxx et al. 1986), and one across settings and time of day (Polvinale and Lutzker 1980). Two of these studies used an ABAB reversal design (Czyzewski et al. 1982; Fyffe et al. 2004). The remaining studies used a simple AB design (Coskun et al. 2009; Luiselli et al. 1977; Withers and Gaskell 1998) or case report format (Albertini et al. 2006; Coskun and Mukaddes 2008). Only one of the studies employed a between groups design (Butler and FontenelleIII 1995).",1
6,24,"Two studies relied solely on the use of aversive procedures: one in the form of facial screening paired with negative feedback contingent upon the display of ISB (Barmann and Murray 1981), and the other aversive involved squirting lemon juice into the child’s mouth contingent upon public masturbation (Cook et al. 1978). It is noteworthy that following intervention, the participant in the Barmann and Murray (1981) study participated in a sex education program designed to teach people with disabilities to appropriately express their sexuality.",1
6,25,"Three of the studies identified used a pharmacological approach for the treatment of inappropriate sexual behavior. This included the use of antidepressant medications, which can reportedly result in sexual dysfunction (Gregorian et al. 2002). The medication prescribed in these three studies was mirtazapine (Albertini et al. 2006; Coskun and Mukaddes 2008; Coskun et al. 2009). Mirtazapine is a noradrenergic and specific serotonergic antidepressant (NaSSA) that has been used effectively in the treatment of clinical depression among adults and the elderly (Croom et al. 2008). There is also a tentative suggestion that mirtazapine may reduce some of the symptoms of ASD and other pervasive developmental disorders (Posey et al. 2001). Coskun et al. (2009) selected the use of mirtazapine as it was reported to have potential antilibidal effects.",1
6,26,"Public masturbation was identified as a focus of treatment in nine of the 12 studies (Albertini et al. 2006; Barmann and Murray 1981; Butler and Fontenelle-III 1995; Cook et al. 1978; Coskun et al. 2009; Czyzewski et al. 1982; Foxx et al. 1986; Luiselli et al. 1977; Withers and Gaskell 1998). In one of these studies, this also included the public display of genitalia (Barmann and Murray 1981). In three of the identified studies, one of the target behaviors included the inappropriate and uninvited sexual touching of another person (Butler and Fontenelle-III 1995; Coskun et al. 2009; Fyffe et al. 2004). In the two studies that provided group intervention, several target behaviors were identified. For example, in the Butler and Fontenelle-III (1995) study, the 30 participants who were the focus of intervention engaged in what was referred to as frequent and recurrent sexual acting out behavior. These behaviors included uninvited and inappropriate sexual touching of another person, public self-stimulatory behavior, exhibitionist behavior, and the inappropriate and public use of sexual language. In the Coskun et al. (2009) study, the target behaviors included public masturbation, inappropriate touching of others, public disrobing, arousal resulting from specific body parts or inanimate objects, and observation of others disrobing or bathing.",1
6,29,"Polvinale and Lutzker (1980) focused on three categories of behavior which they labelled (1) assaultive behavior (nonsexual), (2) inappropriate interpersonal sexual behavior, and (3) genital self-stimulation. No further definition of these behaviors was provided.",1
6,30,"Several standardized norm-referenced measures were used for general changes in behavior in some of the studies reviewed. For example, Albertini et al. (2006) administered the Child Autism Rating Scale (CARS) (Schopler et al. 1980) and Schema of Appraisal of Emotional Development (Dosen 2005) during the first clinical evaluation and then 6 months following treatment. Coskun et al. (2009) administered the Clinical Global Impressions-Severity (CGI-S) scale and Clinical Global Impressions-Improvement (CGI-I) scale at baseline and at the conclusion of their study in order to measure changes in ISB.",1
6,31,"Treatment integrity data was not reported in six of the 12 studies. Those that did not report treatment integrity data were Albertini et al. (2006), Butler and Fontenelle-III (1995), Coskun and Mukaddes (2008), Coskun et al. (2009), Czyzewski et al. (1982), and Withers and Gaskell (1998). Six of the studies collected IOA data over a proportion of phases (Barmann and Murray 1981; Cook et al. 1978; Foxx et al. 1986; Fyffe et al. 2004; Luiselli et al. 1977; Polvinale and Lutzker 1980). One of the studies reported on the procedures that were used to train those implementing intervention procedures (Barmann and Murray 1981), while another reported the data recording procedures (Czyzewski et al. 1982). Only Polvinale and Lutzker (1980) described social validity outcomes.",1
6,32,"Of the two studies which used aversive procedures in response to ISB (Barmann and Murray 1981; Cook et al. 1978), a decrease in ISB from baseline recordings was reported; thus, treatment effects were considered to be positive. In one of these studies (Cook et al. 1978), ISB ceased to occur following treatment, and in the Barmann and Murray (1981) study, a 98 % decrease in self-stimulatory behavior in the classroom, a 91 % decrease on the school bus, and a 92 % decrease in the home were reported.",1
6,34,"In the one study that used a group therapy approach (Butler and Fontenelle-III 1995), the effects of treatment were mixed. Data analysis revealed a significant reduction in sexual acting out behavior between pre- and post-test scores for the sexual intervention group. It was also evident that those in the sexual intervention group showed the most significant reduction in the target behavior when compared to the behavioral intervention and control groups. In the sole study that used an individual cognitive-behavioral intervention (Withers and Gaskell 1998), masturbation behavior decreased from 10–12 times per week prior to intervention to an absence of the behavior by the seventh and final treatment session.",1
6,35,"As 10 of the 12 studies included only one participant in their research design, few statistical analyses of findings were conducted. Butler and Fontenelle-III (1995) conducted an ANOVA to compare gains made between pre-test and posttest scores across treatment groups. Coskun et al. (2009) conducted Wilcoxon nonparametric t tests to measure the changes in CGI-S scores between baseline and post-treatment.",1
6,36,"Seven of the studies in this review included measures to assess the maintenance of treatment effects (Barmann and Murray 1981; Cook et al. 1978; Czyzewski et al. 1982; Foxx et al. 1986; Luiselli et al. 1977; Polvinale and Lutzker 1980; Withers and Gaskell 1998). This ranged from 2 weeks (Foxx et al. 1986) to 12 months post-treatment (Luiselli et al. 1977; Withers and Gaskell 1998). In each of these seven studies, the treatment effects were maintained following a period without intervention (Barmann and Murray 1981; Cook et al. 1978; Czyzewski et al. 1982; Foxx et al. 1986; Luiselli et al. 1977; Polvinale and Lutzker 1980; Withers and Gaskell 1998). Albertini et al. (2006), Coskun and Mukaddes (2008), Coskun et al. (2009), and Fyffe et al. (2004) did not report follow-up data.",1
6,37,"In summary, 11 of the studies reviewed demonstrated positive treatment effects. However, it is possible that some components of intervention when used in isolation (e.g., DRO) may not produce positive treatment outcomes (Polvinale and Lutzker 1980). The findings of these studies should also be interpreted in light of their procedural limitations.",1
6,38,"This systematic review identified 12 studies published between 1977 to 2009 that had examined the effectiveness of treatments for ISB in children and adolescents with developmental disabilities. The treatments for ISB included pharmacological and behavioral interventions, and each reported some positive treatment outcomes in the form of a decrease or elimination of ISB. Given the paucity of studies in this area and in conjunction with the limited number of participants in each study, the authors of this review are restricted in terms of the overall conclusions that are able to be drawn regarding potentially efficacious treatments for ISB.",1
6,39,"A number of limitations were identified in the research that warrants further discussion. Only one of the studies reached a conclusive level of certainty, with the majority of research studies identified as having a suggestive level of certainty. One of the primary reasons for this is due to the experimental design utilized in each of the studies. Several of the studies that were included in this review used a single-case AB research design (Coskun and Mukaddes 2008; Coskun et al. 2009; Luiselli et al. 1977; Withers and Gaskell 1998). This was the case for each of those studies that investigated the use of mirtazapine as a treatment for ISB (Albertini et al. 2006; Coskun and Mukaddes 2008; Coskun et al. 2009) and also the study that used cognitive-behavioral intervention (Withers and Gaskell 1998). While it is acknowledged that it can be unethical to implement a reversal design for behaviors of this nature, the use of an AB design in addition to other procedural limitations means that it is difficult to conclude that the positive treatment effects reported in these studies occurred as a result of intervention.",1
6,40,"In addition to the limitations associated with study design, the small number of participants that are included in each study threatens the external validity of the findings and makes it difficult to generalize the study outcomes across age, gender, disability, IQ, and sexual behaviors. While some of the research studies were strengthened by the use of a multiple baseline design, 10 of the 12 studies included only a single participant.",1
6,42,"It is noteworthy that many of those studies which provided behavioral treatment used time sample and frequency recordings in which IOA data were also gathered (Barmann and Murray 1981; Cook et al. 1978; Foxx et al. 1986; Fyffe et al. 2004; Luiselli et al. 1977; Polvinale and Lutzker 1980). As a result, these studies approached a preponderant or conclusive level of certainty and therefore showed promise as effective approaches to intervention for ISB.",1
6,43,"It is noted that in spite of an ideological shift in the way in which the sexual behavior of people with developmental disabilities is viewed, the approach to treatment of ISB between 1977 and 2009 remains relatively unchanged. The majority of treatment over this time period has been based on the principles of applied behavior analysis. The exception being three recent studies which have used medication as the treatment of choice (Albertini et al. 2006; Coskun and Mukaddes 2008; Coskun et al. 2009). The use of medication as a treatment for ISB needs to be considered carefully. Using medication without also teaching children and adolescents strategies to manage ISB may mean that medications are unable to be faded and therefore may not lead to sustained change in ISB.",1
6,44,"In addition to direct clinical implications, it is very important to consider the home and community impact of learning to refrain from ISB for children and adolescents with developmental disabilities. Given the way in which ISB can impact upon community access and engagement, social, familial, and intimate relationships, and school inclusion, it is essential to design and develop interventions for ISB for use across multiple settings or in which outcomes generalize across relevant settings. For example, intervention may focus on teaching functional alternatives to the ISB that can be applied in multiple contexts and across multiple people.",1
6,45,"As a final point, very few studies included female participants. Only three of the 50 participants collectively were female. It is recognized that there can be gender differences in the patterns of sexual behavior that are exhibited, though there is little research which describes the differences in the ways in which ISB is demonstrated in males and females. There are some suggestions, for typically developing children, that social and cultural factors and also anatomical differences may lead to referral biases in which males are referred more frequently for treatment than females (Mallants and Casteels 2008; Yang et al. 2005). The lack of research in this area makes it very difficult to draw conclusions about any gender differences in terms of the expression of sexual acting out behavior, the severity of ISB, and response to treatment. Furthermore, it raises the question of whether there are gender differences in terms of the rates and/or the manifestation or demonstration of ISB between males and females.",1
6,46,"In recent years, there has been an ideological shift away from viewing the sexual behavior of individuals with disabilities as pathological or deviant. In spite of this change in thinking, it remains that many individuals with disabilities have difficulty expressing their sexual behavior in an appropriate time, place, and manner. To date, there is a paucity of research that has investigated the efficacy of treatments for ISB in children and adolescents with developmental disabilities. It is essential that further methodologically sound research is conducted in order to enhance our understanding of evidence-based treatments for ISB. Providing effective treatment for this behavior has many important implications for social, developmental, community integration, and educational outcomes for this population.",1
7,2,"Understanding the value of testing and the use of testing as a learning device is critically important, especially with the growing use of high-stakes testing in education. What makes testing benefits particularly interesting is the differential impact of information learned during testing relative to information learned during an equivalent amount of time spent studying the material. For example, participants tend to remember information better if they complete a free recall test than if they simply study the material again (Karpicke & Roediger, 2008; Roediger & Karpicke, 2006a). While testing has robust and reliable benefits (see Delaney, Verkoeijen, & Spirgel, 2010; Karpicke, Lehman, & Aue, 2014; Roediger & Karpicke, 2006b, for reviews), there are also negative consequences of testing (see Malmberg, Lehman, Annis, Criss, & Shiffrin, 2014). For instance, retrieving a subset of studied items associated with a particular cue (e.g., category membership) during test can impair retrieval of other items from the same set (Malmberg, Criss, Gangwani, & Shiffrin, 2012; Roediger, 1973; Slamecka, 1968). A substantial negative consequence of testing is the finding that performance decreases over the course of a test list (Criss, Malmberg, & Shiffrin, 2011; Murdock & Anderson, 1975; Ratcliff & Hockley, 1980; Roediger, 1974; Roediger & Schmidt, 1980). This finding, termed Boutput interference (OI), has been modeled as the result of encoding during test by either updating existing memories with information gained during the test or adding new traces to episodic memory. Consequently, items that are tested toward the end of a test list suffer from additional interference generated by the information added to memory during the course of testing (Criss et al., 2011).",1
7,4,"The Annis et al. (2013) data demonstrate that retrieving from semantic traces does not add to the OI measured for an episodic task alone. However, it says nothing about OI occurring within a semantic task. Although the semantic and episodic memory systems dissociate in a variety of functional, pharmacological, and structural ways, the systems are heavily dependent on one another (Greenberg & Verfaellie, 2010; Nyberg & Tulving, 1996; Tulving, 1972). Semantic information contributes to the retrieval of episodic information (e.g., Howard & Kahana, 2002; Prince, Tsukiura, & Cabeza, 2007) and episodic experience primes performance on semantic tasks (Schooler, Shiffrin, & Raaijmakers, 2001; Jacoby & Dallas, 1981; Ratcliff & McKoon, 1997; Reder, Park, & Kieffaber, 2009). Moreover, semantic knowledge is necessarily episodic at one point (i.e., when the fact was initially learned; A. B. Nelson & Shiffrin, 2013; Mueller & Shiffrin, 2006; Schooler et al., 2001); however, through repeated exposure the information becomes more complete and decontextualized. The result is a more durable, semantic memory resistant to episodic interference (Tulving, 1972).",1
7,5,"The stimuli used for the experiment were 300 general knowledge questions developed by T. O. Nelson and Narens (1980) and revised by Tauber, Dunlosky, Rawson, Rhodes, and Sitzman (2013). The materials were adapted for use in a four-alternative forced choice recognition (4AFC) procedure by generating plausible foil items for each target response. Foil items were chosen based on semantic proximity to the target response as measured by latent semantic analysis (LSA; Landauer, Foltz, & Laham, 1998).1 Reasonable responses that were similar parts of speech, were not synonyms, were not another form of the response, and did not appear elsewhere in the stimulus set were selected. In instances where one or more foil responses were unable to be retrieved from LSA we used a simple internet search of the question and selected a response from amongst the top results according to the same constraints. The experiment was administered using MATLAB (R2011a) and Psychtoolbox v3.0 (Brainard, 1997).",1
7,6,"Test performance was analyzed using a Bayesian multiple linear regression developed by Kruschke (2011) and cross-validated with a frequentist regression. Interpretation of the Bayesian model parameters is identical to that of a typical regression from the frequentist tradition. We chose this approach because it allows us to quantify the amount of evidence in favor or against a null effect (e.g., Rouder, Speckman, Dongchu, Morey, & Iverson, 2009). The focus of our analysis was the change in performance acrosstest trials, specifically whetherthere is a nonzero slope for the performance change. Moreover, we examined whether the slope of performance across trials changed from Test 1 to Test 2.",1
7,7,"For each participant, the 150 test trials were binned into 10 blocks of 15 trials each. Entered into the regression model were standardized block-level performance data, block number (1:10), dummy-coded test number (Test 1 = 0, Test 2 = 1), and the interaction of block number and test number.",1
7,9,"The Savage-Dickey estimation of the Bayes Factor (B01) is the ratio of the likelihood of observing a zero slope in the posterior distribution relative to observing a zero slope in the prior distribution. A BF of less than 1 indicates that observing a slope of zero is more likely in the prior distribution and provides greater evidence in favor of the null hypothesis that OI is not present and that slope of the observed data is zero (i.e., β = 0). A BF greater than 1 indicates evidence in favor of the alternative hypothesis (i.e., β1 ≠ 0), that the slope of the observed data is credibly nonzero (i.e., β ≠ 0). The analyses were completed in R (v2.15; R Core Team, 2013) using the JAGS software (v3.1.0) and Brjags package (Plummer, 2013) for R",1
7,10,"The descriptive data and Bayesian modeling results for Test 1 and Test 2 are presented in Fig. 2. Visually, the data suggest that performance on Test 1 does not change across successive trials, whereas performance on Test 2 decreases across trial. The profile plotin Fig. 2a depicts performance for a giventest block (containing 15 test trials each) of Test 1. Indeed, the interaction term, representing the difference in slope of the Test 1 and 2 data, was negative indicating a bigger value for Test 2 (β = -.007, 95 % HDI: -.013, -.0004) and did not include zero as a credible value (BF01 = .341). Therefore, there is very strong evidence that the Test 2 performance declines over the test block and Test 1 does not change, with modest support for a difference between the slopes of Test 1 and Test 2.",1
7,11,"One possible explanation for the OI observed in Test 2 is that performance is a combination of searches of knowledge and recent memory, with the latter being more influenced by OI. To explore this possibility, we evaluated Test 2 performance conditionalized on the accuracy of the Test 1 response. If the Test 1 response was correct, then it is possible that the participant found the answer by a searching knowledge or, in rare cases, by correctly guessing. Under these conditions, OI may not be observed. If the Test 1 response was incorrect, participants may generate a correct Test 2 response on occasion by correctly guessing or by engaging a successful search of semantic memory that failed during Test 1. However, it seems reasonable that participants may also be relying on episodic memory for the Test 1 feedback to generate a correct Test 2 response, particularly given much higher accuracy for Test 2 than Test 1. Under these circumstances, OI should be observed.",1
7,12,"As can be seen in Fig. 3a, when participants answered a question correctly during Test 1, performance on Test 2 did not decline across test position. However, when the question was incorrect on Test 1, performance on Test 2 decreased substantially across test position (see Fig. 3b). These patterns are substantiated by the Bayesian analysis. Indeed, the interaction term, representing the difference in slope of Test 2 when the Test 1 response was correct or incorrect, was credibly positive indicating a steeper slope for the latter (β = .016, 95 % HDI: .0006, .031) and did not include zero as a credible value (BF01 = .148). Examining the simple slopes, the slope for Test 2 given the Test 1 response was correct was relatively flat (β = -.006, 95 % HDI: -.016, .005), and has an HDI that encompasses zero as a credible value. However, the evidence in favor of a zero value is ambiguous because it is nearly equal to evidence in favor of a nonzero slope (BF01 = 1.04). Thus, we can neither reject nor accept the null hypothesis in this instance.",1
7,13,"The Bayesian results were again substantiated by a frequentist multiple regression on the data aggregated across participant by Test Block and Test 1 accuracy indicating that Test Block and Test 1 accuracy explained a significant amount of variance in performance, F(3, 8) = 96.41, p < .001, R2 = .973, R2 Adjusted = .963). Moreover, the interaction of Test Bin and Previous Response was significant, β = .016, t(8) = 3.83, p = .005. The slope of the change in performance across Test Block for Test 2 was shallower when the Test 1 response was correct (β = -.006) relative to when the Test 1 response was incorrect (β = -.022)",1
7,14,"In the current data, we observed that the pattern of output interference (OI) changed depending on whether it was the first or second time the set of questions had been answered. Specifically, no OI was observed during the initial test, but a robust OI effect was observed during the second test – after participants had received corrective feedback. Moreover, this OI was largely restricted to those questions for which the Test 1 response was incorrect. During the initial test, in the absence of recent episodic experience with the factual information, it is reasonable to presume that participants are searching knowledge (i.e., semantic memory), yet we observed no OI for Test 1. Participants could have recent experience with some of the information and, as a result, search episodic memory during Test 1, but such an occurrence would likely not be systematic. Critically, no OI was observed for Test 1. During the second test, it is reasonable to presume that participants are likely answering questions using a combination of knowledge and recent experience. For questions that were answered correctly during Test 1, participants could rely on knowledge as they presumably did during Test 1, to retrieve the correct answer. Of course, they could also search episodic memory. For questions that were answered incorrectly on Test 1, participants could rely on the episodic memory of the corrective feedback from Test 1 in order to answer Test 2. Of course they could also search knowledge, thought this is unlikely to lead to a correct answer given that it failed during Test 1. Importantly, Test 2 demonstrated a robust OI effect that was largely isolated to questions answered incorrectly during Test 1. We suggest that this indicates that OI is most pronounced for episodic memory.",1
7,15,"We therefore suggest that the best explanation of the data is the differential reliance on episodic and semantic memory to correctly answer questions. Episodic memory may be more susceptible to the sort of interference generated during testing (e.g., gradual changes in context, encoding/updating of items), whereas semantic memory is less so. Interestingly, attempting to reinstate encoding context, as suggested by many textbooks based on classic memory research (e.g., S. M. Smith, 1979) as a useful strategy for test taking, may be detrimental for tests intended to measure knowledge. That is, focusing on episodic retrieval using context information allows for interference from other information that matches the same context.",1
7,16,"In summary, we found that successive searches of knowledge do not suffer from OI using a set of general knowledge questions. However, OI was robust when participants presumably completed the test of knowledge by relying on episodic information, namely corrective feedback, provided during Test 1. These data provide potential constraints on the relationship between episodic and semantic memory",1
8,1,"The publication of this issue of Psychological Studies coincides with two important occasions that indicate the progress and development of psychology both as a field of study and research endeavor. First, Calcutta University is celebrating the centenary of Psychology Department which came into existence in the year 1915. Second, this journal is completing 60 years of its publication. These two events showcase the expansion and advancement of psychology in India in the last one century. Further, I am completing 15 years as Editor of this journal of the National Academy of Psychology (NAOP) India. Editing this journal has been a challenging and enriching experience for me. Significantly this task demands a consistent, sustained and collaborative effort. I could accomplish this responsibility with the timely help and support from the community of scholars. On account of personal reasons I found it extremely difficult to continue as Editor and the executive body of the NAOP kindly agreed to my request. I take this opportunity to express my sincere thanks to the NAOP officials and NAOP community for the conviction and trust shown during my tenure. The reviewers , associate editors and consulting editors of the journal have extended full support in editorial process. The administrative and production teams at Springer always helped in organizing the publication process.",1
8,2,"The last few decades have witnessed tremendous expansion of the discipline of psychology in many directions. It has happened in the domains of theory, research and practice. While psychometric, clinical and organizational subfields have continued to receive research attention a small but strong segment of researchers is showing change in their research agenda and increasingly engaging with indigenous concepts and methods. The choice of research issues and problems is showing greater degree of cultural sensibility",1
8,4,"In addition to regular articles the present issue of Psychological Studies includes a stimulating target article by Adrian Brock on Diversity and Presentism in the History of Psychology. It is followed by commentaries by several scholars including Jaan Valsiner and Svend Brinkmann, Christiane Hartnack, Anand Paranjpe and Nick Hopkins. Finally, there is a rejoinder by the author Adrian Brock. I hope the discussion will bring in new ideas and invite further work towards situating the discipline in proper socio-historical and cultural context. The issue also contains many other articles that attend to issues in the Indian context. Taken together the articles strengthen the endeavor to bring cultural sensibility to the center stage of psychological discourse.",1
8,5,"As I look back, my only regret is that we did not have an opportunity to be more innovative in handling the manuscripts. Attempts have been made to reduce the publication lag. The support from my associate editors and reviewers has facilitated the publication procedure. I hope that the process may be planned more effectively and creative use of the journal may be enhanced. The potential for improvements in the publication process is always present. We are very fortunate in having Professor Damodar Suar assuming the editorship of Psychological Studies. It is hoped that under the able editorship of Professor Suar the journal will continue to promote psychology. In addition to being a productive researcher he has been serving as Associate Editor of the journal. He is familiar with the functioning of the journal. I welcome him and his team. With Professor Damodar Suar as Editor the journal is in excellent hands. I wish him success in his endeavor.",1
9,1,"Whereas retrospective studies suggest that crying can be beneficial in terms of mood enhancement, results of quasi-experimental laboratory studies consistently demonstrate its negative effects on mood. The present study was specifically designed to evaluate a parsimonious explanation for this paradox by assessing mood after crying in a laboratory, both immediately and at follow up. Mood ratings of 28 objectively established criers and 32 non-criers were compared before and immediately after the exposure to an emotional movie, as well as 20 and 90 min later. As expected, immediately after the film, negative mood significantly increased in criers, while it did not change in noncriers. This mood deterioration was followed by a recovery that resulted in return to the baseline mood levels at the third measurement. Criers subsequently reported mood enhancements at the final measurement compared to the pre-film measurement. Crying frequency did not predict mood changes above those predicted by the presence of crying. The observed relation between crying and more long-term mood recovery reconciles seemingly contrasting earlier results and provides a simple and obvious explanation. After the initial deterioration of mood following crying that was observed in laboratory studies, it apparently takes some time for the mood, not just to recover, but also to become even less negative than before the emotional event, which corresponds to the results of retrospective studies.",1
9,2,"Humans are the only species having the capacity to shed emotional tears, a behavior that is very common and present in all cultures (Trimble 2012; Vingerhoets 2013; Vingerhoets and Bylsma 2015). Nevertheless, it has received little attention of researchers and the understanding of its functions is still very limited. Theories on the functions of crying can be classified into two global categories (Vingerhoets 2013; Vingerhoets et al. 2009). The first one emphasizes the putative intra-individual benefits of crying, the catharsis effect. According to this view, crying facilitates recovery and homeostatic processes. The alternative view emphasizes the inter-individual functions of crying, which are represented in the communication of one’s helplessness and need for support, and whose effects are evident in elicitation of comfort and succor (Hasson 2009). These two positions are not mutually exclusive but rather supplemental, because receiving comfort and emotional support may also contribute to an increased well-being after crying. Seen from a stress theoretical perspective, crying may be considered as a kind of coping behavior, serving several functions, ranging from facilitation of emotional recovery to an ultimate effort to persuade others to do something about the situation (Vingerhoets 2013).",1
9,3,"When trying to explain these seemingly discrepant findings, some critical methodological issues need to be taken into account. In retrospective studies, participants are generally free to choose which crying episodes they describe. It has been suggested that such a design leaves the possibility that participants preferred to report crying experiences that fit the popular notion that one feels better after having cried (Cornelius 1997). An additional problem in these retrospective studies is that it is not possible to precisely define the time interval between the crying episode and the reported feeling. Participants are usually asked to report how they feel after having cried, without specification how they felt immediately, 10 min or 1 h after crying. One may, of course, wonder whether that would make any sense, that is, whether it is possible for participants to remember exactly the time course of their mood changes. However, it nevertheless could be that, after having cried, people typically first experience a dip in their mood, which is subsequently logically followed by a mood improvement. We currently simply lack the necessary information about the precise time course of mood changes after crying that would help us to understand the popular postulate of emotional recovery that follows tears",1
9,4,"The present study has been especially designed to examine the immediate and delayed effects of crying on mood in a laboratory setting. To increase generalizability and validity, we decided to use stimuli that provoke tears through a wide spectrum of negative and positive emotions. In accordance with the results obtained in previous laboratory studies (Cornelius 1997), we predicted that increases in negative mood (here termed as negative affect, NA) immediately after the potential crying–eliciting films would be more pronounced in participants who cried than in participants who did not cry. Furthermore, based on the results of previous retrospective studies, we anticipated that at the delayed mood measurements, participants who cried would experience greater mood improvement compared to participants who did not cry, both in terms of recovery after initial mood deterioration and of overall mood improvement (i.e., compared to the pre-film baseline values). We also anticipated the presence of a dose–response relationship between frequency of crying episodes and the changes in NA during the same time sequences.",1
9,5,The initial sample consisted of 46 female and 26 male students (age range 19–33; M = 23.80; SD = 3.19) who received course credits for participation. All participants provided written informed consent. Six participants were excluded from the analyses because of missing behavioural data due to equipment failure or because of incomplete questionnaire data.,1
9,6,"NA was assessed using the shortened version of the Emotional States Scale (Kardum and Bezinovic? 1992), containing 18 items on a five-point Likert scale ranging from 1 (I do not feel this way at all) to 5 (I feel this way completely). The items were: nervous, bad tempered, anxious, weepy, tense, guilty, helpless, sad, angry, miserable, rejected, fearful, cheerful, generous, relaxed, calm, active and merry (last six items reversely keyed). The scale showed adequate internal consistency, with the Cronbach’s alphas over the four measurements ranging from .77 to .84",1
9,7,"Participants were individually seated in a sound attenuated room approximately 60 cm from a 19 in. monitor, speakers and video-camera. After having signed the informed consent form, they completed the first mood rating (T1), which was immediately followed by the random exposure to one of the two films. After having watched the film, participants first filled in a short questionnaire about their emotional responses to films that is not in the scope of this study. This was followed by the second mood measurement (T2) after which they were accompanied by the experimenter to another room. After they had filled in additional questionnaires also not in the scope of this study, 20 min following T2 participants completed the mood questionnaire for the third time (T3). After being shortly debriefed, participants were given additional instructions and a closed envelope containing the mood scale which they were requested to complete and return immediately after having received an SMS message via mobile phone. Each participant left the laboratory 120 min after the beginning of the experiment. The fourth mood measurement (T4) took place 90 min after the second one and 60 min after the participants left the laboratory. Participants were not given any instructions how to behave during the 60 min after leaving the laboratory and before T4. The answers to the T4 measure were sent to the experimenter via text messages in which participants returned 18 numbers representing their responses on the mood scale items.",1
9,8,"First, independent samples t test, Chi square tests, and Pearson correlation coefficients were calculated to test the relations between all the relevant variables, in order to test for the existence of possible confounding variables that have to be controlled for. Next, in order to examine whether the groups of participants who cried and who did not cry differed in changes in NA between the four measurements, a 4 9 2 mixed ANOVA was performed with time period as a within-subjects factor (measurements at T1, T2, T3 and T4), group (non-crying and crying) as betweensubjects factor, and age and gender as covariates. Changes within the groups and between specific measurements were analyzed by comparison of NA between points in time for which the hypotheses were made: between (1) T1–T2 (expected mood deterioration), (2) T1 and T4 (expected overall mood enhancement), and (3) T2–T4 (expected recovery), by using two separate within-subjects ANOVAs (for each group), and Bonferroni post hoc tests. To validate the possibility that low mood in criers stimulated (successful) mood enhancing behaviors, we also performed an additional ANOVA by including NA change from T1 to T2 as a covariate.",1
9,10,"A significant main effect of time [F(3, 53) = 5.64; p = .002; partial g2 = .09] and a significant time 9 group interaction [F(2, 36) = 5.11; p = .003; partial g2 = .08] were found—see Fig. 1—confirming our hypothesis about the different course of mood changes in the crying and noncrying group. No main effect of the group [F(1, 55) = .83; p = .365; partial g2 = .02] was observed.",1
9,11,"To better understand the observed interaction two separate ANOVAs were performed in order to test whether there was a significant mood change in each of the two groups (p set to .025). There was no significant overall change in NA in the group of non-criers throughout the four measurements [F(3, 27) = 1.20; p = .311; partial g2 = .04]. However, in the group of criers, a significant effect of time was observed [F(3, 23) = 3.95; p = .021; partial g2 = .34]. Post hoc comparisons (Bonferroni correction) revealed that NA increased from T1 to T2 (p\.001), and decreased from T2 to T3 and from T2 to T4 (p\.001), thus supporting our hypotheses about initial deterioration and subsequent recovery of mood in criers. Most importantly, however, the decrease in NA from T1 to T4 in this group was also significant (p = .013), thus supporting our hypothesis about the overall mood improvements following crying. Finally, the predicted decreases in NA remained significant (recovery: p\.001; overall mood improvement: p = .007) when NA change from T1 to T2 was included as a covariate in an additional ANOVA.",1
9,13,"Perhaps it is in particular the strong mood improvement experienced by those participants who cried that fuels the popular notion that crying brings relief. It is obvious that decreases in NA from T2 to T4 and from T3 to T4 in participants who cried are mainly the consequences of previous (i.e., T1–T2) NA increases, that is, the return to baseline levels. This finding may explain why people report mood improvement after crying: those who cried indeed experience greater mood changes, be it after an initial deterioration. Such strong mood recovery, as well as the observed return of NA even to below baseline levels thus seems to support the hypothesis about the cathartic effects of crying. These findings are in accordance with both of our hypotheses about the negative effects of crying over the short run and about mood increases that follow crying over the longer run. On a more general level, these findings can be compared to the short-term negative and long-term positive effects of the expression of emotion on mood and well-being (Pennebaker 1997; Smyth 1998). However, the question remains whether these long-term mood-enhancing effects of crying and of other types of emotion expression are mediated by the same cognitive, physiological, or behavioral mechanisms.",1
9,14,"One could argue that the observed general decline in NA reported by criers at the final measurement is the consequence of increased tension and nervousness of the study participants at the beginning of the experiment, due to the fact that they are in a new and uncertain situation, rather than being the result of crying. However, if this mood improvement is considered as a kind of return to the (preexperiment) baseline level, it remains unclear why noncriers did not end up with improved mood at the final relative to the first measurement. Also note that both groups did not differ in NA at T1.",1
9,15,"A final critical and still unanswered question is whether the observed decreased NA really reflects a different mood state, induced by the crying, or that it reflects a kind of response shift, a phenomenon, which is well-known in the literature on quality of life in cancer patients. Repeatedly it has been found that cancer patients report a better quality of life than before their disease, when comparing their absolute scores on quality-of-life measures. However, when being asked to compare directly their current quality of life with before their disease (as is also done in retrospective studies on mood changes after crying), they indicate unanimously that their current state is worse than before their disease (Schwartz and Sprangers 1999). This response shift might be the result of changes in internal standards, conceptualization of the concepts, and/or one’s values. This methodological issue certainly needs adequate consideration in future studies, for example by including a measure asking participants to compare directly their current mood state to the pre-film measurement. For future studies, we also suggest to pay an additional attention to factors that influence the memory of emotional events and mood, to stable individual differences related to affect intensity and variability, as well as to mood regulation processes.",1
9,16,"In conclusion, the present findings suggest a simple, obvious, and parsimonious explanation for the paradoxical findings of different studies investigating the effects of crying on mood. After the initial deterioration of mood following crying that is usually observed in laboratory studies, it takes some time for the mood, not just to recover, but also to increase above the levels that it had before the emotional event, a pattern of findings which corresponds to the results of retrospective studies.",1
10,1,"Transient brain responses to cues indicating the potential for reward may not be the only mechanism that links incentive information to enhanced cognitive control. It is possible that information about potential rewards may change cognitive processing and brain activity during the entire task in a more sustained fashion. A more recent line of research has examined state-dependent reward context effects on cognitive control, providing evidence for the presence of motivation-related Bstate effects on cognitive function, as evidenced by increased sustained activations across blocks of trials with incentive information (Engelmann et al., 2009; Jimura et al., 2010; Locke & Braver, 2008). For example, in a study by Engelmann et al. (2009) using a Posner-type task in which cues indicated the location of the face target stimulus, motivation was manipulated in a blocked fashion by varying the valence (e.g., winning, avoiding loss) and magnitude of the rewards associated with task performance (e.g., winning $1 or $4, or avoid losing $2.5 or $0). They found that in several regions in a fronto-parietal attentional network (i.e., the posterior intraparietal sulcus, middle frontal gyrus, the caudate, and putamen), cue-related responses were modulated by the incentive values. Importantly, they also found that several regions thought to be involved in the control of attention (e.g., the intraparietal sulcus and middle frontal gyrus) showed increased sustained activations across the course of blocks with greater incentive values. These results suggest that the enhancing effects of rewards on cognitive control can be evidenced in at least two ways: by (1)increases in cue-related responses, and (2)increases in sustained responses.",1
10,2,"Importantly, providing rewards or incentives does not lead to changes in behavioral performance and brain activity in all individuals. A growing body of research suggests that individual differences in reward-related sensitivity may modulate behavioral and neural responses to either primary (e.g., food) or secondary (i.e., monetary incentives) rewards (e.g., Beaver et al., 2006; Cooper, Duke, Pickering, & Smillie, 2014; Jimura et al., 2010; Locke & Braver, 2008). Specifically, several studies have reported associations between individual differences in reward-related personality traits and reward-related neural activations (e.g., Beaver et al., 2006; Cohen, Young, Baek, Kessler, & Ranganath, 2005; Cooper et al., 2014; Jimura et al., 2010; Locke & Braver, 2008). For example, Beaver et al. (2006) found that individual differences in Behavioral Inhibition and Behavioral Approach Systems (BIS/BAS) drive scores (i.e., items asking about the pursuit of goals) were significantly associated with neural responses to appetizing relative to bland foods in the ventral striatum and orbitofrontal cortex. Cohen et al. (2005) found that when participants received immediate monetary rewards during a gambling task, people higher in extraversion showed a greater magnitude of neural response related to reward receipt versus no reward in the right medial orbitofrontal cortex, amygdala, and right nucleus accumbens. More recent work by Jimura et al. (2010) also showed positive associations between sustained DLPFC activations during reward context and reward sensitivity from the BAS. Thus, personality traits related to reward drive and sensitivity may be factors for understanding individual differences in incentive effects on cognitive control.",1
10,3,"However, another less explored individual-difference factor related to reward processing is anhedonia. Anhedonia is defined as a reduction in the ability to experience pleasure. Experiencing rewards as positive or pleasurable maybe a critical factor that induces approach behavior toward goals and positive emotional states (e.g., as is reviewed in Gorwood, 2008). Even nonclinical populations show individual differences in anhedonia (see, e.g., Franken, Rassin, & Muris, 2007; Harvey, Pruessner, Czechowska, & Lepage, 2007). Individuals who experience rewards as being less pleasurable may be less Bmotivated to modulate their behavior in order to enhance the likelihood of achieving such rewards. As such, individuals who self-report higher levels of anhedonia may show less improvement in cognitive control as a function of reward, and potentially less modulation for incentive-related brain activity, though it is less clear whether anhedonia may influence transient or sustained modulation of brain activity, or both.",1
10,4,"The purpose of this study was first to replicate prior work examining the neural mechanisms that mediate an enhancing effect of rewards on cognitive control, by examining sustained as well as incentive cue-related effects on cognitive control using a mixed state-item fMRI design. We focused on the DLPFC and the striatum, given prior research suggesting their involvement in mediating the influence of rewards on cognitive control. We modified a response conflict processing task originally developed by Padmala and Pessoa (2011) to fit in a mixed state-item design. The state-item fMRI design enabled us to examine sustained context-dependent effects and transient reward-related cue effects in the same study. Participants first performed baseline conditions without knowledge of the potential for incentives in future blocks. Participants then performed additional reward blocks on which they were told that they could win money on some trials (rewarded trials) by performing quickly and accurately. This variant of the paradigm enabled examinations of (1)reward context effects, by comparing performance and brain activity during the baseline versus the reward context, and (2)reward cue effects, by comparing performance during reward versus no-reward trials within reward blocks, as well as trials during the baseline blocks. We predicted that motivational states induced by reward contexts would produce greater sustained activity in the DLPFC than would those in nonincentive baseline blocks. We also predicted that incentive cues would generate increased transient neural activity in both reward-related cortical and subcortical regions.",1
10,5,"Second, we wanted to test the hypotheses that individual differences in self-reported anhedonia would moderate the influence of rewards on cognitive control, with higher levels of self-reported anhedonia being associated with less of an improvement in performance as a function of reward, as well as with less of an increase in the activity of the DLPFC and/or striatum in response to reward information, in terms of either sustained or transient activation (or both). To test these hypotheses, the present study included two measures of trait anhedonia: the Snaith–Hamilton Pleasure Scale (Snaith et al., 1995) and the Social and Physical Anhedonia Scales (Chapman & Chapman, 1978; Eckblad, Chapman, Chapman, & Mishlove, 1982).",1
10,6,"All participants had no personal or family history of psychiatric or neurological disease. All participants were recruited through the Conte Center for the Neuroscience of Mental Disorders at Washington University in St. Louis and provided written informed consent. The study protocol was approved by the Washington University Human Research Protection Office. Participants received a maximum of $20 reward money that depended on their correct and fast behavioral performance, in addition to money for completing the experiment ($25/h).",1
10,7,"As is presented in Fig. 1c, the baseline blocks consisted of two runs in which three different types of trials (i.e., congruent, incongruent, and neutral) were intermixed, with 18 trials per trial type (total of 54 trials). Each task block started with a start cue, BTASK, and ended with an end cue, BDONE, each presented for 2 s. After each start cue was a jittered period ranging from 0 to 4 s. During the baseline blocks, each trial started with an BXX cue for 1 s, with prior instruction to the participants indicating that these cues were not relevant to the task. Then a jittered fixation period occurred, ranging from 2 to 6 s before the onset of the stimuli, to allow for estimates of event-related responses to the cues. The target stimulus was next presented for 1 s, which was followed by a delay of 0.5 s, during which time the participants responded. Participants were then provided with visual feedback indicating whether their performance was correct or incorrect, for 1 s. Finally, there was an intertrial interval (ITI) that varied between 2, 4, and 6 s.",1
10,8,"After the two baseline runs, participants performed four additional runs, for which they were instructed that they could win money on some trials for their correct and fast responses, as is presented in Fig. 1d. The reaction time (RT) threshold to determine Bfast responses was set individually on the basis of the median correct RT for the second baseline run. During reward runs, half of the trials were preceded by a B$20 cue (reward cue: RC), indicating that a fast and correct response would be rewarded by 2,000 points, or by an BXX cue (reward context: RCXT), indicating that zero points would be possible on the trial. A total of 108 trials were presented, with approximately equal numbers of congruent, incongruent, and neutral trials. After the target stimulus, participants received feedback regarding the reward points they had earned on that trial, as well as their cumulative earning in points. The accumulated points were converted into real money at the end of the experiment (with a maximum of $20)",1
10,9,"All imaging data were preprocessed and analyzed using inhouse Washington University software (the FIDL analysis package: www.nil.wustl.edu/~fidl/). The first four images of each run were discarded to allow for signal stabilization. The functional-imaging data preprocessing included (1)correction for slice-dependent time shifts; (2)removal of the first four images of each run; (3)elimination of odd/even slice intensity differences due to interpolated acquisition; (4)realignment of the data to compensate for rigid-body motion; (5) normalization of image intensity to a whole-brain mode value of 1,000; (6)registration of the 3-D structural volume (T1) to the atlas template in the Talairach coordinate system, using a 12-parameter affine transform and resampling to a 1-mm cubic representation (Buckner et al., 2004; Ojemann et al., 1997) ; (7) coregistration of the 3-D fMRI volume to the T2, and the T2 to the structural image; (8) transformation of the fMRI data to a 3 × 3 × 3 mm voxel atlas space, using a single affine 12- parameter transform; and (9) spatial smoothing using a 6-mm full-width at half-maximum Gaussian filter. We assessed head movement during scanning by using the output of the rigidbody rotation and translation algorithm. The translations and rotations in the x, y, and z planes across frames and the total root-mean-square (RMS) linear and angular precision measures were calculated for each run. If the standard deviation of the RMS movement exceeded 20, the BOLD runs were not included in the analysis [RMS/frame, as mean (SD): 27 participants = 0.15 (0.07)].",1
10,10,"Repeated measures ANOVAs were conducted on the median RTs for correct trials and accuracy, with the within-subjects factors Reward (BCXT, RC, RCXT) and Trial Type (congruent, incongruent, and neutral). Post-hoc paired ttests followed, used to determine the source of significant interactions. A behavioral index of reward context effects was estimated by subtracting the RT on RCXT trials, cued by BXX, from that on BCXT trials, with the same cue, BXX. An index of reward cue effects was computed by subtracting the RT on RC trials, cued by B$20, from that on RCXT trials, cued by BXX within the same reward conditions. These behavioral indices of reward context and cue effects were used in a Pearson correlation analysis to examine the associations between individual differences in anhedonia trait and behavioral enhancements of rewards on cognitive tasks.",1
10,11,"We used voxel-wise paired ttests to analyze the sustained estimates, with Reward (baseline, reward) as the withinsubjects factor. For cue-related activity, we conducted a voxel-wise repeated measures ANOVA with Reward (BCXT, RCXT, RC) and Time Point (the eight time frame estimates for the hemodynamic response) as within-subjects factors. We focused on regions showing interactions with time point, due to our use of unassumed GLMs. Post-hoc ANOVAs and ttests were performed within all significant regions identified by the ANOVAs, as we described above. For these post-hoc analyses, we extracted the mean percent signal change across each region for each time point out of the eight estimated time points, to visualize the pattern of activity. For the statistical analyses, we focused on Time Point 4, because this time point encompassed 7–8 s after stimulus onset, which corresponded to the initial peak in a stereotyped hemodynamic responses, unconfounded by sustained activity. This was done for each applicable cue type and trial type effect. We then conducted post-hoc paired ttests to compare the three trial types, to parse the significant cue-related and condition-related effects.",1
10,12,"For target-/receipt-related activation, we conducted two separate repeated measures ANOVAs. The first ANOVA ignored trial type (i.e., congruent, neutral, incongruent) and compared activation in the target phase across trials that could or could not earn reward in either the baseline or the reward blocks (i.e., Reward: BCXT, RCXT, or RC). Post-hoc paired t tests at Time Point 4 (i.e., BCXT–RC, RC–RCXT, BCXT– RCXT) were conducted to follow up on any significant effects. To attempt to replicate previous findings from prior work by Padmala and Pessoa (2011), another repeated measures ANOVA also included trial type (i.e., congruent, neutral, incongruent) and compared activation in the target phase across trials with activation in the reward context when participants could or could not earn reward, with Reward Context (i.e., BCXT, RC), Trial Type (i.e., congruent, neutral, incongruent trials), and Time Point as within-subjects factors.",1
10,13,"We constrained our analyses to a priori masks within the DLPFC and BG, given the involvement of these regions in reward processing (see, e.g., Jimura et al., 2010; Locke & Braver, 2008). We used anatomically defined masks of voxels within the DLPFC (Rajkowska & GoldmanRakic, 1995) and BG (Wang et al., 2008). Voxel-by-voxel neuroimaging analyses were conducted within these masks. All statistical activation maps from these masks were corrected for multiple comparisons using combined p-value and cluster thresholds, determined by the AlphaSim program in the AFNI software package. The DLPFC mask (Brodmann’s areas 9 and 46) included both left and right middle and superior frontal gyri according to anatomical landmarks (Rajkowska & GoldmanRakic, 1995). For the DLPFC mask, we used as thresholds a z value of 2.05 and 13 voxels. The BG mask was based on Wang et al. (2008) and was generated by combining the caudate, nucleus accumbens, putamen, and globus pallidus together. We applied a z value of 2.05 and a 14-voxel threshold for the BG mask. Then we used information about the centroid of activation in these identified subregions to label them as a specific area. For any follow-up analyses to identify the sources of significant effects and further correlations analyses, as described above, we extracted the average of the BOLD response values of the voxels within the identified subregions within the mask regions and imported them into SPSS.",1
10,14,"We examined whether individual differences in anhedonia predicted behavior and/or the degree of brain activations as a function of rewards in the regions of interest (ROIs) that showed sustained reward and transient cue effects within each DLPFC and BG mask. We examined whether either of the following individualdifference measures predicted behavior, the magnitude of sustained brain activation during reward versus baseline contexts, or transient activation during RC versus RCXT trials: (1)total SHPS scores and (2)a composite score of the Chapman social and physical anhedonia scores (z-scored and then combined into one composite score). The brain–personality trait correlations were corrected by using the same smallvolume procedures described above.",1
10,15,"The analogous ANOVA on the error data indicated a significant main effect of trial type [F(2, 52) = 13.91, p < .001, ηp 2 = .35], reflecting more errors on incongruent than on congruent trials [F(1, 26) = 16.36, p < .001, ηp 2 = .38]. We observed no significant main effect of reward [F(2, 52) = 1.20, p = .31, ηp 2 = .04] and no significant interaction of reward and trial type [F(4, 104) = 0.83, p = .51, ηp 2 = .03]. Given the lack of a significant main effect of reward on the error data, further analyses were focused on the RT data.",1
10,16,"Individuals reporting greater anhedonia on the Chapman scales showed less cue-related activation as a function of reward-predicting cues in the lateral globus pallidus (r = –.54, p = .003; see Fig. 5A for a scatterplot), an effect that passed Bonferroni correction (.05/6). We saw a similar relationship in this region to self-report of hedonic tone on the SHPS, with greater hedonic tone being associated with greater cue-related activation as a function of reward-predicting cues in the lateral globus pallidus (r = .45, p = .02; see Fig.5B), though this correlation did not pass Bonferroni correction.",1
10,17,"Regions in the DLPFC and the BG that displayed a significant reward context effect showed two patterns of results (see Table 4). In the top panel of Table 4, regions in the DLPFC and the BG show reduced target-related activation on RC relative to RCXT or BCXT trials. For example, in the medial portion of the right DLPFC (BA 9: x = 26, y = 37, z = 29), target-related activation on RC and RCXT trials was significantly reduced relative to BCXT trials. Interestingly, in several subcortical regions, such as the lateral globus pallidus, targetrelated activity at Time Point 4 did not differ among rewardrelated types. However, the source of the significance effect was observed at Time Point 7, with a greater degree of deactivation on RC than on BCXT and RCXT trials (see Fig. 6 for time courses from the DLPFC and BG regions displaying Reward Context × Time Point effects in the target phase). In the bottom panel of the same table, a different set of larger, more lateral, and more posterior regions in the DLPFC showed greater activation on RC relative to BCXT trials (see Supplemental Fig. 2 for the time courses of each region in the DLPFC).",1
10,18,"In the present study, activation was increased in response to incentive cues versus no-incentive cues in bilateral DLPFC and in several reward-related subcortical regions, such as the lateral globus pallidus and caudate. These results are in line with prior work (e.g., Padmala & Pessoa, 2011; Vassena et al., 2014), which also showed transient increases in a distributed network of several regions, including the lateral PFC and parietal cortex, that are thought to be engaged in cognitive control (Owen, McMillan, Laird, & Bullmore, 2005; Wager & Smith, 2003).",1
10,19,"The DLPFC has traditionally been considered a core component of cognitive control, as we described in the introduction. Recently, accumulated evidence has suggested that the DLPFC represents reward-related value information as well as Bcold information about task goals (see Dixon & Christoff, 2014, for a recent review). Furthermore, anatomical evidence has shown that the DLPFC is strongly connected with key regions involved in value representations, such as the orbitofrontal cortex and the anterior cingulate cortex (Pandya, Van Hoesen, & Mesulam, 1981; Petrides & Pandya, 1999, 2007). Also, the DLPFC (BA 9/10) projects to the BG, including the caudate nucleus and the globus pallidus. Projections from these striatal regions terminate in the thalamus, which in turn projects back to the DLPFC and to premotor and motor cortices (Joel & Weiner, 1994, 1997). With regard to this circuit of anatomical connections, the increased DLPFC and striatal activations in response to incentive cues might reflect enhanced neural representations of reward value through a top-down regulation of activations in this circuit.",1
10,20,"Several regions in the BG also showed greater sustained activity during reward contexts. The present results extend prior work by suggesting that regions in a fronto-parietal network can show sustained increases with regard to reward information. For example, both Jimura et al. (2010) and Locke and Braver (2008) found sustained increases in the parietal cortex as well as the lateral PFC during reward contexts, but did not find effects in the BG. However, in the present study we conducted a hypothesis-driven analysis using an a priori ROI approach, whereas the previous studies had used voxelwise whole-brain analysis. It is possible that this ROI approach offered greater power to detect sustained effects in both prefrontal and striatal regions (Nieto-Castanon, Ghosh, Tourville, & Guenther, 2003). This sustained activity may be reflective of BG’s hypothesized role in reward-based learning and goal-directed behavior (Dasgupta, Worgotter, & Manoonpong, 2014; Schultz, Tremblay, & Hollerman, 1998). Especially, the dorsal striatum is known to receive extensive projections from the DLPFC as well as other frontal regions. Thus, increased sustained activity in the dorsal striatum during the reward context may have represented greater effort to maintain reward-related context information, which may facilitate preparatory responses throughout reward contexts.",1
10,21,"In the present study, we found that people reporting greater trait anhedonia showed less neural activation as a function of reward-predicting cues, but that there was no significant association between anhedonia and sustained context-dependent activation during reward contexts. These results are consistent with the hypothesis that anhedonia, or reductions in the ability to experience pleasure, may influence the degree to which the experience of rewards (or Bliking) influences modulations of brain activation or behavior in response to the explicit presentation of reward cues, as occurred on RC trials. However, these results do not support the idea that anhedonia influences more global effects of incentives that are reflected in either the sustained aspects of brain activation or the behavioral effects of reward context. As we discussed in the introduction, without having positive experiences/expectations of rewards, it may be hard to exert the effort to pursue goal-directed behavior, potentially providing one mechanism by which individual differences in anhedonia may influence behavior.",1
10,22,"Although this study provides crucial insight into one potential neural mechanism underlying anhedonia, it has several limitations that may be answered in future studies. One limitation to this study is that we did not find significant reductions in conflict effects in either accuracy or RT, though we did find a speeding of RT as a function of reward, without a sacrifice in accuracy. Consistent with these behavioral findings, we did not find significant regions displaying interaction effects of reward context and trial type in the target phase, though our analyses were focused on the DLPFC and the basal ganglia. As we discussed above, we cannot exclude a possibility that the difficulty level of present task may not have been optimally adjusted to tap cognitive control among community populations. Future research varying the difficulty level of task performance is needed to understand how engagement of the DLPFC to modulate cognitive control in reward contexts is moderated by the challenge level of the tasks. In summary, the present findings show both sustained context-dependent and transient cue-driven effects of reward on cognitive control thought to be supported by the DLPFC and the basal ganglia. Importantly, self-reported anhedonia trait in healthy adults were associated with transient neural activity during reward predictions implicated in the lateral globus pallidus, but not with sustained DLPFC activity.",1
10,23,"Another major limitation is that, due to the fixed-order presentation of the baseline and reward conditions, the sustained context-dependent effect might have reflected practice-related effects. However, our differences between reward conditions are unlikely to have been due to practice effects, given the previous empirical evidence against this possibility. For example, Chiew and Braver (2013) examined the effect of reward incentives on cognitive control, as measured by the AX-continuous performance task (AX-CPT). Like us, they utilized a mixed block/event design. In the AX-CPT, in which participants perform baseline (no incentive offered) and reward blocks, within the reward blocks, nonincentive trials are randomly intermixed with the incentive trials. In Chiew and Braver’s supplementary analysis, they broke down each block into four 50-trial epochs, and found that potential practice effects disappeared after the first epoch, whereas incentive effects remained throughout. Furthermore, the differences between our RCXT and RC trials cannot be due to practice effects, since these trials were interleaved.",1
10,24,"The present mixed state-item design allowed us to start to dissociate sustained versus transient effects of rewards. However, additional approaches could be used in future studies to further dissociate these effects. In particular, our design did not provide an estimate of the effects of sustained rewards in the absence of transient trial-by-trial effects. Thus, an alternative future design would be to include conditions in which participants were informed that there would be a bonus at the end of a block of trials for overall improved performance, but no trial-specific reward cues. With such a manipulation, one could create a crossed design in which there either was or was not an overall block-wise manipulation of reward bonus (e.g., context effect: high vs. low sustained reward motivation) versus the presence or absence of trial-by-trial cues about the potentially of additional rewards (transient effect: reward cue vs. no-reward cue trials).",1
10,25,"This work was supported by National Institute of Mental Health Grant Number R01-MH066031. All authors have no financial interests or potential conflicts of interest. We thank the members of the Cognitive Control and Psychopathology Laboratory, and all participants in this study who have provided time and effort to make this study possible.",1
11,1,"The current study was a 7-year follow-up of 74 6–12 year old children with Pervasive Developmental Disorder-Not Otherwise Specified. We examined the rates and 7 year stability of comorbid psychiatric diagnoses as ascertained with the Diagnostic Interview Schedule for Children: Parent version at ages 6–12 and again at ages 12–20. Also, we examined childhood factors that predicted the stability of comorbid psychiatric disorders. The rate of comorbid psychiatric disorders dropped significantly from childhood (81 %) to adolescence (61 %). Higher levels of parent reported stereotyped behaviors and reduced social interest in childhood significantly predicted the stability of psychiatric comorbidity. Re-evaluation of psychiatric comorbidity should be considered in clinical practice, since several individuals shifted in comorbid diagnoses.",1
11,3,"Inclusion criteria were: (1) meeting the research criteria for PDD-NOS in childhood (n = 94; De Bruin et al. 2007; Buitelaar et al. 1999), and (2) participation of the parents in the Diagnostic Interview Schedule for Children: Parent version ([DISC-IV-P], Ferdinand and Van der Ende 1998; Shaffer et al. 2000), in childhood (n = 94, wave 1; age 6–12, M = 9.02, SD = 1.81) and 7 years later, in adolescence (n = 74, wave 2; age 12–20, M = 16.00, SD = 1.92). The average follow-up time between the DISC-IV-P at wave 1 and wave 2 was 6.95 years (range 5.58–8.82 year; SD: 0.64).",1
11,4,"The 74 individuals whose parents participated at both wave 1 and wave 2 did not significantly differ in terms of gender, age, nationality, parental nationality, socio-economic status and number of DISC-IV diagnoses from individuals whose parents participated only at wave 1 (n = 94) (p[.05). However, individuals whose parents participated at both wave 1 and wave 2 had significantly higher IQ-scores (M = 92.96, SE = 16.96) versus individuals whose parents only participated at wave 1 [M = 83.94, SE = 16.88; t(86) = -2.01, p = .05].",1
11,5,"The DISC-IV-P (Shaffer et al. 2000) is a structured parent interview determining 1- and 12-month DSM-IV-TR (APA 2000) psychiatric disorders in children and adolescents. Parents were interviewed by phone by trained and certified research assistants. The DISC-IV-P was used to assess internalizing disorders (i.e. anxiety and mood disorders) and externalizing disorders (i.e. disruptive disorders) at wave 1 and 2 and was scored using the internet software (Steenhuis et al. 2009) of the Dutch translation of the DISC-IV-P (Ferdinand and Van der Ende 1998). The anxiety disorder module consists of nine disorders; social phobia (SoPh), separation anxiety disorder (SAD), specific phobia (SP), panic disorder (PD), agoraphobia (AG), generalized anxiety disorder (GAD), selective mutism (SM), obsessive compulsive disorder (OCD) and posttraumatic stress disorder (PTSD). The mood disorder module consists of major depressive episode (MDD), dysthymia, and manic/hypomanic episode. The disruptive behaviors are subdivided in the DISC-IV-P in: ADHD, oppositional defiant disorder (ODD) and CD.",1
11,6,"To examine whether the level and type of parent-rated ASD symptoms in childhood (i.e. wave 1) was associated with the stability of comorbidity, the CSBQ was used. The CSBQ is a parental questionnaire, which contains 49 items about a broad range of features that are typical for ASD (Hartman et al. 2006; Luteijn et al. 1998). The items are scored on a three-point scale (i.e. 0: behavior does not apply; 1: behavior sometimes or somewhat applies; 2: behavior clearly or often applies to the child). The CBSQ consists of six subscales; (1) ‘‘not optimally tuned to the social situation’’, (2) ‘‘reduced contact and social interest’’, (3) ‘‘orientation problems in time, place or activity’’, (4) ‘‘difficulties in understanding social information’’, (5) ‘‘stereotyped behavior’’ and (6) ‘‘fear of and resistance to changes’’. Good test–retest, inter-rater reliability and internal consistency have been reported for this measure (Hartman et al. 2006). Across our sample, internal consistency of CBCQ data was good, with Cronbach’s alpha’s ranging from 0.79 to 0.88.",1
11,7,"To examine whether IQ in childhood (i.e. wave 1) was associated with the stability of comorbidity, the Wechsler Intelligence Scale for Children-Revised (WISC-R; Wechsler 1974) was administered. This instrument comprises a verbal scale (VIQ) and a performance scale (PIQ) together forming a total scale (TIQ). The Dutch version of the WISC-R has been demonstrated to be sufficiently reliable and valid (Van Haasen et al. 1986).",1
11,8,"To assess the use of mental health care and medication between wave 1 and 2, a parent questionnaire was administered at wave 2 (Amone-P’Olak et al. 2010). Eight questions concerned use of mental health care with regard to emotional and/or behavioral problems of the child. These items were scored as 0 (i.e. not used) or 1 (i.e. used). If any of these items was scored 1, the variable ‘mental health care’ was scored 1. Parents were also asked if their child had used psychotropic medication in the past 2 weeks. This variable was also scored as 0 (i.e. not used) or 1 (i.e. used).",1
11,9,"Firstly, the rates of comorbid psychiatric disorders were calculated at wave 1 and wave 2. The significance of putative changes in the prevalence rates was tested using McNemar tests. To investigate the stability of comorbid psychiatric disorders from childhood to adolescence, we made a cross-table of the presence or absence of comorbid disorders at wave 1 and wave 2 (i.e. proportions of individuals in the following groups: 1: ‘‘persistent presence’’, 2: ‘‘from presence to absence’’, 3: ‘‘from absence to presence’’ and 4: ‘‘persistent absence’’). To graphically illustrate whether stability was domain-specific, the number of individuals with either continuous or discontinuous disorders from wave 1 to wave 2 were demonstrated.",1
11,10,"To examine whether gender, age, IQ, level and type of parent-rated ASD symptoms (CSBQ scores), intermediate mental health care and medication were associated with the stability of psychiatric disorders, we compared the group with persistent disorders (n = 38, ‘‘persistent presence’’) with the group that changed from disorder to no disorder (n = 22, ‘‘from presence to absence’’) and the group with persistent absence of disorders (n = 7, ‘‘persistent absence’’) with the group that changed from no disorder to disorder (n = 7, ‘‘from absence to presence’’). Comparisons were performed using t-tests for continuous variables (i.e. IQ, age, CSBQ scores) and Chi Square tests for categorical variables (i.e. gender, mental health care use and the use of psychotropic medication). For the smaller groups ‘‘persistent absence’’ and ‘‘from absence to presence’’, nonparametric testing (i.e. Mann–Whitney U test and Binomial test) was used.",1
11,11,"Figure 1 shows the proportions of individuals in the following groups (1) ‘‘persistent presence’’, (2) ‘‘from presence to absence’’, (3) ‘‘from absence to presence’’ and (4) ‘‘persistent absence’’. Of the individuals who had at least one comorbid psychiatric disorder in childhood (n = 60), 63 % still had at least one comorbid psychiatric disorder in adolescence (n = 38), whereas 37 % of the individuals no longer met criteria for a comorbid psychiatric disorder in adolescence (n = 22). Of the individuals who had no comorbid psychiatric disorder in childhood (n = 14), 50 % (n = 7) stayed free of a comorbid psychiatric disorder in adolescence, whereas 50 % (n = 7) of the individuals developed at least one comorbid psychiatric disorder in adolescence.",1
11,12,"To further clarify this finding, a post hoc test was performed to reveal possible predictors specific for persistent externalizing versus persistent internalizing disorders. In both cases, only parent-reported stereotyped behavior was a significant predictive factor for persistence of the same psychiatric comorbidities [i.e. respectively (t(40) = -2.953, p = .005); (t(39) = -3.287, p = .002)].",1
11,13,"The childhood characteristics of the ‘‘persistent absence’’ group (n = 7) were compared to the ‘‘absent to present’’ group (n = 7) on factors associated with stability of comorbid psychiatric disorders (Table 2). No significant differences were found in age, gender, IQ, level or type of ASD symptomology, intermediate mental health care or use of psychotropic medication.",1
11,14,"The rate of MDD increased slightly from 8 % in childhood to 11 % in adolescence. These rates are in line with those known from the literature, although higher (i.e. 16 %) and much lower rates (i.e. 1 %) have also been reported among individuals with ASD (Leyfer et al. 2006; Simonoff et al. 2008; Mazefsky et al. 2011; Van Steensel et al. 2013; Witwer and Lecavalier 2010). In the general population, also an increase in depression from childhood to adolescence has been found (Maughan et al. 2013), suggesting a similar developmental process.",1
11,15,"The rate of comorbid ADHD decreased from childhood (45 %) to adolescence (39 %). These relatively high rates are in line with previous studies (Goldstein and Schwebach 2004; Leyfer et al. 2006; Mazefsky et al. 2011), although lower rates have also been reported among individuals with ASD (Abdallah et al. 2011; Hanson et al. 2013; Simonoff et al. 2008; Van Steensel et al. 2013). The current study found a decrease for the hyperactivity type of ADHD and the combined type of ADHD in individuals with PDD-NOS from childhood to adolescence, but an increase for the inattentive type of ADHD in adolescence, with 15 new cases in adolescence. This change in the occurrence of ADHD in individuals with PDD-NOS is in line with the suggested trajectory of development of ADHD with hyperactivity at preschool age, more normoactive behavior during the early school years and a tendency to hypoactivity in early adolescence (Gillberg and Billstedt 2000). In adolescence, transition to secondary education increases attentional demands and peer pressures, with the potential to amplify previously unnoticed problems.",1
11,16,"Taken together, the overall prevalence of parent-reported psychiatric comorbidity decreased from childhood to adolescence. Variation in the prevalence of comorbid disorders across different studies may be explained by methodological differences in aspects such as methods of assessment and diagnosis, and how samples were constituted (i.e. differences in levels and types of care in different institutions). Our own data showed no particular transitions from one type of comorbidity to another; only 2 cases shifted from having an internalizing to an externalizing diagnosis, and one from an externalizing to an internalizing one. Although our dataset is limited, cross-domain transitions seem infrequent, and domain stability seems most common",1
11,17,"The current study suggested two predictors of stable psychiatric comorbidity from childhood to adolescence. Children with stable psychiatric comorbidity showed a higher childhood level of parent-reported stereotyped behavior and reduced contact and social interest. Post-hoc analyses also showed that parent-reported stereotyped behaviors were predictive for the persistent presence of either internalizing or externalizing disorders. Thus, our preliminary findings suggest that parent-reported stereotyped behaviors might be an indication for persistent comorbidity. There were no significant predictors for the persistent absence of comorbidity, although there probably was a lack of power to detect these, since these groups were very small. To our knowledge, no previous studies investigated childhood predictors of comorbidity in adolescence, so further research is needed to corroborate our findings.",1
11,19,Our sample of children was diagnosed with PDD-NOS. But one may wonder how these findings apply to individuals diagnosed with ASD using current DSM 5 criteria. The children in our sample also were part of a larger study on phenotypic profiles of children with PDD (Greaves-Lord et al. 2013). This study has found that about 30 % of the sample had a profile more in line with the more recent DSM-5 diagnosis of Social (Pragmatic) Communication Disorder. The reader should interpret our findings against this background.,1
11,20,"Our wave 2 YSR self-report data was used to provide information on adolescents’ internalizing comorbidities through post hoc exploration. Contrary to our expectations we found lower self-reported rates of anxiety rates (15.2 %) than parent-reported DISC-P wave 2 rates (31.1 %). We had expected to see higher self-reported than parent-reported rates of internalizing problems, given that adolescents might not openly share these emotions with their parents. In line with expectations, we found a somewhat higher rate of self-reported depressive symptoms (18.2 %—in the subclinical range) when compared to the parent-reported DISC-P wave 2 rate of 10.8 %. DISC-P data cannot be directly compared to YSR data due to the rather different properties of these instruments, and the lack of comparative research on these two measures. We hope these data provide some background information that helps to broaden the picture from our main analyses. Further research would be needed to profile the longitudinal trajectories of self-reported comorbidities in this group",1
11,21,"The authors thank the children and parents who participated in this project. This research was supported by a grant from the Sophia Foundation for Scientific Research (SSWO; Grant 586, 2009) and a grant from the NutsOhra Foundation (Grant 0803-53).",1
11,22,"CV was responsible for data collection, data analysis, interpretation of the results, and drafted the manuscript. AL, ME, JE, AG, FV, FCV participated in the design of the study, the interpretation of the data and manuscript development. KG participated in the design of the study, data analysis, interpretation of the results, manuscript development and supervised the overall study. All authors read and approved the final version of the manuscript.",1
11,23,"Kirstin Greaves-Lord is second author on the Dutch ADOS-2 manual, for which Yulius receives remuneration. Frank Verhulst is head of the department of Child and Adolescent Psychiatry at Erasmus MC, which publishes ASEBA materials and from which he receives remuneration.",1
11,24,"At wave 1, parents of the participating children signed informed consent forms prior to participation in the study. At wave 2, both parents and adolescents signed the informed consent forms. This study was approved by the local Medical Ethics Committee (MEC-2008-388).",1
12,1,"In two experiments, rats received pairings of the flavor of almond with either fructose or maltodextrin, and the conditioned preference for almond was then tested. In each experiment, half of the rats had received prior exposure to almond on its own, and half had received no preexposure. In Experiment 1, in which the rats were hungry during the test, the preference was greater in the nonpreexposed subjects, both for those trained with fructose and those trained with maltodextrin; that is, latent inhibition was obtained with both reinforcers. In Experiment 2, in which the rats were not food deprived prior to the test, not only was there no latent inhibition with either of the reinforcers, but, for both, the preference was greater for preexposed than for nonpreexposed subjects. These results give no support to the proposal that different types of reinforcer generate different types of learning. They are, however, consistent with the proposal that different types of learning control behavior when a rat is hungry and when it is not, and that the form that generates the preference in the latter case is not susceptible to the latent inhibition effect.",1
12,2,"Prior exposure to the event to be used as the conditioned stimulus (CS) in classical conditioning is usually found to retard acquisition of the conditioned response. This latent inhibition effect is robust and is readily obtained in a wide variety of conditioning procedures (see Lubow, 1989). An exception, however, is the flavor-preference conditioning procedure used in the experiments considered here. In this procedure, subjects (rats, in these experiments) are allowed to consume a neutral or nonpreferred flavor that is presented in compound with a substance of positive motivational value (such as a sucrose solution). After this training, rats given a choice between plain water and water containing the flavor show an increased tendency to consume the latter, an outcome that has been interpreted as an instance of conditioning, with the flavor serving as the CS and sucrose as the unconditioned stimulus (US). Exposure to the CS prior to such conditioning has produced varying results. De la Casa, Márquez, and Lubow (2009) found a reduction in the preference (i.e., latent inhibition), whereas Delamater (2011) found no effect (at least on initial testing; a difference emerged on a further test given after the rats had been given exposure to the US alone).",1
12,3,"A possible interpretation of these findings has come from the suggestion that more than one mechanism can contribute to the preference established with sucrose as the US. Sucrose has both a sweet taste and nutritive postoral consequences, and each of these properties is capable of supporting preference conditioning. A palatable but nonnutritive substance (such as saccharin) will serve as an effective US (e.g., Fanselow & Birk, 1982), a phenomenon referred to as flavor–taste learning. But a preference can also be formed when a nutrient US is delivered by intragastric infusion (e.g., Sclafani, Cardieri, Tucker, Blusk, & Ackroff, 1993), so that its taste properties are irrelevant. We refer to this as flavor– nutrient learning. The implication is that sucrose, when taken orally and subsequently metabolized, supports both forms of learning",1
12,4,"To test this interpretation of the results of Garcia-Burgos et al. (2013), it would be useful to have available procedures that allow for separate examinations of flavor–nutrient and flavor–taste learning. The former would be expected to show latent inhibition; the latter, not. A little information is already available, from experiments using somewhat unorthodox procedures. Weingarten and Kulikovsky (1989) reported results from a study investigating rats’ response to sham-feeding, which they interpreted as supporting the proposal that preexposure to a flavor restricts the learning of an association between the flavor and the postingestive consequences of feeding. In contrast, no latent inhibition was found in a study by Galef and Durlach (1993), in which the training procedure involved allowing the subject rat to interact with another that had recently eaten food with a particular flavor. The enhanced flavor preference induced by this training (taken to reflect an association between the odor of the flavor and other cues produced by the demonstrator rat) was not prevented by preexposure to the flavor. Although these results are suggestive and consistent with the hypothesis under consideration, they come from complex procedures in which a range of factors would be operating, and alternative interpretations might be possible. Accordingly, in the experiments to be reported here, we have made use of the standard preferenceconditioning procedure and have attempted to isolate flavor– taste and flavor–nutrient learning by making use of substances other than sucrose as the USs",1
12,5,"We acknowledge that the effects of these different USs may well be more complex than this. As we have just noted, intragastric fructose can support a degree of preference learning (albeit rather less strong than that produced by sucrose), implying that flavor–nutrient learning will occur to some extent with fructose. and Myers and Sclafani (2001) have demonstrated, using a taste reactivity test, that rats show positive responses to a flavor that has been associated with intragastric infusion of a sugar, implying that flavor–nutrient learning (like flavor–taste learning) may be capable of changing the hedonic response to a flavor. None the less, the strategy of comparing fructose with maltodextrin has been used with some success to address other issues in flavor-preference learning (e.g., Dwyer & Quirk, 2008), and accordingly, we thought it worthwhile to look for latent inhibition in flavorpreference learning in rats trained with either fructose or maltodextrin as the US. Evidence of an effect with the latter but not the former would support the hypotheses (a) that different mechanisms underlie the preferences established by these USs, and (b) that the mechanism engaged by fructose (presumed to be flavor–taste learning) is not susceptible to latent inhibition.",1
12,6,"We created four groups of rats: Two were given preexposure to the almond flavor that was to be used as the CS, and the other groups received only water at this stage. During conditioning, one pair of groups consumed a mixture of almond and fructose, and the other pair a mixture of almond and maltodextrin. In a final test, all subjects were given access to two bottles, one containing the almond solution, and the other, unflavored water. In order to ensure that they would drink the fluids offered, the rats were water deprived throughout training. They had free access to food during preexposure and conditioning, but, given that a preference based on flavor–nutrient learning (such as maltodextrin is likely to produce) may only be fully evident in hungry animals, access to food was denied all subjects prior to the test.",1
12,7,"All of the experimental procedures were approved by the University of Granada Ethics Committee. To initiate the deprivation schedule, the water bottles were removed 24 h before the start of the experiment. The rats were then given three days to accommodate to a deprivation schedule, in which access to water was allowed twice a day for 30 min, at 9:00 a.m. and 1:30 p.m. Rats were randomly allocated to two weight-matched groups—group Pre (n = 16) and group NPre (n = 16)—for the flavor exposure phase. This phase consisted of one single daily trial (at 9:00 a.m.) across eight days. Each trial consisted of 10 min access to 10 ml of either almond (for animals in the Pre condition) or water (for animals in the NPre condition), followed by free access to water for 30 min. An additional 30-min period of access to water was given each day at 1:30 p.m. After the exposure phase, rats were divided into four groups for the conditioning phase, matched on either average almond (groups Pre) or water (groups NPre) consumption during the preexposure phase, Pre/M (n = 8), NPre/M (n = 8), Pre/F (n = 8), and NPre/F (n = 8).",1
